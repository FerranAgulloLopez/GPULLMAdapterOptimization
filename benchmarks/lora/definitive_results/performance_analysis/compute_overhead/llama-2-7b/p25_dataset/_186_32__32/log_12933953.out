WARNING 12-12 10:59:22 _custom_ops.py:14] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
Namespace(backend='openai', base_url=None, host='localhost', port=34448, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_p25.json', model='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=4000, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, request_rate=inf, request_rate_by_lora=None, seed=0, trust_remote_code=False, disable_tqdm=True, save_result=True, metadata=None, result_dir='benchmarks/lora/definitive_results/theory/Sx_multiple/llama-2-7b/p25_dataset/_186_32__32', launch_server=True, server_args='--port=34448 --disable-log-requests --model=/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b --enable-lora --dummy-lora-modules=/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b/lora/yard1_sql-lora-test_dummy_rank_32/ --max-num-seqs=4096 --max-loras=186 --max-lora-rank=32', disable_log_stats=False, disable_loras_users=False, user_lora_request_relation=None, infinite_behaviour=False, restrict_loras=32)
Server started
Requests users. Values: ['0' '1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21'
 '22' '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '4' '5' '6' '7' '8'
 '9']. Counts: [125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125
 125 125 125 125 125 125 125 125 125 125 125 125 125 125]
Requests loras. Values: ['dummy-1' 'dummy-10' 'dummy-11' 'dummy-12' 'dummy-13' 'dummy-14'
 'dummy-15' 'dummy-16' 'dummy-17' 'dummy-18' 'dummy-19' 'dummy-2'
 'dummy-20' 'dummy-21' 'dummy-22' 'dummy-23' 'dummy-24' 'dummy-25'
 'dummy-26' 'dummy-27' 'dummy-28' 'dummy-29' 'dummy-3' 'dummy-30'
 'dummy-31' 'dummy-32' 'dummy-4' 'dummy-5' 'dummy-6' 'dummy-7' 'dummy-8'
 'dummy-9']. Counts: [125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125
 125 125 125 125 125 125 125 125 125 125 125 125 125 125]
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
============ Serving Benchmark Result ============
Successful requests:                     4000      
Benchmark duration (s):                  55.93     
Total input tokens:                      92000     
Total generated tokens:                  108000    
Request throughput (req/s):              71.52     
Input token throughput (tok/s):          1645.04   
Output token throughput (tok/s):         1931.13   
---------------Time to First Token----------------
Mean TTFT (ms):                          30481.43  
Median TTFT (ms):                        31576.62  
P99 TTFT (ms):                           53144.29  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          191.07    
Median TPOT (ms):                        175.43    
P99 TPOT (ms):                           304.25    
---------------Inter-token Latency----------------
Mean ITL (ms):                           190.74    
Median ITL (ms):                         111.67    
P99 ITL (ms):                            1077.92   
==================================================
Concurrent checker terminated
Server terminated
