PYTHONPATH=. python3 benchmarks/lora/deployment/slurm/launcher.py --user bsc98 --queue acc_bsccs --max-duration 00:35:00 --results-path benchmarks/lora/definitive_results/theory/S/llama-2-13b/p25_dataset --default-server-args "{'--disable-log-requests': '', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-13b', '--enable-lora': '', '--max-num-seqs': '4096'}" --default-benchmark-args "{'--disable-loras': '', '--backend': 'openai', '--disable-tqdm': '', '--dataset-path': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_p25.json', '--endpoint': '/v1/completions', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-13b', '--num-prompts': '1000', '--save-result': ''}" --test-server-args "{'--max-loras': ['80', '96', '112'], '--max-lora-rank': ['32']}" --test-benchmark-args "{}"
