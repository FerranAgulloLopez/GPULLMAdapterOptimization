INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.401388802973088,
    "estimated_duration": 3600.0609686999896,
    "input_throughput": 5132.533076702961,
    "output_throughput": 4491.727818109506,
    "total_throughput": 9624.260894812467,
    "itl": 97.55483264379518,
    "ttft": 1394532.430836241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.767824382725951,
    "arrivals": 117840,
    "finished_requests": 74975,
    "scheduler_time": 139.91915980326428
}
#Debug simulation 
Total elapsed time: 11.401575822965242. Arrivals time: 0.2628174096462317 Scheduler time: 10.970088938600384 Scheduler overhead time: 0.056467772054020315 Adapter cache time: 0.029755783907603472 Engine time: 0.05637827794998884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.617380356998183,
    "estimated_duration": 3600.043793397973,
    "input_throughput": 5551.756908250075,
    "output_throughput": 4870.792969840286,
    "total_throughput": 10422.54987809036,
    "itl": 116.0028739764212,
    "ttft": 1266566.2109444113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.476600914630184,
    "arrivals": 116430,
    "finished_requests": 81070,
    "scheduler_time": 126.64836334425449
}
#Debug simulation 
Total elapsed time: 24.617526363988873. Arrivals time: 0.28747906658099964 Scheduler time: 24.181652623345144 Scheduler overhead time: 0.053971884946804494 Adapter cache time: 0.017232098965905607 Engine time: 0.05370622721966356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 23.6975555200479,
    "estimated_duration": 3600.0750148454676,
    "input_throughput": 5397.043650445717,
    "output_throughput": 4739.092082705489,
    "total_throughput": 10136.135733151204,
    "itl": 108.68707953093337,
    "ttft": 1300394.673428712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9896392872463995,
    "arrivals": 116430,
    "finished_requests": 78858,
    "scheduler_time": 130.79395237571484
}
#Debug simulation 
Total elapsed time: 23.69805849401746. Arrivals time: 0.29348408739315346 Scheduler time: 23.244315923249815 Scheduler overhead time: 0.057994687755126506 Adapter cache time: 0.0183929989580065 Engine time: 0.05825181305408478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.128113227023277,
    "estimated_duration": 3600.006918760991,
    "input_throughput": 5125.288483153882,
    "output_throughput": 4492.379421750139,
    "total_throughput": 9617.667904904021,
    "itl": 97.28026381130199,
    "ttft": 1383311.8215421897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.9089726785523995,
    "arrivals": 116430,
    "finished_requests": 74774,
    "scheduler_time": 138.52948988937993
}
#Debug simulation 
Total elapsed time: 13.12826338398736. Arrivals time: 0.2801489353296347 Scheduler time: 12.676082968711853 Scheduler overhead time: 0.06140911468537524 Adapter cache time: 0.02365970949176699 Engine time: 0.059670241840649396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 23.736395276035182,
    "estimated_duration": 3600.016342148508,
    "input_throughput": 5408.61072546675,
    "output_throughput": 4738.601544741621,
    "total_throughput": 10147.21227020837,
    "itl": 108.65091263072286,
    "ttft": 1302547.0816543237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.013144266959272,
    "arrivals": 116430,
    "finished_requests": 78883,
    "scheduler_time": 130.7532506243311
}
#Debug simulation 
Total elapsed time: 23.736554277013056. Arrivals time: 0.3210943664307706 Scheduler time: 23.250428123224992 Scheduler overhead time: 0.06116723868763074 Adapter cache time: 0.019653758325148374 Engine time: 0.05848192749544978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 16.57443219400011,
    "estimated_duration": 3600.0051097231217,
    "input_throughput": 5113.9769080538745,
    "output_throughput": 4491.936957623851,
    "total_throughput": 9605.913865677727,
    "itl": 97.22738870610186,
    "ttft": 1383546.0316739932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4668894004915165,
    "arrivals": 116430,
    "finished_requests": 74653,
    "scheduler_time": 138.66026775013836
}
#Debug simulation 
Total elapsed time: 16.574549991986714. Arrivals time: 0.28686596686020494 Scheduler time: 16.113546359236352 Scheduler overhead time: 0.06302137608872727 Adapter cache time: 0.02174034487688914 Engine time: 0.06166909140301868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.836249943007715,
    "estimated_duration": 3600.0447296044213,
    "input_throughput": 5411.41054159642,
    "output_throughput": 4752.025401051003,
    "total_throughput": 10163.435942647424,
    "itl": 109.21671045003721,
    "ttft": 1298845.407262714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.839012072952441,
    "arrivals": 116430,
    "finished_requests": 79041,
    "scheduler_time": 130.4190119346945
}
#Debug simulation 
Total elapsed time: 24.836347028031014. Arrivals time: 0.3035806704428978 Scheduler time: 24.36794396303594 Scheduler overhead time: 0.06042295607039705 Adapter cache time: 0.019936679513193667 Engine time: 0.058772033371496946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.493478451971896,
    "estimated_duration": 3600.10209656109,
    "input_throughput": 5119.530087106586,
    "output_throughput": 4487.4502352119225,
    "total_throughput": 9606.980322318508,
    "itl": 96.96373442797722,
    "ttft": 1388027.4182095171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.130602292120479,
    "arrivals": 116430,
    "finished_requests": 74643,
    "scheduler_time": 138.8649446566956
}
#Debug simulation 
Total elapsed time: 13.493667803995777. Arrivals time: 0.27903559507103637 Scheduler time: 13.044123218161985 Scheduler overhead time: 0.06092696788255125 Adapter cache time: 0.022356325411237776 Engine time: 0.05988018371863291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.99277670599986,
    "estimated_duration": 3600.0316219238757,
    "input_throughput": 5577.993781418129,
    "output_throughput": 4872.356646308065,
    "total_throughput": 10450.350427726195,
    "itl": 116.5685542851735,
    "ttft": 1229394.7529018847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1078322450165037,
    "arrivals": 115680,
    "finished_requests": 81418,
    "scheduler_time": 125.23653025335548
}
#Debug simulation 
Total elapsed time: 27.992938493960537. Arrivals time: 0.3228346679243259 Scheduler time: 27.507135661377106 Scheduler overhead time: 0.0624076560488902 Adapter cache time: 0.016321913106366992 Engine time: 0.05904413614189252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 27.410336875997018,
    "estimated_duration": 3600.06577887591,
    "input_throughput": 5435.070413104926,
    "output_throughput": 4755.383110067916,
    "total_throughput": 10190.453523172842,
    "itl": 109.44502356301822,
    "ttft": 1292454.5873403272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.064763877177617,
    "arrivals": 115680,
    "finished_requests": 79285,
    "scheduler_time": 129.05853415566716
}
#Debug simulation 
Total elapsed time: 27.410453952034004. Arrivals time: 0.31974699086276814 Scheduler time: 26.92484535771655 Scheduler overhead time: 0.062152613361831754 Adapter cache time: 0.017579181934706867 Engine time: 0.05979689542436972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.858888907008804,
    "estimated_duration": 3600.0151557124013,
    "input_throughput": 5133.905608889749,
    "output_throughput": 4494.567744895525,
    "total_throughput": 9628.473353785274,
    "itl": 97.42825959456951,
    "ttft": 1372596.6480488814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.450813261247255,
    "arrivals": 115680,
    "finished_requests": 74896,
    "scheduler_time": 137.2223936886717
}
#Debug simulation 
Total elapsed time: 13.858977868047077. Arrivals time: 0.2836543705780059 Scheduler time: 13.404149022127967 Scheduler overhead time: 0.061262061120942235 Adapter cache time: 0.02254428790183738 Engine time: 0.060011162946466357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 27.257223285967484,
    "estimated_duration": 3600.061778161414,
    "input_throughput": 5435.1381186555545,
    "output_throughput": 4756.831703245338,
    "total_throughput": 10191.969821900893,
    "itl": 109.40438105505042,
    "ttft": 1291927.3646135614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.807111960067408,
    "arrivals": 115680,
    "finished_requests": 79292,
    "scheduler_time": 129.08276303253632
}
#Debug simulation 
Total elapsed time: 27.257328889972996. Arrivals time: 0.3127390968147665 Scheduler time: 26.777983162959572 Scheduler overhead time: 0.06255871790926903 Adapter cache time: 0.017470608523581177 Engine time: 0.060314604721497744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.338415313977748,
    "estimated_duration": 3600.103213403206,
    "input_throughput": 5139.670421423458,
    "output_throughput": 4500.439303984309,
    "total_throughput": 9640.109725407767,
    "itl": 97.31535514879964,
    "ttft": 1369726.9662253277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 999,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.401307407743313,
    "arrivals": 115680,
    "finished_requests": 75009,
    "scheduler_time": 137.49619515883188
}
#Debug simulation 
Total elapsed time: 14.338542916986626. Arrivals time: 0.2884324180195108 Scheduler time: 13.876705115952063 Scheduler overhead time: 0.0616818445851095 Adapter cache time: 0.023602750210557133 Engine time: 0.06083889969158918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.678582410037052,
    "estimated_duration": 3600.0051720325855,
    "input_throughput": 5435.619968554555,
    "output_throughput": 4756.364833312804,
    "total_throughput": 10191.98480186736,
    "itl": 109.27705998637242,
    "ttft": 1292151.978305112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.54307612201663,
    "arrivals": 115680,
    "finished_requests": 79298,
    "scheduler_time": 129.269814191798
}
#Debug simulation 
Total elapsed time: 27.67872091103345. Arrivals time: 0.31432787323137745 Scheduler time: 27.198369962337893 Scheduler overhead time: 0.062046779959928244 Adapter cache time: 0.0173812696011737 Engine time: 0.06063402397558093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.352358230040409,
    "estimated_duration": 3600.0985459450562,
    "input_throughput": 5136.203291109076,
    "output_throughput": 4500.046260746788,
    "total_throughput": 9636.249551855864,
    "itl": 97.41699811309721,
    "ttft": 1370383.6238760059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.508613050896692,
    "arrivals": 115680,
    "finished_requests": 74952,
    "scheduler_time": 137.3504660369152
}
#Debug simulation 
Total elapsed time: 13.352443879004568. Arrivals time: 0.27951869601383805 Scheduler time: 12.901101764000487 Scheduler overhead time: 0.06151752115692943 Adapter cache time: 0.023126799263991416 Engine time: 0.059776631474960595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.089139623043593,
    "estimated_duration": 3600.022706611708,
    "input_throughput": 5670.05340341639,
    "output_throughput": 4912.03651785947,
    "total_throughput": 10582.08992127586,
    "itl": 115.5907977119224,
    "ttft": 1187502.7110052148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.816886247610697,
    "arrivals": 109355,
    "finished_requests": 82130,
    "scheduler_time": 116.75694659442532
}
#Debug simulation 
Total elapsed time: 27.08932835503947. Arrivals time: 0.33323937508976087 Scheduler time: 26.594445235386956 Scheduler overhead time: 0.061532364634331316 Adapter cache time: 0.015418387192767113 Engine time: 0.05895273888017982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 26.137080378015526,
    "estimated_duration": 3600.0197172373787,
    "input_throughput": 5489.658544194265,
    "output_throughput": 4754.291460696306,
    "total_throughput": 10243.950004890572,
    "itl": 108.14169690473298,
    "ttft": 1215499.1084515466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1315686189523007,
    "arrivals": 109355,
    "finished_requests": 79469,
    "scheduler_time": 121.74670156773944
}
#Debug simulation 
Total elapsed time: 26.137218348041642. Arrivals time: 0.33136336045572534 Scheduler time: 25.636398998263758 Scheduler overhead time: 0.06421880965353921 Adapter cache time: 0.016363966336939484 Engine time: 0.062111349252518266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 19.036856662016362,
    "estimated_duration": 3600.061702754128,
    "input_throughput": 5186.1494445266535,
    "output_throughput": 4492.360224722666,
    "total_throughput": 9678.50966924932,
    "itl": 96.56374919239295,
    "ttft": 1321137.1400986814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.884870166769281,
    "arrivals": 109355,
    "finished_requests": 75029,
    "scheduler_time": 131.02924140410954
}
#Debug simulation 
Total elapsed time: 19.036996132985223. Arrivals time: 0.2957635471248068 Scheduler time: 18.565421140752733 Scheduler overhead time: 0.06374207860790193 Adapter cache time: 0.021156182512640953 Engine time: 0.06285255454713479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 26.968531983031426,
    "estimated_duration": 3600.0868720609683,
    "input_throughput": 5497.827608995766,
    "output_throughput": 4758.691556293609,
    "total_throughput": 10256.519165289375,
    "itl": 108.64379213751073,
    "ttft": 1227030.657581768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.790811924207949,
    "arrivals": 109355,
    "finished_requests": 79589,
    "scheduler_time": 121.37670553394332
}
#Debug simulation 
Total elapsed time: 26.968627876020037. Arrivals time: 0.321733413846232 Scheduler time: 26.475903011334594 Scheduler overhead time: 0.06307614006800577 Adapter cache time: 0.020171551790554076 Engine time: 0.06127142737386748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 15.81042575801257,
    "estimated_duration": 3600.061353079685,
    "input_throughput": 5174.590700812332,
    "output_throughput": 4486.709368489609,
    "total_throughput": 9661.30006930194,
    "itl": 96.22511640583626,
    "ttft": 1323618.4571967665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 813,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.0459591444814835,
    "arrivals": 109355,
    "finished_requests": 74903,
    "scheduler_time": 131.2535438074494
}
#Debug simulation 
Total elapsed time: 15.810536589007825. Arrivals time: 0.295273122494109 Scheduler time: 15.340740052459296 Scheduler overhead time: 0.06329354294575751 Adapter cache time: 0.02163199009373784 Engine time: 0.06165826629148796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 23.167009167023934,
    "estimated_duration": 3600.091550619668,
    "input_throughput": 5491.968668573665,
    "output_throughput": 4767.370151196797,
    "total_throughput": 10259.338819770463,
    "itl": 108.45360997745924,
    "ttft": 1226300.7233570253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9238357907812915,
    "arrivals": 109355,
    "finished_requests": 79559,
    "scheduler_time": 121.54164328063875
}
#Debug simulation 
Total elapsed time: 23.167175006994512. Arrivals time: 0.3221001874189824 Scheduler time: 22.678802222537342 Scheduler overhead time: 0.06286088295746595 Adapter cache time: 0.016008550534024835 Engine time: 0.061239610658958554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.395036319969222,
    "estimated_duration": 3600.0242855243346,
    "input_throughput": 5183.687530952868,
    "output_throughput": 4494.496069112873,
    "total_throughput": 9678.18360006574,
    "itl": 96.50584007543213,
    "ttft": 1320772.7216123417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.793058684989839,
    "arrivals": 109355,
    "finished_requests": 75100,
    "scheduler_time": 130.96393963179108
}
#Debug simulation 
Total elapsed time: 15.395131746015977. Arrivals time: 0.2863416077452712 Scheduler time: 14.937095344939735 Scheduler overhead time: 0.06267961580306292 Adapter cache time: 0.020965471805538982 Engine time: 0.06055435462621972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.7341996760224,
    "estimated_duration": 3600.1100408478596,
    "input_throughput": 5613.906178056767,
    "output_throughput": 4909.935474038195,
    "total_throughput": 10523.841652094961,
    "itl": 116.26414225040894,
    "ttft": 1085307.206933783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.466428568917339,
    "arrivals": 106484,
    "finished_requests": 81975,
    "scheduler_time": 111.12462215367093
}
#Debug simulation 
Total elapsed time: 25.734320871997625. Arrivals time: 0.32052016648231074 Scheduler time: 25.253474437980913 Scheduler overhead time: 0.061223848548252136 Adapter cache time: 0.014618090237490833 Engine time: 0.05885467177722603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.949242033995688,
    "estimated_duration": 3600.0418865438733,
    "input_throughput": 5483.7281404390715,
    "output_throughput": 4777.239693872214,
    "total_throughput": 10260.967834311285,
    "itl": 108.92801950287755,
    "ttft": 1204560.3591330599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.603260927256204,
    "arrivals": 106484,
    "finished_requests": 79859,
    "scheduler_time": 116.15663776877615
}
#Debug simulation 
Total elapsed time: 22.949456857983023. Arrivals time: 0.3116331580094993 Scheduler time: 22.47182412503753 Scheduler overhead time: 0.061522129573859274 Adapter cache time: 0.018516873940825462 Engine time: 0.05956544599030167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.38521249697078,
    "estimated_duration": 3600.076001010439,
    "input_throughput": 5176.977929012882,
    "output_throughput": 4513.2083310018115,
    "total_throughput": 9690.186260014694,
    "itl": 97.1394822273703,
    "ttft": 1291671.1067667974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.158223910806719,
    "arrivals": 106484,
    "finished_requests": 75420,
    "scheduler_time": 126.09344310489608
}
#Debug simulation 
Total elapsed time: 14.385354030993767. Arrivals time: 0.2831282446277328 Scheduler time: 13.9271739841206 Scheduler overhead time: 0.06235497246962041 Adapter cache time: 0.02323344920296222 Engine time: 0.061631890188436955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 22.309284486982506,
    "estimated_duration": 3600.060020028023,
    "input_throughput": 5485.686319153722,
    "output_throughput": 4778.245613767878,
    "total_throughput": 10263.931932921601,
    "itl": 109.07429782378182,
    "ttft": 1189616.813184801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.617964159902177,
    "arrivals": 106484,
    "finished_requests": 79908,
    "scheduler_time": 116.00433449284625
}
#Debug simulation 
Total elapsed time: 22.309402652957942. Arrivals time: 0.2998643965111114 Scheduler time: 21.842596160655376 Scheduler overhead time: 0.06093252496793866 Adapter cache time: 0.02104180509923026 Engine time: 0.058960396505426615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.247260881005786,
    "estimated_duration": 3600.106265414336,
    "input_throughput": 5168.2452206334,
    "output_throughput": 4505.6253355158,
    "total_throughput": 9673.870556149199,
    "itl": 97.31073961161283,
    "ttft": 1293032.6189382055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.452123674107538,
    "arrivals": 106484,
    "finished_requests": 75296,
    "scheduler_time": 125.97244761239826
}
#Debug simulation 
Total elapsed time: 11.24734682199778. Arrivals time: 0.2692381870583631 Scheduler time: 10.799943773134146 Scheduler overhead time: 0.060012239147908986 Adapter cache time: 0.03163642412982881 Engine time: 0.05935194226913154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 23.614820681978017,
    "estimated_duration": 3600.084594429685,
    "input_throughput": 5474.518301735129,
    "output_throughput": 4772.7622919155265,
    "total_throughput": 10247.280593650656,
    "itl": 108.58853882652593,
    "ttft": 1206089.2990767793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2174961540475344,
    "arrivals": 106484,
    "finished_requests": 79748,
    "scheduler_time": 116.37612345445444
}
#Debug simulation 
Total elapsed time: 23.614929540955927. Arrivals time: 0.31190756807336584 Scheduler time: 23.13620012573665 Scheduler overhead time: 0.06301666534272954 Adapter cache time: 0.017012038209941238 Engine time: 0.060816810524556786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.387564065982588,
    "estimated_duration": 3600.069548094871,
    "input_throughput": 5176.790823350191,
    "output_throughput": 4517.174399757305,
    "total_throughput": 9693.965223107496,
    "itl": 97.11461490377998,
    "ttft": 1291910.6761214426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.8061537290551035,
    "arrivals": 106484,
    "finished_requests": 75454,
    "scheduler_time": 126.23321836953933
}
#Debug simulation 
Total elapsed time: 15.38769586395938. Arrivals time: 0.2907696614274755 Scheduler time: 14.922615140036214 Scheduler overhead time: 0.06340122851543128 Adapter cache time: 0.021360391401685774 Engine time: 0.061838313937187195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 34.55467725195922,
    "estimated_duration": 3600.0484492920205,
    "input_throughput": 5654.4689013847155,
    "output_throughput": 4908.2972767977535,
    "total_throughput": 10562.76617818247,
    "itl": 115.70647606865779,
    "ttft": 1073134.0479371771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.684638066971694,
    "arrivals": 105023,
    "finished_requests": 81881,
    "scheduler_time": 108.34073167986662
}
#Debug simulation 
Total elapsed time: 34.55481850396609. Arrivals time: 0.3220172751462087 Scheduler time: 34.06208416633308 Scheduler overhead time: 0.06548064324306324 Adapter cache time: 0.015832562115974724 Engine time: 0.06294728227658197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 21.425372739031445,
    "estimated_duration": 3600.0508867475132,
    "input_throughput": 5500.95335399322,
    "output_throughput": 4774.078350744544,
    "total_throughput": 10275.031704737765,
    "itl": 108.20891507036117,
    "ttft": 1152741.3055339062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7940423684660383,
    "arrivals": 105023,
    "finished_requests": 79720,
    "scheduler_time": 113.57492082458347
}
#Debug simulation 
Total elapsed time: 21.42546715104254. Arrivals time: 0.31132065429119393 Scheduler time: 20.948207173205446 Scheduler overhead time: 0.06310025416314602 Adapter cache time: 0.015228320378810167 Engine time: 0.061097722966223955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.392664243991021,
    "estimated_duration": 3600.107358063446,
    "input_throughput": 5196.249205763357,
    "output_throughput": 4509.263859490133,
    "total_throughput": 9705.51306525349,
    "itl": 96.27154507990835,
    "ttft": 1284432.9425820757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.436666754363128,
    "arrivals": 105023,
    "finished_requests": 75182,
    "scheduler_time": 124.44620335715601
}
#Debug simulation 
Total elapsed time: 15.392829479009379. Arrivals time: 0.29248227598145604 Scheduler time: 14.921350437914953 Scheduler overhead time: 0.06502739974530414 Adapter cache time: 0.022263252816628665 Engine time: 0.06333460815949365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 20.995940769964363,
    "estimated_duration": 3600.1117630768545,
    "input_throughput": 5507.9801142208835,
    "output_throughput": 4782.899013469436,
    "total_throughput": 10290.87912769032,
    "itl": 108.4647779350393,
    "ttft": 1144570.504351734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3176845429651403,
    "arrivals": 105023,
    "finished_requests": 79858,
    "scheduler_time": 113.35726551892647
}
#Debug simulation 
Total elapsed time: 20.996059885947034. Arrivals time: 0.3060122837778181 Scheduler time: 20.528208265372086 Scheduler overhead time: 0.061706866428721696 Adapter cache time: 0.014257035742048174 Engine time: 0.05974390235496685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 15.13760729599744,
    "estimated_duration": 3600.08951793315,
    "input_throughput": 5202.583409857252,
    "output_throughput": 4517.320449669436,
    "total_throughput": 9719.903859526688,
    "itl": 96.45986254569868,
    "ttft": 1282930.5548797883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 868,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.430283445990666,
    "arrivals": 105023,
    "finished_requests": 75291,
    "scheduler_time": 124.36459155547395
}
#Debug simulation 
Total elapsed time: 15.137693583033979. Arrivals time: 0.2870550623629242 Scheduler time: 14.675317829183768 Scheduler overhead time: 0.06362001656088978 Adapter cache time: 0.022249474481213838 Engine time: 0.06146770529448986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 23.901770900993142,
    "estimated_duration": 3600.00531522508,
    "input_throughput": 5503.264096920181,
    "output_throughput": 4780.7134970643665,
    "total_throughput": 10283.977593984548,
    "itl": 108.44138968174677,
    "ttft": 1166389.3779814614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.547184455287632,
    "arrivals": 105023,
    "finished_requests": 79753,
    "scheduler_time": 113.36083098736033
}
#Debug simulation 
Total elapsed time: 23.901866732980125. Arrivals time: 0.32013342779828236 Scheduler time: 23.4143915263121 Scheduler overhead time: 0.06393076240783557 Adapter cache time: 0.015506689727772027 Engine time: 0.0612420886172913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.718012316036038,
    "estimated_duration": 3600.072988181739,
    "input_throughput": 5189.8358898096885,
    "output_throughput": 4507.94665921388,
    "total_throughput": 9697.782549023568,
    "itl": 96.42166589691811,
    "ttft": 1280621.0919369669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.721096900105505,
    "arrivals": 105023,
    "finished_requests": 75118,
    "scheduler_time": 124.47232526835911
}
#Debug simulation 
Total elapsed time: 12.718123695987742. Arrivals time: 0.2857117866515182 Scheduler time: 12.262901349633466 Scheduler overhead time: 0.06121748947771266 Adapter cache time: 0.02043632132699713 Engine time: 0.06029467179905623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 21.083450336009264,
    "estimated_duration": 3600.0740767105044,
    "input_throughput": 5662.355986470782,
    "output_throughput": 4905.65461256762,
    "total_throughput": 10568.010599038402,
    "itl": 115.49477176670445,
    "ttft": 1038251.5763706126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9491344282497,
    "arrivals": 104293,
    "finished_requests": 82275,
    "scheduler_time": 106.89562643613847
}
#Debug simulation 
Total elapsed time: 21.083597054006532. Arrivals time: 0.30583467765245587 Scheduler time: 20.61972166033229 Scheduler overhead time: 0.060678832116536796 Adapter cache time: 0.01521657215198502 Engine time: 0.05727603274863213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.462297946971375,
    "estimated_duration": 3600.11143794942,
    "input_throughput": 5509.672503720613,
    "output_throughput": 4775.777721423288,
    "total_throughput": 10285.450225143903,
    "itl": 108.14460810286734,
    "ttft": 1121731.8974343562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.254534668601122,
    "arrivals": 104293,
    "finished_requests": 80060,
    "scheduler_time": 111.96058974354256
}
#Debug simulation 
Total elapsed time: 18.462429790000897. Arrivals time: 0.29818471847102046 Scheduler time: 18.00278515566606 Scheduler overhead time: 0.060906562372110784 Adapter cache time: 0.015543907473329455 Engine time: 0.059128154010977596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.44407362997299,
    "estimated_duration": 3600.1065316110485,
    "input_throughput": 5210.048879194238,
    "output_throughput": 4518.917664561389,
    "total_throughput": 9728.966543755627,
    "itl": 96.50302506454251,
    "ttft": 1268952.9769752633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.407780073657656,
    "arrivals": 104293,
    "finished_requests": 75688,
    "scheduler_time": 122.66068095877473
}
#Debug simulation 
Total elapsed time: 12.444162922969554. Arrivals time: 0.28039724309928715 Scheduler time: 11.992256249766797 Scheduler overhead time: 0.061895128805190325 Adapter cache time: 0.021608781709801406 Engine time: 0.06040930550079793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 17.562695056025404,
    "estimated_duration": 3600.1001706746797,
    "input_throughput": 5502.453559865143,
    "output_throughput": 4774.937136479301,
    "total_throughput": 10277.390696344444,
    "itl": 108.29343581869081,
    "ttft": 1126621.4426226548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2736295653227674,
    "arrivals": 104293,
    "finished_requests": 80014,
    "scheduler_time": 111.88329326663964
}
#Debug simulation 
Total elapsed time: 17.562877568008844. Arrivals time: 0.2942499350756407 Scheduler time: 17.107044200005475 Scheduler overhead time: 0.060591947578359395 Adapter cache time: 0.01613670855294913 Engine time: 0.05901733849896118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.040880709944759,
    "estimated_duration": 3600.042423965769,
    "input_throughput": 5197.71291455701,
    "output_throughput": 4511.276281602626,
    "total_throughput": 9708.989196159637,
    "itl": 96.20091693880009,
    "ttft": 1270943.9344095343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.203591330037477,
    "arrivals": 104293,
    "finished_requests": 75527,
    "scheduler_time": 123.00403192771712
}
#Debug simulation 
Total elapsed time: 13.040968399960548. Arrivals time: 0.28035922668641433 Scheduler time: 12.586906732816715 Scheduler overhead time: 0.062427337223198265 Adapter cache time: 0.02184639748884365 Engine time: 0.06166931288316846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 18.1198129770346,
    "estimated_duration": 3600.086859740208,
    "input_throughput": 5498.389836468678,
    "output_throughput": 4770.152407166989,
    "total_throughput": 10268.542243635668,
    "itl": 108.04769898923557,
    "ttft": 1134204.9870096599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.211112233106964,
    "arrivals": 104293,
    "finished_requests": 79908,
    "scheduler_time": 112.12849426264025
}
#Debug simulation 
Total elapsed time: 18.119915103015956. Arrivals time: 0.29348564631072804 Scheduler time: 17.66563662979752 Scheduler overhead time: 0.05973192164674401 Adapter cache time: 0.016538598749320954 Engine time: 0.05875814863247797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.30168783798581,
    "estimated_duration": 3600.049748364585,
    "input_throughput": 5203.991419427102,
    "output_throughput": 4513.205687610557,
    "total_throughput": 9717.19710703766,
    "itl": 96.43376193221224,
    "ttft": 1271084.627046408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.450526979081351,
    "arrivals": 104293,
    "finished_requests": 75623,
    "scheduler_time": 122.86217479499923
}
#Debug simulation 
Total elapsed time: 11.301771321974229. Arrivals time: 0.2699044236796908 Scheduler time: 10.859862884739414 Scheduler overhead time: 0.06085260509280488 Adapter cache time: 0.02378629252780229 Engine time: 0.05984116205945611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 18.525944031018298,
    "estimated_duration": 3600.1340029848056,
    "input_throughput": 5671.662494526923,
    "output_throughput": 4912.228540753747,
    "total_throughput": 10583.89103528067,
    "itl": 115.35443083003776,
    "ttft": 923975.096742743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9623592463136004,
    "arrivals": 100777,
    "finished_requests": 82007,
    "scheduler_time": 101.48035343374957
}
#Debug simulation 
Total elapsed time: 18.526057220005896. Arrivals time: 0.2884792425320484 Scheduler time: 18.084747957414947 Scheduler overhead time: 0.057348354428540915 Adapter cache time: 0.01501753181219101 Engine time: 0.055757082358468324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.558789093978703,
    "estimated_duration": 3600.037047675054,
    "input_throughput": 5523.262048883993,
    "output_throughput": 4781.024965039075,
    "total_throughput": 10304.287013923067,
    "itl": 108.29384789803869,
    "ttft": 1028467.2102783928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7383433944778566,
    "arrivals": 100777,
    "finished_requests": 79841,
    "scheduler_time": 105.93836344461103
}
#Debug simulation 
Total elapsed time: 17.558899407973513. Arrivals time: 0.2913527225609869 Scheduler time: 17.1069829397602 Scheduler overhead time: 0.059888035990297794 Adapter cache time: 0.016270077612716705 Engine time: 0.05832934787031263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.164509102003649,
    "estimated_duration": 3600.102579367476,
    "input_throughput": 5211.944545007014,
    "output_throughput": 4519.134286128719,
    "total_throughput": 9731.078831135734,
    "itl": 96.25963064757035,
    "ttft": 1230850.638681617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.300138299078709,
    "arrivals": 100777,
    "finished_requests": 75381,
    "scheduler_time": 117.01629825175286
}
#Debug simulation 
Total elapsed time: 15.164610398991499. Arrivals time: 0.2870696563622914 Scheduler time: 14.70200323825702 Scheduler overhead time: 0.0646466591861099 Adapter cache time: 0.020128262520302087 Engine time: 0.0625030646333471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 17.153521840984467,
    "estimated_duration": 3600.0156048358435,
    "input_throughput": 5531.887687722425,
    "output_throughput": 4791.759507049858,
    "total_throughput": 10323.647194772284,
    "itl": 108.17988919246969,
    "ttft": 1017282.7684674781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.128461457784283,
    "arrivals": 100777,
    "finished_requests": 80004,
    "scheduler_time": 105.93681382684781
}
#Debug simulation 
Total elapsed time: 17.153652184992097. Arrivals time: 0.2904914458631538 Scheduler time: 16.704451234953012 Scheduler overhead time: 0.05964649678207934 Adapter cache time: 0.01566682494012639 Engine time: 0.057732764806132764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.006166971987113,
    "estimated_duration": 3600.079307695888,
    "input_throughput": 5215.577045722716,
    "output_throughput": 4517.191875533463,
    "total_throughput": 9732.76892125618,
    "itl": 96.3750228771997,
    "ttft": 1234722.997597027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.930273409150563,
    "arrivals": 100777,
    "finished_requests": 75340,
    "scheduler_time": 116.75326320594864
}
#Debug simulation 
Total elapsed time: 13.00630710402038. Arrivals time: 0.28384687699144706 Scheduler time: 12.54721560399048 Scheduler overhead time: 0.06281716260127723 Adapter cache time: 0.02276695577893406 Engine time: 0.06155597744509578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 15.788831639976706,
    "estimated_duration": 3600.075911795041,
    "input_throughput": 5516.2711805424315,
    "output_throughput": 4781.283901154573,
    "total_throughput": 10297.555081697004,
    "itl": 107.95951107474876,
    "ttft": 1027326.5774335689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3962459403835084,
    "arrivals": 100777,
    "finished_requests": 79830,
    "scheduler_time": 106.16978499787167
}
#Debug simulation 
Total elapsed time: 15.788974504976068. Arrivals time: 0.2794317485531792 Scheduler time: 15.351907845353708 Scheduler overhead time: 0.058171781594865024 Adapter cache time: 0.017076805350370705 Engine time: 0.05689998291200027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.105956676998176,
    "estimated_duration": 3600.02728258774,
    "input_throughput": 5209.165522356829,
    "output_throughput": 4515.621056158981,
    "total_throughput": 9724.78657851581,
    "itl": 96.40536273990661,
    "ttft": 1236418.569443272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.799024601522855,
    "arrivals": 100777,
    "finished_requests": 75273,
    "scheduler_time": 116.6917381152258
}
#Debug simulation 
Total elapsed time: 13.106079947028775. Arrivals time: 0.27921040396904573 Scheduler time: 12.652108288020827 Scheduler overhead time: 0.06291542120743543 Adapter cache time: 0.022716562845744193 Engine time: 0.061307855241466314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.35358236799948,
    "estimated_duration": 3600.0508808003638,
    "input_throughput": 5701.409418812658,
    "output_throughput": 4931.231137503596,
    "total_throughput": 10632.640556316253,
    "itl": 115.71496032858333,
    "ttft": 787223.1931069416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4282803509011848,
    "arrivals": 99385,
    "finished_requests": 82633,
    "scheduler_time": 96.87970392182292
}
#Debug simulation 
Total elapsed time: 25.353678187006153. Arrivals time: 0.3024895320413634 Scheduler time: 24.892472620354965 Scheduler overhead time: 0.060887298022862524 Adapter cache time: 0.012958431267179549 Engine time: 0.058922601863741875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.611083588039037,
    "estimated_duration": 3600.016479264174,
    "input_throughput": 5542.890460345505,
    "output_throughput": 4790.000851197383,
    "total_throughput": 10332.891311542888,
    "itl": 108.00882755269683,
    "ttft": 938706.3107295863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.773039441127335,
    "arrivals": 99385,
    "finished_requests": 80287,
    "scheduler_time": 101.27211986836242
}
#Debug simulation 
Total elapsed time: 14.611181685992051. Arrivals time: 0.28230204730061814 Scheduler time: 14.17270616197493 Scheduler overhead time: 0.057914311066269875 Adapter cache time: 0.016224607301410288 Engine time: 0.056615618930663913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.560195682977792,
    "estimated_duration": 3600.0557208215173,
    "input_throughput": 5223.133322977875,
    "output_throughput": 4521.835288784151,
    "total_throughput": 9744.968611762026,
    "itl": 96.05904173143924,
    "ttft": 1151944.1229461015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.867009213627344,
    "arrivals": 99385,
    "finished_requests": 75722,
    "scheduler_time": 111.71794117384547
}
#Debug simulation 
Total elapsed time: 11.560316973016597. Arrivals time: 0.26555705117061734 Scheduler time: 11.124453450203873 Scheduler overhead time: 0.06146496970904991 Adapter cache time: 0.020615055167581886 Engine time: 0.06053403147961944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 14.581496390979737,
    "estimated_duration": 3600.0520606687983,
    "input_throughput": 5545.688968812038,
    "output_throughput": 4791.914036041794,
    "total_throughput": 10337.603004853832,
    "itl": 108.20747176558557,
    "ttft": 944183.7935256653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.360303301559755,
    "arrivals": 99385,
    "finished_requests": 80318,
    "scheduler_time": 101.13942576552864
}
#Debug simulation 
Total elapsed time: 14.581604606995825. Arrivals time: 0.2778618241427466 Scheduler time: 14.14567194430856 Scheduler overhead time: 0.05794861412141472 Adapter cache time: 0.017970371758565307 Engine time: 0.05660382431233302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 12.605632223014254,
    "estimated_duration": 3600.035879514317,
    "input_throughput": 5220.71574534852,
    "output_throughput": 4514.2347309584275,
    "total_throughput": 9734.950476306947,
    "itl": 95.86071391315855,
    "ttft": 1165751.2512703994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.179004455073762,
    "arrivals": 99385,
    "finished_requests": 75612,
    "scheduler_time": 111.886439435882
}
#Debug simulation 
Total elapsed time: 12.605741090024821. Arrivals time: 0.2748671706649475 Scheduler time: 12.158954519254621 Scheduler overhead time: 0.06196381489280611 Adapter cache time: 0.02138824894791469 Engine time: 0.06082652596523985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 14.58371817599982,
    "estimated_duration": 3600.039053725453,
    "input_throughput": 5538.350196331103,
    "output_throughput": 4789.166657000063,
    "total_throughput": 10327.516853331166,
    "itl": 108.09073376246194,
    "ttft": 944438.1758310691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.504772596373207,
    "arrivals": 99385,
    "finished_requests": 80263,
    "scheduler_time": 101.42232599723297
}
#Debug simulation 
Total elapsed time: 14.583878663019277. Arrivals time: 0.2746706092148088 Scheduler time: 14.152785089740064 Scheduler overhead time: 0.057679848512634635 Adapter cache time: 0.016621577145997435 Engine time: 0.056714344827923924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.039115526014939,
    "estimated_duration": 3600.062178882533,
    "input_throughput": 5233.190168356458,
    "output_throughput": 4524.327411771479,
    "total_throughput": 9757.517580127937,
    "itl": 96.30732589609019,
    "ttft": 1158228.3505382244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.71216522203761,
    "arrivals": 99385,
    "finished_requests": 75785,
    "scheduler_time": 111.40913530681041
}
#Debug simulation 
Total elapsed time: 12.039234159048647. Arrivals time: 0.2754453407251276 Scheduler time: 11.59043059736723 Scheduler overhead time: 0.06273870432050899 Adapter cache time: 0.022437299601733685 Engine time: 0.06019462883705273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.548093063000124,
    "estimated_duration": 3600.0641575407767,
    "input_throughput": 5719.452237224964,
    "output_throughput": 4938.921980808785,
    "total_throughput": 10658.374218033749,
    "itl": 115.78134625724091,
    "ttft": 736583.4430884836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4216679418692348,
    "arrivals": 98651,
    "finished_requests": 82909,
    "scheduler_time": 94.54942947761627
}
#Debug simulation 
Total elapsed time: 24.548221235047095. Arrivals time: 0.29610295820748433 Scheduler time: 24.09219957672758 Scheduler overhead time: 0.06208217918174341 Adapter cache time: 0.012649681069888175 Engine time: 0.05931164271896705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.08349587401608,
    "estimated_duration": 3600.106015575428,
    "input_throughput": 5566.954393368502,
    "output_throughput": 4809.612807258514,
    "total_throughput": 10376.567200627016,
    "itl": 108.37094034788312,
    "ttft": 896320.423822752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.910435406751936,
    "arrivals": 98651,
    "finished_requests": 80728,
    "scheduler_time": 98.67115981570053
}
#Debug simulation 
Total elapsed time: 16.083643972990103. Arrivals time: 0.277220229327213 Scheduler time: 15.648301729757804 Scheduler overhead time: 0.058921431947965175 Adapter cache time: 0.016716714075300843 Engine time: 0.057040471059735864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.487954373995308,
    "estimated_duration": 3600.0490289382124,
    "input_throughput": 5254.669546980959,
    "output_throughput": 4543.1528483443635,
    "total_throughput": 9797.822395325324,
    "itl": 96.43789806089573,
    "ttft": 1110499.6346065667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.851934886672558,
    "arrivals": 98651,
    "finished_requests": 76167,
    "scheduler_time": 108.60489964006844
}
#Debug simulation 
Total elapsed time: 10.488065632001963. Arrivals time: 0.26255275041330606 Scheduler time: 10.057649164111353 Scheduler overhead time: 0.060394962958525866 Adapter cache time: 0.020547781139612198 Engine time: 0.05949894891818985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 14.245072580000851,
    "estimated_duration": 3600.0754406304836,
    "input_throughput": 5567.6961026376875,
    "output_throughput": 4812.800810909009,
    "total_throughput": 10380.496913546696,
    "itl": 108.36865993398237,
    "ttft": 893760.747760134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6047624171851145,
    "arrivals": 98651,
    "finished_requests": 80747,
    "scheduler_time": 98.6095724925059
}
#Debug simulation 
Total elapsed time: 14.24517041404033. Arrivals time: 0.26724885182920843 Scheduler time: 13.823133318219334 Scheduler overhead time: 0.0573248618748039 Adapter cache time: 0.016554459230974317 Engine time: 0.05563188693486154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 10.405635252012871,
    "estimated_duration": 3600.101193213475,
    "input_throughput": 5253.944815677966,
    "output_throughput": 4542.144823824779,
    "total_throughput": 9796.089639502747,
    "itl": 96.5010047978686,
    "ttft": 1109742.7654805111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.320430769636319,
    "arrivals": 98651,
    "finished_requests": 76188,
    "scheduler_time": 108.60057147734533
}
#Debug simulation 
Total elapsed time: 10.405730433994904. Arrivals time: 0.2631778311333619 Scheduler time: 9.974685513006989 Scheduler overhead time: 0.060178145475219935 Adapter cache time: 0.021314260899089277 Engine time: 0.05919908278156072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 14.11782091105124,
    "estimated_duration": 3600.0740345240197,
    "input_throughput": 5562.600048764743,
    "output_throughput": 4808.070843545457,
    "total_throughput": 10370.670892310201,
    "itl": 108.5060201928539,
    "ttft": 891283.4043917335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9493714745435735,
    "arrivals": 98651,
    "finished_requests": 80697,
    "scheduler_time": 98.60907370931749
}
#Debug simulation 
Total elapsed time: 14.117914933012798. Arrivals time: 0.2662778052617796 Scheduler time: 13.698677556938492 Scheduler overhead time: 0.05696524650556967 Adapter cache time: 0.015346195141319185 Engine time: 0.05549419968156144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.350278017984238,
    "estimated_duration": 3600.0682506868575,
    "input_throughput": 5251.743768022398,
    "output_throughput": 4542.08777760817,
    "total_throughput": 9793.831545630568,
    "itl": 96.46056224497991,
    "ttft": 1111631.023378707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.8076554182730895,
    "arrivals": 98651,
    "finished_requests": 76151,
    "scheduler_time": 108.62087926012765
}
#Debug simulation 
Total elapsed time: 10.350434031977784. Arrivals time: 0.2666355525725521 Scheduler time: 9.915562654437963 Scheduler overhead time: 0.06034697766881436 Adapter cache time: 0.020624354481697083 Engine time: 0.05991374613950029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 18.025085830013268,
    "estimated_duration": 3600.0552042713875,
    "input_throughput": 5694.754895890345,
    "output_throughput": 4944.160017013511,
    "total_throughput": 10638.914912903856,
    "itl": 115.6570562504763,
    "ttft": 664523.3602214998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5620547677157441,
    "arrivals": 96558,
    "finished_requests": 82582,
    "scheduler_time": 91.83017334857334
}
#Debug simulation 
Total elapsed time: 18.025194207031745. Arrivals time: 0.2736226306296885 Scheduler time: 17.604304389562458 Scheduler overhead time: 0.05703454476315528 Adapter cache time: 0.009743636299390346 Engine time: 0.05620019498746842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.72861309896689,
    "estimated_duration": 3600.0067128220217,
    "input_throughput": 5534.288847028876,
    "output_throughput": 4808.084090052011,
    "total_throughput": 10342.372937080887,
    "itl": 108.16974908746455,
    "ttft": 793673.4784623028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0095284563908358,
    "arrivals": 96558,
    "finished_requests": 80239,
    "scheduler_time": 95.86615111493683
}
#Debug simulation 
Total elapsed time: 17.7287198479753. Arrivals time: 0.27280908898683265 Scheduler time: 17.30147633521119 Scheduler overhead time: 0.059148765343707055 Adapter cache time: 0.011089453240856528 Engine time: 0.058656995999626815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.519080324971583,
    "estimated_duration": 3600.058885251642,
    "input_throughput": 5218.2749223800165,
    "output_throughput": 4539.388526934525,
    "total_throughput": 9757.663449314541,
    "itl": 96.37569815571187,
    "ttft": 1061416.2074844881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.352183477240641,
    "arrivals": 96558,
    "finished_requests": 75720,
    "scheduler_time": 105.58891984125279
}
#Debug simulation 
Total elapsed time: 10.51916640100535. Arrivals time: 0.25598278193501756 Scheduler time: 10.095028923766222 Scheduler overhead time: 0.06019804812967777 Adapter cache time: 0.02111752610653639 Engine time: 0.05957486206898466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 17.94088766502682,
    "estimated_duration": 3600.0448313438915,
    "input_throughput": 5534.0955275167435,
    "output_throughput": 4807.916237403822,
    "total_throughput": 10342.011764920566,
    "itl": 108.17040997150494,
    "ttft": 793838.254648312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9406745916511858,
    "arrivals": 96558,
    "finished_requests": 80239,
    "scheduler_time": 95.87313861021104
}
#Debug simulation 
Total elapsed time: 17.94100090803113. Arrivals time: 0.2787324154051021 Scheduler time: 17.504948183952365 Scheduler overhead time: 0.0604006607318297 Adapter cache time: 0.011333059868775308 Engine time: 0.059543064213357866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.043645429017488,
    "estimated_duration": 3600.082862232321,
    "input_throughput": 5212.127253194628,
    "output_throughput": 4534.357298064484,
    "total_throughput": 9746.484551259111,
    "itl": 95.92458115845487,
    "ttft": 1055026.5432755281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.017713212915732,
    "arrivals": 96558,
    "finished_requests": 75636,
    "scheduler_time": 105.9426185169431
}
#Debug simulation 
Total elapsed time: 11.043768008996267. Arrivals time: 0.25993826769990847 Scheduler time: 10.61738245759625 Scheduler overhead time: 0.06053415738279 Adapter cache time: 0.017312845098786056 Engine time: 0.06105564424069598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.831975933047943,
    "estimated_duration": 3600.031944301473,
    "input_throughput": 5535.612546867768,
    "output_throughput": 4807.925392828276,
    "total_throughput": 10343.537939696043,
    "itl": 108.15542862822608,
    "ttft": 788658.373678479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8107579594524567,
    "arrivals": 96558,
    "finished_requests": 80246,
    "scheduler_time": 95.87910017007036
}
#Debug simulation 
Total elapsed time: 17.832103085995186. Arrivals time: 0.27760888409102336 Scheduler time: 17.399848434550222 Scheduler overhead time: 0.05928642052458599 Adapter cache time: 0.010796321672387421 Engine time: 0.058680065209046006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.597547722049057,
    "estimated_duration": 3600.0135040894447,
    "input_throughput": 5214.29766268277,
    "output_throughput": 4533.6716046925385,
    "total_throughput": 9747.969267375309,
    "itl": 96.15010080208825,
    "ttft": 1064868.9561622893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 842,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.211194893755046,
    "arrivals": 96558,
    "finished_requests": 75631,
    "scheduler_time": 105.77162006418398
}
#Debug simulation 
Total elapsed time: 10.59767509601079. Arrivals time: 0.2626180201768875 Scheduler time: 10.165045978617854 Scheduler overhead time: 0.06147967040305957 Adapter cache time: 0.021138016774784774 Engine time: 0.059960971761029214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.91000646300381,
    "estimated_duration": 3600.10239743061,
    "input_throughput": 5736.169064173968,
    "output_throughput": 4945.778212505187,
    "total_throughput": 10681.947276679155,
    "itl": 115.5616314647982,
    "ttft": 637099.828815857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7802642657700918,
    "arrivals": 95849,
    "finished_requests": 82801,
    "scheduler_time": 90.29869756016458
}
#Debug simulation 
Total elapsed time: 16.910179394995794. Arrivals time: 0.265783793060109 Scheduler time: 16.498632556118537 Scheduler overhead time: 0.0561780515126884 Adapter cache time: 0.010188131651375443 Engine time: 0.05476521578384563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.330222839023918,
    "estimated_duration": 3600.0298299967444,
    "input_throughput": 5577.184897942403,
    "output_throughput": 4811.147078749529,
    "total_throughput": 10388.331976691932,
    "itl": 108.13613583436366,
    "ttft": 769524.7890478709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3270719070080679,
    "arrivals": 95849,
    "finished_requests": 80568,
    "scheduler_time": 94.2232044783608
}
#Debug simulation 
Total elapsed time: 16.330342300003394. Arrivals time: 0.26850970002124086 Scheduler time: 15.907093301590066 Scheduler overhead time: 0.059291657875292 Adapter cache time: 0.011526281188707799 Engine time: 0.05816481163492426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.560845845961012,
    "estimated_duration": 3600.0899838586893,
    "input_throughput": 5257.488864129164,
    "output_throughput": 4535.519410128421,
    "total_throughput": 9793.008274257585,
    "itl": 95.96332468562252,
    "ttft": 1025987.0245785414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6234861646220375,
    "arrivals": 95849,
    "finished_requests": 75928,
    "scheduler_time": 104.07273328025146
}
#Debug simulation 
Total elapsed time: 9.560962673975155. Arrivals time: 0.2528907866217196 Scheduler time: 9.140538216859568 Scheduler overhead time: 0.06057066406356171 Adapter cache time: 0.020044500415679067 Engine time: 0.05957181815756485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 16.53491423599189,
    "estimated_duration": 3600.0090948865077,
    "input_throughput": 5582.97228430575,
    "output_throughput": 4810.373402833289,
    "total_throughput": 10393.345687139039,
    "itl": 108.08089529942218,
    "ttft": 771283.3014279971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5038573330780474,
    "arrivals": 95849,
    "finished_requests": 80567,
    "scheduler_time": 94.28936150682648
}
#Debug simulation 
Total elapsed time: 16.53501111100195. Arrivals time: 0.2664572066278197 Scheduler time: 16.113925636105705 Scheduler overhead time: 0.05901693069608882 Adapter cache time: 0.012359957385342568 Engine time: 0.05742033221758902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.008337054983713,
    "estimated_duration": 3600.0585598538764,
    "input_throughput": 5261.761908886523,
    "output_throughput": 4540.814191829013,
    "total_throughput": 9802.576100715536,
    "itl": 96.27069352332067,
    "ttft": 1023843.8210001887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.117243998325459,
    "arrivals": 95849,
    "finished_requests": 75985,
    "scheduler_time": 103.83730587690333
}
#Debug simulation 
Total elapsed time: 9.008425234991591. Arrivals time: 0.2482792743248865 Scheduler time: 8.594054872519337 Scheduler overhead time: 0.05956481595057994 Adapter cache time: 0.020454854937270284 Engine time: 0.0588185511296615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.260424288979266,
    "estimated_duration": 3600.105204831047,
    "input_throughput": 5578.106710062779,
    "output_throughput": 4811.579110731273,
    "total_throughput": 10389.685820794053,
    "itl": 108.12745714162864,
    "ttft": 769097.3522060934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1554896902432636,
    "arrivals": 95849,
    "finished_requests": 80580,
    "scheduler_time": 94.22169940935831
}
#Debug simulation 
Total elapsed time: 16.260527687962167. Arrivals time: 0.2669217293150723 Scheduler time: 15.84050317882793 Scheduler overhead time: 0.05901831766823307 Adapter cache time: 0.01152877596905455 Engine time: 0.05704863235587254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.947381604986731,
    "estimated_duration": 3600.0494374377026,
    "input_throughput": 5260.435538207164,
    "output_throughput": 4538.775170718125,
    "total_throughput": 9799.21070892529,
    "itl": 96.2145496394119,
    "ttft": 1025730.2127066145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.405996950566794,
    "arrivals": 95849,
    "finished_requests": 75953,
    "scheduler_time": 103.87105608050165
}
#Debug simulation 
Total elapsed time: 8.94747020502109. Arrivals time: 0.24934014433529228 Scheduler time: 8.530397642520256 Scheduler overhead time: 0.05974860809510574 Adapter cache time: 0.02142126695252955 Engine time: 0.05925651179859415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.000446691992693,
    "estimated_duration": 3600.066814542278,
    "input_throughput": 5701.939729863015,
    "output_throughput": 4942.713543015837,
    "total_throughput": 10644.653272878852,
    "itl": 115.2726304875684,
    "ttft": 613884.0818103562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8199387199617914,
    "arrivals": 94443,
    "finished_requests": 82596,
    "scheduler_time": 89.07437519630993
}
#Debug simulation 
Total elapsed time: 12.000543522008229. Arrivals time: 0.24925168819027022 Scheduler time: 11.613046317885164 Scheduler overhead time: 0.05274758260929957 Adapter cache time: 0.009811363939661533 Engine time: 0.05193375638918951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.30088361701928,
    "estimated_duration": 3600.0475824658897,
    "input_throughput": 5539.593170138039,
    "output_throughput": 4807.170350827988,
    "total_throughput": 10346.763520966026,
    "itl": 107.93408513563965,
    "ttft": 758616.7368321315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8478901779372277,
    "arrivals": 94443,
    "finished_requests": 80331,
    "scheduler_time": 92.88413766345633
}
#Debug simulation 
Total elapsed time: 12.300979660998564. Arrivals time: 0.26147406559903175 Scheduler time: 11.888171980739571 Scheduler overhead time: 0.05676672811387107 Adapter cache time: 0.013853774929884821 Engine time: 0.05524025985505432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.80206142400857,
    "estimated_duration": 3600.0470892491394,
    "input_throughput": 5235.815958154972,
    "output_throughput": 4543.121963277223,
    "total_throughput": 9778.937921432194,
    "itl": 95.84879814233263,
    "ttft": 983082.1469152467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.904105773172371,
    "arrivals": 94443,
    "finished_requests": 75875,
    "scheduler_time": 102.16783330565883
}
#Debug simulation 
Total elapsed time: 8.802167061017826. Arrivals time: 0.24591791455168277 Scheduler time: 8.39259474730352 Scheduler overhead time: 0.05949038593098521 Adapter cache time: 0.018335250148084015 Engine time: 0.05864625936374068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 12.304929536010604,
    "estimated_duration": 3600.0763538586502,
    "input_throughput": 5539.393346095401,
    "output_throughput": 4807.790529622634,
    "total_throughput": 10347.183875718034,
    "itl": 107.94500138228307,
    "ttft": 758155.928034887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5874807742470836,
    "arrivals": 94443,
    "finished_requests": 80347,
    "scheduler_time": 92.8801665262664
}
#Debug simulation 
Total elapsed time: 12.305028247006703. Arrivals time: 0.2565578664653003 Scheduler time: 11.897751726326533 Scheduler overhead time: 0.05604783643502742 Adapter cache time: 0.013686009915545583 Engine time: 0.055748775659594685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.928020897030365,
    "estimated_duration": 3600.0062878633485,
    "input_throughput": 5235.106411768408,
    "output_throughput": 4542.841787564341,
    "total_throughput": 9777.948199332748,
    "itl": 95.98491371692201,
    "ttft": 983684.4465268984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.71861165844373,
    "arrivals": 94443,
    "finished_requests": 75856,
    "scheduler_time": 102.12140052749697
}
#Debug simulation 
Total elapsed time: 8.928140829026233. Arrivals time: 0.24399865296436474 Scheduler time: 8.519613464537542 Scheduler overhead time: 0.05994225916219875 Adapter cache time: 0.01839276810642332 Engine time: 0.05875020305393264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.206771466007922,
    "estimated_duration": 3600.0697780777978,
    "input_throughput": 5540.135949989631,
    "output_throughput": 4808.810402903776,
    "total_throughput": 10348.946352893407,
    "itl": 107.95671861319632,
    "ttft": 757753.5172814269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.432273878357363,
    "arrivals": 94443,
    "finished_requests": 80358,
    "scheduler_time": 92.87920948926464
}
#Debug simulation 
Total elapsed time: 12.20691040402744. Arrivals time: 0.25061152083799243 Scheduler time: 11.805566440103576 Scheduler overhead time: 0.05636260664323345 Adapter cache time: 0.013687031751032919 Engine time: 0.055510882870294154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.386731997015886,
    "estimated_duration": 3600.086866073925,
    "input_throughput": 5233.9875955685,
    "output_throughput": 4544.153407565048,
    "total_throughput": 9778.141003133547,
    "itl": 96.07565579685199,
    "ttft": 983061.5867620223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 747,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.499684596266623,
    "arrivals": 94443,
    "finished_requests": 75874,
    "scheduler_time": 102.07427371414511
}
#Debug simulation 
Total elapsed time: 8.386839477985632. Arrivals time: 0.24059248314006254 Scheduler time: 7.981945260078646 Scheduler overhead time: 0.05925261595984921 Adapter cache time: 0.01945973461261019 Engine time: 0.05847029888536781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.209311251994222,
    "estimated_duration": 3599.789581124415,
    "input_throughput": 2784.183012405248,
    "output_throughput": 2412.8299180439813,
    "total_throughput": 5197.012930449229,
    "itl": 48.74076445721318,
    "ttft": 36792.33010610088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.000999555918824,
    "arrivals": 40505,
    "finished_requests": 40224,
    "scheduler_time": 23.25747540381832
}
#Debug simulation 
Total elapsed time: 4.209385760012083. Arrivals time: 0.11430652858689427 Scheduler time: 3.7884122190298513 Scheduler overhead time: 0.08450841356534511 Adapter cache time: 0.10282122576609254 Engine time: 0.08101355883991346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.237300190026872,
    "estimated_duration": 3599.7639509335477,
    "input_throughput": 2784.461463758081,
    "output_throughput": 2413.127115667468,
    "total_throughput": 5197.588579425549,
    "itl": 48.872204293705444,
    "ttft": 36954.1425951378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.91368094479506,
    "arrivals": 40505,
    "finished_requests": 40223,
    "scheduler_time": 23.298751716559227
}
#Debug simulation 
Total elapsed time: 4.2374164090142585. Arrivals time: 0.11378506332403049 Scheduler time: 3.8176142738666385 Scheduler overhead time: 0.084828844119329 Adapter cache time: 0.10251694591715932 Engine time: 0.0801153362262994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.18880944600096,
    "estimated_duration": 3599.7777378256783,
    "input_throughput": 2784.3760726333426,
    "output_throughput": 2412.8695248963772,
    "total_throughput": 5197.24559752972,
    "itl": 48.90755849169601,
    "ttft": 37163.4350225882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.6792192518119,
    "arrivals": 40505,
    "finished_requests": 40221,
    "scheduler_time": 23.309525477013604
}
#Debug simulation 
Total elapsed time: 4.188925025984645. Arrivals time: 0.1150157354422845 Scheduler time: 3.7679453790187836 Scheduler overhead time: 0.08490494982106611 Adapter cache time: 0.1025370272109285 Engine time: 0.079703850497026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.197115929971915,
    "estimated_duration": 3599.7813536556337,
    "input_throughput": 2784.665238020716,
    "output_throughput": 2412.8451554924363,
    "total_throughput": 5197.510393513152,
    "itl": 48.79229433782143,
    "ttft": 36653.3451503462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.11874721085407,
    "arrivals": 40505,
    "finished_requests": 40226,
    "scheduler_time": 23.274898203156337
}
#Debug simulation 
Total elapsed time: 4.197204822965432. Arrivals time: 0.11622639675624669 Scheduler time: 3.773974692740012 Scheduler overhead time: 0.08476733398856595 Adapter cache time: 0.10384060116484761 Engine time: 0.08019386779051274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.1604038849473,
    "estimated_duration": 3599.7654433990547,
    "input_throughput": 2784.0950077393677,
    "output_throughput": 2412.8099834745694,
    "total_throughput": 5196.904991213937,
    "itl": 48.88984280533766,
    "ttft": 37235.55905173718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.09669824116499,
    "arrivals": 40505,
    "finished_requests": 40220,
    "scheduler_time": 23.304706128391675
}
#Debug simulation 
Total elapsed time: 4.160481002996676. Arrivals time: 0.1140149199636653 Scheduler time: 3.742292183684185 Scheduler overhead time: 0.08437588665401563 Adapter cache time: 0.10116820246912539 Engine time: 0.08005317609058693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.192049475037493,
    "estimated_duration": 3599.7725056968156,
    "input_throughput": 2784.1556609866816,
    "output_throughput": 2412.8052498469538,
    "total_throughput": 5196.960910833635,
    "itl": 48.70790454276734,
    "ttft": 36960.251472595046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.01707350791164,
    "arrivals": 40505,
    "finished_requests": 40222,
    "scheduler_time": 23.24644425462489
}
#Debug simulation 
Total elapsed time: 4.1921264140401036. Arrivals time: 0.11494167166529223 Scheduler time: 3.7706749093485996 Scheduler overhead time: 0.08495019795373082 Adapter cache time: 0.10259797761682421 Engine time: 0.08059925423003733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.225262192019727,
    "estimated_duration": 3599.7499665682753,
    "input_throughput": 2784.455335256377,
    "output_throughput": 2412.8323024279866,
    "total_throughput": 5197.287637684364,
    "itl": 48.87979046139131,
    "ttft": 37114.60549848229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.5148452439865,
    "arrivals": 40505,
    "finished_requests": 40221,
    "scheduler_time": 23.299178421076057
}
#Debug simulation 
Total elapsed time: 4.225336326984689. Arrivals time: 0.11495427484624088 Scheduler time: 3.8042946457280777 Scheduler overhead time: 0.08457364194327965 Adapter cache time: 0.1030479118344374 Engine time: 0.08022621896816418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.645561142009683,
    "estimated_duration": 3600.0268562571973,
    "input_throughput": 2586.174595841638,
    "output_throughput": 2279.6907711217555,
    "total_throughput": 4865.865366963394,
    "itl": 47.482861637630016,
    "ttft": 23553.554837451888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.13731513756791,
    "arrivals": 37714,
    "finished_requests": 37543,
    "scheduler_time": 20.410084213661897
}
#Debug simulation 
Total elapsed time: 3.6456363900215365. Arrivals time: 0.1056888488237746 Scheduler time: 3.2244632671936415 Scheduler overhead time: 0.08588877553120255 Adapter cache time: 0.10949568497017026 Engine time: 0.08073179027996957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.666432614030782,
    "estimated_duration": 3600.034437197667,
    "input_throughput": 2586.080539620354,
    "output_throughput": 2279.5423608192027,
    "total_throughput": 4865.622900439556,
    "itl": 47.6217079692695,
    "ttft": 23999.779915395735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 72.61813028696479,
    "arrivals": 37714,
    "finished_requests": 37540,
    "scheduler_time": 20.45137827827814
}
#Debug simulation 
Total elapsed time: 3.6665096430224366. Arrivals time: 0.10684970911825076 Scheduler time: 3.242161240952555 Scheduler overhead time: 0.08535555662820116 Adapter cache time: 0.11103784688748419 Engine time: 0.08222202432807535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.673011041013524,
    "estimated_duration": 3600.0098730913237,
    "input_throughput": 2585.9442968710555,
    "output_throughput": 2279.387915387486,
    "total_throughput": 4865.332212258541,
    "itl": 47.65543965981616,
    "ttft": 24306.30952557509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9917,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 74.28731313060449,
    "arrivals": 37714,
    "finished_requests": 37536,
    "scheduler_time": 20.46266105675214
}
#Debug simulation 
Total elapsed time: 3.673090455995407. Arrivals time: 0.1068547471659258 Scheduler time: 3.2481111221713945 Scheduler overhead time: 0.08592867181869224 Adapter cache time: 0.11144155991496518 Engine time: 0.08162042184267193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.721845004009083,
    "estimated_duration": 3600.0466446258665,
    "input_throughput": 2585.553721614999,
    "output_throughput": 2279.1340807343067,
    "total_throughput": 4864.687802349306,
    "itl": 47.4699367705095,
    "ttft": 25368.632974825377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.9479575107455,
    "arrivals": 37714,
    "finished_requests": 37533,
    "scheduler_time": 20.476011830854425
}
#Debug simulation 
Total elapsed time: 3.721959339978639. Arrivals time: 0.10650684969732538 Scheduler time: 3.302925081399735 Scheduler overhead time: 0.08585007884539664 Adapter cache time: 0.10629301780136302 Engine time: 0.08127583144232631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.6634733360260725,
    "estimated_duration": 3600.0345396520506,
    "input_throughput": 2586.080466022369,
    "output_throughput": 2279.542295945073,
    "total_throughput": 4865.622761967442,
    "itl": 47.641170772808316,
    "ttft": 24026.899304539726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.73910188885793,
    "arrivals": 37714,
    "finished_requests": 37540,
    "scheduler_time": 20.460079836137282
}
#Debug simulation 
Total elapsed time: 3.6635497780516744. Arrivals time: 0.10660369752440602 Scheduler time: 3.240397831075825 Scheduler overhead time: 0.0859389352845028 Adapter cache time: 0.11016012984327972 Engine time: 0.08108670328510925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.684472502034623,
    "estimated_duration": 3600.015659743708,
    "input_throughput": 2586.1470837776324,
    "output_throughput": 2279.876471588547,
    "total_throughput": 4866.02355536618,
    "itl": 47.44994807449135,
    "ttft": 23446.15082476361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.01795919204872,
    "arrivals": 37714,
    "finished_requests": 37544,
    "scheduler_time": 20.397597611819403
}
#Debug simulation 
Total elapsed time: 3.6845837850123644. Arrivals time: 0.10685115016531199 Scheduler time: 3.2596878966432996 Scheduler overhead time: 0.08573332510422915 Adapter cache time: 0.11129632947267964 Engine time: 0.0818381094140932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.650449585984461,
    "estimated_duration": 3600.0427530388206,
    "input_throughput": 2586.169287056687,
    "output_throughput": 2279.5740392451685,
    "total_throughput": 4865.743326301856,
    "itl": 47.61615218307501,
    "ttft": 23819.684062640445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.16562277182834,
    "arrivals": 37714,
    "finished_requests": 37542,
    "scheduler_time": 20.455461803474282
}
#Debug simulation 
Total elapsed time: 3.650536013999954. Arrivals time: 0.10730782756581903 Scheduler time: 3.2275914896745235 Scheduler overhead time: 0.0861205275868997 Adapter cache time: 0.1095319096930325 Engine time: 0.08111636125249788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.2755408490193076,
    "estimated_duration": 3600.0382649065627,
    "input_throughput": 2485.326360894173,
    "output_throughput": 2155.482922402049,
    "total_throughput": 4640.809283296222,
    "itl": 46.28388728208075,
    "ttft": 19656.72860875038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.96640743139058,
    "arrivals": 36267,
    "finished_requests": 36113,
    "scheduler_time": 17.99287816914808
}
#Debug simulation 
Total elapsed time: 3.2756210130173713. Arrivals time: 0.10242088831728324 Scheduler time: 2.845854324987158 Scheduler overhead time: 0.08665431919507682 Adapter cache time: 0.11920968536287546 Engine time: 0.08200285356724635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.3228490100009367,
    "estimated_duration": 3600.0005879620053,
    "input_throughput": 2485.3351496437117,
    "output_throughput": 2155.2610368856663,
    "total_throughput": 4640.5961865293775,
    "itl": 46.420632662920184,
    "ttft": 20011.257487182495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 81.0282672319026,
    "arrivals": 36267,
    "finished_requests": 36110,
    "scheduler_time": 18.03705609154475
}
#Debug simulation 
Total elapsed time: 3.322944587969687. Arrivals time: 0.1028679531882517 Scheduler time: 2.8913142899400555 Scheduler overhead time: 0.08667160954792053 Adapter cache time: 0.11959159892285243 Engine time: 0.08290000492706895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.2956483290181495,
    "estimated_duration": 3600.0462336300993,
    "input_throughput": 2485.303637608593,
    "output_throughput": 2155.233709922744,
    "total_throughput": 4640.537347531336,
    "itl": 46.45795892189866,
    "ttft": 20031.62979308672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.02838404642739,
    "arrivals": 36267,
    "finished_requests": 36110,
    "scheduler_time": 18.05023001485866
}
#Debug simulation 
Total elapsed time: 3.295722276030574. Arrivals time: 0.10238184034824371 Scheduler time: 2.866348578245379 Scheduler overhead time: 0.08675133652286604 Adapter cache time: 0.1184324118657969 Engine time: 0.0821123935165815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.300035192980431,
    "estimated_duration": 3600.0222527086994,
    "input_throughput": 2485.3374151418,
    "output_throughput": 2155.4925095703,
    "total_throughput": 4640.8299247121,
    "itl": 46.32349852762072,
    "ttft": 19678.129125846364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.29740818650309,
    "arrivals": 36267,
    "finished_requests": 36113,
    "scheduler_time": 18.007629262743134
}
#Debug simulation 
Total elapsed time: 3.3001283899648115. Arrivals time: 0.10389793285867199 Scheduler time: 2.8685989397927187 Scheduler overhead time: 0.0866781520890072 Adapter cache time: 0.11890254769241437 Engine time: 0.08211618411587551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.2390737860114314,
    "estimated_duration": 3600.031247035478,
    "input_throughput": 2485.3139836960495,
    "output_throughput": 2155.242681959848,
    "total_throughput": 4640.556665655898,
    "itl": 46.44706936369787,
    "ttft": 20025.50956330609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 82.37014919748823,
    "arrivals": 36267,
    "finished_requests": 36110,
    "scheduler_time": 18.046033259676825
}
#Debug simulation 
Total elapsed time: 3.2391815169830807. Arrivals time: 0.09829339408315718 Scheduler time: 2.8215348263038322 Scheduler overhead time: 0.08424695953726768 Adapter cache time: 0.1169853457249701 Engine time: 0.07941610482521355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.245163401006721,
    "estimated_duration": 3600.0354084909645,
    "input_throughput": 2485.33472167999,
    "output_throughput": 2155.3643560557425,
    "total_throughput": 4640.699077735732,
    "itl": 46.23111043212797,
    "ttft": 19644.620415914233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.4743788506278,
    "arrivals": 36267,
    "finished_requests": 36113,
    "scheduler_time": 17.97755525656325
}
#Debug simulation 
Total elapsed time: 3.2452383649651892. Arrivals time: 0.09817591437604278 Scheduler time: 2.8248901729821227 Scheduler overhead time: 0.0846693404018879 Adapter cache time: 0.11741551785962656 Engine time: 0.0811144519248046 
