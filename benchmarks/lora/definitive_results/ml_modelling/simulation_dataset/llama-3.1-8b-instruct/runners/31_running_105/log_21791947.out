INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.147647730074823,
    "estimated_duration": 3599.8765317986627,
    "input_throughput": 704.0585913466416,
    "output_throughput": 615.6705599268473,
    "total_throughput": 1319.729151273489,
    "itl": 23.173937434358894,
    "ttft": 6768.663410072762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.65105702792131,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.147761429194361. Arrivals time: 0.03680120687931776 Scheduler time: 0.7451538946479559 Scheduler overhead time: 0.12741640117019415 Adapter cache time: 0.0457960688509047 Engine time: 0.12949422001838684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1406242540106177,
    "estimated_duration": 3599.8839873122106,
    "input_throughput": 704.057133211217,
    "output_throughput": 615.6692848468124,
    "total_throughput": 1319.7264180580294,
    "itl": 23.207277388660998,
    "ttft": 6770.368534900817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.51950688710313,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.140731736086309. Arrivals time: 0.0367680792696774 Scheduler time: 0.744669200386852 Scheduler overhead time: 0.1262844568118453 Adapter cache time: 0.045343798119574785 Engine time: 0.12506681447848678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1535934461280704,
    "estimated_duration": 3599.8746210385493,
    "input_throughput": 704.0589650505106,
    "output_throughput": 615.6708867156589,
    "total_throughput": 1319.7298517661693,
    "itl": 23.212693912065806,
    "ttft": 6770.670655934695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.63419244985494,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1536843390204012. Arrivals time: 0.0374675658531487 Scheduler time: 0.756581183988601 Scheduler overhead time: 0.12656169850379229 Adapter cache time: 0.04559421679005027 Engine time: 0.1251694024540484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1385693429037929,
    "estimated_duration": 3599.8782321208487,
    "input_throughput": 704.0582588002703,
    "output_throughput": 615.6702691285911,
    "total_throughput": 1319.7285279288615,
    "itl": 23.188501535108415,
    "ttft": 6769.31797289256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.99683552547479,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1386508657597005. Arrivals time: 0.03665734175592661 Scheduler time: 0.7403885978274047 Scheduler overhead time: 0.12677832320332527 Adapter cache time: 0.04553454602137208 Engine time: 0.12663936521857977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.139869490172714,
    "estimated_duration": 3599.8865731600395,
    "input_throughput": 704.0566274773356,
    "output_throughput": 615.6688426031329,
    "total_throughput": 1319.7254700804685,
    "itl": 23.21309797968004,
    "ttft": 6770.4105000431855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.28286535979187,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1400135750882328. Arrivals time: 0.03654125612229109 Scheduler time: 0.739988564979285 Scheduler overhead time: 0.1259325873106718 Adapter cache time: 0.04515307582914829 Engine time: 0.13002493558451533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1671771169640124,
    "estimated_duration": 3599.8671334685146,
    "input_throughput": 704.0604294631164,
    "output_throughput": 615.6721672848331,
    "total_throughput": 1319.7325967479494,
    "itl": 23.169152005409487,
    "ttft": 6768.056339699618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.3181262309095,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1672709519043565. Arrivals time: 0.03736285027116537 Scheduler time: 0.767736685462296 Scheduler overhead time: 0.12666249182075262 Adapter cache time: 0.04551093885675073 Engine time: 0.1270976602099836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1751668839715421,
    "estimated_duration": 3599.8667795406536,
    "input_throughput": 704.0604986841785,
    "output_throughput": 615.6722278158323,
    "total_throughput": 1319.7327265000108,
    "itl": 23.20858267484214,
    "ttft": 6770.66076814154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.87526025272854,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1752598490566015. Arrivals time: 0.03787435172125697 Scheduler time: 0.7723634615540504 Scheduler overhead time: 0.1272294488735497 Adapter cache time: 0.045944737270474434 Engine time: 0.128597111441195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.167616973631084,
    "estimated_duration": 3599.7746272848876,
    "input_throughput": 679.2155768496392,
    "output_throughput": 609.1586910411484,
    "total_throughput": 1288.3742678907877,
    "itl": 23.29752282189791,
    "ttft": 6913.655226242503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.82603213510258,
    "arrivals": 10134,
    "finished_requests": 10115,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1676912298426032. Arrivals time: 0.03765237843617797 Scheduler time: 0.7685782839544117 Scheduler overhead time: 0.12722048023715615 Adapter cache time: 0.04481152771040797 Engine time: 0.1262835506349802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1586525249294937,
    "estimated_duration": 3599.777705935181,
    "input_throughput": 679.2149959617607,
    "output_throughput": 609.1581700682617,
    "total_throughput": 1288.3731660300223,
    "itl": 23.3234071260861,
    "ttft": 6915.29038760097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.46683986247407,
    "arrivals": 10134,
    "finished_requests": 10115,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.158732711803168. Arrivals time: 0.037081845570355654 Scheduler time: 0.7618168108165264 Scheduler overhead time: 0.1259593553841114 Adapter cache time: 0.04508979106321931 Engine time: 0.12608901970088482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1595010249875486,
    "estimated_duration": 3599.776227745736,
    "input_throughput": 679.2152748703301,
    "output_throughput": 609.1584202091373,
    "total_throughput": 1288.3736950794673,
    "itl": 23.32795888495281,
    "ttft": 6915.704775660193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.52153693614971,
    "arrivals": 10134,
    "finished_requests": 10115,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1597485360689461. Arrivals time: 0.03778639668598771 Scheduler time: 0.7579610710963607 Scheduler overhead time: 0.12644847854971886 Adapter cache time: 0.045068418607115746 Engine time: 0.12946278881281614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1712962640449405,
    "estimated_duration": 3599.7746110279927,
    "input_throughput": 679.2155799170358,
    "output_throughput": 609.158693792162,
    "total_throughput": 1288.3742737091977,
    "itl": 23.30496634070988,
    "ttft": 6914.006966742554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.07827822901426,
    "arrivals": 10134,
    "finished_requests": 10115,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1713721971027553. Arrivals time: 0.03744015749543905 Scheduler time: 0.7680156184360385 Scheduler overhead time: 0.1272214693017304 Adapter cache time: 0.04522210964933038 Engine time: 0.12925453390926123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1786112538538873,
    "estimated_duration": 3599.7876745812646,
    "input_throughput": 679.2131150580736,
    "output_throughput": 609.1564831681567,
    "total_throughput": 1288.3695982262304,
    "itl": 23.32884815139117,
    "ttft": 6915.364315375358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.14029206904102,
    "arrivals": 10134,
    "finished_requests": 10115,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.17869809595868. Arrivals time: 0.03729360597208142 Scheduler time: 0.7675388515926898 Scheduler overhead time: 0.126108864787966 Adapter cache time: 0.04550603870302439 Engine time: 0.13941282406449318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1676175338216126,
    "estimated_duration": 3599.7790076543574,
    "input_throughput": 679.2147503502431,
    "output_throughput": 609.1579497900531,
    "total_throughput": 1288.372700140296,
    "itl": 23.28606998366845,
    "ttft": 6912.904775499399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.600851497895796,
    "arrivals": 10134,
    "finished_requests": 10115,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1677123997360468. Arrivals time: 0.0368724730797112 Scheduler time: 0.7677172990515828 Scheduler overhead time: 0.12644869787618518 Adapter cache time: 0.04490932961925864 Engine time: 0.12909527216106653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1659185397438705,
    "estimated_duration": 3599.765936504169,
    "input_throughput": 679.2172166544885,
    "output_throughput": 609.1601617102697,
    "total_throughput": 1288.3773783647582,
    "itl": 23.325927544290767,
    "ttft": 6915.494306011719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.75598746497176,
    "arrivals": 10134,
    "finished_requests": 10115,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.16603785706684. Arrivals time: 0.03783972980454564 Scheduler time: 0.7615792406722903 Scheduler overhead time: 0.1280299322679639 Adapter cache time: 0.0455084228888154 Engine time: 0.12987344665452838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0902028484269977,
    "estimated_duration": 3600.0149497676325,
    "input_throughput": 641.1951150783395,
    "output_throughput": 557.3396299727888,
    "total_throughput": 1198.5347450511283,
    "itl": 22.711708648245978,
    "ttft": 5428.089333100705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.317895411487527,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0902712973766029. Arrivals time: 0.036166380159556866 Scheduler time: 0.6922578760422766 Scheduler overhead time: 0.1280522714368999 Adapter cache time: 0.04242673283442855 Engine time: 0.12774286093190312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1008296911604702,
    "estimated_duration": 3600.002851385966,
    "input_throughput": 641.1972699164176,
    "output_throughput": 557.3415030011834,
    "total_throughput": 1198.538772917601,
    "itl": 22.734278652857938,
    "ttft": 5429.032630853389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.414117117853856,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.10107886698097. Arrivals time: 0.03535679867491126 Scheduler time: 0.7036077179946005 Scheduler overhead time: 0.12796136131510139 Adapter cache time: 0.04256155900657177 Engine time: 0.12777941394597292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1074916538782418,
    "estimated_duration": 3600.021994422915,
    "input_throughput": 641.1938603641846,
    "output_throughput": 557.3385393501273,
    "total_throughput": 1198.532399714312,
    "itl": 22.73824916931374,
    "ttft": 5429.355440082719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.27218677318292,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1075665266253054. Arrivals time: 0.036021419800817966 Scheduler time: 0.7074090833775699 Scheduler overhead time: 0.12783372215926647 Adapter cache time: 0.042912413366138935 Engine time: 0.1299547702074051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1002030801028013,
    "estimated_duration": 3600.014663653117,
    "input_throughput": 641.195166037918,
    "output_throughput": 557.3396742678744,
    "total_throughput": 1198.5348403057924,
    "itl": 22.721776614920508,
    "ttft": 5428.523278937757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.612763478421424,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1003163577988744. Arrivals time: 0.03652069764211774 Scheduler time: 0.6960125407204032 Scheduler overhead time: 0.1280594002455473 Adapter cache time: 0.04269156977534294 Engine time: 0.13119544880464673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0858193971216679,
    "estimated_duration": 3600.022742062217,
    "input_throughput": 641.1937272034342,
    "output_throughput": 557.3384236041373,
    "total_throughput": 1198.5321508075715,
    "itl": 22.739011345450237,
    "ttft": 5429.3694484484995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.010751530799254,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0859143822453916. Arrivals time: 0.035416367929428816 Scheduler time: 0.6910397284664214 Scheduler overhead time: 0.12676210422068834 Adapter cache time: 0.042336146812886 Engine time: 0.12704362254589796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0961973038502038,
    "estimated_duration": 3600.0113800750155,
    "input_throughput": 641.1957508734043,
    "output_throughput": 557.3401826185868,
    "total_throughput": 1198.535933491991,
    "itl": 22.70291558683652,
    "ttft": 5427.740478101999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.276661433459264,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0962898680008948. Arrivals time: 0.03535802289843559 Scheduler time: 0.6960672452114522 Scheduler overhead time: 0.13047790247946978 Adapter cache time: 0.04238554649055004 Engine time: 0.12785730976611376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.108638244215399,
    "estimated_duration": 3600.0186750915727,
    "input_throughput": 641.1944515652503,
    "output_throughput": 557.3390532339288,
    "total_throughput": 1198.5335047991791,
    "itl": 22.733419063652622,
    "ttft": 5429.273593764171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.66222519153848,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1087019038386643. Arrivals time: 0.03612827742472291 Scheduler time: 0.704763213172555 Scheduler overhead time: 0.12807170674204826 Adapter cache time: 0.04271060833707452 Engine time: 0.1325881415978074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0888164672069252,
    "estimated_duration": 3599.0046932141236,
    "input_throughput": 628.6540843544797,
    "output_throughput": 546.6597483769792,
    "total_throughput": 1175.313832731459,
    "itl": 22.626101907275906,
    "ttft": 7907.320502896714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.67140556253238,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0889112730510533. Arrivals time: 0.03511268086731434 Scheduler time: 0.6880301195196807 Scheduler overhead time: 0.12948568165302277 Adapter cache time: 0.04188271006569266 Engine time: 0.13000655313953757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0953196133486927,
    "estimated_duration": 3599.003896073554,
    "input_throughput": 628.6542235945832,
    "output_throughput": 546.659869456221,
    "total_throughput": 1175.314093050804,
    "itl": 22.648363536841295,
    "ttft": 7908.0885071697585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.564649628521067,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.095604653004557. Arrivals time: 0.03527523763477802 Scheduler time: 0.6924553248099983 Scheduler overhead time: 0.1305275703780353 Adapter cache time: 0.0418986133299768 Engine time: 0.12998321000486612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0922056292183697,
    "estimated_duration": 3599.017946343689,
    "input_throughput": 628.6517693801851,
    "output_throughput": 546.6577353410396,
    "total_throughput": 1175.3095047212246,
    "itl": 22.653937018746483,
    "ttft": 7908.081726576739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.379620102966676,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0922756041400135. Arrivals time: 0.036218260414898396 Scheduler time: 0.6894967379048467 Scheduler overhead time: 0.12919288920238614 Adapter cache time: 0.04346129298210144 Engine time: 0.12980096880346537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.100432472769171,
    "estimated_duration": 3599.0010062793203,
    "input_throughput": 628.6547283683655,
    "output_throughput": 546.6603083931749,
    "total_throughput": 1175.3150367615403,
    "itl": 22.63150127605223,
    "ttft": 7907.428663271041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.802449507145976,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1005271100439131. Arrivals time: 0.03487291652709246 Scheduler time: 0.6943473569117486 Scheduler overhead time: 0.13345216028392315 Adapter cache time: 0.04239955637603998 Engine time: 0.12958088936284184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.081061420030892,
    "estimated_duration": 3599.0222156383543,
    "input_throughput": 628.6510236499604,
    "output_throughput": 546.6570868752026,
    "total_throughput": 1175.308110525163,
    "itl": 22.65398628721192,
    "ttft": 7908.017695532949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.10348403058628,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0811427212320268. Arrivals time: 0.03484513936564326 Scheduler time: 0.6849126275628805 Scheduler overhead time: 0.12834930466488004 Adapter cache time: 0.041705073323100805 Engine time: 0.12735394481569529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0784282586537302,
    "estimated_duration": 3599.0143559949493,
    "input_throughput": 628.6523965183026,
    "output_throughput": 546.6582806825461,
    "total_throughput": 1175.3106772008487,
    "itl": 22.61791890329695,
    "ttft": 7906.845690498951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.661529435494703,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0784946978092194. Arrivals time: 0.035047756507992744 Scheduler time: 0.6803327668458223 Scheduler overhead time: 0.1285013658925891 Adapter cache time: 0.04135287273675203 Engine time: 0.1292164227925241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0816028318367898,
    "estimated_duration": 3599.0051655280186,
    "input_throughput": 628.6540018533314,
    "output_throughput": 546.6596766363223,
    "total_throughput": 1175.3136784896535,
    "itl": 22.64772245994336,
    "ttft": 7907.897765508934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.78736985357627,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0816950658336282. Arrivals time: 0.03502875613048673 Scheduler time: 0.6853777426294982 Scheduler overhead time: 0.12773276306688786 Adapter cache time: 0.0415950114838779 Engine time: 0.12836421933025122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0453117173165083,
    "estimated_duration": 3599.826383202865,
    "input_throughput": 589.9734525836756,
    "output_throughput": 517.9880365066257,
    "total_throughput": 1107.9614890903013,
    "itl": 22.364186365472033,
    "ttft": 6218.535520276953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.59968783502798,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.045532674062997. Arrivals time: 0.0335313780233264 Scheduler time: 0.6492483248002827 Scheduler overhead time: 0.12963274493813515 Adapter cache time: 0.03936824854463339 Engine time: 0.12892007129266858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0362628581933677,
    "estimated_duration": 3599.8259043747294,
    "input_throughput": 589.9735310585507,
    "output_throughput": 517.9881054064149,
    "total_throughput": 1107.9616364649655,
    "itl": 22.383797932949687,
    "ttft": 6218.745244626276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.97988903977854,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.036346129141748. Arrivals time: 0.0331612778827548 Scheduler time: 0.642806495539844 Scheduler overhead time: 0.12903470220044255 Adapter cache time: 0.03918775636702776 Engine time: 0.12780621834099293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0546702472493052,
    "estimated_duration": 3599.8167249716735,
    "input_throughput": 589.975035469816,
    "output_throughput": 517.9894262574362,
    "total_throughput": 1107.9644617272522,
    "itl": 22.385228001612834,
    "ttft": 6218.861164352057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.64632349589929,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.05492347991094. Arrivals time: 0.03377408720552921 Scheduler time: 0.6573094241321087 Scheduler overhead time: 0.12961371196433902 Adapter cache time: 0.03926415368914604 Engine time: 0.1302232132293284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0552225396968424,
    "estimated_duration": 3599.824687002914,
    "input_throughput": 589.9737305730303,
    "output_throughput": 517.988280577201,
    "total_throughput": 1107.9620111502313,
    "itl": 22.372084220353592,
    "ttft": 6218.728080477942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.68079753956339,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.05545465182513. Arrivals time: 0.033700264524668455 Scheduler time: 0.6559800053946674 Scheduler overhead time: 0.13072824571281672 Adapter cache time: 0.03935674298554659 Engine time: 0.13054660521447659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.039446183014661,
    "estimated_duration": 3599.8141491744364,
    "input_throughput": 589.9754576182946,
    "output_throughput": 517.9897968976074,
    "total_throughput": 1107.9652545159022,
    "itl": 22.384713318884263,
    "ttft": 6218.883357391617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.44619793082209,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0395405828021467. Arrivals time: 0.03342487569898367 Scheduler time: 0.6448389636352658 Scheduler overhead time: 0.12956583267077804 Adapter cache time: 0.039267889223992825 Engine time: 0.12803328083828092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0413307161070406,
    "estimated_duration": 3599.8212280500693,
    "input_throughput": 589.9742974598794,
    "output_throughput": 517.9887782955384,
    "total_throughput": 1107.9630757554178,
    "itl": 22.357438427455833,
    "ttft": 6218.265690006726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.80336559971988,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.041399568784982. Arrivals time: 0.03354833135381341 Scheduler time: 0.6460042125545442 Scheduler overhead time: 0.12984060356393456 Adapter cache time: 0.03969274554401636 Engine time: 0.1278895726427436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0466923359781504,
    "estimated_duration": 3599.815436389744,
    "input_throughput": 589.9752466559679,
    "output_throughput": 517.9896116757794,
    "total_throughput": 1107.9648583317473,
    "itl": 22.382447562299063,
    "ttft": 6219.054927734241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.144122197647494,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0467740981839597. Arrivals time: 0.033402242697775364 Scheduler time: 0.6484923153184354 Scheduler overhead time: 0.1298598451539874 Adapter cache time: 0.03966290410608053 Engine time: 0.13085525576025248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9351434540003538,
    "estimated_duration": 3599.7540508305183,
    "input_throughput": 465.6193107452146,
    "output_throughput": 416.8404226543773,
    "total_throughput": 882.4597333995919,
    "itl": 22.225522426942682,
    "ttft": 5813.3948193757315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.250245084992248,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9353441172279418. Arrivals time: 0.029348539654165506 Scheduler time: 0.5405833479017019 Scheduler overhead time: 0.12962784245610237 Adapter cache time: 0.04098313022404909 Engine time: 0.13007931970059872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9322761339135468,
    "estimated_duration": 3599.738155492426,
    "input_throughput": 465.62136677708327,
    "output_throughput": 416.8422632936578,
    "total_throughput": 882.4636300707411,
    "itl": 22.24966740035275,
    "ttft": 5814.093140419725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.50692935496008,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.932341055944562. Arrivals time: 0.029049277771264315 Scheduler time: 0.5409763944335282 Scheduler overhead time: 0.1287562008947134 Adapter cache time: 0.04106998164206743 Engine time: 0.128104196395725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9367902879603207,
    "estimated_duration": 3599.756735370839,
    "input_throughput": 465.6189635068022,
    "output_throughput": 416.8401117931152,
    "total_throughput": 882.4590752999173,
    "itl": 22.256301590572924,
    "ttft": 5814.314255897556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.431560698198965,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9368824497796595. Arrivals time: 0.028960085473954678 Scheduler time: 0.5447956891730428 Scheduler overhead time: 0.1291814148426056 Adapter cache time: 0.04130801558494568 Engine time: 0.12816746113821864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9388819518499076,
    "estimated_duration": 3599.740685753507,
    "input_throughput": 465.62103949139083,
    "output_throughput": 416.84197029484267,
    "total_throughput": 882.4630097862336,
    "itl": 22.234830231220926,
    "ttft": 5813.712811750003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.34047359954672,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9389465199783444. Arrivals time: 0.0288439248688519 Scheduler time: 0.5433982168324292 Scheduler overhead time: 0.1302178092300892 Adapter cache time: 0.04097194271162152 Engine time: 0.13032386684790254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9420638689771295,
    "estimated_duration": 3599.7523113100747,
    "input_throughput": 465.6195357480036,
    "output_throughput": 416.84062408557986,
    "total_throughput": 882.4601598335835,
    "itl": 22.250667212477495,
    "ttft": 5814.161222116597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.08738830919,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9421554361470044. Arrivals time: 0.029068894684314728 Scheduler time: 0.5451284046284854 Scheduler overhead time: 0.1291681886650622 Adapter cache time: 0.04139640927314758 Engine time: 0.13230159459635615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9385991999879479,
    "estimated_duration": 3599.733751609246,
    "input_throughput": 465.62193641424165,
    "output_throughput": 416.84277325488233,
    "total_throughput": 882.464709669124,
    "itl": 22.2172981783681,
    "ttft": 5813.144912198635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.195946048901543,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.93866619002074. Arrivals time: 0.029499960597604513 Scheduler time: 0.5431057550013065 Scheduler overhead time: 0.1318113631568849 Adapter cache time: 0.04115176945924759 Engine time: 0.12822039844468236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9398203319869936,
    "estimated_duration": 3599.7476400546266,
    "input_throughput": 465.62013996474616,
    "output_throughput": 416.84116500378605,
    "total_throughput": 882.4613049685322,
    "itl": 22.249967730587716,
    "ttft": 5814.125877175166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.76532109955422,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9399414737708867. Arrivals time: 0.028601357247680426 Scheduler time: 0.5454694186337292 Scheduler overhead time: 0.13051795028150082 Adapter cache time: 0.040882959961891174 Engine time: 0.12959764432162046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9129963382147253,
    "estimated_duration": 3599.631477839894,
    "input_throughput": 435.48235691634966,
    "output_throughput": 385.63947685917617,
    "total_throughput": 821.1218337755258,
    "itl": 21.769190775234595,
    "ttft": 3417.102160234967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.639869753548435,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9130650400184095. Arrivals time: 0.028278099838644266 Scheduler time: 0.5152422012761235 Scheduler overhead time: 0.13198620127514005 Adapter cache time: 0.03912662714719772 Engine time: 0.13282211823388934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9089966430328786,
    "estimated_duration": 3599.6420282994773,
    "input_throughput": 435.4810805285951,
    "output_throughput": 385.6383465596402,
    "total_throughput": 821.1194270882353,
    "itl": 21.78628090600704,
    "ttft": 3417.4516084621764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.526270817861995,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9090697318315506. Arrivals time: 0.02834302419796586 Scheduler time: 0.5150116058066487 Scheduler overhead time: 0.13020929507911205 Adapter cache time: 0.03921405039727688 Engine time: 0.1312958998605609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9326218501664698,
    "estimated_duration": 3599.636384122488,
    "input_throughput": 435.48176335653426,
    "output_throughput": 385.6389512349045,
    "total_throughput": 821.1207145914387,
    "itl": 21.79497745252588,
    "ttft": 3417.6336220947355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.34079854277105,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9327049539424479. Arrivals time: 0.032640127930790186 Scheduler time: 0.527234127279371 Scheduler overhead time: 0.1353544401936233 Adapter cache time: 0.03925387095659971 Engine time: 0.1312079061754048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9063850729726255,
    "estimated_duration": 3599.642662677567,
    "input_throughput": 435.4810037821839,
    "output_throughput": 385.63827859719487,
    "total_throughput": 821.1192823793788,
    "itl": 21.77618305050575,
    "ttft": 3417.1641344293025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.5433435617303,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9064592816866934. Arrivals time: 0.028587609995156527 Scheduler time: 0.5123929022811353 Scheduler overhead time: 0.12923853704705834 Adapter cache time: 0.03929299209266901 Engine time: 0.13160675903782248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9122947570867836,
    "estimated_duration": 3599.6265753261155,
    "input_throughput": 435.4829500218317,
    "output_throughput": 385.640002081115,
    "total_throughput": 821.1229521029467,
    "itl": 21.793315114145546,
    "ttft": 3417.5011982858296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.057667865824428,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9123778669163585. Arrivals time: 0.028928485698997974 Scheduler time: 0.5142253823578358 Scheduler overhead time: 0.1332045360468328 Adapter cache time: 0.03899601940065622 Engine time: 0.1313063078559935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9051236077211797,
    "estimated_duration": 3599.6418527985775,
    "input_throughput": 435.48110176051887,
    "output_throughput": 385.6383653614765,
    "total_throughput": 821.1194671219954,
    "itl": 21.7610436413553,
    "ttft": 3416.939669646573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.68478953158728,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9051839248277247. Arrivals time: 0.027793799992650747 Scheduler time: 0.5120793022215366 Scheduler overhead time: 0.13003533612936735 Adapter cache time: 0.03912827791646123 Engine time: 0.13041819538921118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9041031911037862,
    "estimated_duration": 3599.6291707331466,
    "input_throughput": 435.48263602962396,
    "output_throughput": 385.6397240267029,
    "total_throughput": 821.1223600563269,
    "itl": 21.79237991948799,
    "ttft": 3417.700085956854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.76170041347061,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9041818883270025. Arrivals time: 0.0284246071241796 Scheduler time: 0.5103790392167866 Scheduler overhead time: 0.12924392661079764 Adapter cache time: 0.03905438119545579 Engine time: 0.13181794993579388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8962920112535357,
    "estimated_duration": 3597.8490282202574,
    "input_throughput": 409.5627660977527,
    "output_throughput": 373.2277228609143,
    "total_throughput": 782.790488958667,
    "itl": 21.64753437681193,
    "ttft": 6491.279429958314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.365201046558195,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8963543493300676. Arrivals time: 0.028122693300247192 Scheduler time: 0.5015147374942899 Scheduler overhead time: 0.13057536585256457 Adapter cache time: 0.038149905391037464 Engine time: 0.1328009720891714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9082821789197624,
    "estimated_duration": 3597.8424525154137,
    "input_throughput": 409.5635146474461,
    "output_throughput": 373.2284050017744,
    "total_throughput": 782.7919196492205,
    "itl": 21.667895213628427,
    "ttft": 6491.845395311022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.990645059770195,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9084007968194783. Arrivals time: 0.028176929336041212 Scheduler time: 0.5090680634602904 Scheduler overhead time: 0.13068053033202887 Adapter cache time: 0.03818618459627032 Engine time: 0.1365483170375228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8875432247295976,
    "estimated_duration": 3597.8399154593862,
    "input_throughput": 409.56380345562206,
    "output_throughput": 373.2286681878518,
    "total_throughput": 782.7924716434738,
    "itl": 21.674781867835723,
    "ttft": 6491.857234689667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.72590182691458,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8876027786172926. Arrivals time: 0.027119755279272795 Scheduler time: 0.4972268561832607 Scheduler overhead time: 0.1302327625453472 Adapter cache time: 0.03791744448244572 Engine time: 0.12999245943501592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8965103742666543,
    "estimated_duration": 3597.839487714597,
    "input_throughput": 409.5638521483954,
    "output_throughput": 373.2287125607646,
    "total_throughput": 782.79256470916,
    "itl": 21.65295612057342,
    "ttft": 6491.51120707938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.176240247651826,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8967715352773666. Arrivals time: 0.02763841301202774 Scheduler time: 0.5040063099004328 Scheduler overhead time: 0.1298168720677495 Adapter cache time: 0.03817114559933543 Engine time: 0.1316887498833239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8944533802568913,
    "estimated_duration": 3597.840908195077,
    "input_throughput": 409.5636904465659,
    "output_throughput": 373.2285652045823,
    "total_throughput": 782.7922556511481,
    "itl": 21.672006843981258,
    "ttft": 6491.831700009119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.45690848347374,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8945176852867007. Arrivals time: 0.02772650681436062 Scheduler time: 0.5010150112211704 Scheduler overhead time: 0.1313980296254158 Adapter cache time: 0.03838450834155083 Engine time: 0.13003184413537383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8990187728777528,
    "estimated_duration": 3597.841162880663,
    "input_throughput": 409.5636614541886,
    "output_throughput": 373.2285387843121,
    "total_throughput": 782.7922002385006,
    "itl": 21.64252179639125,
    "ttft": 6491.112984228485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.495104648971296,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8990895207971334. Arrivals time: 0.02758448850363493 Scheduler time: 0.5034355237148702 Scheduler overhead time: 0.13055922044441104 Adapter cache time: 0.03848625207319856 Engine time: 0.13336868956685066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8865792052820325,
    "estimated_duration": 3597.8532144569663,
    "input_throughput": 409.56228955616416,
    "output_throughput": 373.22728859650687,
    "total_throughput": 782.789578152671,
    "itl": 21.67164608954834,
    "ttft": 6491.715977974444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.2266930727485,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8868106021545827. Arrivals time: 0.027788954321295023 Scheduler time: 0.4962652334943414 Scheduler overhead time: 0.13059050031006336 Adapter cache time: 0.03768789442256093 Engine time: 0.12871070206165314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8502114028669894,
    "estimated_duration": 3599.910401652011,
    "input_throughput": 358.9906013791187,
    "output_throughput": 328.35289441024906,
    "total_throughput": 687.3434957893677,
    "itl": 21.373310987796966,
    "ttft": 4023.711097166764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.589515489315673,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8503304310142994. Arrivals time: 0.026362928561866283 Scheduler time: 0.4589887890033424 Scheduler overhead time: 0.1307224198244512 Adapter cache time: 0.03610235778614879 Engine time: 0.13233019318431616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8464610180817544,
    "estimated_duration": 3599.908178260296,
    "input_throughput": 358.9908231005319,
    "output_throughput": 328.3530972090619,
    "total_throughput": 687.3439203095938,
    "itl": 21.386382097377208,
    "ttft": 4023.90633325255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.76098517293988,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8465295727364719. Arrivals time: 0.026026311330497265 Scheduler time: 0.45479522459208965 Scheduler overhead time: 0.13096885662525892 Adapter cache time: 0.03596337977796793 Engine time: 0.13308738730847836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8460437236353755,
    "estimated_duration": 3599.9148408814185,
    "input_throughput": 358.9901586904149,
    "output_throughput": 328.3524895023861,
    "total_throughput": 687.342648192801,
    "itl": 21.39143700901355,
    "ttft": 4024.1258268448437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.3805697695079,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8461121148429811. Arrivals time: 0.025918027851730585 Scheduler time: 0.45227324590086937 Scheduler overhead time: 0.13117176853120327 Adapter cache time: 0.03620917536318302 Engine time: 0.13423725171014667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.847196142654866,
    "estimated_duration": 3599.895208688792,
    "input_throughput": 358.9921164596103,
    "output_throughput": 328.354280187656,
    "total_throughput": 687.3463966472663,
    "itl": 21.375733235981592,
    "ttft": 4023.8959975005805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.36638027868754,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8472860590554774. Arrivals time: 0.02602129941806197 Scheduler time: 0.455958338920027 Scheduler overhead time: 0.1309334607794881 Adapter cache time: 0.03627327922731638 Engine time: 0.13191999774426222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8448487180285156,
    "estimated_duration": 3599.913184521866,
    "input_throughput": 358.99032386572554,
    "output_throughput": 328.3526405809691,
    "total_throughput": 687.3429644466946,
    "itl": 21.389811514688958,
    "ttft": 4024.0765117865544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.17174378649859,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8451285171322525. Arrivals time: 0.026020783931016922 Scheduler time: 0.4535072036087513 Scheduler overhead time: 0.13151408359408379 Adapter cache time: 0.0360407498665154 Engine time: 0.13138904701918364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8476785230450332,
    "estimated_duration": 3599.9015305036,
    "input_throughput": 358.99148603078925,
    "output_throughput": 328.3537035621752,
    "total_throughput": 687.3451895929645,
    "itl": 21.367679331410326,
    "ttft": 4023.3440347027667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.843501870964463,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8477665060199797. Arrivals time: 0.02620359044522047 Scheduler time: 0.4545704103074968 Scheduler overhead time: 0.1306766360066831 Adapter cache time: 0.03604866890236735 Engine time: 0.13389151636511087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8457645480521023,
    "estimated_duration": 3599.910598252044,
    "input_throughput": 358.99058177375287,
    "output_throughput": 328.3528764780843,
    "total_throughput": 687.3434582518372,
    "itl": 21.386573813646866,
    "ttft": 4024.0458155030215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.952405199949293,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8460833933204412. Arrivals time: 0.02588835684582591 Scheduler time: 0.4524656552821398 Scheduler overhead time: 0.13086147280409932 Adapter cache time: 0.0364452013745904 Engine time: 0.13366688787937164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8240654631517828,
    "estimated_duration": 3598.529753372424,
    "input_throughput": 342.17113220921794,
    "output_throughput": 308.80667276922554,
    "total_throughput": 650.9778049784435,
    "itl": 21.339533983044195,
    "ttft": 2134.7341008746075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.295009555229587,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8241383680142462. Arrivals time: 0.02553882682695985 Scheduler time: 0.43291751109063625 Scheduler overhead time: 0.13156884536147118 Adapter cache time: 0.03507147589698434 Engine time: 0.1326256711035967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8260226617567241,
    "estimated_duration": 3598.509945310527,
    "input_throughput": 342.1730156962915,
    "output_throughput": 308.80837260103965,
    "total_throughput": 650.9813882973311,
    "itl": 21.35409991520788,
    "ttft": 2134.986561607598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.217039566691547,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8261076011694968. Arrivals time: 0.025531623512506485 Scheduler time: 0.43438736675307155 Scheduler overhead time: 0.13130889693275094 Adapter cache time: 0.03488205745816231 Engine time: 0.13366265268996358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8298871489241719,
    "estimated_duration": 3598.5105198655233,
    "input_throughput": 342.1729610633497,
    "output_throughput": 308.8083232952526,
    "total_throughput": 650.9812843586024,
    "itl": 21.355801254816896,
    "ttft": 2135.136358234264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2917,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.777329767817033,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8302502739243209. Arrivals time: 0.02538147009909153 Scheduler time: 0.43499712320044637 Scheduler overhead time: 0.1320710564032197 Adapter cache time: 0.035309101920574903 Engine time: 0.13528555864468217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8247411912307143,
    "estimated_duration": 3598.509945310527,
    "input_throughput": 342.1730156962915,
    "output_throughput": 308.80837260103965,
    "total_throughput": 650.9813882973311,
    "itl": 21.34399483253357,
    "ttft": 2134.9350202360138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2920,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.011223247126214,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8248307630419731. Arrivals time: 0.02553780097514391 Scheduler time: 0.43372370675206184 Scheduler overhead time: 0.13099080650135875 Adapter cache time: 0.03543358203023672 Engine time: 0.1326609654352069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8220108128152788,
    "estimated_duration": 3598.5105198655233,
    "input_throughput": 342.1729610633497,
    "output_throughput": 308.8083232952526,
    "total_throughput": 650.9812843586024,
    "itl": 21.35570668637527,
    "ttft": 2135.072118919483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.58512652443288,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8220792389474809. Arrivals time: 0.025501365307718515 Scheduler time: 0.4316233592107892 Scheduler overhead time: 0.1313991453498602 Adapter cache time: 0.0351139004342258 Engine time: 0.13160568848252296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8314239648170769,
    "estimated_duration": 3598.5288394200593,
    "input_throughput": 342.17121911365285,
    "output_throughput": 308.80675119977354,
    "total_throughput": 650.9779703134263,
    "itl": 21.330478329086898,
    "ttft": 2134.4465129973737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.628281304586192,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8315011188387871. Arrivals time: 0.02511900756508112 Scheduler time: 0.4347845851443708 Scheduler overhead time: 0.13205787353217602 Adapter cache time: 0.03521455265581608 Engine time: 0.1374799315817654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.821332510560751,
    "estimated_duration": 3598.51010563117,
    "input_throughput": 342.17300045181634,
    "output_throughput": 308.8083588430244,
    "total_throughput": 650.9813592948408,
    "itl": 21.354546666902948,
    "ttft": 2134.9601321205305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.3953523286435,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8214128259569407. Arrivals time: 0.025119884870946407 Scheduler time: 0.4310191594995558 Scheduler overhead time: 0.13183061638846993 Adapter cache time: 0.0349629670381546 Engine time: 0.13207422150298953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7944460608996451,
    "estimated_duration": 3599.4210626645727,
    "input_throughput": 316.84678734300087,
    "output_throughput": 274.13464077179907,
    "total_throughput": 590.9814281148,
    "itl": 21.047811365451885,
    "ttft": 3885.6012146371554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.168866319293578,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7947764238342643. Arrivals time: 0.02433484001085162 Scheduler time: 0.4018976893275976 Scheduler overhead time: 0.13330976525321603 Adapter cache time: 0.033090661745518446 Engine time: 0.13440711377188563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7969477749429643,
    "estimated_duration": 3599.41304484536,
    "input_throughput": 316.8474931303688,
    "output_throughput": 274.13525141635756,
    "total_throughput": 590.9827445467264,
    "itl": 21.055869868559963,
    "ttft": 3886.005717459236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.663471263670086,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7972902855835855. Arrivals time: 0.024465329945087433 Scheduler time: 0.4012912265025079 Scheduler overhead time: 0.13326651230454445 Adapter cache time: 0.03345535974949598 Engine time: 0.13665773160755634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7898273062892258,
    "estimated_duration": 3599.4136352276946,
    "input_throughput": 316.8474411604699,
    "output_throughput": 274.13520645219785,
    "total_throughput": 590.9826476126677,
    "itl": 21.05961047181754,
    "ttft": 3886.1101134459655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.102303703296744,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7901931521482766. Arrivals time: 0.024259396828711033 Scheduler time: 0.39829589892178774 Scheduler overhead time: 0.13257519342005253 Adapter cache time: 0.033343690913170576 Engine time: 0.13426469825208187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7953424598090351,
    "estimated_duration": 3599.4093165259087,
    "input_throughput": 316.84782132551635,
    "output_throughput": 274.13553536955664,
    "total_throughput": 590.983356695073,
    "itl": 21.053266918160894,
    "ttft": 3885.876266834523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.77944835679165,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7954023079946637. Arrivals time: 0.024388260208070278 Scheduler time: 0.40419394290074706 Scheduler overhead time: 0.13256846740841866 Adapter cache time: 0.03304469492286444 Engine time: 0.13414402585476637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7936219158582389,
    "estimated_duration": 3599.406066845355,
    "input_throughput": 316.8481073877678,
    "output_throughput": 274.13578286953356,
    "total_throughput": 590.9838902573014,
    "itl": 21.058618931588633,
    "ttft": 3886.0719411176387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.976374963400684,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7936918889172375. Arrivals time: 0.02411534171551466 Scheduler time: 0.400464060716331 Scheduler overhead time: 0.13330871751531959 Adapter cache time: 0.03303218958899379 Engine time: 0.1354959891177714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7956645227968693,
    "estimated_duration": 3599.415961717646,
    "input_throughput": 316.84723636547096,
    "output_throughput": 274.1350292643402,
    "total_throughput": 590.9822656298111,
    "itl": 21.044697231217754,
    "ttft": 3885.5751977257137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.625562874847935,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7957255030050874. Arrivals time: 0.024276780895888805 Scheduler time: 0.39898667531087995 Scheduler overhead time: 0.13239468168467283 Adapter cache time: 0.033159810584038496 Engine time: 0.1398732722736895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8048126860521734,
    "estimated_duration": 3599.419629703608,
    "input_throughput": 316.84691348252466,
    "output_throughput": 274.1347499072375,
    "total_throughput": 590.9816633897622,
    "itl": 21.057022874646105,
    "ttft": 3886.043958560773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.79038673182927,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8048972450196743. Arrivals time: 0.024174350779503584 Scheduler time: 0.40842010313645005 Scheduler overhead time: 0.1363432421348989 Adapter cache time: 0.03328838525339961 Engine time: 0.13385554356500506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7119086422026157,
    "estimated_duration": 3599.8548290980157,
    "input_throughput": 222.0747885548229,
    "output_throughput": 200.40224793752577,
    "total_throughput": 422.4770364923487,
    "itl": 20.6336502941234,
    "ttft": 4400.667742354198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.036618138654575,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7120048440992832. Arrivals time: 0.021332642063498497 Scheduler time: 0.3228760175406933 Scheduler overhead time: 0.1333620622754097 Adapter cache time: 0.030926406383514404 Engine time: 0.13588228961452842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7100691767409444,
    "estimated_duration": 3599.862486823282,
    "input_throughput": 222.07431615130042,
    "output_throughput": 200.40182163642038,
    "total_throughput": 422.4761377877208,
    "itl": 20.648265745839524,
    "ttft": 4401.393306604171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.57771332717936,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7101797969080508. Arrivals time: 0.02116707945242524 Scheduler time: 0.32362685864791274 Scheduler overhead time: 0.13256806414574385 Adapter cache time: 0.030950075946748257 Engine time: 0.13460261980071664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7075954438187182,
    "estimated_duration": 3599.858853617367,
    "input_throughput": 222.07454028278772,
    "output_throughput": 200.4020238946514,
    "total_throughput": 422.4765641774391,
    "itl": 20.648252555986115,
    "ttft": 4401.416101369374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.017210564980992,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7077311868779361. Arrivals time: 0.021210244856774807 Scheduler time: 0.3208536207675934 Scheduler overhead time: 0.1320860437117517 Adapter cache time: 0.030866303015500307 Engine time: 0.13515977002680302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.70083530806005,
    "estimated_duration": 3599.860865156739,
    "input_throughput": 222.07441619141363,
    "output_throughput": 200.40191191350092,
    "total_throughput": 422.47632810491456,
    "itl": 20.640443244492197,
    "ttft": 4401.0783130619375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.574586747400737,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.700930162332952. Arrivals time: 0.020613945089280605 Scheduler time: 0.319033941719681 Scheduler overhead time: 0.1312498738989234 Adapter cache time: 0.030481256544589996 Engine time: 0.13280918961390853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7056857538409531,
    "estimated_duration": 3599.845351899891,
    "input_throughput": 222.07537320404086,
    "output_throughput": 200.40277553013675,
    "total_throughput": 422.4781487341776,
    "itl": 20.65021157547753,
    "ttft": 4401.294661338375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.868500432171622,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7057500937953591. Arrivals time: 0.02101842174306512 Scheduler time: 0.32131936540827155 Scheduler overhead time: 0.1313197873532772 Adapter cache time: 0.030834218487143517 Engine time: 0.13466160232201219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.709929053671658,
    "estimated_duration": 3599.8478026893745,
    "input_throughput": 222.07522201431865,
    "output_throughput": 200.40263909519794,
    "total_throughput": 422.4778611095166,
    "itl": 20.631251696138083,
    "ttft": 4400.767121373777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.517036218858221,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7100642309524119. Arrivals time: 0.021523446310311556 Scheduler time: 0.3242286238819361 Scheduler overhead time: 0.13095484534278512 Adapter cache time: 0.030777424573898315 Engine time: 0.13519095350056887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.72593640582636,
    "estimated_duration": 3599.8525174859674,
    "input_throughput": 222.07493115809746,
    "output_throughput": 200.4023766239785,
    "total_throughput": 422.47730778207597,
    "itl": 20.64669270667367,
    "ttft": 4401.380534078779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.70094413280461,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7260139752179384. Arrivals time: 0.021142632234841585 Scheduler time: 0.3362330007366836 Scheduler overhead time: 0.135025292634964 Adapter cache time: 0.030942726880311966 Engine time: 0.1336119300685823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6895023239776492,
    "estimated_duration": 3599.375201644547,
    "input_throughput": 200.28420478938213,
    "output_throughput": 182.7947805217376,
    "total_throughput": 383.0789853111197,
    "itl": 20.587145913319482,
    "ttft": 5889.789164695964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.198368427772433,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6895871968008578. Arrivals time: 0.020493757911026478 Scheduler time: 0.30751411244273186 Scheduler overhead time: 0.13064296636730433 Adapter cache time: 0.029868034180253744 Engine time: 0.13407176779583097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6835947101935744,
    "estimated_duration": 3599.371147493142,
    "input_throughput": 200.28443037948023,
    "output_throughput": 182.79498641262407,
    "total_throughput": 383.07941679210427,
    "itl": 20.766190388920712,
    "ttft": 5890.221349829264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.47121744844576,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6836677649989724. Arrivals time: 0.020396308042109013 Scheduler time: 0.3024234692566097 Scheduler overhead time: 0.13011443195864558 Adapter cache time: 0.02971888752654195 Engine time: 0.1340528023429215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6888669389300048,
    "estimated_duration": 3599.3719926716744,
    "input_throughput": 200.28438335013695,
    "output_throughput": 182.79494349002573,
    "total_throughput": 383.0793268401627,
    "itl": 20.76824014603243,
    "ttft": 5890.5071599856265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.853638040851536,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6889297869056463. Arrivals time: 0.020369831938296556 Scheduler time: 0.30907735042274 Scheduler overhead time: 0.12970829475671053 Adapter cache time: 0.029720063786953688 Engine time: 0.13374593062326312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.6905137780122459,
    "estimated_duration": 3599.3749904488823,
    "input_throughput": 200.28421654118787,
    "output_throughput": 182.79479124734004,
    "total_throughput": 383.0790077885279,
    "itl": 20.590295932302933,
    "ttft": 5889.66795793381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.661308481712108,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6905782939866185. Arrivals time: 0.020313402637839317 Scheduler time: 0.30700383661314845 Scheduler overhead time: 0.13116608327254653 Adapter cache time: 0.030231914948672056 Engine time: 0.13485205313190818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6833358812145889,
    "estimated_duration": 3599.371578437321,
    "input_throughput": 200.2844063999028,
    "output_throughput": 182.79496452701608,
    "total_throughput": 383.07937092691884,
    "itl": 20.76522035736945,
    "ttft": 5890.431928884188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.715076649696305,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6834230590611696. Arrivals time: 0.020522361621260643 Scheduler time: 0.3032473810017109 Scheduler overhead time: 0.13001585518941283 Adapter cache time: 0.029839031398296356 Engine time: 0.1331722098402679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6903948751278222,
    "estimated_duration": 3599.373602227909,
    "input_throughput": 200.2842937876148,
    "output_throughput": 182.79486174837467,
    "total_throughput": 383.0791555359895,
    "itl": 20.585672518361303,
    "ttft": 5889.569699454934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.735922276438805,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6904671401716769. Arrivals time: 0.02038108604028821 Scheduler time: 0.3050482594408095 Scheduler overhead time: 0.13110256753861904 Adapter cache time: 0.029984699096530676 Engine time: 0.13658374035730958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6823886521160603,
    "estimated_duration": 3599.3713713201446,
    "input_throughput": 200.28441792478768,
    "output_throughput": 182.79497504551307,
    "total_throughput": 383.0793929703008,
    "itl": 20.764133789407712,
    "ttft": 5890.236863468621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.577345223761839,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6824519359506667. Arrivals time: 0.020055152475833893 Scheduler time: 0.30443856166675687 Scheduler overhead time: 0.12939487770199776 Adapter cache time: 0.02972565544769168 Engine time: 0.1326680164784193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6610211692750454,
    "estimated_duration": 3599.4398998951733,
    "input_throughput": 173.11943450372584,
    "output_throughput": 160.74056411300268,
    "total_throughput": 333.85999861672855,
    "itl": 20.37550599631811,
    "ttft": 16710.23728641073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.064086546628062,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6610817899927497. Arrivals time: 0.019663361366838217 Scheduler time: 0.2843951159156859 Scheduler overhead time: 0.12947499938309193 Adapter cache time: 0.027890182565897703 Engine time: 0.1327964337542653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6634700237773359,
    "estimated_duration": 3599.4498200952085,
    "input_throughput": 173.1189573809693,
    "output_throughput": 160.74012110681298,
    "total_throughput": 333.85907848778226,
    "itl": 20.382134005267574,
    "ttft": 16710.560527430065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.087889993181362,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6635930319316685. Arrivals time: 0.01918118493631482 Scheduler time: 0.2836887459270656 Scheduler overhead time: 0.13058791402727365 Adapter cache time: 0.028304978273808956 Engine time: 0.1351832370273769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6622537518851459,
    "estimated_duration": 3599.4417291993705,
    "input_throughput": 173.119346521163,
    "output_throughput": 160.7404824216153,
    "total_throughput": 333.85982894277834,
    "itl": 20.385536018688473,
    "ttft": 16710.368093595505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.379281060006347,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6623378260992467. Arrivals time: 0.019359595607966185 Scheduler time: 0.28223917772993445 Scheduler overhead time: 0.12988568097352982 Adapter cache time: 0.028370569460093975 Engine time: 0.1356336227618158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.6577866487205029,
    "estimated_duration": 3599.4357805082136,
    "input_throughput": 173.11963263087256,
    "output_throughput": 160.74074807310754,
    "total_throughput": 333.8603807039801,
    "itl": 20.37934716169559,
    "ttft": 16710.34403724174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.447920124484325,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6578562627546489. Arrivals time: 0.019108321983367205 Scheduler time: 0.28057117853313684 Scheduler overhead time: 0.13036251533776522 Adapter cache time: 0.028136861976236105 Engine time: 0.13280628947541118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6553967888467014,
    "estimated_duration": 3599.4361584875924,
    "input_throughput": 173.11961445145548,
    "output_throughput": 160.74073119360602,
    "total_throughput": 333.8603456450615,
    "itl": 20.386294371678968,
    "ttft": 16710.53792205076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.283800041586971,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6554608861915767. Arrivals time: 0.01910885563120246 Scheduler time: 0.278426680713892 Scheduler overhead time: 0.13009398244321346 Adapter cache time: 0.028067865874618292 Engine time: 0.1330945510417223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6659317086450756,
    "estimated_duration": 3599.444624627256,
    "input_throughput": 173.11920726229513,
    "output_throughput": 160.7403531204248,
    "total_throughput": 333.8595603827199,
    "itl": 20.375901401518732,
    "ttft": 16710.01555214655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.71632767154854,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.66599236195907. Arrivals time: 0.019065491389483213 Scheduler time: 0.28243436524644494 Scheduler overhead time: 0.1313919136300683 Adapter cache time: 0.028000896330922842 Engine time: 0.13824683846905828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6714547513984144,
    "estimated_duration": 3599.4303662871807,
    "input_throughput": 173.11989303539795,
    "output_throughput": 160.74098985745965,
    "total_throughput": 333.8608828928576,
    "itl": 20.38585297191813,
    "ttft": 16710.54423146293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.174649289511033,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6715661981143057. Arrivals time: 0.01942248735576868 Scheduler time: 0.28650525072589517 Scheduler overhead time: 0.13511751778423786 Adapter cache time: 0.02784615522250533 Engine time: 0.13490321347489953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.536025115288794,
    "estimated_duration": 3599.2892030640714,
    "input_throughput": 116.92308571418471,
    "output_throughput": 96.55239698553719,
    "total_throughput": 213.4754826997219,
    "itl": 19.88416394537791,
    "ttft": 8789.63038495077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.227363071921447,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5360887493006885. Arrivals time: 0.015756205189973116 Scheduler time: 0.20125245489180088 Scheduler overhead time: 0.11604858003556728 Adapter cache time: 0.02349324245005846 Engine time: 0.11945660039782524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5462584174238145,
    "estimated_duration": 3599.284088128588,
    "input_throughput": 116.92325187335007,
    "output_throughput": 96.55253419595716,
    "total_throughput": 213.47578606930725,
    "itl": 19.888895602027667,
    "ttft": 8789.960094858301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.981309351748798,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.546374561265111. Arrivals time: 0.016165846027433872 Scheduler time: 0.20916007366031408 Scheduler overhead time: 0.11743485275655985 Adapter cache time: 0.02351219765841961 Engine time: 0.1198316034860909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5438616760075092,
    "estimated_duration": 3599.2888608216153,
    "input_throughput": 116.92309683194868,
    "output_throughput": 96.55240616633117,
    "total_throughput": 213.47550299827984,
    "itl": 19.890225524813957,
    "ttft": 8790.230899628476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.194889831417242,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5439195679500699. Arrivals time: 0.015802270267158747 Scheduler time: 0.20544727891683578 Scheduler overhead time: 0.11888909433037043 Adapter cache time: 0.023225145880132914 Engine time: 0.11985956411808729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.537763390224427,
    "estimated_duration": 3599.291666239158,
    "input_throughput": 116.92300569787636,
    "output_throughput": 96.55233090990875,
    "total_throughput": 213.4753366077851,
    "itl": 19.885586315389524,
    "ttft": 8789.722850844351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.494043790115963,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5378245981410146. Arrivals time: 0.015647127758711576 Scheduler time: 0.20061506051570177 Scheduler overhead time: 0.11729656904935837 Adapter cache time: 0.023466245736926794 Engine time: 0.12080399040132761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5516917370259762,
    "estimated_duration": 3599.286789649849,
    "input_throughput": 116.92316411411628,
    "output_throughput": 96.55246172639883,
    "total_throughput": 213.4756258405151,
    "itl": 19.889721552005767,
    "ttft": 8790.104970439514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.122191702425486,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5517668928951025. Arrivals time: 0.01572796143591404 Scheduler time: 0.20668536191806197 Scheduler overhead time: 0.11690234672278166 Adapter cache time: 0.02350190421566367 Engine time: 0.12869673548266292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.5407400927506387,
    "estimated_duration": 3599.284333775169,
    "input_throughput": 116.92324389348673,
    "output_throughput": 96.55252760636942,
    "total_throughput": 213.47577149985614,
    "itl": 19.88265144842732,
    "ttft": 8789.633909256627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.977625588043558,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5408180449157953. Arrivals time: 0.015744832810014486 Scheduler time: 0.20594544569030404 Scheduler overhead time: 0.1169905448332429 Adapter cache time: 0.023424226325005293 Engine time: 0.1186391287483275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5399070670828223,
    "estimated_duration": 3599.285457073026,
    "input_throughput": 116.92320740301359,
    "output_throughput": 96.55249747337535,
    "total_throughput": 213.47570487638896,
    "itl": 19.88926466545574,
    "ttft": 8790.10418058964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.04514411272482,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5400057341903448. Arrivals time: 0.015595476608723402 Scheduler time: 0.20171135244891047 Scheduler overhead time: 0.117559265345335 Adapter cache time: 0.023523445706814528 Engine time: 0.12128371372818947 
