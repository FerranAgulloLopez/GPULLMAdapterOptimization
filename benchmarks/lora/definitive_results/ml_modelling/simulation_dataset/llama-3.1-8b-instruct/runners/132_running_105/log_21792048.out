INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5447889608331025,
    "estimated_duration": 3599.6204824471342,
    "input_throughput": 1078.1583833420132,
    "output_throughput": 964.9092222185428,
    "total_throughput": 2043.067605560556,
    "itl": 27.69405019130277,
    "ttft": 6546.025523270994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 77.40326211861168,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5449043936096132. Arrivals time: 0.049627617467194796 Scheduler time: 1.1274814624339342 Scheduler overhead time: 0.1136306133121252 Adapter cache time: 0.08183019375428557 Engine time: 0.11641630716621876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.5409750482067466,
    "estimated_duration": 3599.636677652576,
    "input_throughput": 1078.1535325756497,
    "output_throughput": 964.904880973999,
    "total_throughput": 2043.0584135496485,
    "itl": 27.768945487902535,
    "ttft": 6551.777468545757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 84.47742066854994,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.541058064904064. Arrivals time: 0.048980922903865576 Scheduler time: 1.1316682775504887 Scheduler overhead time: 0.11200202768668532 Adapter cache time: 0.0818568472750485 Engine time: 0.11133184330537915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.5211296048946679,
    "estimated_duration": 3599.626154654638,
    "input_throughput": 1078.1566844050099,
    "output_throughput": 964.907701736944,
    "total_throughput": 2043.064386141954,
    "itl": 27.638175277320094,
    "ttft": 6541.965314342136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 72.189377995971,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5212113820016384. Arrivals time: 0.04802055470645428 Scheduler time: 1.1117336605675519 Scheduler overhead time: 0.11403367249295115 Adapter cache time: 0.08087032940238714 Engine time: 0.11046719737350941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.535012505017221,
    "estimated_duration": 3599.6197249207453,
    "input_throughput": 1078.158610236377,
    "output_throughput": 964.9094252800478,
    "total_throughput": 2043.0680355164247,
    "itl": 27.760277862139507,
    "ttft": 6550.941329216698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.6914643487928,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5350845879875124. Arrivals time: 0.04882430378347635 Scheduler time: 1.1245844503864646 Scheduler overhead time: 0.11182685242965817 Adapter cache time: 0.08108750451356173 Engine time: 0.1135609676130116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.4912863853387535,
    "estimated_duration": 3599.6798750551447,
    "input_throughput": 1045.5276943043011,
    "output_throughput": 920.2240518538484,
    "total_throughput": 1965.7517461581494,
    "itl": 27.242283189360307,
    "ttft": 7668.164905889835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 70.0452488754473,
    "arrivals": 15306,
    "finished_requests": 15274,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4913588552735746. Arrivals time: 0.04722210392355919 Scheduler time: 1.0834586871787906 Scheduler overhead time: 0.11399967735633254 Adapter cache time: 0.07866632333025336 Engine time: 0.11200248962268233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4963924959301949,
    "estimated_duration": 3599.703307929748,
    "input_throughput": 1045.5208882657864,
    "output_throughput": 920.2180615004861,
    "total_throughput": 1965.7389497662725,
    "itl": 27.133796927443502,
    "ttft": 7640.485194642281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.07811210872818,
    "arrivals": 15306,
    "finished_requests": 15274,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4964664028957486. Arrivals time: 0.04772895993664861 Scheduler time: 1.0830170651897788 Scheduler overhead time: 0.11362321628257632 Adapter cache time: 0.07911552349105477 Engine time: 0.11708323517814279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.5371988001279533,
    "estimated_duration": 3599.6984133456403,
    "input_throughput": 1045.5223098820823,
    "output_throughput": 920.2193127399462,
    "total_throughput": 1965.7416226220284,
    "itl": 27.157632192022565,
    "ttft": 7641.20711724642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 80.24393801580828,
    "arrivals": 15306,
    "finished_requests": 15274,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.537275259848684. Arrivals time: 0.048446561209857464 Scheduler time: 1.1257072696462274 Scheduler overhead time: 0.1125748478807509 Adapter cache time: 0.08013380412012339 Engine time: 0.1143451351672411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5321494871750474,
    "estimated_duration": 3599.6906040578033,
    "input_throughput": 1045.5245780727562,
    "output_throughput": 920.2213090941547,
    "total_throughput": 1965.745887166911,
    "itl": 27.262738606882575,
    "ttft": 7669.372176926819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 72.4245116121318,
    "arrivals": 15306,
    "finished_requests": 15274,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5322220460511744. Arrivals time: 0.04836726002395153 Scheduler time: 1.1207022643648088 Scheduler overhead time: 0.11233755061402917 Adapter cache time: 0.0797595358453691 Engine time: 0.11529828468337655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.524672629777342,
    "estimated_duration": 3599.700867557464,
    "input_throughput": 1045.5215970636261,
    "output_throughput": 920.2186853508379,
    "total_throughput": 1965.740282414464,
    "itl": 27.148661918022718,
    "ttft": 7641.022755592236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.45394123521783,
    "arrivals": 15306,
    "finished_requests": 15274,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5247475327923894. Arrivals time: 0.04791182233020663 Scheduler time: 1.11438192659989 Scheduler overhead time: 0.11298532038927078 Adapter cache time: 0.07980123860761523 Engine time: 0.11366907693445683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.548836585599929,
    "estimated_duration": 3599.686017008085,
    "input_throughput": 1045.5259103759624,
    "output_throughput": 920.2224817244554,
    "total_throughput": 1965.7483921004177,
    "itl": 27.214697507732176,
    "ttft": 7666.72061765208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.6312584444081,
    "arrivals": 15306,
    "finished_requests": 15274,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5489106657914817. Arrivals time: 0.048307590652257204 Scheduler time: 1.1267117848619819 Scheduler overhead time: 0.11908568302169442 Adapter cache time: 0.08194736624136567 Engine time: 0.11656770016998053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.5306430952623487,
    "estimated_duration": 3599.703835933721,
    "input_throughput": 1045.5207349089526,
    "output_throughput": 920.2179265230504,
    "total_throughput": 1965.738661432003,
    "itl": 27.14006402058307,
    "ttft": 7640.708718359013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.7136544322793,
    "arrivals": 15306,
    "finished_requests": 15274,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.530716577079147. Arrivals time: 0.04808759456500411 Scheduler time: 1.1187326679937541 Scheduler overhead time: 0.11327952751889825 Adapter cache time: 0.07971791550517082 Engine time: 0.1147248256020248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3892450486309826,
    "estimated_duration": 3599.8794996367246,
    "input_throughput": 915.2884146073505,
    "output_throughput": 810.2899000631434,
    "total_throughput": 1725.578314670494,
    "itl": 25.83017237325946,
    "ttft": 7257.479553141701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.04728641914249,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3893201369792223. Arrivals time: 0.04436755133792758 Scheduler time: 0.9737712685018778 Scheduler overhead time: 0.11813715752214193 Adapter cache time: 0.07288426160812378 Engine time: 0.12147020222619176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3651527520269156,
    "estimated_duration": 3599.876897610292,
    "input_throughput": 915.2890761868201,
    "output_throughput": 810.2904857486537,
    "total_throughput": 1725.5795619354737,
    "itl": 25.895884308328018,
    "ttft": 7258.22985155333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9082,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.61628087821258,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3652257407084107. Arrivals time: 0.043475630693137646 Scheduler time: 0.9563850127160549 Scheduler overhead time: 0.11760618956759572 Adapter cache time: 0.07202997617423534 Engine time: 0.11753378761932254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3922181716188788,
    "estimated_duration": 3599.8806442854907,
    "input_throughput": 915.2881235744364,
    "output_throughput": 810.2896424164528,
    "total_throughput": 1725.5777659908892,
    "itl": 25.908708051795085,
    "ttft": 7258.540491280071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.44526875074169,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3922926178202033. Arrivals time: 0.044100633822381496 Scheduler time: 0.9803730580024421 Scheduler overhead time: 0.1175540229305625 Adapter cache time: 0.07255216268822551 Engine time: 0.11950153484940529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.355025858618319,
    "estimated_duration": 3599.880843470501,
    "input_throughput": 915.2880729306283,
    "output_throughput": 810.2895975823159,
    "total_throughput": 1725.5776705129442,
    "itl": 25.85473515654718,
    "ttft": 7257.699141927105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.21646090754525,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.355111960787326. Arrivals time: 0.04326772829517722 Scheduler time: 0.9470629817806184 Scheduler overhead time: 0.11766271898522973 Adapter cache time: 0.07233691122382879 Engine time: 0.11643488937988877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.3716373560018837,
    "estimated_duration": 3599.8858595036677,
    "input_throughput": 915.2867975803784,
    "output_throughput": 810.2884685355475,
    "total_throughput": 1725.5752661159258,
    "itl": 25.908829636569926,
    "ttft": 7258.4062014666015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9077,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.77053734785521,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3717080540955067. Arrivals time: 0.04382659774273634 Scheduler time: 0.9612978012301028 Scheduler overhead time: 0.11607487453147769 Adapter cache time: 0.07175165647640824 Engine time: 0.12082305317744613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3682302008382976,
    "estimated_duration": 3599.8767954252826,
    "input_throughput": 915.2891021679378,
    "output_throughput": 810.2905087493133,
    "total_throughput": 1725.579610917251,
    "itl": 25.81017972675481,
    "ttft": 7257.250987763193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.01068958697107,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.368333535734564. Arrivals time: 0.044224908109754324 Scheduler time: 0.9533053757622838 Scheduler overhead time: 0.12330759549513459 Adapter cache time: 0.07124736160039902 Engine time: 0.11768037267029285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3682734589092433,
    "estimated_duration": 3599.875329531073,
    "input_throughput": 915.2894748800103,
    "output_throughput": 810.2908387052302,
    "total_throughput": 1725.5803135852404,
    "itl": 25.899348370462214,
    "ttft": 7258.393064280545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.15192721725987,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3683298211544752. Arrivals time: 0.04370175674557686 Scheduler time: 0.9599485322833061 Scheduler overhead time: 0.11739705735817552 Adapter cache time: 0.07184981321915984 Engine time: 0.11731719085946679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.324557245709002,
    "estimated_duration": 3599.6299708615497,
    "input_throughput": 874.2840307129571,
    "output_throughput": 765.5328526283092,
    "total_throughput": 1639.8168833412665,
    "itl": 25.278478889325612,
    "ttft": 5358.111802593409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.34738983359993,
    "arrivals": 12878,
    "finished_requests": 12859,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.324639251921326. Arrivals time: 0.04269566619768739 Scheduler time: 0.914306310005486 Scheduler overhead time: 0.1194334621541202 Adapter cache time: 0.06799426255747676 Engine time: 0.12067604251205921 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3201779960654676,
    "estimated_duration": 3599.630623577145,
    "input_throughput": 874.2838721803516,
    "output_throughput": 765.532713815391,
    "total_throughput": 1639.8165859957426,
    "itl": 25.334605068427493,
    "ttft": 5358.622500139962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.35315311799061,
    "arrivals": 12878,
    "finished_requests": 12859,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3202525009401143. Arrivals time: 0.04211557982489467 Scheduler time: 0.9109065150842071 Scheduler overhead time: 0.12022084649652243 Adapter cache time: 0.06803936045616865 Engine time: 0.11971486546099186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3375545456074178,
    "estimated_duration": 3599.6285388697333,
    "input_throughput": 874.2843785176162,
    "output_throughput": 765.5331571699497,
    "total_throughput": 1639.817535687566,
    "itl": 25.351674042645538,
    "ttft": 5358.885407656667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.0674743029892,
    "arrivals": 12878,
    "finished_requests": 12859,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3376278360374272. Arrivals time: 0.042423613369464874 Scheduler time: 0.9227610188536346 Scheduler overhead time: 0.12356921657919884 Adapter cache time: 0.06847568973898888 Engine time: 0.1200126619078219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.3076865612529218,
    "estimated_duration": 3599.633623630759,
    "input_throughput": 874.2831435232813,
    "output_throughput": 765.5320757951298,
    "total_throughput": 1639.8152193184112,
    "itl": 25.294989077579384,
    "ttft": 5358.229183386329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.314261122701794,
    "arrivals": 12878,
    "finished_requests": 12859,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3077627643942833. Arrivals time: 0.04183322237804532 Scheduler time: 0.9023307668976486 Scheduler overhead time: 0.11890753032639623 Adapter cache time: 0.06758410949259996 Engine time: 0.11782067408785224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.3163163037970662,
    "estimated_duration": 3599.643794211109,
    "input_throughput": 874.2806732880391,
    "output_throughput": 765.5299128295887,
    "total_throughput": 1639.8105861176277,
    "itl": 25.347209223491276,
    "ttft": 5358.667146290793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.44607389719209,
    "arrivals": 12878,
    "finished_requests": 12859,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3164053070358932. Arrivals time: 0.04226950882002711 Scheduler time: 0.9080024687573314 Scheduler overhead time: 0.11881163623183966 Adapter cache time: 0.0680736075155437 Engine time: 0.12001392990350723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3152458840049803,
    "estimated_duration": 3599.637917621414,
    "input_throughput": 874.2821005951496,
    "output_throughput": 765.5311625956206,
    "total_throughput": 1639.8132631907702,
    "itl": 25.262254447507267,
    "ttft": 5357.772120350157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.48859797337682,
    "arrivals": 12878,
    "finished_requests": 12859,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.315296741668135. Arrivals time: 0.042154389433562756 Scheduler time: 0.9042868446558714 Scheduler overhead time: 0.12062675226479769 Adapter cache time: 0.06815404631197453 Engine time: 0.120021793525666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3431901880539954,
    "estimated_duration": 3599.6292945201944,
    "input_throughput": 874.2841949838855,
    "output_throughput": 765.5329964657672,
    "total_throughput": 1639.8171914496527,
    "itl": 25.340314717173555,
    "ttft": 5358.7310233893595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.8748965930705,
    "arrivals": 12878,
    "finished_requests": 12859,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3432426759973168. Arrivals time: 0.04293892998248339 Scheduler time: 0.9189419676549733 Scheduler overhead time: 0.12460921704769135 Adapter cache time: 0.06919166445732117 Engine time: 0.12655275966972113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.2326694899238646,
    "estimated_duration": 3599.8701550967708,
    "input_throughput": 794.6739401002365,
    "output_throughput": 689.825158411372,
    "total_throughput": 1484.4990985116083,
    "itl": 24.549548939421626,
    "ttft": 6538.090563671308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6897,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.60578509335948,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2327428739517927. Arrivals time: 0.03961525158956647 Scheduler time: 0.8269574446603656 Scheduler overhead time: 0.1219697524793446 Adapter cache time: 0.06250441633164883 Engine time: 0.12101358873769641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.2350975722074509,
    "estimated_duration": 3599.8805033915833,
    "input_throughput": 794.6716557132396,
    "output_throughput": 689.823175424964,
    "total_throughput": 1484.4948311382036,
    "itl": 24.593119806765273,
    "ttft": 6538.619792920129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.66948031166379,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2351729380898178. Arrivals time: 0.03900944907218218 Scheduler time: 0.8292152490466833 Scheduler overhead time: 0.12138337315991521 Adapter cache time: 0.0625701523385942 Engine time: 0.12240190338343382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.241175034083426,
    "estimated_duration": 3599.8849191095305,
    "input_throughput": 794.6706809471093,
    "output_throughput": 689.8223292688662,
    "total_throughput": 1484.4930102159753,
    "itl": 24.602163225296046,
    "ttft": 6538.547747101411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.051135557919714,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.241251029074192. Arrivals time: 0.039669495075941086 Scheduler time: 0.8317575952969491 Scheduler overhead time: 0.12330907303839922 Adapter cache time: 0.06309470161795616 Engine time: 0.12209886219352484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.2442250410094857,
    "estimated_duration": 3599.8861898191813,
    "input_throughput": 794.6704004394348,
    "output_throughput": 689.8220857711984,
    "total_throughput": 1484.4924862106332,
    "itl": 24.56571229207389,
    "ttft": 6538.259176446199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.2711153689974,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2442978699691594. Arrivals time: 0.03990500560030341 Scheduler time: 0.8348230235278606 Scheduler overhead time: 0.12334628403186798 Adapter cache time: 0.0626694979146123 Engine time: 0.12282704887911677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.2373489439487457,
    "estimated_duration": 3599.877898394269,
    "input_throughput": 794.6722307653906,
    "output_throughput": 689.8236746050947,
    "total_throughput": 1484.4959053704854,
    "itl": 24.603920585442175,
    "ttft": 6538.4324198162885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.56088620784417,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2374006411992013. Arrivals time: 0.03960542194545269 Scheduler time: 0.8302254476584494 Scheduler overhead time: 0.12193370284512639 Adapter cache time: 0.06217721616849303 Engine time: 0.12255275249481201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.2463676957413554,
    "estimated_duration": 3599.884171626265,
    "input_throughput": 794.6708459532615,
    "output_throughput": 689.82247250421,
    "total_throughput": 1484.4933184574716,
    "itl": 24.536893322026664,
    "ttft": 6537.890150464836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.036286648060305,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2464304435998201. Arrivals time: 0.03976146085187793 Scheduler time: 0.8372659683227539 Scheduler overhead time: 0.1212150352075696 Adapter cache time: 0.0627614171244204 Engine time: 0.12450441438704729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.2457117168232799,
    "estimated_duration": 3599.8710609704876,
    "input_throughput": 794.6737401280086,
    "output_throughput": 689.8249848233546,
    "total_throughput": 1484.4987249513633,
    "itl": 24.599095708976602,
    "ttft": 6538.701973175606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.07996012374491,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.245787977706641. Arrivals time: 0.03973612282425165 Scheduler time: 0.8385791168548167 Scheduler overhead time: 0.12230352777987719 Adapter cache time: 0.06251587625592947 Engine time: 0.12202218780294061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0435073468834162,
    "estimated_duration": 3599.9790496800956,
    "input_throughput": 582.0269982366128,
    "output_throughput": 510.9710291684786,
    "total_throughput": 1092.9980274050913,
    "itl": 22.95231858945026,
    "ttft": 5514.786119319832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.398766712862795,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0435657538473606. Arrivals time: 0.03265070915222168 Scheduler time: 0.640273361466825 Scheduler overhead time: 0.12661853292956948 Adapter cache time: 0.054936856497079134 Engine time: 0.1253664824180305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0464769341051579,
    "estimated_duration": 3599.9839118117075,
    "input_throughput": 582.0262121520257,
    "output_throughput": 510.97033905195184,
    "total_throughput": 1092.9965512039776,
    "itl": 22.99459248426202,
    "ttft": 5515.449097142474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.981905998539425,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0465547977946699. Arrivals time: 0.032689121551811695 Scheduler time: 0.6420495114289224 Scheduler overhead time: 0.1262598978355527 Adapter cache time: 0.055368035566061735 Engine time: 0.12691221572458744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0439547123387456,
    "estimated_duration": 3599.9801053558995,
    "input_throughput": 582.0268275601643,
    "output_throughput": 510.97087932883056,
    "total_throughput": 1092.9977068889948,
    "itl": 23.00228664595098,
    "ttft": 5515.643339761544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.289273395000954,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0440273261629045. Arrivals time: 0.03247771458700299 Scheduler time: 0.639618864748627 Scheduler overhead time: 0.12550073955208063 Adapter cache time: 0.055400794837623835 Engine time: 0.12767548440024257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.0563598722219467,
    "estimated_duration": 3599.988651880035,
    "input_throughput": 582.0254458040505,
    "output_throughput": 510.9696662625198,
    "total_throughput": 1092.9951120665703,
    "itl": 22.963411362651435,
    "ttft": 5514.914838377531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.926988820206894,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0564096453599632. Arrivals time: 0.032514977268874645 Scheduler time: 0.6499507082626224 Scheduler overhead time: 0.1262720595113933 Adapter cache time: 0.05550437653437257 Engine time: 0.12820388516411185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.0538556878454983,
    "estimated_duration": 3600.0006668444053,
    "input_throughput": 582.0235033002454,
    "output_throughput": 510.9679609066317,
    "total_throughput": 1092.991464206877,
    "itl": 22.99915265563478,
    "ttft": 5515.395593253666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.81829192840782,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0539368158206344. Arrivals time: 0.032295703422278166 Scheduler time: 0.6489440225996077 Scheduler overhead time: 0.1266736164689064 Adapter cache time: 0.05542534729465842 Engine time: 0.12695503886789083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0438712420873344,
    "estimated_duration": 3599.9886884533526,
    "input_throughput": 582.025439891087,
    "output_throughput": 510.9696610714324,
    "total_throughput": 1092.9951009625195,
    "itl": 22.93723163758876,
    "ttft": 5514.6786633588945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.908165387180325,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0439295512624085. Arrivals time: 0.03252701601013541 Scheduler time: 0.6408902732655406 Scheduler overhead time: 0.1262639444321394 Adapter cache time: 0.054706338327378035 Engine time: 0.12618914432823658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0490494347177446,
    "estimated_duration": 3599.9830811966267,
    "input_throughput": 582.026346441476,
    "output_throughput": 510.9704569468585,
    "total_throughput": 1092.9968033883345,
    "itl": 22.993036813910276,
    "ttft": 5515.290217128653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.364189194569526,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0491143129765987. Arrivals time: 0.03249378362670541 Scheduler time: 0.6442469707690179 Scheduler overhead time: 0.12597756646573544 Adapter cache time: 0.05515341181308031 Engine time: 0.1277956198900938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5188949 . Total output tokens: 4611678
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0138808386400342,
    "estimated_duration": 3598.5232744715427,
    "input_throughput": 543.1919848530239,
    "output_throughput": 468.17537959301114,
    "total_throughput": 1011.367364446035,
    "itl": 22.578181405401303,
    "ttft": 3212.2318682744854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.65766943695326,
    "arrivals": 7949,
    "finished_requests": 7942,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.013977188616991. Arrivals time: 0.03139492683112621 Scheduler time: 0.6020082570612431 Scheduler overhead time: 0.12750915857031941 Adapter cache time: 0.053852788638323545 Engine time: 0.13057968067005277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5188949 . Total output tokens: 4611678
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.9989699493162334,
    "estimated_duration": 3598.523188712567,
    "input_throughput": 543.19199779822,
    "output_throughput": 468.17539075043294,
    "total_throughput": 1011.3673885486529,
    "itl": 22.607412229601845,
    "ttft": 3213.011674572955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.78743353495227,
    "arrivals": 7949,
    "finished_requests": 7942,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9990369332954288. Arrivals time: 0.03131060069426894 Scheduler time: 0.5959955975413322 Scheduler overhead time: 0.12761011812835932 Adapter cache time: 0.05223708087578416 Engine time: 0.12754042958840728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5188949 . Total output tokens: 4611678
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0230166581459343,
    "estimated_duration": 3598.522006734601,
    "input_throughput": 543.1921762161847,
    "output_throughput": 468.1755445282882,
    "total_throughput": 1011.3677207444729,
    "itl": 22.61773575697679,
    "ttft": 3213.152439429692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.965700890406964,
    "arrivals": 7949,
    "finished_requests": 7942,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0230905339121819. Arrivals time: 0.031364824157208204 Scheduler time: 0.6091662566177547 Scheduler overhead time: 0.1268507051281631 Adapter cache time: 0.05467445682734251 Engine time: 0.13150641415268183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5188949 . Total output tokens: 4611678
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.0245838477276266,
    "estimated_duration": 3598.5201422420105,
    "input_throughput": 543.1924576590411,
    "output_throughput": 468.17578710295754,
    "total_throughput": 1011.3682447619987,
    "itl": 22.586050257373987,
    "ttft": 3212.4968436107574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.086229374009456,
    "arrivals": 7949,
    "finished_requests": 7942,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.024636241607368. Arrivals time: 0.0316784200258553 Scheduler time: 0.6167926746420562 Scheduler overhead time: 0.1268609892576933 Adapter cache time: 0.05268986290320754 Engine time: 0.1322066937573254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5188949 . Total output tokens: 4611678
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.004956778138876,
    "estimated_duration": 3598.5244081481255,
    "input_throughput": 543.1918137262054,
    "output_throughput": 468.17523209937093,
    "total_throughput": 1011.3670458255763,
    "itl": 22.61798815023759,
    "ttft": 3213.078109122806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.57036457271693,
    "arrivals": 7949,
    "finished_requests": 7942,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0050265970639884. Arrivals time: 0.031579828821122646 Scheduler time: 0.6012342255562544 Scheduler overhead time: 0.1276019890792668 Adapter cache time: 0.052015612833201885 Engine time: 0.1286977231502533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5188949 . Total output tokens: 4611678
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.004013148136437,
    "estimated_duration": 3598.5224269908676,
    "input_throughput": 543.1921127790599,
    "output_throughput": 468.1754898520396,
    "total_throughput": 1011.3676026310997,
    "itl": 22.564017776157016,
    "ttft": 3212.184891582506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.36919759843407,
    "arrivals": 7949,
    "finished_requests": 7942,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0040647201240063. Arrivals time: 0.0314227738417685 Scheduler time: 0.5997767192311585 Scheduler overhead time: 0.12782713398337364 Adapter cache time: 0.05248710606247187 Engine time: 0.12810341361910105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5188949 . Total output tokens: 4611678
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0090013891458511,
    "estimated_duration": 3598.51469066125,
    "input_throughput": 543.1932805701048,
    "output_throughput": 468.1764963672882,
    "total_throughput": 1011.369776937393,
    "itl": 22.608065700918438,
    "ttft": 3213.1033695647366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.158719004820256,
    "arrivals": 7949,
    "finished_requests": 7942,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.009083990007639. Arrivals time: 0.03127381019294262 Scheduler time: 0.6050232364796102 Scheduler overhead time: 0.1265436806716025 Adapter cache time: 0.05226136278361082 Engine time: 0.13009689701721072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4371344 . Total output tokens: 3889561
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.9377343468368053,
    "estimated_duration": 3597.528775932565,
    "input_throughput": 451.3003511915295,
    "output_throughput": 400.1163269713848,
    "total_throughput": 851.4166781629143,
    "itl": 21.946510253030514,
    "ttft": 8608.299467068497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.517793918621773,
    "arrivals": 6723,
    "finished_requests": 6707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9377871458418667. Arrivals time: 0.028798953630030155 Scheduler time: 0.5318243368528783 Scheduler overhead time: 0.12846070807427168 Adapter cache time: 0.04670352954417467 Engine time: 0.1365270665846765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4371344 . Total output tokens: 3889561
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.9392334930598736,
    "estimated_duration": 3597.5329524015606,
    "input_throughput": 451.29982726528635,
    "output_throughput": 400.1158624659984,
    "total_throughput": 851.4156897312848,
    "itl": 21.970717120037282,
    "ttft": 8608.729509761288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.78575433446452,
    "arrivals": 6723,
    "finished_requests": 6707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.93930375110358. Arrivals time: 0.028686492703855038 Scheduler time: 0.5315878437831998 Scheduler overhead time: 0.13082072604447603 Adapter cache time: 0.04703752417117357 Engine time: 0.13465371308848262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4371344 . Total output tokens: 3889561
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.9326519267633557,
    "estimated_duration": 3597.5348657519494,
    "input_throughput": 451.2995872412888,
    "output_throughput": 400.11564966421344,
    "total_throughput": 851.4152369055022,
    "itl": 21.97899374848305,
    "ttft": 8609.051094271292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.703528525872315,
    "arrivals": 6723,
    "finished_requests": 6707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9327028668485582. Arrivals time: 0.028582892380654812 Scheduler time: 0.532010754570365 Scheduler overhead time: 0.1291793342679739 Adapter cache time: 0.04719565762206912 Engine time: 0.13070200150832534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4371344 . Total output tokens: 3889561
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 0.9300890569575131,
    "estimated_duration": 3597.5225229333255,
    "input_throughput": 451.3011356149028,
    "output_throughput": 400.1170224297377,
    "total_throughput": 851.4181580446406,
    "itl": 21.95512569249991,
    "ttft": 8608.507285121963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.592922380558203,
    "arrivals": 6723,
    "finished_requests": 6707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9301600633189082. Arrivals time: 0.028771847020834684 Scheduler time: 0.5304538155905902 Scheduler overhead time: 0.12918387865647674 Adapter cache time: 0.0466763386502862 Engine time: 0.12967782467603683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4371344 . Total output tokens: 3889561
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 0.9341842718422413,
    "estimated_duration": 3597.5183010235723,
    "input_throughput": 451.30166524463823,
    "output_throughput": 400.11749199175745,
    "total_throughput": 851.4191572363957,
    "itl": 21.97787810598406,
    "ttft": 8609.03590222474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.36815544446581,
    "arrivals": 6723,
    "finished_requests": 6707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9342338480055332. Arrivals time: 0.028591542039066553 Scheduler time: 0.5335802691988647 Scheduler overhead time: 0.1283614537678659 Adapter cache time: 0.04701879620552063 Engine time: 0.13157206447795033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4371344 . Total output tokens: 3889561
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.9329686788842082,
    "estimated_duration": 3597.524460549075,
    "input_throughput": 451.3008925454817,
    "output_throughput": 400.11680692792453,
    "total_throughput": 851.4176994734062,
    "itl": 21.93966118101415,
    "ttft": 8608.334173103878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.510590920590698,
    "arrivals": 6723,
    "finished_requests": 6707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9330283082090318. Arrivals time: 0.028938046656548977 Scheduler time: 0.5324459187686443 Scheduler overhead time: 0.12883914774283767 Adapter cache time: 0.04686258267611265 Engine time: 0.13063476607203484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4371344 . Total output tokens: 3889561
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.9274550341069698,
    "estimated_duration": 3597.5343071238976,
    "input_throughput": 451.29965731945555,
    "output_throughput": 400.11571179449675,
    "total_throughput": 851.4153691139524,
    "itl": 21.97291041594196,
    "ttft": 8608.89714324571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.04453802840909,
    "arrivals": 6723,
    "finished_requests": 6707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9275102610699832. Arrivals time: 0.02823537541553378 Scheduler time: 0.5270085418596864 Scheduler overhead time: 0.12969675846397877 Adapter cache time: 0.04684633668512106 Engine time: 0.1304007926955819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2766688 . Total output tokens: 2483633
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.7716492372564971,
    "estimated_duration": 3599.658083063745,
    "input_throughput": 287.73982864462465,
    "output_throughput": 253.86383342893112,
    "total_throughput": 541.6036620735557,
    "itl": 21.055254520660423,
    "ttft": 4287.048807623561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.98778626740837,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7716966602019966. Arrivals time: 0.023159518372267485 Scheduler time: 0.37666794937103987 Scheduler overhead time: 0.1321426802314818 Adapter cache time: 0.038114911410957575 Engine time: 0.13454079907387495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2766688 . Total output tokens: 2483633
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.778103964868933,
    "estimated_duration": 3599.649517379667,
    "input_throughput": 287.7405133469705,
    "output_throughput": 253.8644375203532,
    "total_throughput": 541.6049508673237,
    "itl": 21.072078665577134,
    "ttft": 4287.570929251893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.255012299906777,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7781927841715515. Arrivals time: 0.02329682931303978 Scheduler time: 0.38195557007566094 Scheduler overhead time: 0.13216029200702906 Adapter cache time: 0.03810506779700518 Engine time: 0.13530112896114588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2766688 . Total output tokens: 2483633
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.7708650100976229,
    "estimated_duration": 3599.6619442230144,
    "input_throughput": 287.7395200019455,
    "output_throughput": 253.86356112316773,
    "total_throughput": 541.6030811251132,
    "itl": 21.07882369885001,
    "ttft": 4287.6783752942465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.89808248030542,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7709360672160983. Arrivals time: 0.022745915222913027 Scheduler time: 0.37805339554324746 Scheduler overhead time: 0.13213283848017454 Adapter cache time: 0.037740069441497326 Engine time: 0.13298747781664133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2766688 . Total output tokens: 2483633
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 0.7764718630351126,
    "estimated_duration": 3599.6574517464296,
    "input_throughput": 287.7398791091865,
    "output_throughput": 253.86387795223254,
    "total_throughput": 541.6037570614191,
    "itl": 21.060224069680526,
    "ttft": 4287.072355285173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.717694498524622,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7765265218913555. Arrivals time: 0.0231315977871418 Scheduler time: 0.3809395874850452 Scheduler overhead time: 0.13230462558567524 Adapter cache time: 0.03800351358950138 Engine time: 0.1348928092047572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2766688 . Total output tokens: 2483633
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 0.7739131329581141,
    "estimated_duration": 3599.6506677959155,
    "input_throughput": 287.7404213876688,
    "output_throughput": 253.86435638754315,
    "total_throughput": 541.6047777752119,
    "itl": 21.07240731158901,
    "ttft": 4287.4887330579995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.667768179909846,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7740008379332721. Arrivals time: 0.023282161448150873 Scheduler time: 0.3803342431783676 Scheduler overhead time: 0.13188895490020514 Adapter cache time: 0.03784970939159393 Engine time: 0.1334947133436799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2766688 . Total output tokens: 2483633
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.7717000939883292,
    "estimated_duration": 3599.6602545370347,
    "input_throughput": 287.7396550673123,
    "output_throughput": 253.8636802871081,
    "total_throughput": 541.6033353544204,
    "itl": 21.0534104689189,
    "ttft": 4286.710686008758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.26894898631304,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.771751765627414. Arrivals time: 0.02315301401540637 Scheduler time: 0.3771962784230709 Scheduler overhead time: 0.1315136542543769 Adapter cache time: 0.037767147179692984 Engine time: 0.13490031426772475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2766688 . Total output tokens: 2483633
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.7758136210031807,
    "estimated_duration": 3599.659822288414,
    "input_throughput": 287.7396896192075,
    "output_throughput": 253.86371077116246,
    "total_throughput": 541.60340039037,
    "itl": 21.07190340134248,
    "ttft": 4287.512252310116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.452573433407153,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7758601340465248. Arrivals time: 0.023070786148309708 Scheduler time: 0.3800500244833529 Scheduler overhead time: 0.1326949717476964 Adapter cache time: 0.038093904964625835 Engine time: 0.13448295509442687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 722451510 . Total output tokens: 636530890
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 35.7494886610657,
    "estimated_duration": 3600.073996198169,
    "input_throughput": 5616.5359438036885,
    "output_throughput": 4882.65075066874,
    "total_throughput": 10499.186694472428,
    "itl": 118.07707570710386,
    "ttft": 2108713.745274115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.332654152102809,
    "arrivals": 1078565,
    "finished_requests": 81603,
    "scheduler_time": 149.38448275355472
}
#Debug simulation 
Total elapsed time: 35.74965447606519. Arrivals time: 0.38206345308572054 Scheduler time: 35.21237521665171 Scheduler overhead time: 0.057809616439044476 Adapter cache time: 0.015580082777887583 Engine time: 0.05808180384337902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 722451510 . Total output tokens: 636530890
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 28.674402056261897,
    "estimated_duration": 3600.0056298770974,
    "input_throughput": 5446.083427561011,
    "output_throughput": 4740.778141667143,
    "total_throughput": 10186.861569228155,
    "itl": 110.10373202538076,
    "ttft": 2126525.2842590506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.741393689545807,
    "arrivals": 1078565,
    "finished_requests": 79112,
    "scheduler_time": 153.00385122002538
}
#Debug simulation 
Total elapsed time: 28.674519817344844. Arrivals time: 0.33624983159825206 Scheduler time: 28.180132224224508 Scheduler overhead time: 0.057840922847390175 Adapter cache time: 0.015376731287688017 Engine time: 0.05796442227438092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 722451510 . Total output tokens: 636530890
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 14.56928313197568,
    "estimated_duration": 3600.0644659266945,
    "input_throughput": 5151.791912488951,
    "output_throughput": 4483.3397159307015,
    "total_throughput": 9635.131628419653,
    "itl": 98.3371422147618,
    "ttft": 2154230.2299866173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.785483687822727,
    "arrivals": 1078565,
    "finished_requests": 74919,
    "scheduler_time": 159.1933490390679
}
#Debug simulation 
Total elapsed time: 14.569387480150908. Arrivals time: 0.32477819733321667 Scheduler time: 14.081901057157665 Scheduler overhead time: 0.05776260932907462 Adapter cache time: 0.020852571353316307 Engine time: 0.05844743549823761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 722451510 . Total output tokens: 636530890
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 28.631422771140933,
    "estimated_duration": 3600.0150427746653,
    "input_throughput": 5446.371408739487,
    "output_throughput": 4741.016022767857,
    "total_throughput": 10187.387431507344,
    "itl": 110.09632848770141,
    "ttft": 2126555.5928223496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5095607870025507,
    "arrivals": 1078565,
    "finished_requests": 79118,
    "scheduler_time": 153.01306691868336
}
#Debug simulation 
Total elapsed time: 28.631577247288078. Arrivals time: 0.33799384627491236 Scheduler time: 28.13754027429968 Scheduler overhead time: 0.05797854159027338 Adapter cache time: 0.015587406698614359 Engine time: 0.05794221442192793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 722451510 . Total output tokens: 636530890
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 14.505698888096958,
    "estimated_duration": 3600.0048242950893,
    "input_throughput": 5151.877262728839,
    "output_throughput": 4483.413991857748,
    "total_throughput": 9635.291254586587,
    "itl": 98.33557517203685,
    "ttft": 2154208.327779817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.726041058134308,
    "arrivals": 1078565,
    "finished_requests": 74919,
    "scheduler_time": 159.1931500371512
}
#Debug simulation 
Total elapsed time: 14.505793674383312. Arrivals time: 0.3026305860839784 Scheduler time: 14.040801636874676 Scheduler overhead time: 0.058089882135391235 Adapter cache time: 0.020873226691037416 Engine time: 0.05766384257003665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 722451510 . Total output tokens: 636530890
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 26.282264484092593,
    "estimated_duration": 3600.0158193815228,
    "input_throughput": 5461.0518359826365,
    "output_throughput": 4749.664128680845,
    "total_throughput": 10210.715964663481,
    "itl": 110.62811234465553,
    "ttft": 2126918.093676984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2557996796909574,
    "arrivals": 1078565,
    "finished_requests": 79374,
    "scheduler_time": 152.66345765712637
}
#Debug simulation 
Total elapsed time: 26.282413348089904. Arrivals time: 0.3555450174026191 Scheduler time: 25.771772290114313 Scheduler overhead time: 0.05709790112450719 Adapter cache time: 0.015754700638353825 Engine time: 0.057740407064557076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 722451510 . Total output tokens: 636530890
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 14.588067285250872,
    "estimated_duration": 3600.0511586041043,
    "input_throughput": 5151.830399874489,
    "output_throughput": 4483.495175179258,
    "total_throughput": 9635.325575053746,
    "itl": 98.33404936766935,
    "ttft": 2154182.4397216314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.66224896773698,
    "arrivals": 1078565,
    "finished_requests": 74920,
    "scheduler_time": 159.19788959516688
}
#Debug simulation 
Total elapsed time: 14.588182535022497. Arrivals time: 0.3025616747327149 Scheduler time: 14.12357463967055 Scheduler overhead time: 0.05751154664903879 Adapter cache time: 0.020745567977428436 Engine time: 0.05820424063131213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 671492301 . Total output tokens: 591525524
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 27.294381556101143,
    "estimated_duration": 3600.104291215969,
    "input_throughput": 5602.16076217835,
    "output_throughput": 4881.822741325045,
    "total_throughput": 10483.983503503394,
    "itl": 118.43582347299704,
    "ttft": 2101770.26453171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.696336648860067,
    "arrivals": 1002554,
    "finished_requests": 81583,
    "scheduler_time": 149.0666665121112
}
#Debug simulation 
Total elapsed time: 27.294478285126388. Arrivals time: 0.510261851362884 Scheduler time: 26.63466294296086 Scheduler overhead time: 0.05481652170419693 Adapter cache time: 0.016107706353068352 Engine time: 0.05565363401547074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 671492301 . Total output tokens: 591525524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 19.476163088344038,
    "estimated_duration": 3600.0442921212766,
    "input_throughput": 5431.319009822146,
    "output_throughput": 4730.123192447197,
    "total_throughput": 10161.442202269342,
    "itl": 109.93788554876714,
    "ttft": 2117342.725432609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.194208088149324,
    "arrivals": 1002554,
    "finished_requests": 79049,
    "scheduler_time": 152.79766696037672
}
#Debug simulation 
Total elapsed time: 19.476260336115956. Arrivals time: 0.8166507794521749 Scheduler time: 18.505125802010298 Scheduler overhead time: 0.05571846617385745 Adapter cache time: 0.018255578819662333 Engine time: 0.056424473877996206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 671492301 . Total output tokens: 591525524
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 13.984555944800377,
    "estimated_duration": 3600.0944949754744,
    "input_throughput": 5131.151425547747,
    "output_throughput": 4474.817820055511,
    "total_throughput": 9605.969245603257,
    "itl": 97.96422377300793,
    "ttft": 2145068.284253413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.356240173759892,
    "arrivals": 1002554,
    "finished_requests": 74744,
    "scheduler_time": 159.28087509717278
}
#Debug simulation 
Total elapsed time: 13.984707180876285. Arrivals time: 0.39917523972690105 Scheduler time: 13.42308332817629 Scheduler overhead time: 0.05724044656381011 Adapter cache time: 0.021893807221204042 Engine time: 0.057668707333505154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 671492301 . Total output tokens: 591525524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 18.9741979832761,
    "estimated_duration": 3600.0724769382127,
    "input_throughput": 5443.422077065126,
    "output_throughput": 4743.846716809615,
    "total_throughput": 10187.268793874742,
    "itl": 110.64690545573924,
    "ttft": 2116078.1985757826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.07532140227034,
    "arrivals": 1002554,
    "finished_requests": 79286,
    "scheduler_time": 152.45140796488568
}
#Debug simulation 
Total elapsed time: 18.974291942082345. Arrivals time: 0.42691848427057266 Scheduler time: 18.39335516700521 Scheduler overhead time: 0.05516463704407215 Adapter cache time: 0.018859168514609337 Engine time: 0.05626979423686862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 671492301 . Total output tokens: 591525524
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 14.125194057822227,
    "estimated_duration": 3600.0261604200978,
    "input_throughput": 5131.248823437542,
    "output_throughput": 4474.902759628864,
    "total_throughput": 9606.151583066407,
    "itl": 97.96239945809933,
    "ttft": 2145041.7335969526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2880986226536555,
    "arrivals": 1002554,
    "finished_requests": 74744,
    "scheduler_time": 159.28068209290277
}
#Debug simulation 
Total elapsed time: 14.125335352960974. Arrivals time: 0.42271686997264624 Scheduler time: 13.538884109817445 Scheduler overhead time: 0.05804264545440674 Adapter cache time: 0.02167787915095687 Engine time: 0.05813477747142315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 671492301 . Total output tokens: 591525524
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 18.74848156236112,
    "estimated_duration": 3600.076049689966,
    "input_throughput": 5444.262490423753,
    "output_throughput": 4744.423107803773,
    "total_throughput": 10188.685598227526,
    "itl": 110.63669357401227,
    "ttft": 2115931.232434344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.724101496022172,
    "arrivals": 1002554,
    "finished_requests": 79296,
    "scheduler_time": 152.4658077814228
}
#Debug simulation 
Total elapsed time: 18.748612700030208. Arrivals time: 0.4214196582324803 Scheduler time: 18.174660850781947 Scheduler overhead time: 0.05516669899225235 Adapter cache time: 0.01855574268847704 Engine time: 0.0550323617644608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 671492301 . Total output tokens: 591525524
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 14.051384642720222,
    "estimated_duration": 3600.0644064645476,
    "input_throughput": 5131.557081819649,
    "output_throughput": 4475.142158865333,
    "total_throughput": 9606.699240684982,
    "itl": 97.9610959704203,
    "ttft": 2145032.7189065963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.220164188724034,
    "arrivals": 1002554,
    "finished_requests": 74748,
    "scheduler_time": 159.2853018852432
}
#Debug simulation 
Total elapsed time: 14.051503513939679. Arrivals time: 0.39918283512815833 Scheduler time: 13.489288322161883 Scheduler overhead time: 0.05768697848543525 Adapter cache time: 0.021424930542707443 Engine time: 0.05818613478913903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 633270312 . Total output tokens: 557881236
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 29.177587404847145,
    "estimated_duration": 3600.094728343101,
    "input_throughput": 5599.2507200713,
    "output_throughput": 4877.099722340045,
    "total_throughput": 10476.350442411345,
    "itl": 118.50774480162382,
    "ttft": 2098542.1940246727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.891656447467517,
    "arrivals": 945185,
    "finished_requests": 81466,
    "scheduler_time": 148.9224209182543
}
#Debug simulation 
Total elapsed time: 29.177681378554553. Arrivals time: 0.4064309885725379 Scheduler time: 28.615661616437137 Scheduler overhead time: 0.05619910312816501 Adapter cache time: 0.019260148517787457 Engine time: 0.05669980309903622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 633270312 . Total output tokens: 557881236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 19.42055074032396,
    "estimated_duration": 3600.096044027818,
    "input_throughput": 5453.049518655649,
    "output_throughput": 4750.435208074647,
    "total_throughput": 10203.484726730296,
    "itl": 110.85363978229888,
    "ttft": 2109980.1154795256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1006,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.321791656920695,
    "arrivals": 945185,
    "finished_requests": 79370,
    "scheduler_time": 152.39903891725683
}
#Debug simulation 
Total elapsed time: 19.420697286259383. Arrivals time: 0.34599837753921747 Scheduler time: 18.919611820485443 Scheduler overhead time: 0.055238403379917145 Adapter cache time: 0.020404041279107332 Engine time: 0.05562890414148569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 633270312 . Total output tokens: 557881236
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.211217731703073,
    "estimated_duration": 3600.0572319708426,
    "input_throughput": 5138.861081347896,
    "output_throughput": 4486.269511653922,
    "total_throughput": 9625.130593001819,
    "itl": 98.38459253213433,
    "ttft": 2139798.2722672503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.890689183603866,
    "arrivals": 945185,
    "finished_requests": 74885,
    "scheduler_time": 159.04420063435703
}
#Debug simulation 
Total elapsed time: 11.211350953672081. Arrivals time: 0.284211665391922 Scheduler time: 10.763913871254772 Scheduler overhead time: 0.05571044376119971 Adapter cache time: 0.02652527205646038 Engine time: 0.055656151846051216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 633270312 . Total output tokens: 557881236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 19.521324028261006,
    "estimated_duration": 3600.1148454217323,
    "input_throughput": 5437.52153487393,
    "output_throughput": 4739.256310586198,
    "total_throughput": 10176.777845460128,
    "itl": 110.42517918717562,
    "ttft": 2111365.756673898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.424850264922705,
    "arrivals": 945185,
    "finished_requests": 79198,
    "scheduler_time": 152.54541604226262
}
#Debug simulation 
Total elapsed time: 19.521509811282158. Arrivals time: 0.32003994612023234 Scheduler time: 19.046398499049246 Scheduler overhead time: 0.055469795130193233 Adapter cache time: 0.019695052411407232 Engine time: 0.05587449064478278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 633270312 . Total output tokens: 557881236
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 11.159488902892917,
    "estimated_duration": 3600.072741376305,
    "input_throughput": 5139.173102632068,
    "output_throughput": 4486.609899394715,
    "total_throughput": 9625.783002026783,
    "itl": 98.38269131073912,
    "ttft": 2139750.6467336253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.797900688480487,
    "arrivals": 945185,
    "finished_requests": 74889,
    "scheduler_time": 159.0488367690022
}
#Debug simulation 
Total elapsed time: 11.159580441191792. Arrivals time: 0.28083593072369695 Scheduler time: 10.71789296483621 Scheduler overhead time: 0.05496870866045356 Adapter cache time: 0.025615970138460398 Engine time: 0.05538190063089132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 633270312 . Total output tokens: 557881236
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 19.394201119896024,
    "estimated_duration": 3600.0482264216944,
    "input_throughput": 5438.382979513637,
    "output_throughput": 4740.163166358955,
    "total_throughput": 10178.546145872593,
    "itl": 110.41338521152383,
    "ttft": 2111325.030473813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.994501763195701,
    "arrivals": 945185,
    "finished_requests": 79210,
    "scheduler_time": 152.5599667161047
}
#Debug simulation 
Total elapsed time: 19.394298696890473. Arrivals time: 0.3224759506992996 Scheduler time: 18.918749057222158 Scheduler overhead time: 0.054929949808865786 Adapter cache time: 0.019374423660337925 Engine time: 0.05532371671870351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 633270312 . Total output tokens: 557881236
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.155102790798992,
    "estimated_duration": 3600.0789988462684,
    "input_throughput": 5139.293056049427,
    "output_throughput": 4486.694321201408,
    "total_throughput": 9625.987377250834,
    "itl": 98.38003063604272,
    "ttft": 2139752.4427713742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.694342100173138,
    "arrivals": 945185,
    "finished_requests": 74890,
    "scheduler_time": 159.05354940479126
}
#Debug simulation 
Total elapsed time: 11.155196047853678. Arrivals time: 0.2860438306815922 Scheduler time: 10.708273703232408 Scheduler overhead time: 0.05478591984137893 Adapter cache time: 0.02581450715661049 Engine time: 0.055342186242341995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 626824356 . Total output tokens: 552268076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 29.843406434636563,
    "estimated_duration": 3600.0049688891495,
    "input_throughput": 5670.570506545483,
    "output_throughput": 4935.833465108514,
    "total_throughput": 10606.403971653997,
    "itl": 116.84003829273361,
    "ttft": 2093972.8074625186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.223803135240551,
    "arrivals": 935737,
    "finished_requests": 82662,
    "scheduler_time": 150.73238466548634
}
#Debug simulation 
Total elapsed time: 29.843523104675114. Arrivals time: 0.3578618266619742 Scheduler time: 29.333444196730852 Scheduler overhead time: 0.055642413441091776 Adapter cache time: 0.017942621372640133 Engine time: 0.055539488792419434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 626824356 . Total output tokens: 552268076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 19.381362144835293,
    "estimated_duration": 3600.042163032005,
    "input_throughput": 5488.01739126308,
    "output_throughput": 4780.577621209099,
    "total_throughput": 10268.595012472178,
    "itl": 109.64827861336585,
    "ttft": 2106147.6001337497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.782935991021811,
    "arrivals": 935737,
    "finished_requests": 80030,
    "scheduler_time": 153.55488046244727
}
#Debug simulation 
Total elapsed time: 19.38147577783093. Arrivals time: 0.33544853096827865 Scheduler time: 18.893431404605508 Scheduler overhead time: 0.05466380808502436 Adapter cache time: 0.018322091549634933 Engine time: 0.05597598711028695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 626824356 . Total output tokens: 552268076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 13.651648475788534,
    "estimated_duration": 3600.10400857574,
    "input_throughput": 5198.82813258067,
    "output_throughput": 4529.3305307729,
    "total_throughput": 9728.15866335357,
    "itl": 97.49941210571963,
    "ttft": 2132669.5478877486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.69775392304176,
    "arrivals": 935737,
    "finished_requests": 75716,
    "scheduler_time": 160.33823149822274
}
#Debug simulation 
Total elapsed time: 13.651756736915559. Arrivals time: 0.33618225809186697 Scheduler time: 13.15834718151018 Scheduler overhead time: 0.05571829620748758 Adapter cache time: 0.020444568246603012 Engine time: 0.05601387284696102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 626824356 . Total output tokens: 552268076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 19.43825558712706,
    "estimated_duration": 3600.1066157376963,
    "input_throughput": 5508.0274326644485,
    "output_throughput": 4784.819128605239,
    "total_throughput": 10292.846561269687,
    "itl": 109.59235455999944,
    "ttft": 2106347.1377035314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.817811113959169,
    "arrivals": 935737,
    "finished_requests": 80150,
    "scheduler_time": 153.67210616456464
}
#Debug simulation 
Total elapsed time: 19.43831988191232. Arrivals time: 0.30055151460692286 Scheduler time: 18.989231773186475 Scheduler overhead time: 0.05330591183155775 Adapter cache time: 0.018596612848341465 Engine time: 0.05337207019329071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 626824356 . Total output tokens: 552268076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 13.508315774146467,
    "estimated_duration": 3600.034226719139,
    "input_throughput": 5198.928904922374,
    "output_throughput": 4529.418325797527,
    "total_throughput": 9728.347230719903,
    "itl": 97.49757373982254,
    "ttft": 2132640.8154477663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.62816255169922,
    "arrivals": 935737,
    "finished_requests": 75716,
    "scheduler_time": 160.33804101296434
}
#Debug simulation 
Total elapsed time: 13.508450621273369. Arrivals time: 0.2748177507892251 Scheduler time: 13.076789345126599 Scheduler overhead time: 0.055493985302746296 Adapter cache time: 0.020242818631231785 Engine time: 0.05602973885834217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 626824356 . Total output tokens: 552268076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 21.776068607810885,
    "estimated_duration": 3600.044472574981,
    "input_throughput": 5505.588931189845,
    "output_throughput": 4784.8295017531145,
    "total_throughput": 10290.41843294296,
    "itl": 109.47573126644745,
    "ttft": 2107530.5920413956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.483788087950061,
    "arrivals": 935737,
    "finished_requests": 80172,
    "scheduler_time": 153.792078346242
}
#Debug simulation 
Total elapsed time: 21.77617100160569. Arrivals time: 0.30227389466017485 Scheduler time: 21.322133908513933 Scheduler overhead time: 0.054696724750101566 Adapter cache time: 0.01882845861837268 Engine time: 0.054811703972518444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 626824356 . Total output tokens: 552268076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 13.559692927170545,
    "estimated_duration": 3600.073494453798,
    "input_throughput": 5199.455796898933,
    "output_throughput": 4529.88446628205,
    "total_throughput": 9729.340263180984,
    "itl": 97.4947257561374,
    "ttft": 2132649.098417663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.557328477296993,
    "arrivals": 935737,
    "finished_requests": 75723,
    "scheduler_time": 160.34275598062865
}
#Debug simulation 
Total elapsed time: 13.559791801031679. Arrivals time: 0.2738353912718594 Scheduler time: 13.129058588296175 Scheduler overhead time: 0.05583988968282938 Adapter cache time: 0.020381688605993986 Engine time: 0.055632200092077255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 623613941 . Total output tokens: 549468286
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 28.148392893839628,
    "estimated_duration": 3600.0354933576073,
    "input_throughput": 5717.1525219614,
    "output_throughput": 4977.343704822209,
    "total_throughput": 10694.496226783609,
    "itl": 115.64420366121941,
    "ttft": 2093138.0205330593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.471514741773762,
    "arrivals": 931056,
    "finished_requests": 83038,
    "scheduler_time": 152.16743318420146
}
#Debug simulation 
Total elapsed time: 28.1485300171189. Arrivals time: 0.3178526470437646 Scheduler time: 27.684089980553836 Scheduler overhead time: 0.05426339339464903 Adapter cache time: 0.014801861718297005 Engine time: 0.05471050925552845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 623613941 . Total output tokens: 549468286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 21.109383798670024,
    "estimated_duration": 3600.0125238037162,
    "input_throughput": 5536.140462906527,
    "output_throughput": 4819.261012366951,
    "total_throughput": 10355.401475273478,
    "itl": 108.67845219781864,
    "ttft": 2100075.9578514625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.914694310054189,
    "arrivals": 931056,
    "finished_requests": 80450,
    "scheduler_time": 154.90450831927907
}
#Debug simulation 
Total elapsed time: 21.10953982686624. Arrivals time: 0.30260304687544703 Scheduler time: 20.658861866220832 Scheduler overhead time: 0.054215218871831894 Adapter cache time: 0.015975376591086388 Engine time: 0.054174395743757486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 623613941 . Total output tokens: 549468286
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.895533096045256,
    "estimated_duration": 3600.0257489619858,
    "input_throughput": 5235.735884787704,
    "output_throughput": 4566.765114038522,
    "total_throughput": 9802.500998826226,
    "itl": 96.38506969859131,
    "ttft": 2131672.6357628354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.655359819182218,
    "arrivals": 931056,
    "finished_requests": 76059,
    "scheduler_time": 162.01162957077312
}
#Debug simulation 
Total elapsed time: 11.895629752893. Arrivals time: 0.27111081639304757 Scheduler time: 11.466147468890995 Scheduler overhead time: 0.05616654362529516 Adapter cache time: 0.020659768022596836 Engine time: 0.05625082412734628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 623613941 . Total output tokens: 549468286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 18.779851243831217,
    "estimated_duration": 3600.074066549668,
    "input_throughput": 5519.379221840203,
    "output_throughput": 4810.247422658432,
    "total_throughput": 10329.626644498634,
    "itl": 108.62652673270797,
    "ttft": 2104482.7900831727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.6567495844559685,
    "arrivals": 931056,
    "finished_requests": 80261,
    "scheduler_time": 154.84120837738357
}
#Debug simulation 
Total elapsed time: 18.779994837008417. Arrivals time: 0.349160339217633 Scheduler time: 18.28257508110255 Scheduler overhead time: 0.05390280997380614 Adapter cache time: 0.01634871307760477 Engine time: 0.05430039810016751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 623613941 . Total output tokens: 549468286
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 11.90735766896978,
    "estimated_duration": 3600.0613149557253,
    "input_throughput": 5235.919711059649,
    "output_throughput": 4566.886105994614,
    "total_throughput": 9802.805817054263,
    "itl": 96.38225333799996,
    "ttft": 2131738.524455626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.584318627603375,
    "arrivals": 931056,
    "finished_requests": 76062,
    "scheduler_time": 162.01625094167954
}
#Debug simulation 
Total elapsed time: 11.907460661605. Arrivals time: 0.3258364708162844 Scheduler time: 11.424551925156265 Scheduler overhead time: 0.0558832180686295 Adapter cache time: 0.020474835764616728 Engine time: 0.05534870084375143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 623613941 . Total output tokens: 549468286
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 19.00650800904259,
    "estimated_duration": 3600.1097685744794,
    "input_throughput": 5520.665556781015,
    "output_throughput": 4811.176078905624,
    "total_throughput": 10331.84163568664,
    "itl": 108.6170935396256,
    "ttft": 2104498.1880925857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3346823186473715,
    "arrivals": 931056,
    "finished_requests": 80276,
    "scheduler_time": 154.85560892793023
}
#Debug simulation 
Total elapsed time: 19.006634761113673. Arrivals time: 0.5933188111521304 Scheduler time: 18.2671042047441 Scheduler overhead time: 0.05328910471871495 Adapter cache time: 0.015879650600254536 Engine time: 0.05348491435870528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 623613941 . Total output tokens: 549468286
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.85145864635706,
    "estimated_duration": 3600.097073075044,
    "input_throughput": 5236.055200005731,
    "output_throughput": 4567.03573994358,
    "total_throughput": 9803.090939949312,
    "itl": 96.37959811009334,
    "ttft": 2131802.336974034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.5138987875543775,
    "arrivals": 931056,
    "finished_requests": 76066,
    "scheduler_time": 162.02086821500836
}
#Debug simulation 
Total elapsed time: 11.851572676096112. Arrivals time: 0.2734753042459488 Scheduler time: 11.420546653680503 Scheduler overhead time: 0.055964699015021324 Adapter cache time: 0.020480360835790634 Engine time: 0.055890302173793316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621989178 . Total output tokens: 548039165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 26.17661163583398,
    "estimated_duration": 3600.0568265878915,
    "input_throughput": 5763.123750372686,
    "output_throughput": 4989.693181322745,
    "total_throughput": 10752.81693169543,
    "itl": 115.7111403087931,
    "ttft": 2089642.1578644896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.167343926304055,
    "arrivals": 928543,
    "finished_requests": 83673,
    "scheduler_time": 152.35604447414204
}
#Debug simulation 
Total elapsed time: 26.176719903945923. Arrivals time: 0.4084296035580337 Scheduler time: 25.622496524825692 Scheduler overhead time: 0.05446967529132962 Adapter cache time: 0.013838161248713732 Engine time: 0.054678427055478096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621989178 . Total output tokens: 548039165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 18.100964097771794,
    "estimated_duration": 3600.0597406744987,
    "input_throughput": 5625.980527813486,
    "output_throughput": 4875.733533441677,
    "total_throughput": 10501.714061255163,
    "itl": 107.58756952119812,
    "ttft": 2102277.0606308435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.387586358566774,
    "arrivals": 928543,
    "finished_requests": 81658,
    "scheduler_time": 156.73264218917586
}
#Debug simulation 
Total elapsed time: 18.10107128508389. Arrivals time: 0.3915879325941205 Scheduler time: 17.561747036408633 Scheduler overhead time: 0.054452311247587204 Adapter cache time: 0.01509430492296815 Engine time: 0.054567981511354446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621989178 . Total output tokens: 548039165
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.046434219926596,
    "estimated_duration": 3600.0563311209803,
    "input_throughput": 5284.653697092569,
    "output_throughput": 4582.208577515073,
    "total_throughput": 9866.862274607642,
    "itl": 96.1516263937459,
    "ttft": 2131639.7281084396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.506096829939659,
    "arrivals": 928543,
    "finished_requests": 76712,
    "scheduler_time": 162.56304283147398
}
#Debug simulation 
Total elapsed time: 12.0465181437321. Arrivals time: 0.3710726769641042 Scheduler time: 11.520864775869995 Scheduler overhead time: 0.05543254455551505 Adapter cache time: 0.018408823758363724 Engine time: 0.05555021716281772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621989178 . Total output tokens: 548039165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 17.46695172227919,
    "estimated_duration": 3600.1013313783405,
    "input_throughput": 5630.0051399497515,
    "output_throughput": 4885.931917162321,
    "total_throughput": 10515.937057112073,
    "itl": 107.80318819653017,
    "ttft": 2099590.5399023793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.172393152336585,
    "arrivals": 928543,
    "finished_requests": 81794,
    "scheduler_time": 156.69294223095653
}
#Debug simulation 
Total elapsed time: 17.467054238077253. Arrivals time: 0.4017424718476832 Scheduler time: 16.916920746676624 Scheduler overhead time: 0.05499381897971034 Adapter cache time: 0.015203857328742743 Engine time: 0.05440374603495002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621989178 . Total output tokens: 548039165
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 12.100462259724736,
    "estimated_duration": 3600.1026360655737,
    "input_throughput": 5284.881550152963,
    "output_throughput": 4582.464631627661,
    "total_throughput": 9867.346181780624,
    "itl": 96.15072596623223,
    "ttft": 2131600.8522108486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4443759113084775,
    "arrivals": 928543,
    "finished_requests": 76717,
    "scheduler_time": 162.56766578571032
}
#Debug simulation 
Total elapsed time: 12.100542134605348. Arrivals time: 0.36673208698630333 Scheduler time: 11.578776244074106 Scheduler overhead time: 0.055788975674659014 Adapter cache time: 0.018495981115847826 Engine time: 0.05548554612323642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621989178 . Total output tokens: 548039165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 17.385701990686357,
    "estimated_duration": 3600.056759248019,
    "input_throughput": 5630.351784851836,
    "output_throughput": 4886.278516251613,
    "total_throughput": 10516.630301103449,
    "itl": 107.79449568065745,
    "ttft": 2099601.8292908394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8878078528074367,
    "arrivals": 928543,
    "finished_requests": 81799,
    "scheduler_time": 156.7023423932844
}
#Debug simulation 
Total elapsed time: 17.385782130993903. Arrivals time: 0.392075480427593 Scheduler time: 16.847427959088236 Scheduler overhead time: 0.05384968547150493 Adapter cache time: 0.01527706254273653 Engine time: 0.05349975824356079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_160_slots_64_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621989178 . Total output tokens: 548039165
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.163595612160861,
    "estimated_duration": 3600.0424137464834,
    "input_throughput": 5284.969956840022,
    "output_throughput": 4582.541288126543,
    "total_throughput": 9867.511244966565,
    "itl": 96.14913824394722,
    "ttft": 2131578.1039084806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.384311930090216,
    "arrivals": 928543,
    "finished_requests": 76717,
    "scheduler_time": 162.56750744783812
}
#Debug simulation 
Total elapsed time: 12.163707522209734. Arrivals time: 0.37218574434518814 Scheduler time: 11.635200588032603 Scheduler overhead time: 0.056423709727823734 Adapter cache time: 0.018525704741477966 Engine time: 0.055804688949137926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_160_slots_64_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 621175011 . Total output tokens: 547344786
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 28.022622210904956,
    "estimated_duration": 3600.037705318082,
    "input_throughput": 5768.120141998697,
    "output_throughput": 5020.738803179561,
    "total_throughput": 10788.85894517826,
    "itl": 115.06803209919592,
    "ttft": 2076793.103136345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.49949061407709,
    "arrivals": 927414,
    "finished_requests": 84322,
    "scheduler_time": 153.09365571707758
}
#Debug simulation 
Total elapsed time: 28.022709695156664. Arrivals time: 0.4146155077032745 Scheduler time: 27.46356664504856 Scheduler overhead time: 0.054774374701082706 Adapter cache time: 0.01228815596550703 Engine time: 0.054418733809143305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_160_slots_64_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 621175011 . Total output tokens: 547344786
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 17.981114275753498,
    "estimated_duration": 3600.086096418268,
    "input_throughput": 5616.415679646244,
    "output_throughput": 4896.118461593623,
    "total_throughput": 10512.534141239867,
    "itl": 107.26281527087588,
    "ttft": 2100175.412324542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9920476356893837,
    "arrivals": 927414,
    "finished_requests": 82074,
    "scheduler_time": 157.14340459356694
}
#Debug simulation 
Total elapsed time: 17.981201382819563. Arrivals time: 0.3148063784465194 Scheduler time: 17.519779747817665 Scheduler overhead time: 0.0543290046043694 Adapter cache time: 0.014526785351336002 Engine time: 0.05411679344251752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_160_slots_64_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 621175011 . Total output tokens: 547344786
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.121014520060271,
    "estimated_duration": 3600.0007380919874,
    "input_throughput": 5292.100581650823,
    "output_throughput": 4602.084612010617,
    "total_throughput": 9894.18519366144,
    "itl": 95.95063217941284,
    "ttft": 2125277.5838338877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.64975734427108,
    "arrivals": 927414,
    "finished_requests": 77247,
    "scheduler_time": 162.9202590552365
}
#Debug simulation 
Total elapsed time: 11.121093249879777. Arrivals time: 0.3640826935879886 Scheduler time: 10.60218698065728 Scheduler overhead time: 0.055586994625627995 Adapter cache time: 0.018417530227452517 Engine time: 0.05546614248305559 
