INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.44975852797506,
    "estimated_duration": 3600.107798231415,
    "input_throughput": 7308.758646873341,
    "output_throughput": 6371.516989371421,
    "total_throughput": 13680.275636244762,
    "itl": 86.4941136248284,
    "ttft": 1679034.7799688957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4613423960609344,
    "arrivals": 313505,
    "finished_requests": 106501,
    "scheduler_time": 268.67701480076835
}
#Debug simulation 
Total elapsed time: 99.44998615200166. Arrivals time: 0.7861113550025038 Scheduler time: 98.42858430120395 Scheduler overhead time: 0.09203001105925068 Adapter cache time: 0.017481411807239056 Engine time: 0.09082073817262426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 101.77251343202079,
    "estimated_duration": 3600.0423144052183,
    "input_throughput": 7235.043570398497,
    "output_throughput": 6309.882778073124,
    "total_throughput": 13544.926348471621,
    "itl": 85.18881223632324,
    "ttft": 1679305.6398710567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.443654035716319,
    "arrivals": 313505,
    "finished_requests": 105411,
    "scheduler_time": 271.3630554504378
}
#Debug simulation 
Total elapsed time: 101.77271902700886. Arrivals time: 0.5273120615747757 Scheduler time: 101.0057772831642 Scheduler overhead time: 0.09505537088261917 Adapter cache time: 0.017794274375773966 Engine time: 0.09112679457757622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.49845089396695,
    "estimated_duration": 3600.0350791436967,
    "input_throughput": 7094.53531382674,
    "output_throughput": 6187.721372231341,
    "total_throughput": 13282.256686058081,
    "itl": 82.19197272406281,
    "ttft": 1695911.4777495798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.502433452690023,
    "arrivals": 313505,
    "finished_requests": 103433,
    "scheduler_time": 277.15635836732906
}
#Debug simulation 
Total elapsed time: 100.49870674096746. Arrivals time: 0.5166844911873341 Scheduler time: 99.738737242762 Scheduler overhead time: 0.0962672310997732 Adapter cache time: 0.0184071832918562 Engine time: 0.09216323267901316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 100.32495902699884,
    "estimated_duration": 3600.004788603758,
    "input_throughput": 7263.18644985502,
    "output_throughput": 6336.549071327029,
    "total_throughput": 13599.73552118205,
    "itl": 85.44834916905205,
    "ttft": 1673636.8729503562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.51829672673717,
    "arrivals": 313505,
    "finished_requests": 105893,
    "scheduler_time": 269.99666309784595
}
#Debug simulation 
Total elapsed time: 100.3251187390415. Arrivals time: 0.5277791055850685 Scheduler time: 99.55949556600535 Scheduler overhead time: 0.09368336136685684 Adapter cache time: 0.01766128948656842 Engine time: 0.09098348207771778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 100.1372450729832,
    "estimated_duration": 3600.022465113924,
    "input_throughput": 7094.560172193747,
    "output_throughput": 6187.743053235382,
    "total_throughput": 13282.303225429128,
    "itl": 82.19169411117629,
    "ttft": 1695906.1139895343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4897993049165261,
    "arrivals": 313505,
    "finished_requests": 103433,
    "scheduler_time": 277.1560750916668
}
#Debug simulation 
Total elapsed time: 100.13742244901368. Arrivals time: 0.5198847316787578 Scheduler time: 99.37203189212596 Scheduler overhead time: 0.09712601185310632 Adapter cache time: 0.018260249111335725 Engine time: 0.09384491859236732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.11399408103898,
    "estimated_duration": 3600.0092786133055,
    "input_throughput": 7252.930195240385,
    "output_throughput": 6324.659532202753,
    "total_throughput": 13577.589727443139,
    "itl": 85.41907711331748,
    "ttft": 1678609.153204994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.289552029995244,
    "arrivals": 313505,
    "finished_requests": 105737,
    "scheduler_time": 270.6490056373059
}
#Debug simulation 
Total elapsed time: 99.11417393601732. Arrivals time: 0.5275571113452315 Scheduler time: 98.34967770037474 Scheduler overhead time: 0.09294897713698447 Adapter cache time: 0.01785171910887584 Engine time: 0.09104571299394593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 101.70517524000024,
    "estimated_duration": 3600.0277947083578,
    "input_throughput": 7184.269254258698,
    "output_throughput": 6265.418570699469,
    "total_throughput": 13449.687824958168,
    "itl": 83.13443060158414,
    "ttft": 1683355.3487402014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.471315862480554,
    "arrivals": 313505,
    "finished_requests": 104597,
    "scheduler_time": 273.47676707135605
}
#Debug simulation 
Total elapsed time: 101.70535639597801. Arrivals time: 0.5158434074837714 Scheduler time: 100.94763228076044 Scheduler overhead time: 0.09569650527555496 Adapter cache time: 0.01796636520884931 Engine time: 0.09261050733039156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 100.30530228099087,
    "estimated_duration": 3600.039587022483,
    "input_throughput": 7310.5368326705675,
    "output_throughput": 6363.0458627667695,
    "total_throughput": 13673.582695437337,
    "itl": 86.50264688344615,
    "ttft": 1671828.8171276804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3621562605816855,
    "arrivals": 311621,
    "finished_requests": 106617,
    "scheduler_time": 268.42627666066517
}
#Debug simulation 
Total elapsed time: 100.30547765601659. Arrivals time: 0.5166670751641504 Scheduler time: 99.55081296095159 Scheduler overhead time: 0.09365164954215288 Adapter cache time: 0.017683297803159803 Engine time: 0.09125935274641961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.24237176199676,
    "estimated_duration": 3600.0836065339586,
    "input_throughput": 7288.185461131874,
    "output_throughput": 6343.6951737872305,
    "total_throughput": 13631.880634919105,
    "itl": 85.63041227883626,
    "ttft": 1672856.6707259952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6770921462541466,
    "arrivals": 311621,
    "finished_requests": 106165,
    "scheduler_time": 269.52446378096937
}
#Debug simulation 
Total elapsed time: 100.24254719301825. Arrivals time: 0.5211696476326324 Scheduler time: 99.48336213215953 Scheduler overhead time: 0.09371180576272309 Adapter cache time: 0.01807525270851329 Engine time: 0.09120216668816283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 95.08510122000007,
    "estimated_duration": 3600.0787624114346,
    "input_throughput": 7230.02626269356,
    "output_throughput": 6289.182957995632,
    "total_throughput": 13519.209220689192,
    "itl": 83.54741946621928,
    "ttft": 1682877.6453056405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.830439778817822,
    "arrivals": 311621,
    "finished_requests": 105347,
    "scheduler_time": 271.94630846956886
}
#Debug simulation 
Total elapsed time: 95.08527467795648. Arrivals time: 0.5125938864075579 Scheduler time: 94.33419833233347 Scheduler overhead time: 0.09321889386046678 Adapter cache time: 0.017951032263226807 Engine time: 0.09193042188417166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 99.90323866601102,
    "estimated_duration": 3600.0855475520693,
    "input_throughput": 7293.301409977187,
    "output_throughput": 6344.8664478353285,
    "total_throughput": 13638.167857812516,
    "itl": 85.48980257172393,
    "ttft": 1674308.684460881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.519127763784489,
    "arrivals": 311621,
    "finished_requests": 106263,
    "scheduler_time": 269.23639210475363
}
#Debug simulation 
Total elapsed time: 99.90342102601426. Arrivals time: 0.5296304717776366 Scheduler time: 99.13321739225648 Scheduler overhead time: 0.09489978989586234 Adapter cache time: 0.01812541240360588 Engine time: 0.09183183900313452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 95.6262158259633,
    "estimated_duration": 3600.063394771283,
    "input_throughput": 7230.057125606155,
    "output_throughput": 6289.209804717466,
    "total_throughput": 13519.266930323622,
    "itl": 83.5471429309501,
    "ttft": 1682871.268674227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8155273421015632,
    "arrivals": 311621,
    "finished_requests": 105347,
    "scheduler_time": 271.9460555285762
}
#Debug simulation 
Total elapsed time: 95.62639184499858. Arrivals time: 0.5239643398672342 Scheduler time: 94.85969001502963 Scheduler overhead time: 0.09482841263525188 Adapter cache time: 0.01775746583007276 Engine time: 0.09434606542345136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 103.71514857199509,
    "estimated_duration": 3600.0426163308935,
    "input_throughput": 7252.735531950747,
    "output_throughput": 6329.620904105866,
    "total_throughput": 13582.356436056614,
    "itl": 85.10424105142951,
    "ttft": 1671297.2319265837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3087037928169556,
    "arrivals": 311621,
    "finished_requests": 105743,
    "scheduler_time": 271.245697086831
}
#Debug simulation 
Total elapsed time: 103.71531849401072. Arrivals time: 0.5325092681450769 Scheduler time: 102.94229837757302 Scheduler overhead time: 0.09492186061106622 Adapter cache time: 0.018213068367913365 Engine time: 0.09217728697694838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 96.10533971094992,
    "estimated_duration": 3600.0434945363277,
    "input_throughput": 7195.000849103942,
    "output_throughput": 6266.604843591105,
    "total_throughput": 13461.605692695048,
    "itl": 83.40555294351336,
    "ttft": 1680598.3507641302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7777849952690348,
    "arrivals": 311621,
    "finished_requests": 104873,
    "scheduler_time": 273.0141319697732
}
#Debug simulation 
Total elapsed time: 96.10551898897393. Arrivals time: 0.5182554359198548 Scheduler time: 95.34726316691376 Scheduler overhead time: 0.09410259214928374 Adapter cache time: 0.018233283597510308 Engine time: 0.09185867453925312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 101.56477377103874,
    "estimated_duration": 3600.0259145175296,
    "input_throughput": 7281.9564698920585,
    "output_throughput": 6392.575094305738,
    "total_throughput": 13674.531564197798,
    "itl": 86.24635871378723,
    "ttft": 1667063.8822078025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4745672141248343,
    "arrivals": 310685,
    "finished_requests": 106576,
    "scheduler_time": 267.6026702524492
}
#Debug simulation 
Total elapsed time: 101.56494174298132. Arrivals time: 0.5310248447931372 Scheduler time: 100.79692395037273 Scheduler overhead time: 0.093276476720348 Adapter cache time: 0.017764489457476884 Engine time: 0.09094135777559131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 103.82372329197824,
    "estimated_duration": 3600.070136175361,
    "input_throughput": 7268.423394606167,
    "output_throughput": 6374.621918999786,
    "total_throughput": 13643.045313605953,
    "itl": 85.53396794286388,
    "ttft": 1668685.051052656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4783500823657971,
    "arrivals": 310685,
    "finished_requests": 106296,
    "scheduler_time": 268.4986890920326
}
#Debug simulation 
Total elapsed time: 103.8239033499849. Arrivals time: 0.5353135013720021 Scheduler time: 103.05210094939684 Scheduler overhead time: 0.09267729503335431 Adapter cache time: 0.01784992654575035 Engine time: 0.09096044336911291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 102.12840609898558,
    "estimated_duration": 3600.011281298226,
    "input_throughput": 7189.048582833048,
    "output_throughput": 6301.5283084944085,
    "total_throughput": 13490.576891327457,
    "itl": 83.26603232785163,
    "ttft": 1677120.150118679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5151679866481598,
    "arrivals": 310685,
    "finished_requests": 105107,
    "scheduler_time": 272.0442756690884
}
#Debug simulation 
Total elapsed time: 102.12858994799899. Arrivals time: 0.5339345401152968 Scheduler time: 101.35227498837048 Scheduler overhead time: 0.09513910952955484 Adapter cache time: 0.018187842098996043 Engine time: 0.09248794941231608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 99.26212074200157,
    "estimated_duration": 3600.0360806498966,
    "input_throughput": 7190.977929123035,
    "output_throughput": 6309.570374055649,
    "total_throughput": 13500.548303178684,
    "itl": 84.7696307371793,
    "ttft": 1673005.5013172743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.516908505763857,
    "arrivals": 310685,
    "finished_requests": 105146,
    "scheduler_time": 271.5862715160477
}
#Debug simulation 
Total elapsed time: 99.26228695799364. Arrivals time: 0.5126038849703036 Scheduler time: 98.51322395377792 Scheduler overhead time: 0.09292499208822846 Adapter cache time: 0.01767340855440125 Engine time: 0.09034431190229952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 100.09870038501685,
    "estimated_duration": 3600.001708257431,
    "input_throughput": 7104.533573229925,
    "output_throughput": 6239.356761547902,
    "total_throughput": 13343.890334777827,
    "itl": 82.16463634900953,
    "ttft": 1671611.686437141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5023804459441483,
    "arrivals": 310685,
    "finished_requests": 103893,
    "scheduler_time": 275.3893368976843
}
#Debug simulation 
Total elapsed time: 100.09887013403932. Arrivals time: 0.5242773488280363 Scheduler time: 99.33402307709912 Scheduler overhead time: 0.09450983622809872 Adapter cache time: 0.018132886849343777 Engine time: 0.09196614107349887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 96.77680483000586,
    "estimated_duration": 3600.0702320128385,
    "input_throughput": 7260.785294564993,
    "output_throughput": 6362.979198656452,
    "total_throughput": 13623.764493221446,
    "itl": 85.47917292958252,
    "ttft": 1672344.2999488793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4619178953906475,
    "arrivals": 310685,
    "finished_requests": 106128,
    "scheduler_time": 269.078418900323
}
#Debug simulation 
Total elapsed time: 96.77698606502963. Arrivals time: 0.5225544990389608 Scheduler time: 96.01707121700747 Scheduler overhead time: 0.09291492751799524 Adapter cache time: 0.017762900388333946 Engine time: 0.09193374449387193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 101.19055207498604,
    "estimated_duration": 3600.004677052244,
    "input_throughput": 7114.18047961284,
    "output_throughput": 6238.253006490216,
    "total_throughput": 13352.433486103057,
    "itl": 82.56686237762746,
    "ttft": 1680964.8180561017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6106747158058017,
    "arrivals": 310685,
    "finished_requests": 103996,
    "scheduler_time": 274.9759373003148
}
#Debug simulation 
Total elapsed time: 101.19071719702333. Arrivals time: 0.5172632915200666 Scheduler time: 100.43056219234131 Scheduler overhead time: 0.09474235429661348 Adapter cache time: 0.01815839612390846 Engine time: 0.09365953813539818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 100.08877507701982,
    "estimated_duration": 3600.0130910444304,
    "input_throughput": 7269.204955143044,
    "output_throughput": 6423.299697860629,
    "total_throughput": 13692.504653003673,
    "itl": 86.97450759661157,
    "ttft": 1661043.8836028138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5274664863804337,
    "arrivals": 310219,
    "finished_requests": 106507,
    "scheduler_time": 266.8955065853142
}
#Debug simulation 
Total elapsed time: 100.088949441968. Arrivals time: 0.5223760916851461 Scheduler time: 99.32884644588921 Scheduler overhead time: 0.09278855554293841 Adapter cache time: 0.017793036182411015 Engine time: 0.09177010378334671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.87562444497598,
    "estimated_duration": 3600.089611035194,
    "input_throughput": 7236.73319690189,
    "output_throughput": 6377.695135593541,
    "total_throughput": 13614.42833249543,
    "itl": 85.86027170583067,
    "ttft": 1672611.2668216412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6884717671619744,
    "arrivals": 310219,
    "finished_requests": 106032,
    "scheduler_time": 268.09145157615205
}
#Debug simulation 
Total elapsed time: 99.8758065039874. Arrivals time: 0.543157973617781 Scheduler time: 99.09368264308432 Scheduler overhead time: 0.09384165791561827 Adapter cache time: 0.018210116657428443 Engine time: 0.09155920706689358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 97.1778152519837,
    "estimated_duration": 3600.089717504927,
    "input_throughput": 7195.887056379879,
    "output_throughput": 6342.493879798358,
    "total_throughput": 13538.380936178237,
    "itl": 83.96850945752932,
    "ttft": 1677151.3559134707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.787109757759613,
    "arrivals": 310219,
    "finished_requests": 105318,
    "scheduler_time": 269.8007176133446
}
#Debug simulation 
Total elapsed time: 97.17798656295054. Arrivals time: 0.5498753202846274 Scheduler time: 96.38883597380482 Scheduler overhead time: 0.09360574348829687 Adapter cache time: 0.01795689994469285 Engine time: 0.09224448871100321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 100.44510821899166,
    "estimated_duration": 3600.0264183152062,
    "input_throughput": 7242.554906639327,
    "output_throughput": 6384.281760564468,
    "total_throughput": 13626.836667203796,
    "itl": 85.78668172860797,
    "ttft": 1665619.048421101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5396677475795133,
    "arrivals": 310219,
    "finished_requests": 106053,
    "scheduler_time": 268.16812630473936
}
#Debug simulation 
Total elapsed time: 100.44527824496618. Arrivals time: 0.5271968315937556 Scheduler time: 99.67984050908126 Scheduler overhead time: 0.09309604275040329 Adapter cache time: 0.017664571583736688 Engine time: 0.09239592618541792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 95.43849585199496,
    "estimated_duration": 3600.005094044165,
    "input_throughput": 7168.427912142117,
    "output_throughput": 6313.1169001954695,
    "total_throughput": 13481.544812337586,
    "itl": 83.81856902462694,
    "ttft": 1677817.4798786046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7721973210433544,
    "arrivals": 310219,
    "finished_requests": 104932,
    "scheduler_time": 270.99504706087833
}
#Debug simulation 
Total elapsed time: 95.43866738898214. Arrivals time: 0.5539253755123354 Scheduler time: 94.64463884342695 Scheduler overhead time: 0.09401736070867628 Adapter cache time: 0.018144791829399765 Engine time: 0.09254755522124469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 100.43781068897806,
    "estimated_duration": 3600.064401944847,
    "input_throughput": 7242.652377528066,
    "output_throughput": 6384.545506347897,
    "total_throughput": 13627.197883875962,
    "itl": 85.78371005075083,
    "ttft": 1665536.2592669695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.429998290687795,
    "arrivals": 310219,
    "finished_requests": 106056,
    "scheduler_time": 268.1792105992061
}
#Debug simulation 
Total elapsed time: 100.43797936401097. Arrivals time: 0.5259836313198321 Scheduler time: 99.67211429652525 Scheduler overhead time: 0.09436922549502924 Adapter cache time: 0.017776622204110026 Engine time: 0.09190243243938312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 95.47686395898927,
    "estimated_duration": 3600.08409358465,
    "input_throughput": 7168.500881962297,
    "output_throughput": 6313.2453046032115,
    "total_throughput": 13481.746186565508,
    "itl": 83.81821874837608,
    "ttft": 1677868.9631572661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7541781266778753,
    "arrivals": 310219,
    "finished_requests": 104936,
    "scheduler_time": 271.00209111920987
}
#Debug simulation 
Total elapsed time: 95.47702651901636. Arrivals time: 0.5478767043096013 Scheduler time: 94.69160367193399 Scheduler overhead time: 0.09315204009180889 Adapter cache time: 0.017892620584461838 Engine time: 0.0911242316942662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 100.35721529403236,
    "estimated_duration": 3600.0108900274718,
    "input_throughput": 7286.072404019822,
    "output_throughput": 6391.728998304338,
    "total_throughput": 13677.80140232416,
    "itl": 85.665831887674,
    "ttft": 1597742.321044149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.309256988326086,
    "arrivals": 270597,
    "finished_requests": 106236,
    "scheduler_time": 265.68066014481985
}
#Debug simulation 
Total elapsed time: 100.35739898204338. Arrivals time: 0.5226547383354045 Scheduler time: 99.59504659677623 Scheduler overhead time: 0.09415617561899126 Adapter cache time: 0.01777801994467154 Engine time: 0.09243506100028753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.65502908901544,
    "estimated_duration": 3600.071697639463,
    "input_throughput": 7264.615317841696,
    "output_throughput": 6359.029464610587,
    "total_throughput": 13623.644782452282,
    "itl": 84.50991744000086,
    "ttft": 1600918.6640796277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4358818938024356,
    "arrivals": 270597,
    "finished_requests": 105852,
    "scheduler_time": 267.52687772167315
}
#Debug simulation 
Total elapsed time: 100.65520298201591. Arrivals time: 0.5149289224646054 Scheduler time: 99.89999724802328 Scheduler overhead time: 0.09423129388596863 Adapter cache time: 0.01772744522895664 Engine time: 0.09327406366355717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.41662048001308,
    "estimated_duration": 3600.0718968700808,
    "input_throughput": 7171.624272961494,
    "output_throughput": 6279.434035651932,
    "total_throughput": 13451.058308613427,
    "itl": 82.30746929480195,
    "ttft": 1611916.1694443065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4412424784898783,
    "arrivals": 270597,
    "finished_requests": 104481,
    "scheduler_time": 271.1705840022103
}
#Debug simulation 
Total elapsed time: 99.41678673104616. Arrivals time: 0.4986001445213333 Scheduler time: 98.67721194203477 Scheduler overhead time: 0.09432804345851764 Adapter cache time: 0.017400787270162255 Engine time: 0.09321550582535565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 99.61087087995838,
    "estimated_duration": 3600.0108787279337,
    "input_throughput": 7272.592745400597,
    "output_throughput": 6365.9163185912,
    "total_throughput": 13638.509063991798,
    "itl": 84.53269563143496,
    "ttft": 1605302.0080064405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4419635285716492,
    "arrivals": 270597,
    "finished_requests": 105974,
    "scheduler_time": 266.9655057837474
}
#Debug simulation 
Total elapsed time: 99.61105171998497. Arrivals time: 0.510796437447425 Scheduler time: 98.86225427151658 Scheduler overhead time: 0.09300624550087377 Adapter cache time: 0.017967679537832737 Engine time: 0.09142100211465731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 99.82218400097918,
    "estimated_duration": 3600.0572395856852,
    "input_throughput": 7171.65347153517,
    "output_throughput": 6279.459601759463,
    "total_throughput": 13451.113073294633,
    "itl": 82.30721323654711,
    "ttft": 1611909.7150276944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.428194096363152,
    "arrivals": 270597,
    "finished_requests": 104481,
    "scheduler_time": 271.17018867460314
}
#Debug simulation 
Total elapsed time: 99.82234817399876. Arrivals time: 0.5060695030842908 Scheduler time: 99.07568513741717 Scheduler overhead time: 0.09421261370880529 Adapter cache time: 0.017665337538346648 Engine time: 0.09266110393218696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.93225432699546,
    "estimated_duration": 3600.0106343946613,
    "input_throughput": 7272.744905211224,
    "output_throughput": 6366.1189722717745,
    "total_throughput": 13638.863877482998,
    "itl": 84.53036450744854,
    "ttft": 1605303.4536100987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.340623397519808,
    "arrivals": 270597,
    "finished_requests": 105977,
    "scheduler_time": 266.9710794195796
}
#Debug simulation 
Total elapsed time: 98.93242979201023. Arrivals time: 0.5193786788149737 Scheduler time: 98.1744125658879 Scheduler overhead time: 0.09390822157729417 Adapter cache time: 0.017682886274997145 Engine time: 0.09184280841145664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.56763979699463,
    "estimated_duration": 3600.043780792306,
    "input_throughput": 7171.680282820848,
    "output_throughput": 6279.483077570998,
    "total_throughput": 13451.163360391847,
    "itl": 82.30698385332217,
    "ttft": 1611904.1524534905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4147314798831965,
    "arrivals": 270597,
    "finished_requests": 104481,
    "scheduler_time": 271.16988910403796
}
#Debug simulation 
Total elapsed time: 99.56781686999602. Arrivals time: 0.5112462899414822 Scheduler time: 98.81416674546199 Scheduler overhead time: 0.09461396734695882 Adapter cache time: 0.017943163984455168 Engine time: 0.09381882211891934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 102.02265858702594,
    "estimated_duration": 3600.0491074704914,
    "input_throughput": 7211.159410611676,
    "output_throughput": 6322.309035387669,
    "total_throughput": 13533.468445999344,
    "itl": 84.95908086718484,
    "ttft": 1596070.5171747452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3423190334858357,
    "arrivals": 266811,
    "finished_requests": 105413,
    "scheduler_time": 268.3906983344839
}
#Debug simulation 
Total elapsed time: 102.02283556904877. Arrivals time: 0.5093291013035923 Scheduler time: 101.27294697117759 Scheduler overhead time: 0.09440516593167558 Adapter cache time: 0.017971270077396184 Engine time: 0.09206772793550044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 97.04439778497908,
    "estimated_duration": 3600.0903513421335,
    "input_throughput": 7153.8196229988,
    "output_throughput": 6271.012890435782,
    "total_throughput": 13424.832513434581,
    "itl": 83.64692907145314,
    "ttft": 1605607.6055510645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6870835461886613,
    "arrivals": 266811,
    "finished_requests": 104624,
    "scheduler_time": 270.93980420396593
}
#Debug simulation 
Total elapsed time: 97.04457320302026. Arrivals time: 0.5089802881702781 Scheduler time: 96.29216346441535 Scheduler overhead time: 0.0958193201222457 Adapter cache time: 0.018192358140368015 Engine time: 0.09356350882444531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.41380402096547,
    "estimated_duration": 3600.073115643817,
    "input_throughput": 7112.869427214568,
    "output_throughput": 6238.038028287057,
    "total_throughput": 13350.907455501625,
    "itl": 82.05524594465847,
    "ttft": 1604738.9535904282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5058510654792217,
    "arrivals": 266811,
    "finished_requests": 103975,
    "scheduler_time": 272.33255668979706
}
#Debug simulation 
Total elapsed time: 99.41398875397863. Arrivals time: 0.5056098698405549 Scheduler time: 98.66280296375044 Scheduler overhead time: 0.09618262760341167 Adapter cache time: 0.01824947912245989 Engine time: 0.09468692581867799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 101.02711292001186,
    "estimated_duration": 3600.087033090851,
    "input_throughput": 7173.204359403693,
    "output_throughput": 6289.644886879206,
    "total_throughput": 13462.849246282898,
    "itl": 83.95234811853702,
    "ttft": 1599430.8824985519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3950568239670236,
    "arrivals": 266811,
    "finished_requests": 104859,
    "scheduler_time": 269.9351938599415
}
#Debug simulation 
Total elapsed time: 101.02728925202973. Arrivals time: 0.5102868896210566 Scheduler time: 100.27551555878017 Scheduler overhead time: 0.09481805755058303 Adapter cache time: 0.01773726992541924 Engine time: 0.09301174350548536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 99.29595546697965,
    "estimated_duration": 3600.0610832693155,
    "input_throughput": 7112.8932003413975,
    "output_throughput": 6238.05887749155,
    "total_throughput": 13350.952077832948,
    "itl": 82.05508228501873,
    "ttft": 1604734.1879940147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.493216917705725,
    "arrivals": 266811,
    "finished_requests": 103975,
    "scheduler_time": 272.332450544516
}
#Debug simulation 
Total elapsed time: 99.29613327095285. Arrivals time: 0.5133040638174862 Scheduler time: 98.53861602285178 Scheduler overhead time: 0.09600334096467122 Adapter cache time: 0.01825082302093506 Engine time: 0.0941991035360843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 97.48964324896224,
    "estimated_duration": 3600.0960246367954,
    "input_throughput": 7164.113352393715,
    "output_throughput": 6280.923576831888,
    "total_throughput": 13445.036929225604,
    "itl": 83.74351820882528,
    "ttft": 1604665.426068693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5129892629152115,
    "arrivals": 266811,
    "finished_requests": 104759,
    "scheduler_time": 270.46115908893927
}
#Debug simulation 
Total elapsed time: 97.48981462797383. Arrivals time: 0.5038423064397648 Scheduler time: 96.747385154129 Scheduler overhead time: 0.09337944851722568 Adapter cache time: 0.0175973575678654 Engine time: 0.09201667993329465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.93217581702629,
    "estimated_duration": 3600.068980594731,
    "input_throughput": 7112.486771231252,
    "output_throughput": 6237.585757673542,
    "total_throughput": 13350.072528904793,
    "itl": 82.00402380332129,
    "ttft": 1598880.441496193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.528260755185041,
    "arrivals": 266811,
    "finished_requests": 103947,
    "scheduler_time": 272.5164712196458
}
#Debug simulation 
Total elapsed time: 99.93234655202832. Arrivals time: 0.49103585787815973 Scheduler time: 99.20022168254945 Scheduler overhead time: 0.09482370049227029 Adapter cache time: 0.017583526961971074 Engine time: 0.0929208550369367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.7709739060374,
    "estimated_duration": 3600.0119025400095,
    "input_throughput": 7279.164544292437,
    "output_throughput": 6396.0107975626615,
    "total_throughput": 13675.1753418551,
    "itl": 86.08138521253342,
    "ttft": 1585422.2353101743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3753810786455853,
    "arrivals": 264887,
    "finished_requests": 106462,
    "scheduler_time": 264.3860993646162
}
#Debug simulation 
Total elapsed time: 99.77114500600146. Arrivals time: 0.5178004070767201 Scheduler time: 99.0150732731563 Scheduler overhead time: 0.09396722260862589 Adapter cache time: 0.017651649832259864 Engine time: 0.09136802103603259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.38441564701498,
    "estimated_duration": 3600.0417921799794,
    "input_throughput": 7244.15312529133,
    "output_throughput": 6367.700522198256,
    "total_throughput": 13611.853647489586,
    "itl": 85.07030686085848,
    "ttft": 1587564.246724503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5341432967362942,
    "arrivals": 264887,
    "finished_requests": 105910,
    "scheduler_time": 265.6438317137386
}
#Debug simulation 
Total elapsed time: 98.38458522304427. Arrivals time: 0.5029519565869123 Scheduler time: 97.64549862156855 Scheduler overhead time: 0.09270052309148014 Adapter cache time: 0.017392633482813835 Engine time: 0.09121168247656897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.63630610599648,
    "estimated_duration": 3600.0041208333273,
    "input_throughput": 7180.1017811103575,
    "output_throughput": 6309.654721934594,
    "total_throughput": 13489.756503044951,
    "itl": 83.17374590150943,
    "ttft": 1593157.9086154797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6091312129423065,
    "arrivals": 264887,
    "finished_requests": 105046,
    "scheduler_time": 268.3297217044598
}
#Debug simulation 
Total elapsed time: 98.63647330499953. Arrivals time: 0.4973977847257629 Scheduler time: 97.89834408357274 Scheduler overhead time: 0.09482977259904146 Adapter cache time: 0.017240811372175813 Engine time: 0.09280662902165204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 98.13207738299388,
    "estimated_duration": 3600.0311377494936,
    "input_throughput": 7257.427505566768,
    "output_throughput": 6367.040762411035,
    "total_throughput": 13624.468267977802,
    "itl": 85.08811703666231,
    "ttft": 1587812.649312772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4708328382065503,
    "arrivals": 264887,
    "finished_requests": 106034,
    "scheduler_time": 265.5811120660415
}
#Debug simulation 
Total elapsed time: 98.13225168397184. Arrivals time: 0.5129098760080524 Scheduler time: 97.38108714629197 Scheduler overhead time: 0.09342174581252038 Adapter cache time: 0.017387083324138075 Engine time: 0.09225434553809464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 98.39838483399944,
    "estimated_duration": 3600.031679955287,
    "input_throughput": 7180.0468156772,
    "output_throughput": 6309.606419986316,
    "total_throughput": 13489.653235663516,
    "itl": 83.17219486182125,
    "ttft": 1593246.9604653965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5954614792857362,
    "arrivals": 264887,
    "finished_requests": 105046,
    "scheduler_time": 268.33173334146034
}
#Debug simulation 
Total elapsed time: 98.39855994097888. Arrivals time: 0.5014400808140635 Scheduler time: 97.65578091487987 Scheduler overhead time: 0.09403732063947245 Adapter cache time: 0.017818343359977007 Engine time: 0.09263854171149433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.6478239329881,
    "estimated_duration": 3600.008696263205,
    "input_throughput": 7257.255246943952,
    "output_throughput": 6366.770175802996,
    "total_throughput": 13624.025422746949,
    "itl": 85.08514420969742,
    "ttft": 1587725.5067221376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3597751603415196,
    "arrivals": 264887,
    "finished_requests": 106030,
    "scheduler_time": 265.5882992820365
}
#Debug simulation 
Total elapsed time: 98.64799095800845. Arrivals time: 0.5069012708845548 Scheduler time: 97.90197520062793 Scheduler overhead time: 0.09421077719889581 Adapter cache time: 0.017442013893742114 Engine time: 0.09210568270646036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.68099824700039,
    "estimated_duration": 3600.014137619356,
    "input_throughput": 7180.081802982368,
    "output_throughput": 6309.6371657642985,
    "total_throughput": 13489.718968746667,
    "itl": 83.1718575257885,
    "ttft": 1593239.427136825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5784778708033307,
    "arrivals": 264887,
    "finished_requests": 105046,
    "scheduler_time": 268.3312921677653
}
#Debug simulation 
Total elapsed time: 98.6811666249996. Arrivals time: 0.4910842970130034 Scheduler time: 97.95133543061092 Scheduler overhead time: 0.09339200099930167 Adapter cache time: 0.017906648921780288 Engine time: 0.09179666033014655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.86108868196607,
    "estimated_duration": 3600.069057537984,
    "input_throughput": 7234.8801047201,
    "output_throughput": 6342.863604848801,
    "total_throughput": 13577.7437095689,
    "itl": 85.36924506502343,
    "ttft": 1579698.9444885808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1902336257509873,
    "arrivals": 263940,
    "finished_requests": 105941,
    "scheduler_time": 266.5668732347719
}
#Debug simulation 
Total elapsed time: 98.86127322597895. Arrivals time: 0.5015816129161976 Scheduler time: 98.12257460394176 Scheduler overhead time: 0.09272307471837848 Adapter cache time: 0.017634970892686397 Engine time: 0.09165020153159276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.42241799499607,
    "estimated_duration": 3600.0107026664546,
    "input_throughput": 7102.650272973107,
    "output_throughput": 6233.444523756222,
    "total_throughput": 13336.094796729329,
    "itl": 83.57274033017741,
    "ttft": 1595683.9199957317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.247131229848602,
    "arrivals": 263940,
    "finished_requests": 104067,
    "scheduler_time": 271.67851493301555
}
#Debug simulation 
Total elapsed time: 99.42258810898056. Arrivals time: 0.4983040785882622 Scheduler time: 98.68200137227541 Scheduler overhead time: 0.09524655435234308 Adapter cache time: 0.017911837378051132 Engine time: 0.09286891086958349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 96.66449726803694,
    "estimated_duration": 3600.0575316896907,
    "input_throughput": 7144.4172137793985,
    "output_throughput": 6256.773899229323,
    "total_throughput": 13401.191113008723,
    "itl": 82.38942848116318,
    "ttft": 1590431.160911116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.376633891500534,
    "arrivals": 263940,
    "finished_requests": 104556,
    "scheduler_time": 270.5238721999171
}
#Debug simulation 
Total elapsed time: 96.6646767280181. Arrivals time: 0.5018353998311795 Scheduler time: 95.92197443882469 Scheduler overhead time: 0.0951376793673262 Adapter cache time: 0.017716041940730065 Engine time: 0.09225775062805042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 101.2991668379982,
    "estimated_duration": 3600.010532389052,
    "input_throughput": 7228.146352875135,
    "output_throughput": 6340.52867196812,
    "total_throughput": 13568.675024843255,
    "itl": 84.52838729223029,
    "ttft": 1576111.4545892153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2507197534758585,
    "arrivals": 263940,
    "finished_requests": 105905,
    "scheduler_time": 266.5741451566442
}
#Debug simulation 
Total elapsed time: 101.29936163499951. Arrivals time: 0.5257911296794191 Scheduler time: 100.53378119808622 Scheduler overhead time: 0.09401673678075895 Adapter cache time: 0.017684330407064408 Engine time: 0.0926103467354551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 99.9400816950365,
    "estimated_duration": 3600.0753532545255,
    "input_throughput": 7131.031848206142,
    "output_throughput": 6256.349878798662,
    "total_throughput": 13387.381727004804,
    "itl": 82.23975522240322,
    "ttft": 1588818.057216688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3350611940398824,
    "arrivals": 263940,
    "finished_requests": 104472,
    "scheduler_time": 270.67813141416485
}
#Debug simulation 
Total elapsed time: 99.94025568902725. Arrivals time: 0.506758569739759 Scheduler time: 99.18894034309778 Scheduler overhead time: 0.09676977980416268 Adapter cache time: 0.01774967019446194 Engine time: 0.09409968607360497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.16234421299305,
    "estimated_duration": 3600.041292867583,
    "input_throughput": 7210.416183677587,
    "output_throughput": 6322.114983817536,
    "total_throughput": 13532.531167495123,
    "itl": 84.40042700045966,
    "ttft": 1580998.9908336923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1554896902432636,
    "arrivals": 263940,
    "finished_requests": 105589,
    "scheduler_time": 267.533206277625
}
#Debug simulation 
Total elapsed time: 99.1625193869695. Arrivals time: 0.49773388635367155 Scheduler time: 98.42590618523536 Scheduler overhead time: 0.09410770534304902 Adapter cache time: 0.017492722312454134 Engine time: 0.0921375269535929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.30883509898558,
    "estimated_duration": 3600.061713268107,
    "input_throughput": 7131.058866403415,
    "output_throughput": 6256.373582983249,
    "total_throughput": 13387.432449386664,
    "itl": 82.23951687710885,
    "ttft": 1588812.010615889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3218056947365415,
    "arrivals": 263940,
    "finished_requests": 104472,
    "scheduler_time": 270.67786363542507
}
#Debug simulation 
Total elapsed time: 100.30901941302. Arrivals time: 0.49582719756290317 Scheduler time: 99.56946746323956 Scheduler overhead time: 0.09571990452241153 Adapter cache time: 0.01788689458044246 Engine time: 0.0937471894430928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.66512901999522,
    "estimated_duration": 3600.018145811141,
    "input_throughput": 7275.139162971867,
    "output_throughput": 6360.48377329519,
    "total_throughput": 13635.622936267058,
    "itl": 85.23837318550996,
    "ttft": 1592371.2610911615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5274664863804337,
    "arrivals": 263449,
    "finished_requests": 106057,
    "scheduler_time": 266.6348898954595
}
#Debug simulation 
Total elapsed time: 99.66529951698612. Arrivals time: 0.5085652737761848 Scheduler time: 98.9176497531007 Scheduler overhead time: 0.0942740470636636 Adapter cache time: 0.017449651088099927 Engine time: 0.09202823310624808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 101.54737309197662,
    "estimated_duration": 3600.0493287301624,
    "input_throughput": 7218.791918378155,
    "output_throughput": 6316.115953894566,
    "total_throughput": 13534.90787227272,
    "itl": 84.22608130948947,
    "ttft": 1594845.5841921181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5696703804330916,
    "arrivals": 263449,
    "finished_requests": 105315,
    "scheduler_time": 268.474132235602
}
#Debug simulation 
Total elapsed time: 101.5475541499909. Arrivals time: 0.504192694905214 Scheduler time: 100.80064278555801 Scheduler overhead time: 0.09528425900498405 Adapter cache time: 0.017866178357508034 Engine time: 0.09408865048317239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.37888818001375,
    "estimated_duration": 3600.0621211483167,
    "input_throughput": 7175.581456844461,
    "output_throughput": 6267.755733282355,
    "total_throughput": 13443.337190126816,
    "itl": 82.29144526635964,
    "ttft": 1589769.602074656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5797765736375033,
    "arrivals": 263449,
    "finished_requests": 104553,
    "scheduler_time": 270.8143669324843
}
#Debug simulation 
Total elapsed time: 100.37905754498206. Arrivals time: 0.4995643357397057 Scheduler time: 99.63861691718921 Scheduler overhead time: 0.0942452292656526 Adapter cache time: 0.017430589359719306 Engine time: 0.09249476582044736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 101.39429395803018,
    "estimated_duration": 3600.0840632638074,
    "input_throughput": 7218.851155503035,
    "output_throughput": 6316.2027887163085,
    "total_throughput": 13535.053944219344,
    "itl": 84.2244584235355,
    "ttft": 1594841.9636818897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.476659575221127,
    "arrivals": 263449,
    "finished_requests": 105316,
    "scheduler_time": 268.4835368147711
}
#Debug simulation 
Total elapsed time: 101.39447414001916. Arrivals time: 0.5124197504483163 Scheduler time: 100.64070370129775 Scheduler overhead time: 0.09487710386747494 Adapter cache time: 0.017729989252984524 Engine time: 0.09329471504315734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 100.09616744198138,
    "estimated_duration": 3600.0477735837294,
    "input_throughput": 7175.6100542756285,
    "output_throughput": 6267.78071268148,
    "total_throughput": 13443.390766957107,
    "itl": 82.29118077012302,
    "ttft": 1589763.9661483425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.565278371274474,
    "arrivals": 263449,
    "finished_requests": 104553,
    "scheduler_time": 270.8140119141528
}
#Debug simulation 
Total elapsed time: 100.09633688197937. Arrivals time: 0.5087190497433767 Scheduler time: 99.34537626133533 Scheduler overhead time: 0.0948672637459822 Adapter cache time: 0.018020514282397926 Engine time: 0.09332070616073906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 101.55331443203613,
    "estimated_duration": 3600.080606685682,
    "input_throughput": 7218.882808272916,
    "output_throughput": 6316.334961436973,
    "total_throughput": 13535.217769709889,
    "itl": 84.22268405397494,
    "ttft": 1594738.7412903022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3725430022226606,
    "arrivals": 263449,
    "finished_requests": 105318,
    "scheduler_time": 268.4889653606658
}
#Debug simulation 
Total elapsed time: 101.55349536600988. Arrivals time: 0.5123966058017686 Scheduler time: 100.79734853247646 Scheduler overhead time: 0.09564251400297508 Adapter cache time: 0.018504601495806128 Engine time: 0.09339917555917054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.618194990966,
    "estimated_duration": 3600.0336554646847,
    "input_throughput": 7175.638194600598,
    "output_throughput": 6267.805292805644,
    "total_throughput": 13443.44348740624,
    "itl": 82.29090332539926,
    "ttft": 1589758.217770563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5503659345582157,
    "arrivals": 263449,
    "finished_requests": 104553,
    "scheduler_time": 270.81379491960706
}
#Debug simulation 
Total elapsed time: 100.61835153499851. Arrivals time: 0.5002421087701805 Scheduler time: 99.87639406434027 Scheduler overhead time: 0.09500565059715882 Adapter cache time: 0.01768346136668697 Engine time: 0.09314033907139674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 97.01804890797939,
    "estimated_duration": 3600.0246368772146,
    "input_throughput": 7279.303794635057,
    "output_throughput": 6326.844757306267,
    "total_throughput": 13606.148551941324,
    "itl": 85.45513341352455,
    "ttft": 1577529.3113099835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3687686696136354,
    "arrivals": 259027,
    "finished_requests": 106019,
    "scheduler_time": 266.8563976939654
}
#Debug simulation 
Total elapsed time: 97.01821883697994. Arrivals time: 0.49731538840569556 Scheduler time: 96.28278973221313 Scheduler overhead time: 0.09423394635086879 Adapter cache time: 0.01700227370020002 Engine time: 0.0918441591784358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 102.34796975296922,
    "estimated_duration": 3600.0275621582837,
    "input_throughput": 7166.081524257432,
    "output_throughput": 6238.038907273405,
    "total_throughput": 13404.120431530837,
    "itl": 83.37539714612815,
    "ttft": 1580152.5597163648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2279794670268902,
    "arrivals": 259027,
    "finished_requests": 104487,
    "scheduler_time": 271.16302235653166
}
#Debug simulation 
Total elapsed time: 102.3481477299938. Arrivals time: 0.4806206860812381 Scheduler time: 101.62565077428007 Scheduler overhead time: 0.09545025991974398 Adapter cache time: 0.01727553765522316 Engine time: 0.09328410372836515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 97.73067095695296,
    "estimated_duration": 3600.0744467255563,
    "input_throughput": 7141.6959233676625,
    "output_throughput": 6205.873053631094,
    "total_throughput": 13347.568976998757,
    "itl": 81.80323864578608,
    "ttft": 1598080.3666104104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4527361646527452,
    "arrivals": 259027,
    "finished_requests": 103986,
    "scheduler_time": 272.7394895973269
}
#Debug simulation 
Total elapsed time: 97.73084018100053. Arrivals time: 0.46877007151488215 Scheduler time: 97.0224629517179 Scheduler overhead time: 0.09518740221392363 Adapter cache time: 0.016711888660211116 Engine time: 0.09199731424450874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 94.66144599800464,
    "estimated_duration": 3600.0071006364315,
    "input_throughput": 7157.624493419656,
    "output_throughput": 6221.581617447474,
    "total_throughput": 13379.20611086713,
    "itl": 83.33042845349482,
    "ttft": 1590476.965920963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2662640373036256,
    "arrivals": 259027,
    "finished_requests": 104243,
    "scheduler_time": 271.9617615652665
}
#Debug simulation 
Total elapsed time: 94.66161590395495. Arrivals time: 0.418661902542226 Scheduler time: 94.01585732144304 Scheduler overhead time: 0.08966470876475796 Adapter cache time: 0.016032426327001303 Engine time: 0.08704191277502105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 98.00398263003444,
    "estimated_duration": 3600.081479676805,
    "input_throughput": 7163.790915730969,
    "output_throughput": 6227.804322365725,
    "total_throughput": 13391.595238096694,
    "itl": 82.0586334899009,
    "ttft": 1586969.3241989876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5376862626103718,
    "arrivals": 259027,
    "finished_requests": 104336,
    "scheduler_time": 271.62508945891796
}
#Debug simulation 
Total elapsed time: 98.0041593760252. Arrivals time: 0.4400876400177367 Scheduler time: 97.33160414826125 Scheduler overhead time: 0.09180414624279365 Adapter cache time: 0.016593734442722052 Engine time: 0.08888648322317749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 96.04567537800176,
    "estimated_duration": 3600.0611206188414,
    "input_throughput": 7245.65753914647,
    "output_throughput": 6295.045900805252,
    "total_throughput": 13540.703439951723,
    "itl": 84.413877050696,
    "ttft": 1580683.2642139278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3087037928169556,
    "arrivals": 259027,
    "finished_requests": 105499,
    "scheduler_time": 268.4249202894707
}
#Debug simulation 
Total elapsed time: 96.0458471190068. Arrivals time: 0.45537153154145926 Scheduler time: 95.36065941117704 Scheduler overhead time: 0.0908544929116033 Adapter cache time: 0.01613999909022823 Engine time: 0.08825622138101608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.45722653303528,
    "estimated_duration": 3600.0876848188714,
    "input_throughput": 7096.151326460071,
    "output_throughput": 6176.681777438089,
    "total_throughput": 13272.83310389816,
    "itl": 81.35860164540263,
    "ttft": 1590317.7988402238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2663624912500395,
    "arrivals": 259027,
    "finished_requests": 103467,
    "scheduler_time": 274.1618426677516
}
#Debug simulation 
Total elapsed time: 98.45739197201328. Arrivals time: 0.452071200881619 Scheduler time: 97.76770306058461 Scheduler overhead time: 0.0945069282897748 Adapter cache time: 0.016424993344116956 Engine time: 0.09129827155265957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 97.82480007200502,
    "estimated_duration": 3600.0065106444363,
    "input_throughput": 7255.93715532587,
    "output_throughput": 6342.934639835522,
    "total_throughput": 13598.87179516139,
    "itl": 85.4132961573628,
    "ttft": 1575215.1607034137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.216683261878787,
    "arrivals": 257078,
    "finished_requests": 105833,
    "scheduler_time": 266.1690064822654
}
#Debug simulation 
Total elapsed time: 97.8249699450098. Arrivals time: 0.45348667190410197 Scheduler time: 97.14304133120459 Scheduler overhead time: 0.09066141018411145 Adapter cache time: 0.01605255645699799 Engine time: 0.08688384300330654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.56300493696472,
    "estimated_duration": 3600.017993066466,
    "input_throughput": 7257.079284136137,
    "output_throughput": 6335.045281419219,
    "total_throughput": 13592.124565555356,
    "itl": 84.69284897528604,
    "ttft": 1578133.5294857437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5527378756320116,
    "arrivals": 257078,
    "finished_requests": 105749,
    "scheduler_time": 266.4503053096396
}
#Debug simulation 
Total elapsed time: 93.56316889595473. Arrivals time: 0.45302741206251085 Scheduler time: 92.88344483741093 Scheduler overhead time: 0.09017901221523061 Adapter cache time: 0.01604655320988968 Engine time: 0.08658829022897407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.2674689439591,
    "estimated_duration": 3600.0652114141753,
    "input_throughput": 7167.439611424145,
    "output_throughput": 6264.07625298029,
    "total_throughput": 13431.515864404435,
    "itl": 82.56397854000983,
    "ttft": 1585864.8850331816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4552178602432846,
    "arrivals": 257078,
    "finished_requests": 104492,
    "scheduler_time": 269.78939008164133
}
#Debug simulation 
Total elapsed time: 93.26763153501088. Arrivals time: 0.4429231673129834 Scheduler time: 92.59472788963467 Scheduler overhead time: 0.09159608173649758 Adapter cache time: 0.016155348683241755 Engine time: 0.08746173611143604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 98.64306325296639,
    "estimated_duration": 3600.031305123359,
    "input_throughput": 7174.043448801348,
    "output_throughput": 6273.21767115193,
    "total_throughput": 13447.261119953278,
    "itl": 84.12067540985679,
    "ttft": 1581443.8198851205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2401711696153495,
    "arrivals": 257078,
    "finished_requests": 104633,
    "scheduler_time": 269.50050890980606
}
#Debug simulation 
Total elapsed time: 98.64323411794612. Arrivals time: 0.449315159174148 Scheduler time: 97.96448656055145 Scheduler overhead time: 0.09188759815879166 Adapter cache time: 0.016206301981583238 Engine time: 0.08646576426690444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 93.29646823200164,
    "estimated_duration": 3600.0426025492925,
    "input_throughput": 7167.95378524876,
    "output_throughput": 6264.298923582312,
    "total_throughput": 13432.252708831073,
    "itl": 82.56327970998893,
    "ttft": 1585772.8682789854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.442583712469788,
    "arrivals": 257078,
    "finished_requests": 104496,
    "scheduler_time": 269.7859285258225
}
#Debug simulation 
Total elapsed time: 93.29663160897326. Arrivals time: 0.4462047677952796 Scheduler time: 92.62135165720247 Scheduler overhead time: 0.09110942389816046 Adapter cache time: 0.016279941773973405 Engine time: 0.08729703654535115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 95.94021836901084,
    "estimated_duration": 3600.093909245034,
    "input_throughput": 7232.366059434319,
    "output_throughput": 6319.782087232058,
    "total_throughput": 13552.148146666377,
    "itl": 84.55347811364628,
    "ttft": 1578261.3851028737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2704002671735326,
    "arrivals": 257078,
    "finished_requests": 105387,
    "scheduler_time": 267.2865945278376
}
#Debug simulation 
Total elapsed time: 95.94036776997382. Arrivals time: 0.45609113055979833 Scheduler time: 95.25582308805315 Scheduler overhead time: 0.09116623981390148 Adapter cache time: 0.01639883575262502 Engine time: 0.08659794961567968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.23909575399011,
    "estimated_duration": 3600.0085412187323,
    "input_throughput": 7167.356328344963,
    "output_throughput": 6263.721805606106,
    "total_throughput": 13431.078133951069,
    "itl": 82.56139081849365,
    "ttft": 1585870.0700529166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4214592569693938,
    "arrivals": 257078,
    "finished_requests": 104481,
    "scheduler_time": 269.78853577396524
}
#Debug simulation 
Total elapsed time: 93.2392494790256. Arrivals time: 0.44914256763877347 Scheduler time: 92.5631295152125 Scheduler overhead time: 0.09020958835026249 Adapter cache time: 0.015778660075739026 Engine time: 0.0869426773278974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.01590455998667,
    "estimated_duration": 3600.0109695241777,
    "input_throughput": 7334.393484775928,
    "output_throughput": 6379.226950809924,
    "total_throughput": 13713.620435585852,
    "itl": 85.76380933845037,
    "ttft": 1564302.5968277087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.408443123805335,
    "arrivals": 256097,
    "finished_requests": 106104,
    "scheduler_time": 264.2766769070427
}
#Debug simulation 
Total elapsed time: 98.01605238998309. Arrivals time: 0.46118403878062963 Scheduler time: 97.32753656618297 Scheduler overhead time: 0.09060968400444835 Adapter cache time: 0.01614551740931347 Engine time: 0.08637283206917346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.10545626503881,
    "estimated_duration": 3600.086149837945,
    "input_throughput": 7245.0405113705665,
    "output_throughput": 6311.911452736451,
    "total_throughput": 13556.951964107018,
    "itl": 84.45443695673403,
    "ttft": 1574932.5436033527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.389249042319135,
    "arrivals": 256097,
    "finished_requests": 104962,
    "scheduler_time": 267.49033039369215
}
#Debug simulation 
Total elapsed time: 98.1056058020331. Arrivals time: 0.4577522071194835 Scheduler time: 97.41926697490271 Scheduler overhead time: 0.09113857324700803 Adapter cache time: 0.015908274392131716 Engine time: 0.08716228132834658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.81005408399506,
    "estimated_duration": 3600.021353066579,
    "input_throughput": 7216.394418847087,
    "output_throughput": 6283.2593980954825,
    "total_throughput": 13499.65381694257,
    "itl": 82.6233471225016,
    "ttft": 1580389.0810485824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5266616728110265,
    "arrivals": 256097,
    "finished_requests": 104511,
    "scheduler_time": 268.88585519875653
}
#Debug simulation 
Total elapsed time: 93.81020740797976. Arrivals time: 0.45505068480269983 Scheduler time: 93.12515145266661 Scheduler overhead time: 0.09142955567222089 Adapter cache time: 0.016471732349600643 Engine time: 0.08765630493871868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 92.53589868702693,
    "estimated_duration": 3600.019092748872,
    "input_throughput": 7219.609488280302,
    "output_throughput": 6291.592743388818,
    "total_throughput": 13511.20223166912,
    "itl": 84.23524165019342,
    "ttft": 1579506.721180858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.320111846774815,
    "arrivals": 256097,
    "finished_requests": 104547,
    "scheduler_time": 268.4306264939709
}
#Debug simulation 
Total elapsed time: 92.53604403301142. Arrivals time: 0.44771033216966316 Scheduler time: 91.85932162532117 Scheduler overhead time: 0.09037688939133659 Adapter cache time: 0.016221099416725338 Engine time: 0.08786908851470798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 93.35186106502078,
    "estimated_duration": 3600.0352916449315,
    "input_throughput": 7213.971501966446,
    "output_throughput": 6278.656504412222,
    "total_throughput": 13492.628006378669,
    "itl": 82.57312385455306,
    "ttft": 1584880.9739997701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6691780150029842,
    "arrivals": 256097,
    "finished_requests": 104441,
    "scheduler_time": 268.99923591753674
}
#Debug simulation 
Total elapsed time: 93.35200752102537. Arrivals time: 0.45750117988791317 Scheduler time: 92.66352202306734 Scheduler overhead time: 0.09185151400743052 Adapter cache time: 0.01644562726141885 Engine time: 0.08793434995459393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 92.39490506798029,
    "estimated_duration": 3600.071635811952,
    "input_throughput": 7258.371122414221,
    "output_throughput": 6324.963029482727,
    "total_throughput": 13583.334151896948,
    "itl": 84.54299824081478,
    "ttft": 1575620.417096812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.289552029995244,
    "arrivals": 256097,
    "finished_requests": 105104,
    "scheduler_time": 266.87517427581224
}
#Debug simulation 
Total elapsed time: 92.39505647099577. Arrivals time: 0.450120699882973 Scheduler time: 91.71694284887053 Scheduler overhead time: 0.09101164859021083 Adapter cache time: 0.016222617006860673 Engine time: 0.0865554788033478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.73403323802631,
    "estimated_duration": 3600.0909963314025,
    "input_throughput": 7216.3123172369105,
    "output_throughput": 6282.421478525869,
    "total_throughput": 13498.733795762779,
    "itl": 82.60368993888977,
    "ttft": 1584065.9352091695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5694677354954207,
    "arrivals": 256097,
    "finished_requests": 104482,
    "scheduler_time": 268.8411990550303
}
#Debug simulation 
Total elapsed time: 93.73417907202384. Arrivals time: 0.45516839443007484 Scheduler time: 93.04774459538748 Scheduler overhead time: 0.09204561333172023 Adapter cache time: 0.016160377475898713 Engine time: 0.08791779685998335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 94.47731214901432,
    "estimated_duration": 3600.033983864374,
    "input_throughput": 7288.651195407308,
    "output_throughput": 6387.998030872583,
    "total_throughput": 13676.64922627989,
    "itl": 86.16965947540845,
    "ttft": 1562603.3938935662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2629701251024366,
    "arrivals": 255593,
    "finished_requests": 106310,
    "scheduler_time": 263.353845781671
}
#Debug simulation 
Total elapsed time: 94.47745342296548. Arrivals time: 0.456361556542106 Scheduler time: 93.7949986414751 Scheduler overhead time: 0.09003982489230111 Adapter cache time: 0.01569720753468573 Engine time: 0.08657370606670156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 101.64327180397231,
    "estimated_duration": 3600.0283980398635,
    "input_throughput": 7196.748229571358,
    "output_throughput": 6309.9305028727895,
    "total_throughput": 13506.678732444148,
    "itl": 84.59721745873054,
    "ttft": 1565609.7104929422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2909876393852762,
    "arrivals": 255593,
    "finished_requests": 104978,
    "scheduler_time": 266.94996373206703
}
#Debug simulation 
Total elapsed time: 101.64342116902117. Arrivals time: 0.46371854888275266 Scheduler time: 100.94914735335624 Scheduler overhead time: 0.0919957208679989 Adapter cache time: 0.015991299238521606 Engine time: 0.08800426538800821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.66586025903234,
    "estimated_duration": 3600.0483129275012,
    "input_throughput": 7115.827837090444,
    "output_throughput": 6251.669434318849,
    "total_throughput": 13367.497271409293,
    "itl": 82.61537464501548,
    "ttft": 1587705.376069529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6439172020275183,
    "arrivals": 255593,
    "finished_requests": 103917,
    "scheduler_time": 269.8862072592478
}
#Debug simulation 
Total elapsed time: 93.66599744203268. Arrivals time: 0.4525434247334488 Scheduler time: 92.98350005986867 Scheduler overhead time: 0.09146251430502161 Adapter cache time: 0.016404116933699697 Engine time: 0.08710142585914582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 99.04093503399054,
    "estimated_duration": 3600.0671873206848,
    "input_throughput": 7124.62980978117,
    "output_throughput": 6247.301461264808,
    "total_throughput": 13371.931271045978,
    "itl": 84.00026138561927,
    "ttft": 1575354.8170545315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.153846571515313,
    "arrivals": 255593,
    "finished_requests": 103888,
    "scheduler_time": 270.13849507378785
}
#Debug simulation 
Total elapsed time: 99.04107982403366. Arrivals time: 0.4597646438051015 Scheduler time: 98.34848244820023 Scheduler overhead time: 0.09261010918999091 Adapter cache time: 0.01648664369713515 Engine time: 0.08845209883293137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 93.88772350398358,
    "estimated_duration": 3600.0883247895654,
    "input_throughput": 7112.633549482913,
    "output_throughput": 6247.078952240596,
    "total_throughput": 13359.712501723508,
    "itl": 82.55045017109826,
    "ttft": 1587797.1392596015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6121793980523973,
    "arrivals": 255593,
    "finished_requests": 103877,
    "scheduler_time": 270.089762761078
}
#Debug simulation 
Total elapsed time: 93.887869321974. Arrivals time: 0.4548180186538957 Scheduler time: 93.19996294716839 Scheduler overhead time: 0.09233461390249431 Adapter cache time: 0.01662490190938115 Engine time: 0.08915917336707935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 94.3561648830073,
    "estimated_duration": 3600.091629414181,
    "input_throughput": 7258.431642822415,
    "output_throughput": 6364.303011845376,
    "total_throughput": 13622.73465466779,
    "itl": 85.17013629182472,
    "ttft": 1566129.8489884152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.378926923163231,
    "arrivals": 255593,
    "finished_requests": 105895,
    "scheduler_time": 264.57904405308454
}
#Debug simulation 
Total elapsed time: 94.35630825802218. Arrivals time: 0.4561323835514486 Scheduler time: 93.67011698358692 Scheduler overhead time: 0.0915630774688907 Adapter cache time: 0.016311720421072096 Engine time: 0.08778093080036342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.88893154502148,
    "estimated_duration": 3600.05133497807,
    "input_throughput": 7118.689878392001,
    "output_throughput": 6242.228209819928,
    "total_throughput": 13360.91808821193,
    "itl": 82.3880161597356,
    "ttft": 1575971.4477301855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2712280690111233,
    "arrivals": 255593,
    "finished_requests": 103793,
    "scheduler_time": 270.3726649623962
}
#Debug simulation 
Total elapsed time: 99.88908003503457. Arrivals time: 0.4595300913788378 Scheduler time: 99.19376603985438 Scheduler overhead time: 0.09441613435046747 Adapter cache time: 0.016366093361284584 Engine time: 0.0895248424494639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 95.62606841296656,
    "estimated_duration": 3600.003956940356,
    "input_throughput": 7169.797397094259,
    "output_throughput": 6260.706451877218,
    "total_throughput": 13430.503848971477,
    "itl": 85.05592538605892,
    "ttft": 1567336.3792612492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1968460347829373,
    "arrivals": 253064,
    "finished_requests": 104552,
    "scheduler_time": 268.9103602017523
}
#Debug simulation 
Total elapsed time: 95.62621546897572. Arrivals time: 0.4540742435492575 Scheduler time: 94.93972798320465 Scheduler overhead time: 0.09250272274948657 Adapter cache time: 0.016642914910335094 Engine time: 0.0882778114755638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.40834159200313,
    "estimated_duration": 3600.0534033066306,
    "input_throughput": 7127.703710292552,
    "output_throughput": 6213.166443435354,
    "total_throughput": 13340.870153727907,
    "itl": 83.69581150225457,
    "ttft": 1570809.4682366266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2732240975368778,
    "arrivals": 253064,
    "finished_requests": 103840,
    "scheduler_time": 271.2566414788023
}
#Debug simulation 
Total elapsed time: 98.40848512900993. Arrivals time: 0.45826464315177873 Scheduler time: 97.71402435284108 Scheduler overhead time: 0.09407291962997988 Adapter cache time: 0.0165313973557204 Engine time: 0.09036128281150013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 94.29903513600584,
    "estimated_duration": 3600.0316507278626,
    "input_throughput": 7229.682270914975,
    "output_throughput": 6307.943708052868,
    "total_throughput": 13537.625978967842,
    "itl": 82.81856947252199,
    "ttft": 1565410.340326591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9158589731389708,
    "arrivals": 253064,
    "finished_requests": 105372,
    "scheduler_time": 266.71816929086447
}
#Debug simulation 
Total elapsed time: 94.2991805030033. Arrivals time: 0.46068376902258024 Scheduler time: 93.60578857827932 Scheduler overhead time: 0.09269994852365926 Adapter cache time: 0.01706091465894133 Engine time: 0.08817113284021616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 94.74511029897258,
    "estimated_duration": 3600.064366899874,
    "input_throughput": 7131.650543823197,
    "output_throughput": 6225.61841006754,
    "total_throughput": 13357.268953890736,
    "itl": 84.02895012175952,
    "ttft": 1571435.0983793812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2529390114964902,
    "arrivals": 253064,
    "finished_requests": 103989,
    "scheduler_time": 270.59203468271807
}
#Debug simulation 
Total elapsed time: 94.74525415699463. Arrivals time: 0.4504534231382422 Scheduler time: 94.06322038028156 Scheduler overhead time: 0.09211603121366352 Adapter cache time: 0.016554575820919126 Engine time: 0.08847547927871346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 94.12235695298295,
    "estimated_duration": 3600.01360394772,
    "input_throughput": 7229.718513135365,
    "output_throughput": 6307.975329620388,
    "total_throughput": 13537.693842755752,
    "itl": 82.81818338447812,
    "ttft": 1565403.6952317427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8978397787734917,
    "arrivals": 253064,
    "finished_requests": 105372,
    "scheduler_time": 266.7179507928948
}
#Debug simulation 
Total elapsed time: 94.1225004469743. Arrivals time: 0.45949073211522773 Scheduler time: 93.43001253635157 Scheduler overhead time: 0.0920972649473697 Adapter cache time: 0.016920156951528043 Engine time: 0.08834679133724421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 96.58631520700874,
    "estimated_duration": 3600.090192634945,
    "input_throughput": 7178.480987190239,
    "output_throughput": 6266.74827373907,
    "total_throughput": 13445.229260929309,
    "itl": 84.1299554163737,
    "ttft": 1570122.625804898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1491057693026931,
    "arrivals": 253064,
    "finished_requests": 104681,
    "scheduler_time": 268.71566074576356
}
#Debug simulation 
Total elapsed time: 96.5864647339913. Arrivals time: 0.4535672018537298 Scheduler time: 95.90083007060457 Scheduler overhead time: 0.09222664835397154 Adapter cache time: 0.01652528834529221 Engine time: 0.08859162172302604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 97.04620432702359,
    "estimated_duration": 3600.0562861224166,
    "input_throughput": 7061.805699538865,
    "output_throughput": 6164.812779609226,
    "total_throughput": 13226.61847914809,
    "itl": 81.74177261254583,
    "ttft": 1577308.7119951781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2993400052562378,
    "arrivals": 253064,
    "finished_requests": 102971,
    "scheduler_time": 273.63863642658026
}
#Debug simulation 
Total elapsed time: 97.04635056998814. Arrivals time: 0.44975177163723856 Scheduler time: 96.35956226830604 Scheduler overhead time: 0.0940215919399634 Adapter cache time: 0.01688662392552942 Engine time: 0.0902229929342866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 104.92215839301934,
    "estimated_duration": 3600.0705338262933,
    "input_throughput": 7229.203082401541,
    "output_throughput": 6347.756185685513,
    "total_throughput": 13576.959268087054,
    "itl": 85.65383361706706,
    "ttft": 1546998.91557342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2431328980065868,
    "arrivals": 252140,
    "finished_requests": 105472,
    "scheduler_time": 265.33669905677516
}
#Debug simulation 
Total elapsed time: 104.92230403103167. Arrivals time: 0.4650913361692801 Scheduler time: 104.22329627576983 Scheduler overhead time: 0.09328055533114821 Adapter cache time: 0.01665644528111443 Engine time: 0.08897916082059965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.27975150494603,
    "estimated_duration": 3600.067988704299,
    "input_throughput": 7235.364743590542,
    "output_throughput": 6344.1976850609935,
    "total_throughput": 13579.562428651536,
    "itl": 84.96427702055229,
    "ttft": 1559534.0854340403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6573831995064403,
    "arrivals": 252140,
    "finished_requests": 105582,
    "scheduler_time": 265.5925549270325
}
#Debug simulation 
Total elapsed time: 93.27990147395758. Arrivals time: 0.44631148007465526 Scheduler time: 92.60416947246995 Scheduler overhead time: 0.09130733279744163 Adapter cache time: 0.016622346418444067 Engine time: 0.08706782129593194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 90.99423306999961,
    "estimated_duration": 3600.062549937907,
    "input_throughput": 7191.128943147534,
    "output_throughput": 6300.844134052959,
    "total_throughput": 13491.973077200493,
    "itl": 82.99669136358663,
    "ttft": 1568609.7451669686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7905273705488112,
    "arrivals": 252140,
    "finished_requests": 104877,
    "scheduler_time": 267.56691641163815
}
#Debug simulation 
Total elapsed time: 90.99438166199252. Arrivals time: 0.45121940807439387 Scheduler time: 90.31365272641415 Scheduler overhead time: 0.0913283156696707 Adapter cache time: 0.01647675660206005 Engine time: 0.08681683510076255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 103.09059101395542,
    "estimated_duration": 3600.037996311868,
    "input_throughput": 7230.674794729301,
    "output_throughput": 6346.349406146873,
    "total_throughput": 13577.024200876172,
    "itl": 84.69435781008848,
    "ttft": 1556282.3799922427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3661875143321214,
    "arrivals": 252140,
    "finished_requests": 105553,
    "scheduler_time": 265.4004624928816
}
#Debug simulation 
Total elapsed time: 103.09074299299391. Arrivals time: 0.4679634437779896 Scheduler time: 102.3900499062147 Scheduler overhead time: 0.09234728314913809 Adapter cache time: 0.01671025773975998 Engine time: 0.08887737680925056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 93.91651546797948,
    "estimated_duration": 3600.08509220193,
    "input_throughput": 7217.396071076698,
    "output_throughput": 6324.613006875803,
    "total_throughput": 13542.0090779525,
    "itl": 83.08900244821466,
    "ttft": 1562734.3732936603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7390645588422229,
    "arrivals": 252140,
    "finished_requests": 105276,
    "scheduler_time": 266.42930414335086
}
#Debug simulation 
Total elapsed time: 93.91665932600154. Arrivals time: 0.4604555200203322 Scheduler time: 93.22404688468669 Scheduler overhead time: 0.09198551694862545 Adapter cache time: 0.01689486438408494 Engine time: 0.08853443915722892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 104.13262382900575,
    "estimated_duration": 3600.0753741378867,
    "input_throughput": 7241.313942279009,
    "output_throughput": 6354.533620140753,
    "total_throughput": 13595.847562419762,
    "itl": 84.78345964522171,
    "ttft": 1553785.7256089088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3597751603415196,
    "arrivals": 252140,
    "finished_requests": 105650,
    "scheduler_time": 265.10195088168456
}
#Debug simulation 
Total elapsed time: 104.13276446104283. Arrivals time: 0.4680765903904103 Scheduler time: 103.43290574540151 Scheduler overhead time: 0.09236690128454939 Adapter cache time: 0.016859177267178893 Engine time: 0.08811023237649351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 91.61632393399486,
    "estimated_duration": 3600.054780973717,
    "input_throughput": 7197.1802031834595,
    "output_throughput": 6313.127266872534,
    "total_throughput": 13510.307470055994,
    "itl": 83.02301749135451,
    "ttft": 1566802.31018176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7556798158958595,
    "arrivals": 252140,
    "finished_requests": 105000,
    "scheduler_time": 267.01223647234536
}
#Debug simulation 
Total elapsed time: 91.6164715209743. Arrivals time: 0.4536682078614831 Scheduler time: 90.93156780593563 Scheduler overhead time: 0.0916439521824941 Adapter cache time: 0.016872986394446343 Engine time: 0.08781278773676604 
