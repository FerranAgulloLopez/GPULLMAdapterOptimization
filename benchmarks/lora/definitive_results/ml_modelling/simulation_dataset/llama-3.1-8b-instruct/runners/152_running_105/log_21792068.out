INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61530096 . Total output tokens: 54440120
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.754002190195024,
    "estimated_duration": 3600.0459327713065,
    "input_throughput": 4296.632678820493,
    "output_throughput": 3745.456378002431,
    "total_throughput": 8042.089056822924,
    "itl": 136.69029317880756,
    "ttft": 1455203.1159675354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.350961299836765,
    "arrivals": 92215,
    "finished_requests": 62241,
    "scheduler_time": 54.57236698184123
}
#Debug simulation 
Total elapsed time: 4.754114926792681. Arrivals time: 0.2142549050040543 Scheduler time: 4.367418727837503 Scheduler overhead time: 0.03941418509930372 Adapter cache time: 0.07339368062093854 Engine time: 0.04075569426640868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61530096 . Total output tokens: 54440120
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.665388181805611,
    "estimated_duration": 3600.0112786260206,
    "input_throughput": 4182.10467544594,
    "output_throughput": 3650.116064362772,
    "total_throughput": 7832.220739808712,
    "itl": 117.58077522145643,
    "ttft": 1494271.683257875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.89488807463514,
    "arrivals": 92215,
    "finished_requests": 60593,
    "scheduler_time": 53.32795909661917
}
#Debug simulation 
Total elapsed time: 4.665488050784916. Arrivals time: 0.19896630896255374 Scheduler time: 4.271231293212622 Scheduler overhead time: 0.04471255838871002 Adapter cache time: 0.08242105273529887 Engine time: 0.046716831624507904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61530096 . Total output tokens: 54440120
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.685719111934304,
    "estimated_duration": 3600.0541661560674,
    "input_throughput": 4183.531776156917,
    "output_throughput": 3651.3695053748647,
    "total_throughput": 7834.901281531781,
    "itl": 117.48192179341231,
    "ttft": 1493966.740180971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.691045593018995,
    "arrivals": 92215,
    "finished_requests": 60617,
    "scheduler_time": 53.33954588481702
}
#Debug simulation 
Total elapsed time: 4.685808954760432. Arrivals time: 0.19494229974225163 Scheduler time: 4.295217825565487 Scheduler overhead time: 0.04485915834084153 Adapter cache time: 0.08275500172749162 Engine time: 0.04646036494523287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61530096 . Total output tokens: 54440120
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.669308368116617,
    "estimated_duration": 3600.1145979150997,
    "input_throughput": 4186.5222870206635,
    "output_throughput": 3654.219787230852,
    "total_throughput": 7840.742074251516,
    "itl": 117.48374440358127,
    "ttft": 1493922.4664436958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.49605171043535,
    "arrivals": 92215,
    "finished_requests": 60661,
    "scheduler_time": 53.3595547156739
}
#Debug simulation 
Total elapsed time: 4.66942672803998. Arrivals time: 0.19689311925321817 Scheduler time: 4.27654631016776 Scheduler overhead time: 0.04484896222129464 Adapter cache time: 0.08261474361643195 Engine time: 0.04676254093647003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59963727 . Total output tokens: 53014399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.8908371538855135,
    "estimated_duration": 3600.1060356497815,
    "input_throughput": 4466.494275660343,
    "output_throughput": 3902.2847829715015,
    "total_throughput": 8368.779058631844,
    "itl": 132.4857312575614,
    "ttft": 1335001.4785276353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.520342769832622,
    "arrivals": 89808,
    "finished_requests": 65147,
    "scheduler_time": 56.22474279017087
}
#Debug simulation 
Total elapsed time: 4.890953803900629. Arrivals time: 0.19656122149899602 Scheduler time: 4.525404233951122 Scheduler overhead time: 0.04092812305316329 Adapter cache time: 0.06587429996579885 Engine time: 0.04264036798849702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59963727 . Total output tokens: 53014399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.833716855384409,
    "estimated_duration": 3600.064786531123,
    "input_throughput": 4348.25258105523,
    "output_throughput": 3799.0485757836686,
    "total_throughput": 8147.301156838898,
    "itl": 114.17407467907735,
    "ttft": 1414601.937007965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.225285958805966,
    "arrivals": 89808,
    "finished_requests": 63395,
    "scheduler_time": 54.82281987605103
}
#Debug simulation 
Total elapsed time: 4.833801785018295. Arrivals time: 0.20195644814521074 Scheduler time: 4.441772402264178 Scheduler overhead time: 0.04617071058601141 Adapter cache time: 0.0733125233091414 Engine time: 0.04817179311066866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59963727 . Total output tokens: 53014399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.807527706027031,
    "estimated_duration": 3600.0966277109983,
    "input_throughput": 4348.683832398728,
    "output_throughput": 3799.5607936493643,
    "total_throughput": 8148.244626048092,
    "itl": 114.15979673024678,
    "ttft": 1414212.6480967447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.574210322322404,
    "arrivals": 89808,
    "finished_requests": 63403,
    "scheduler_time": 54.83255650773225
}
#Debug simulation 
Total elapsed time: 4.807603871915489. Arrivals time: 0.19991361489519477 Scheduler time: 4.4167811227962375 Scheduler overhead time: 0.04637477407231927 Adapter cache time: 0.07427798770368099 Engine time: 0.0480889780446887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59963727 . Total output tokens: 53014399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.831992240156978,
    "estimated_duration": 3600.059862520673,
    "input_throughput": 4348.478524754004,
    "output_throughput": 3799.2754349432594,
    "total_throughput": 8147.753959697264,
    "itl": 114.02460345393727,
    "ttft": 1414338.986440401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.818470406597681,
    "arrivals": 89808,
    "finished_requests": 63397,
    "scheduler_time": 54.829171254063354
}
#Debug simulation 
Total elapsed time: 4.832113194745034. Arrivals time: 0.2057989831082523 Scheduler time: 4.434903370216489 Scheduler overhead time: 0.046427751425653696 Adapter cache time: 0.07442810339853168 Engine time: 0.0483182049356401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59161959 . Total output tokens: 52305498
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.0317421169020236,
    "estimated_duration": 3600.114352794672,
    "input_throughput": 4572.215042897778,
    "output_throughput": 4008.510448785475,
    "total_throughput": 8580.725491683253,
    "itl": 127.874747106736,
    "ttft": 1215751.906564719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.395725770071255,
    "arrivals": 88684,
    "finished_requests": 66683,
    "scheduler_time": 57.291216249785094
}
#Debug simulation 
Total elapsed time: 5.031853711232543. Arrivals time: 0.20723906764760613 Scheduler time: 4.661171595100313 Scheduler overhead time: 0.04239964857697487 Adapter cache time: 0.05647894088178873 Engine time: 0.04428448434919119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59161959 . Total output tokens: 52305498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.945356453768909,
    "estimated_duration": 3600.0462081800165,
    "input_throughput": 4438.620527617676,
    "output_throughput": 3901.2224254477446,
    "total_throughput": 8339.842953065421,
    "itl": 110.82787900820428,
    "ttft": 1312830.5563951647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7895937650837075,
    "arrivals": 88684,
    "finished_requests": 64796,
    "scheduler_time": 55.78443954761403
}
#Debug simulation 
Total elapsed time: 4.945441695861518. Arrivals time: 0.20444057136774063 Scheduler time: 4.55546912830323 Scheduler overhead time: 0.04761348897591233 Adapter cache time: 0.06523254793137312 Engine time: 0.04977634362876415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59161959 . Total output tokens: 52305498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.930408779066056,
    "estimated_duration": 3600.00489689945,
    "input_throughput": 4436.771187104892,
    "output_throughput": 3900.0127505638075,
    "total_throughput": 8336.7839376687,
    "itl": 110.69294369524798,
    "ttft": 1313807.3613746176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.46197361538186,
    "arrivals": 88684,
    "finished_requests": 64775,
    "scheduler_time": 55.769258422139075
}
#Debug simulation 
Total elapsed time: 4.930521861184388. Arrivals time: 0.20140559691935778 Scheduler time: 4.543725429102778 Scheduler overhead time: 0.047712682746350765 Adapter cache time: 0.06468426575884223 Engine time: 0.04994752584025264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59161959 . Total output tokens: 52305498
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.932362477760762,
    "estimated_duration": 3600.0725750675983,
    "input_throughput": 4429.877639258578,
    "output_throughput": 3893.763724954014,
    "total_throughput": 8323.641364212592,
    "itl": 110.82406183689356,
    "ttft": 1318635.5874269418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.056065384931838,
    "arrivals": 88684,
    "finished_requests": 64680,
    "scheduler_time": 55.70002666855561
}
#Debug simulation 
Total elapsed time: 4.932454347610474. Arrivals time: 0.20387323247268796 Scheduler time: 4.54396474827081 Scheduler overhead time: 0.04754222184419632 Adapter cache time: 0.06425488879904151 Engine time: 0.049939549062401056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58762688 . Total output tokens: 51955503
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.12545224558562,
    "estimated_duration": 3600.0722059257737,
    "input_throughput": 4664.41811149224,
    "output_throughput": 4105.929590986867,
    "total_throughput": 8770.347702479106,
    "itl": 125.17916547941924,
    "ttft": 1122917.494223751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4862657960131895,
    "arrivals": 88054,
    "finished_requests": 67898,
    "scheduler_time": 58.34176856564257
}
#Debug simulation 
Total elapsed time: 5.125530899967998. Arrivals time: 0.19348467281088233 Scheduler time: 4.77302120719105 Scheduler overhead time: 0.04297058889642358 Adapter cache time: 0.050542236771434546 Engine time: 0.04493071511387825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58762688 . Total output tokens: 51955503
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.016445727087557,
    "estimated_duration": 3599.976652507666,
    "input_throughput": 4512.468431895033,
    "output_throughput": 3969.7874123836605,
    "total_throughput": 8482.255844278694,
    "itl": 108.6501512155938,
    "ttft": 1242102.1616281972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6655234349239643,
    "arrivals": 88054,
    "finished_requests": 65674,
    "scheduler_time": 56.453365810863154
}
#Debug simulation 
Total elapsed time: 5.016533838119358. Arrivals time: 0.20103409187868237 Scheduler time: 4.635793494060636 Scheduler overhead time: 0.04848765395581722 Adapter cache time: 0.05736172245815396 Engine time: 0.05056344112381339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58762688 . Total output tokens: 51955503
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.979502317029983,
    "estimated_duration": 3600.023817872037,
    "input_throughput": 4512.567644511468,
    "output_throughput": 3969.896234866522,
    "total_throughput": 8482.46387937799,
    "itl": 108.64345567397585,
    "ttft": 1241969.8273284754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5155955698061705,
    "arrivals": 88054,
    "finished_requests": 65677,
    "scheduler_time": 56.455441675505405
}
#Debug simulation 
Total elapsed time: 4.979605485219508. Arrivals time: 0.1992082386277616 Scheduler time: 4.599226518534124 Scheduler overhead time: 0.048597042448818684 Adapter cache time: 0.058632844127714634 Engine time: 0.050955417566001415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58762688 . Total output tokens: 51955503
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.0226780120283365,
    "estimated_duration": 3599.98599228498,
    "input_throughput": 4512.615058729371,
    "output_throughput": 3969.9379471553916,
    "total_throughput": 8482.553005884763,
    "itl": 108.63658240805933,
    "ttft": 1241794.2446682155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3428989851893762,
    "arrivals": 88054,
    "finished_requests": 65677,
    "scheduler_time": 56.456141862032716
}
#Debug simulation 
Total elapsed time: 5.022793836891651. Arrivals time: 0.20299123646691442 Scheduler time: 4.639309571590275 Scheduler overhead time: 0.048630908597260714 Adapter cache time: 0.05772540718317032 Engine time: 0.050865362863987684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56753960 . Total output tokens: 50222776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.136018869932741,
    "estimated_duration": 3600.068238824737,
    "input_throughput": 4689.913879385765,
    "output_throughput": 4110.230978519064,
    "total_throughput": 8800.144857904828,
    "itl": 125.29966194779651,
    "ttft": 977581.176952245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.168358854963737,
    "arrivals": 85140,
    "finished_requests": 68268,
    "scheduler_time": 57.81243733849869
}
#Debug simulation 
Total elapsed time: 5.13609362533316. Arrivals time: 0.19022255297750235 Scheduler time: 4.773097227793187 Scheduler overhead time: 0.043208288960158825 Adapter cache time: 0.06383397150784731 Engine time: 0.04497677739709616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56753960 . Total output tokens: 50222776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.038966496940702,
    "estimated_duration": 3600.077665861847,
    "input_throughput": 4555.554496926057,
    "output_throughput": 3994.878815081626,
    "total_throughput": 8550.433312007683,
    "itl": 108.12000377780579,
    "ttft": 1087579.8390064393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.817356965234387,
    "arrivals": 85140,
    "finished_requests": 66290,
    "scheduler_time": 56.086578804101634
}
#Debug simulation 
Total elapsed time: 5.0390568929724395. Arrivals time: 0.1968411640264094 Scheduler time: 4.64910715771839 Scheduler overhead time: 0.049044398590922356 Adapter cache time: 0.06931710196658969 Engine time: 0.05129874870181084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56753960 . Total output tokens: 50222776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.01825533201918,
    "estimated_duration": 3600.095976137735,
    "input_throughput": 4556.875735740763,
    "output_throughput": 3995.6470870068993,
    "total_throughput": 8552.522822747662,
    "itl": 108.09659258273705,
    "ttft": 1086869.302683856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.113528931764993,
    "arrivals": 85140,
    "finished_requests": 66305,
    "scheduler_time": 56.094572914041834
}
#Debug simulation 
Total elapsed time: 5.0183326210826635. Arrivals time: 0.1945088286884129 Scheduler time: 4.630659910850227 Scheduler overhead time: 0.04897167766466737 Adapter cache time: 0.06946155615150928 Engine time: 0.05130398040637374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56753960 . Total output tokens: 50222776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.071364440955222,
    "estimated_duration": 3600.0172566531874,
    "input_throughput": 4557.8795406259715,
    "output_throughput": 3996.8580632240455,
    "total_throughput": 8554.737603850017,
    "itl": 108.07002929747092,
    "ttft": 1086110.2739464657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.32280016090282,
    "arrivals": 85140,
    "finished_requests": 66318,
    "scheduler_time": 56.102211037701395
}
#Debug simulation 
Total elapsed time: 5.071493338793516. Arrivals time: 0.19797978969290853 Scheduler time: 4.680715186521411 Scheduler overhead time: 0.0489307651296258 Adapter cache time: 0.06907662050798535 Engine time: 0.05111194355413318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55925102 . Total output tokens: 49512946
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.357936643995345,
    "estimated_duration": 3600.0754289669426,
    "input_throughput": 4855.028275064648,
    "output_throughput": 4288.5318112432715,
    "total_throughput": 9143.56008630792,
    "itl": 120.09674121101767,
    "ttft": 777062.1345503088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.818919948116065,
    "arrivals": 83948,
    "finished_requests": 70903,
    "scheduler_time": 59.657592626305366
}
#Debug simulation 
Total elapsed time: 5.358027519192547. Arrivals time: 0.19248238764703274 Scheduler time: 4.997967983130366 Scheduler overhead time: 0.04474113276228309 Adapter cache time: 0.054505737498402596 Engine time: 0.04687310103327036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55925102 . Total output tokens: 49512946
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.211679485160857,
    "estimated_duration": 3600.1047239090876,
    "input_throughput": 4705.210070002331,
    "output_throughput": 4150.272324238452,
    "total_throughput": 8855.482394240782,
    "itl": 104.09168999216763,
    "ttft": 909633.8041303012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.326702594188982,
    "arrivals": 83948,
    "finished_requests": 68654,
    "scheduler_time": 57.61823793308783
}
#Debug simulation 
Total elapsed time: 5.211813557893038. Arrivals time: 0.19631004007533193 Scheduler time: 4.8274926245212555 Scheduler overhead time: 0.05057171219959855 Adapter cache time: 0.060079810209572315 Engine time: 0.05314532574266195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55925102 . Total output tokens: 49512946
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.1714123990386724,
    "estimated_duration": 3600.047159005282,
    "input_throughput": 4705.4575264732375,
    "output_throughput": 4150.572850864723,
    "total_throughput": 8856.03037733796,
    "itl": 104.08457439440936,
    "ttft": 909329.8759450065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.941060494412661,
    "arrivals": 83948,
    "finished_requests": 68658,
    "scheduler_time": 57.62194024911069
}
#Debug simulation 
Total elapsed time: 5.171500141732395. Arrivals time: 0.19341615214943886 Scheduler time: 4.790648966096342 Scheduler overhead time: 0.05068256100639701 Adapter cache time: 0.05963306687772274 Engine time: 0.052824285347014666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55925102 . Total output tokens: 49512946
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.217198075260967,
    "estimated_duration": 3600.098834646709,
    "input_throughput": 4706.186907133247,
    "output_throughput": 4151.046036897631,
    "total_throughput": 8857.232944030877,
    "itl": 104.0668767067809,
    "ttft": 908546.8142635449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.509323771712343,
    "arrivals": 83948,
    "finished_requests": 68673,
    "scheduler_time": 57.625850102501175
}
#Debug simulation 
Total elapsed time: 5.217291180975735. Arrivals time: 0.19736615614965558 Scheduler time: 4.83285197429359 Scheduler overhead time: 0.050605385564267635 Adapter cache time: 0.0590470009483397 Engine time: 0.053133109118789434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.392859078943729,
    "estimated_duration": 3600.055984547322,
    "input_throughput": 5005.034665388868,
    "output_throughput": 4352.409258982743,
    "total_throughput": 9357.443924371612,
    "itl": 117.23583706134411,
    "ttft": 668123.4347759666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.253305243719407,
    "arrivals": 83337,
    "finished_requests": 72308,
    "scheduler_time": 60.22348956869555
}
#Debug simulation 
Total elapsed time: 5.3929368406534195. Arrivals time: 0.18733825162053108 Scheduler time: 5.039209276903421 Scheduler overhead time: 0.046117950696498156 Adapter cache time: 0.050606883596628904 Engine time: 0.04780516494065523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.267610847949982,
    "estimated_duration": 3600.015504308316,
    "input_throughput": 4836.924446342246,
    "output_throughput": 4201.613293581131,
    "total_throughput": 9038.537739923377,
    "itl": 101.7958791523606,
    "ttft": 816646.3788021714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.512394095049243,
    "arrivals": 83337,
    "finished_requests": 69823,
    "scheduler_time": 57.97023411250705
}
#Debug simulation 
Total elapsed time: 5.267701360862702. Arrivals time: 0.1947001558728516 Scheduler time: 4.888524758629501 Scheduler overhead time: 0.051714134868234396 Adapter cache time: 0.054050561506301165 Engine time: 0.054103114642202854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.246759084053338,
    "estimated_duration": 3600.0150627379007,
    "input_throughput": 4837.963368618279,
    "output_throughput": 4202.497971909589,
    "total_throughput": 9040.461340527869,
    "itl": 101.86235864042361,
    "ttft": 815682.9564359282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3155405699601346,
    "arrivals": 83337,
    "finished_requests": 69839,
    "scheduler_time": 57.98138371759718
}
#Debug simulation 
Total elapsed time: 5.246864412911236. Arrivals time: 0.19160401169210672 Scheduler time: 4.870099410880357 Scheduler overhead time: 0.05141656845808029 Adapter cache time: 0.054976808838546276 Engine time: 0.054193293675780296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.279214222915471,
    "estimated_duration": 3600.111706886906,
    "input_throughput": 4838.676524030209,
    "output_throughput": 4203.251518849429,
    "total_throughput": 9041.92804287964,
    "itl": 101.85736175436502,
    "ttft": 815245.8240300457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1025855771172655,
    "arrivals": 83337,
    "finished_requests": 69850,
    "scheduler_time": 57.985427385277795
}
#Debug simulation 
Total elapsed time: 5.2793014496564865. Arrivals time: 0.200435777194798 Scheduler time: 4.891960733104497 Scheduler overhead time: 0.05179812712594867 Adapter cache time: 0.05601883167400956 Engine time: 0.05406915070489049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.5544996811077,
    "estimated_duration": 3600.1131722496198,
    "input_throughput": 5172.08712868456,
    "output_throughput": 4498.228590375312,
    "total_throughput": 9670.315719059872,
    "itl": 113.63222392331008,
    "ttft": 418789.6724938563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.453711215183279,
    "arrivals": 81595,
    "finished_requests": 74674,
    "scheduler_time": 61.36606984363869
}
#Debug simulation 
Total elapsed time: 5.55460866028443. Arrivals time: 0.18381594168022275 Scheduler time: 5.202644030097872 Scheduler overhead time: 0.04748973995447159 Adapter cache time: 0.04857071349397302 Engine time: 0.0495207398198545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.405198246706277,
    "estimated_duration": 3599.9906577088623,
    "input_throughput": 4981.7209835243875,
    "output_throughput": 4333.824302180103,
    "total_throughput": 9315.545285704491,
    "itl": 98.91311593988212,
    "ttft": 588251.2820191534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.916261534108789,
    "arrivals": 81595,
    "finished_requests": 71975,
    "scheduler_time": 58.86210274820746
}
#Debug simulation 
Total elapsed time: 5.405309644062072. Arrivals time: 0.19367870455607772 Scheduler time: 5.026080406270921 Scheduler overhead time: 0.05314955534413457 Adapter cache time: 0.051420871168375015 Engine time: 0.05561604630202055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.372823889832944,
    "estimated_duration": 3599.997893697039,
    "input_throughput": 4981.955692641119,
    "output_throughput": 4334.448647128339,
    "total_throughput": 9316.404339769457,
    "itl": 98.899541505542,
    "ttft": 587763.5484563954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 947,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.49535672607365,
    "arrivals": 81595,
    "finished_requests": 71983,
    "scheduler_time": 58.867678570996745
}
#Debug simulation 
Total elapsed time: 5.372910238802433. Arrivals time: 0.1871369811706245 Scheduler time: 5.000212984159589 Scheduler overhead time: 0.053374587558209896 Adapter cache time: 0.05107389064505696 Engine time: 0.05584181286394596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.376631848979741,
    "estimated_duration": 3599.9970439656745,
    "input_throughput": 4982.868535980676,
    "output_throughput": 4334.968003976172,
    "total_throughput": 9317.836539956848,
    "itl": 98.88732032351268,
    "ttft": 587284.8911750177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.064724893541976,
    "arrivals": 81595,
    "finished_requests": 71991,
    "scheduler_time": 58.87222666488871
}
#Debug simulation 
Total elapsed time: 5.376717172097415. Arrivals time: 0.1890069073997438 Scheduler time: 5.002250936347991 Scheduler overhead time: 0.053280814085155725 Adapter cache time: 0.050862887408584356 Engine time: 0.05580110242590308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.643948024138808,
    "estimated_duration": 3600.112161731195,
    "input_throughput": 5230.150104808287,
    "output_throughput": 4585.297695853441,
    "total_throughput": 9815.447800661728,
    "itl": 111.11157924835514,
    "ttft": 312082.2771002149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.954220601106123,
    "arrivals": 81010,
    "finished_requests": 75926,
    "scheduler_time": 62.257531268740095
}
#Debug simulation 
Total elapsed time: 5.644079212099314. Arrivals time: 0.18488450860604644 Scheduler time: 5.294780992902815 Scheduler overhead time: 0.04841078631579876 Adapter cache time: 0.042677354998886585 Engine time: 0.050273038912564516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.482229507993907,
    "estimated_duration": 3600.0610301533557,
    "input_throughput": 5036.9284987448,
    "output_throughput": 4417.267892628639,
    "total_throughput": 9454.196391373438,
    "itl": 97.05238059631432,
    "ttft": 493760.2985085289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.229924262268474,
    "arrivals": 81010,
    "finished_requests": 73086,
    "scheduler_time": 59.70688468143516
}
#Debug simulation 
Total elapsed time: 5.482318812981248. Arrivals time: 0.18752659484744072 Scheduler time: 5.113586970604956 Scheduler overhead time: 0.05423858668655157 Adapter cache time: 0.044770526234060526 Engine time: 0.05643652146682143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.468998657073826,
    "estimated_duration": 3600.019324107638,
    "input_throughput": 5036.697963974001,
    "output_throughput": 4417.226289178813,
    "total_throughput": 9453.924253152814,
    "itl": 97.00277390298142,
    "ttft": 494222.7824076371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9583901354251374,
    "arrivals": 81010,
    "finished_requests": 73082,
    "scheduler_time": 59.69965268534873
}
#Debug simulation 
Total elapsed time: 5.46911788219586. Arrivals time: 0.2001537592150271 Scheduler time: 5.08842375734821 Scheduler overhead time: 0.05405204789713025 Adapter cache time: 0.04439029796048999 Engine time: 0.05615547392517328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.490877929143608,
    "estimated_duration": 3600.0178915339025,
    "input_throughput": 5035.272753124119,
    "output_throughput": 4416.269162825153,
    "total_throughput": 9451.541915949272,
    "itl": 96.91065198841656,
    "ttft": 495489.2057662033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6835223827091808,
    "arrivals": 81010,
    "finished_requests": 73059,
    "scheduler_time": 59.68403856231089
}
#Debug simulation 
Total elapsed time: 5.490975685883313. Arrivals time: 0.1921312832273543 Scheduler time: 5.117598338983953 Scheduler overhead time: 0.05414739158004522 Adapter cache time: 0.04431109968572855 Engine time: 0.05695573939010501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.7887615049257874,
    "estimated_duration": 3600.057839943854,
    "input_throughput": 5385.837634292674,
    "output_throughput": 4768.456997976379,
    "total_throughput": 10154.294632269053,
    "itl": 107.24822387512485,
    "ttft": 51001.39402668977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7029490578920172,
    "arrivals": 79794,
    "finished_requests": 78961,
    "scheduler_time": 64.06620473739908
}
#Debug simulation 
Total elapsed time: 5.788849832024425. Arrivals time: 0.17985851923003793 Scheduler time: 5.452444053720683 Scheduler overhead time: 0.04942543804645538 Adapter cache time: 0.032707829028367996 Engine time: 0.05068831564858556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.641033473890275,
    "estimated_duration": 3600.0875154118394,
    "input_throughput": 5164.142238323671,
    "output_throughput": 4576.556800207451,
    "total_throughput": 9740.699038531122,
    "itl": 94.2844532685494,
    "ttft": 267226.9120425551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9245914696063893,
    "arrivals": 79794,
    "finished_requests": 75698,
    "scheduler_time": 61.150680211441355
}
#Debug simulation 
Total elapsed time: 5.641114379744977. Arrivals time: 0.18320957524701953 Scheduler time: 5.284516813233495 Scheduler overhead time: 0.05539605114609003 Adapter cache time: 0.033715581987053156 Engine time: 0.05769589217379689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.625818952918053,
    "estimated_duration": 3600.0827893546093,
    "input_throughput": 5164.743726166719,
    "output_throughput": 4577.183904971827,
    "total_throughput": 9741.927631138546,
    "itl": 94.27436983867788,
    "ttft": 266684.4282524186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6849864251492495,
    "arrivals": 79794,
    "finished_requests": 75707,
    "scheduler_time": 61.1514241766864
}
#Debug simulation 
Total elapsed time: 5.6259051421657205. Arrivals time: 0.18307828390970826 Scheduler time: 5.270316011272371 Scheduler overhead time: 0.05531909503042698 Adapter cache time: 0.03357271244749427 Engine time: 0.05720082996413112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.638336135074496,
    "estimated_duration": 3600.0229504248346,
    "input_throughput": 5164.70401884684,
    "output_throughput": 4577.250541709859,
    "total_throughput": 9741.954560556698,
    "itl": 94.27198342399144,
    "ttft": 266468.92928965203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.428165545086361,
    "arrivals": 79794,
    "finished_requests": 75705,
    "scheduler_time": 61.153232404506504
}
#Debug simulation 
Total elapsed time: 5.638414635788649. Arrivals time: 0.1840033191256225 Scheduler time: 5.278523330111057 Scheduler overhead time: 0.055481445509940386 Adapter cache time: 0.03372087050229311 Engine time: 0.06012908695265651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.7976283938623965,
    "estimated_duration": 3599.829315889108,
    "input_throughput": 2310.4634331657885,
    "output_throughput": 2043.871626780943,
    "total_throughput": 4354.335059946731,
    "itl": 48.71725721057936,
    "ttft": 13870.980304892822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.428272664526087,
    "arrivals": 33938,
    "finished_requests": 33808,
    "scheduler_time": 16.46737044856449
}
#Debug simulation 
Total elapsed time: 2.7977501349523664. Arrivals time: 0.0916251358576119 Scheduler time: 2.3342110221274197 Scheduler overhead time: 0.07639029016718268 Adapter cache time: 0.18324033776298165 Engine time: 0.07573924912139773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.749311280902475,
    "estimated_duration": 3599.8294643857653,
    "input_throughput": 2310.4633378568024,
    "output_throughput": 2043.8715424691422,
    "total_throughput": 4354.334880325944,
    "itl": 49.01456253618278,
    "ttft": 13871.607787265493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.2212118783213,
    "arrivals": 33938,
    "finished_requests": 33808,
    "scheduler_time": 16.549765646526303
}
#Debug simulation 
Total elapsed time: 2.749382020905614. Arrivals time: 0.08957876777276397 Scheduler time: 2.295438840519637 Scheduler overhead time: 0.07541386969387531 Adapter cache time: 0.1790634747594595 Engine time: 0.0738464375026524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.753524994943291,
    "estimated_duration": 3599.8295618929596,
    "input_throughput": 2310.463275274173,
    "output_throughput": 2043.8714871075824,
    "total_throughput": 4354.334762381755,
    "itl": 48.74860976045327,
    "ttft": 13870.939158422461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.46260028057346,
    "arrivals": 33938,
    "finished_requests": 33808,
    "scheduler_time": 16.47652509989968
}
#Debug simulation 
Total elapsed time: 2.7536116717383265. Arrivals time: 0.09086077054962516 Scheduler time: 2.2937992764636874 Scheduler overhead time: 0.07555651292204857 Adapter cache time: 0.18248925544321537 Engine time: 0.0748095572926104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.765699735376984,
    "estimated_duration": 3599.8210567577685,
    "input_throughput": 2310.468734101765,
    "output_throughput": 2043.876316070755,
    "total_throughput": 4354.34505017252,
    "itl": 48.68478850584972,
    "ttft": 13870.847062531599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.461352298667283,
    "arrivals": 33938,
    "finished_requests": 33808,
    "scheduler_time": 16.458790868834893
}
#Debug simulation 
Total elapsed time: 2.765772633254528. Arrivals time: 0.0893114022910595 Scheduler time: 2.3073803978040814 Scheduler overhead time: 0.07573219249024987 Adapter cache time: 0.1828626892529428 Engine time: 0.0743031888268888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.623843891080469,
    "estimated_duration": 3599.7763326310783,
    "input_throughput": 2154.2724556811395,
    "output_throughput": 1890.1360449322428,
    "total_throughput": 4044.4085006133823,
    "itl": 42.39271907024799,
    "ttft": 10573.29293116286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.043230547686525,
    "arrivals": 31534,
    "finished_requests": 31442,
    "scheduler_time": 12.238707374941633
}
#Debug simulation 
Total elapsed time: 2.6239264742471278. Arrivals time: 0.0851992815732956 Scheduler time: 2.1543772178702056 Scheduler overhead time: 0.08461528643965721 Adapter cache time: 0.17471189750358462 Engine time: 0.08477218449115753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.626641491893679,
    "estimated_duration": 3599.780062103779,
    "input_throughput": 2154.270223794698,
    "output_throughput": 1890.134086698501,
    "total_throughput": 4044.404310493199,
    "itl": 42.43015542685972,
    "ttft": 10573.545328664453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.591586059229158,
    "arrivals": 31534,
    "finished_requests": 31442,
    "scheduler_time": 12.252729819366312
}
#Debug simulation 
Total elapsed time: 2.6267143259756267. Arrivals time: 0.08571444824337959 Scheduler time: 2.156792202964425 Scheduler overhead time: 0.08499509887769818 Adapter cache time: 0.17407695949077606 Engine time: 0.08441160712391138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6293941610492766,
    "estimated_duration": 3599.7577910679975,
    "input_throughput": 2154.2835518662023,
    "output_throughput": 1890.1457806085696,
    "total_throughput": 4044.429332474772,
    "itl": 42.40593790883948,
    "ttft": 10573.356234720937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.589847700423874,
    "arrivals": 31534,
    "finished_requests": 31442,
    "scheduler_time": 12.243626903881754
}
#Debug simulation 
Total elapsed time: 2.629503082949668. Arrivals time: 0.08584770048037171 Scheduler time: 2.161507620010525 Scheduler overhead time: 0.08381364308297634 Adapter cache time: 0.17434872360900044 Engine time: 0.08381754672154784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.596838063094765,
    "estimated_duration": 3599.7700608357236,
    "input_throughput": 2154.276209019756,
    "output_throughput": 1890.139338072156,
    "total_throughput": 4044.4155470919122,
    "itl": 42.380517124462884,
    "ttft": 10573.378900876036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.536187981679936,
    "arrivals": 31534,
    "finished_requests": 31442,
    "scheduler_time": 12.23420934002376
}
#Debug simulation 
Total elapsed time: 2.596945445984602. Arrivals time: 0.08494777465239167 Scheduler time: 2.131675729062408 Scheduler overhead time: 0.08431582525372505 Adapter cache time: 0.17360848933458328 Engine time: 0.08197658555582166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.53068875009194,
    "estimated_duration": 3599.987604523606,
    "input_throughput": 2067.6398970504265,
    "output_throughput": 1810.7540125440605,
    "total_throughput": 3878.393909594487,
    "itl": 39.526471461583974,
    "ttft": 8840.893916753916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.0172922190745695,
    "arrivals": 30357,
    "finished_requests": 30283,
    "scheduler_time": 9.971339086745418
}
#Debug simulation 
Total elapsed time: 2.530785661190748. Arrivals time: 0.08541400777176023 Scheduler time: 2.0595720098353922 Scheduler overhead time: 0.08928253408521414 Adapter cache time: 0.1646489016711712 Engine time: 0.08930618828162551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5264698220416903,
    "estimated_duration": 3600.0048717292293,
    "input_throughput": 2067.62997974072,
    "output_throughput": 1810.7453273719616,
    "total_throughput": 3878.3753071126816,
    "itl": 39.53851139733607,
    "ttft": 8841.004384113212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.618700883360588,
    "arrivals": 30357,
    "finished_requests": 30283,
    "scheduler_time": 9.976498218468084
}
#Debug simulation 
Total elapsed time: 2.5265421071089804. Arrivals time: 0.08247317094355822 Scheduler time: 2.059713775292039 Scheduler overhead time: 0.08870672527700663 Adapter cache time: 0.1651658108457923 Engine time: 0.08795935101807117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4914013012312353,
    "estimated_duration": 3600.0056751989982,
    "input_throughput": 2067.629518275286,
    "output_throughput": 1810.7449232395072,
    "total_throughput": 3878.374441514793,
    "itl": 39.53018814297756,
    "ttft": 8840.958445039834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.242492999592788,
    "arrivals": 30357,
    "finished_requests": 30283,
    "scheduler_time": 9.973343518439867
}
#Debug simulation 
Total elapsed time: 2.4914807798340917. Arrivals time: 0.08174840081483126 Scheduler time: 2.027101063169539 Scheduler overhead time: 0.08892828784883022 Adapter cache time: 0.1633252939209342 Engine time: 0.0874282605946064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.544114293064922,
    "estimated_duration": 3599.978942323517,
    "input_throughput": 2067.6448721657775,
    "output_throughput": 1810.7583695455373,
    "total_throughput": 3878.4032417113153,
    "itl": 39.52196173474148,
    "ttft": 8840.935498380322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.8093680559191565,
    "arrivals": 30357,
    "finished_requests": 30283,
    "scheduler_time": 9.969592813901661
}
#Debug simulation 
Total elapsed time: 2.544213070999831. Arrivals time: 0.08297245018184185 Scheduler time: 2.074812200386077 Scheduler overhead time: 0.08925285516306758 Adapter cache time: 0.16436436725780368 Engine time: 0.08945075049996376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.417235474102199,
    "estimated_duration": 3600.0173362490355,
    "input_throughput": 2026.1838537700332,
    "output_throughput": 1770.6914730143496,
    "total_throughput": 3796.8753267843827,
    "itl": 38.24207162781915,
    "ttft": 6734.242264748791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0086461095372514,
    "arrivals": 29680,
    "finished_requests": 29625,
    "scheduler_time": 8.812761048845775
}
#Debug simulation 
Total elapsed time: 2.417342881206423. Arrivals time: 0.08038171008229256 Scheduler time: 1.9562163995578885 Scheduler overhead time: 0.09082440938800573 Adapter cache time: 0.15771666448563337 Engine time: 0.08876883517950773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.483503662981093,
    "estimated_duration": 3600.018438967355,
    "input_throughput": 2026.0521226919584,
    "output_throughput": 1770.5709312501108,
    "total_throughput": 3796.6230539420694,
    "itl": 38.69857271881066,
    "ttft": 6977.641091924012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.304765521395023,
    "arrivals": 29680,
    "finished_requests": 29623,
    "scheduler_time": 9.012450173671693
}
#Debug simulation 
Total elapsed time: 2.483573571778834. Arrivals time: 0.08073990186676383 Scheduler time: 2.0178601993247867 Scheduler overhead time: 0.09045550553128123 Adapter cache time: 0.1614697389304638 Engine time: 0.08943570451810956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4955269428901374,
    "estimated_duration": 3600.0131579334147,
    "input_throughput": 2026.1862054380065,
    "output_throughput": 1770.6935281479052,
    "total_throughput": 3796.8797335859117,
    "itl": 38.24341908266813,
    "ttft": 6734.29866174639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1073642900632645,
    "arrivals": 29680,
    "finished_requests": 29625,
    "scheduler_time": 8.813478522719114
}
#Debug simulation 
Total elapsed time: 2.495657918974757. Arrivals time: 0.08171907160431147 Scheduler time: 2.0270525692030787 Scheduler overhead time: 0.09124343423172832 Adapter cache time: 0.1599673144519329 Engine time: 0.09143654024228454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.4508586023002863,
    "estimated_duration": 3600.0159329146654,
    "input_throughput": 2026.1846436036046,
    "output_throughput": 1770.6921632535734,
    "total_throughput": 3796.876806857178,
    "itl": 38.24023823381496,
    "ttft": 6734.328358373925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.90468402795958,
    "arrivals": 29680,
    "finished_requests": 29625,
    "scheduler_time": 8.811838123748325
}
#Debug simulation 
Total elapsed time: 2.450933902990073. Arrivals time: 0.08015877939760685 Scheduler time: 1.9875821555033326 Scheduler overhead time: 0.09134976146742702 Adapter cache time: 0.15808628359809518 Engine time: 0.08986317878589034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.303067437838763,
    "estimated_duration": 3599.9905578831854,
    "input_throughput": 1803.5594526163982,
    "output_throughput": 1590.0394481495025,
    "total_throughput": 3393.598900765901,
    "itl": 34.86134521481147,
    "ttft": 9353.730749337978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.841298340047125,
    "arrivals": 26722,
    "finished_requests": 26653,
    "scheduler_time": 4.713022024142018
}
#Debug simulation 
Total elapsed time: 2.3031456121243536. Arrivals time: 0.07550983550027013 Scheduler time: 1.8257340309210122 Scheduler overhead time: 0.10008936189115047 Adapter cache time: 0.15824356628581882 Engine time: 0.09578571282327175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2727547311224043,
    "estimated_duration": 3599.954860222526,
    "input_throughput": 1803.5770591853081,
    "output_throughput": 1589.9807698272605,
    "total_throughput": 3393.5578290125686,
    "itl": 34.883491489405976,
    "ttft": 9488.398379174305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.163391544641733,
    "arrivals": 26722,
    "finished_requests": 26652,
    "scheduler_time": 4.723626664172469
}
#Debug simulation 
Total elapsed time: 2.2728274520486593. Arrivals time: 0.07477814331650734 Scheduler time: 1.801080618519336 Scheduler overhead time: 0.0978136919438839 Adapter cache time: 0.1569948852993548 Engine time: 0.09471350442618132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2966520097106695,
    "estimated_duration": 3599.9809875472088,
    "input_throughput": 1803.564247272252,
    "output_throughput": 1590.0436751750863,
    "total_throughput": 3393.6079224473383,
    "itl": 34.86846141283752,
    "ttft": 9353.746519768782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.302694541188169,
    "arrivals": 26722,
    "finished_requests": 26653,
    "scheduler_time": 4.71675607816039
}
#Debug simulation 
Total elapsed time: 2.2967308568768203. Arrivals time: 0.07556687574833632 Scheduler time: 1.82229754794389 Scheduler overhead time: 0.0979572725482285 Adapter cache time: 0.15718957874923944 Engine time: 0.09669676423072815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.3129398562014103,
    "estimated_duration": 3599.9765994816153,
    "input_throughput": 1803.5664456638249,
    "output_throughput": 1590.0456133032242,
    "total_throughput": 3393.612058967049,
    "itl": 34.85363619526557,
    "ttft": 9353.533489928692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.397574466588521,
    "arrivals": 26722,
    "finished_requests": 26653,
    "scheduler_time": 4.709766399621104
}
#Debug simulation 
Total elapsed time: 2.313032721169293. Arrivals time: 0.07540756976231933 Scheduler time: 1.8394307009875774 Scheduler overhead time: 0.09802241018041968 Adapter cache time: 0.15682554431259632 Engine time: 0.09608657890930772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.191197824664414,
    "estimated_duration": 3600.014791692852,
    "input_throughput": 1725.8787420365966,
    "output_throughput": 1514.047390187789,
    "total_throughput": 3239.9261322243856,
    "itl": 33.17318294501496,
    "ttft": 5980.7671387346445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.167851390633896,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 2.9873882555301776
}
#Debug simulation 
Total elapsed time: 2.1913055260665715. Arrivals time: 0.07404381688684225 Scheduler time: 1.7156930435448885 Scheduler overhead time: 0.1019723666831851 Adapter cache time: 0.14879416907206178 Engine time: 0.10066760051995516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.209037706255913,
    "estimated_duration": 3600.000984463945,
    "input_throughput": 1725.8853613689134,
    "output_throughput": 1514.0531970747825,
    "total_throughput": 3239.938558443696,
    "itl": 33.18391971728421,
    "ttft": 5839.967449476783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.88914853895084,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 2.991833791679528
}
#Debug simulation 
Total elapsed time: 2.2091171382926404. Arrivals time: 0.07330327248200774 Scheduler time: 1.7345874141901731 Scheduler overhead time: 0.10193516314029694 Adapter cache time: 0.14924278482794762 Engine time: 0.10053325910121202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.187365810852498,
    "estimated_duration": 3600.0043159095567,
    "input_throughput": 1725.8837642338244,
    "output_throughput": 1514.0517959692734,
    "total_throughput": 3239.935560203098,
    "itl": 33.176602383871895,
    "ttft": 5839.880851400738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.442972422591399,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 2.989003718656673
}
#Debug simulation 
Total elapsed time: 2.1874335911124945. Arrivals time: 0.0718467771075666 Scheduler time: 1.717237746808678 Scheduler overhead time: 0.1020464594475925 Adapter cache time: 0.14841784723103046 Engine time: 0.09891241230070591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.203864418901503,
    "estimated_duration": 3600.0027984537146,
    "input_throughput": 1725.884491720037,
    "output_throughput": 1514.0524341650948,
    "total_throughput": 3239.936925885132,
    "itl": 33.169022348724795,
    "ttft": 5839.7618270861285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.920170299578423,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 2.9858827110848036
}
#Debug simulation 
Total elapsed time: 2.2039416660554707. Arrivals time: 0.07168692164123058 Scheduler time: 1.7318305419757962 Scheduler overhead time: 0.10183018585667014 Adapter cache time: 0.1494982447475195 Engine time: 0.10002078209072351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.180268202908337,
    "estimated_duration": 3599.960937339576,
    "input_throughput": 1706.9982444146572,
    "output_throughput": 1494.837886762433,
    "total_throughput": 3201.8361311770905,
    "itl": 32.73868618648385,
    "ttft": 8712.55095282897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.960833010138073,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.6810256363021545
}
#Debug simulation 
Total elapsed time: 2.180340281687677. Arrivals time: 0.0706173125654459 Scheduler time: 1.7139525851234794 Scheduler overhead time: 0.1023168615065515 Adapter cache time: 0.14225798984989524 Engine time: 0.10206606984138489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.139996926765889,
    "estimated_duration": 3599.946978602775,
    "input_throughput": 1707.0048632730336,
    "output_throughput": 1494.8436829724178,
    "total_throughput": 3201.8485462454514,
    "itl": 32.74557409135908,
    "ttft": 8712.539237422357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.354269055207264,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.6832193818565417
}
#Debug simulation 
Total elapsed time: 2.1401460426859558. Arrivals time: 0.06911544408649206 Scheduler time: 1.6805774089880288 Scheduler overhead time: 0.10209986614063382 Adapter cache time: 0.14128326578065753 Engine time: 0.09771393286064267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.160563320387155,
    "estimated_duration": 3599.954511433093,
    "input_throughput": 1707.0012914006816,
    "output_throughput": 1494.8405550429454,
    "total_throughput": 3201.841846443627,
    "itl": 32.740333993997176,
    "ttft": 8712.69691254133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.09467173319775,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.6818185438002495
}
#Debug simulation 
Total elapsed time: 2.1606316873803735. Arrivals time: 0.0699823540635407 Scheduler time: 1.6972179030999541 Scheduler overhead time: 0.1023038774728775 Adapter cache time: 0.14227381255477667 Engine time: 0.09952604956924915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1290729460306466,
    "estimated_duration": 3599.9456667590803,
    "input_throughput": 1707.0054853167458,
    "output_throughput": 1494.8442277032116,
    "total_throughput": 3201.849713019957,
    "itl": 32.737600615632246,
    "ttft": 8712.514535777678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8239686434017317,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.680077233004479
}
#Debug simulation 
Total elapsed time: 2.1291546230204403. Arrivals time: 0.07025856943801045 Scheduler time: 1.6674812408164144 Scheduler overhead time: 0.10090362979099154 Adapter cache time: 0.1412178799510002 Engine time: 0.10001389076933265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0527343661524355,
    "estimated_duration": 3599.253054112586,
    "input_throughput": 1572.6201839385715,
    "output_throughput": 1380.3736290014658,
    "total_throughput": 2952.993812940037,
    "itl": 30.888324347004513,
    "ttft": 7825.692887360909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.698370349365435,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0678038450415441
}
#Debug simulation 
Total elapsed time: 2.0528072039596736. Arrivals time: 0.06698486767709255 Scheduler time: 1.5850166180171072 Scheduler overhead time: 0.10731555288657546 Adapter cache time: 0.13422633847221732 Engine time: 0.10677362559363246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.04693071404472,
    "estimated_duration": 3599.2498017553394,
    "input_throughput": 1572.6216049909942,
    "output_throughput": 1380.3748763358892,
    "total_throughput": 2952.9964813268834,
    "itl": 30.898354797315555,
    "ttft": 7825.61113592706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.384525976157756,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0700412913663833
}
#Debug simulation 
Total elapsed time: 2.0470013190060854. Arrivals time: 0.06646662158891559 Scheduler time: 1.5841506742872298 Scheduler overhead time: 0.1076088915579021 Adapter cache time: 0.13311702013015747 Engine time: 0.10388637008145452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.0502372719347477,
    "estimated_duration": 3599.2690474452156,
    "input_throughput": 1572.772672834251,
    "output_throughput": 1380.4919650357506,
    "total_throughput": 2953.2646378700015,
    "itl": 30.892232077423674,
    "ttft": 7670.166402739416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.944459927617562,
    "arrivals": 23153,
    "finished_requests": 23104,
    "scheduler_time": 1.0686500857761907
}
#Debug simulation 
Total elapsed time: 2.050317756831646. Arrivals time: 0.06682639848440886 Scheduler time: 1.5861805472522974 Scheduler overhead time: 0.10704023344442248 Adapter cache time: 0.13388757314532995 Engine time: 0.10484360391274095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0657852781005204,
    "estimated_duration": 3599.2426824409963,
    "input_throughput": 1572.6247156419108,
    "output_throughput": 1380.3776067221183,
    "total_throughput": 2953.002322364029,
    "itl": 30.885234352141982,
    "ttft": 7825.605800670217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.466911912797918,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0669950918092816
}
#Debug simulation 
Total elapsed time: 2.065861784853041. Arrivals time: 0.0668740258552134 Scheduler time: 1.6011086972430348 Scheduler overhead time: 0.10658092936500907 Adapter cache time: 0.13415910489857197 Engine time: 0.1052202945575118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.040436005219817,
    "estimated_duration": 3600.0304844554553,
    "input_throughput": 1527.5695646871252,
    "output_throughput": 1347.9508079037892,
    "total_throughput": 2875.520372590914,
    "itl": 30.23936506977516,
    "ttft": 8189.400255017864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.736011103051768,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7266822022718974
}
#Debug simulation 
Total elapsed time: 2.0405165082775056. Arrivals time: 0.0655850749462843 Scheduler time: 1.5768375960178673 Scheduler overhead time: 0.10842159017920494 Adapter cache time: 0.1281169019639492 Engine time: 0.10907495254650712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.013266536872834,
    "estimated_duration": 3600.01771907543,
    "input_throughput": 1527.5749813288003,
    "output_throughput": 1347.955587631463,
    "total_throughput": 2875.5305689602633,
    "itl": 30.24496352675368,
    "ttft": 8189.444171141589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.116392428628173,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7274844506061106
}
#Debug simulation 
Total elapsed time: 2.013364771846682. Arrivals time: 0.06514344830065966 Scheduler time: 1.5521056251600385 Scheduler overhead time: 0.10836873389780521 Adapter cache time: 0.12781543796882033 Engine time: 0.10683279344812036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.0246817488223314,
    "estimated_duration": 3600.0047430422164,
    "input_throughput": 1527.5804873947943,
    "output_throughput": 1347.960446268527,
    "total_throughput": 2875.540933663321,
    "itl": 30.240577521963942,
    "ttft": 8030.256558943684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8637362114852234,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7269073356622172
}
#Debug simulation 
Total elapsed time: 2.02477882290259. Arrivals time: 0.06743600405752659 Scheduler time: 1.5616951412521303 Scheduler overhead time: 0.10863031027838588 Adapter cache time: 0.12759914947673678 Engine time: 0.10687779868021607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0183297656476498,
    "estimated_duration": 3600.0227367552375,
    "input_throughput": 1527.57285220832,
    "output_throughput": 1347.9537088629029,
    "total_throughput": 2875.5265610712227,
    "itl": 30.40167765323667,
    "ttft": 8189.817613836265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.606915331422335,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.756322143184655
}
#Debug simulation 
Total elapsed time: 2.0184081196784973. Arrivals time: 0.06457221088930964 Scheduler time: 1.5611977586522698 Scheduler overhead time: 0.10794770531356335 Adapter cache time: 0.12643809569999576 Engine time: 0.10597496712580323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9635231709107757,
    "estimated_duration": 3599.865593480593,
    "input_throughput": 1451.8508717284353,
    "output_throughput": 1288.639500430562,
    "total_throughput": 2740.490372158997,
    "itl": 29.326253075134517,
    "ttft": 4283.412338099001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5905381043488647,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.3851689118631276
}
#Debug simulation 
Total elapsed time: 1.9636318730190396. Arrivals time: 0.06237622629851103 Scheduler time: 1.5069743641652167 Scheduler overhead time: 0.11053785076364875 Adapter cache time: 0.11882127076387405 Engine time: 0.11112139606848359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9950554291717708,
    "estimated_duration": 3599.8886471421665,
    "input_throughput": 1451.8415740856656,
    "output_throughput": 1288.631247992266,
    "total_throughput": 2740.4728220779316,
    "itl": 29.4898484891229,
    "ttft": 4283.806755472898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9648404001491198,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.40237127546092416
}
#Debug simulation 
Total elapsed time: 1.9951482191681862. Arrivals time: 0.06390317715704441 Scheduler time: 1.5375129478052258 Scheduler overhead time: 0.11090904893353581 Adapter cache time: 0.11778302909806371 Engine time: 0.11106304544955492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.9277955750003457,
    "estimated_duration": 3599.8715774672123,
    "input_throughput": 1451.848458348957,
    "output_throughput": 1288.6373583537236,
    "total_throughput": 2740.4858167026805,
    "itl": 29.32701213603828,
    "ttft": 4283.450829025737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.719125287872734,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.3853252416487274
}
#Debug simulation 
Total elapsed time: 1.9278678339906037. Arrivals time: 0.06208643643185496 Scheduler time: 1.474249540362507 Scheduler overhead time: 0.11065642675384879 Adapter cache time: 0.11876189429312944 Engine time: 0.10758238518610597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9270228100940585,
    "estimated_duration": 3599.8668788587806,
    "input_throughput": 1451.850353326643,
    "output_throughput": 1288.6390403054627,
    "total_throughput": 2740.4893936321055,
    "itl": 29.324633544440722,
    "ttft": 4283.516600465433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.466469070729784,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.38489528264433326
}
#Debug simulation 
Total elapsed time: 1.9270940967835486. Arrivals time: 0.061686836183071136 Scheduler time: 1.4696130244992673 Scheduler overhead time: 0.11086108721792698 Adapter cache time: 0.11883387668058276 Engine time: 0.11139065632596612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6393688879907131,
    "estimated_duration": 3599.57487979688,
    "input_throughput": 1183.8086836077862,
    "output_throughput": 1010.3504223268783,
    "total_throughput": 2194.1591059346647,
    "itl": 27.626693447594704,
    "ttft": 7177.107838349885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.249741463852507,
    "arrivals": 17165,
    "finished_requests": 17131,
    "scheduler_time": 0.012061621917460545
}
#Debug simulation 
Total elapsed time: 1.639447825960815. Arrivals time: 0.05306220753118396 Scheduler time: 1.1634164741262794 Scheduler overhead time: 0.11447700392454863 Adapter cache time: 0.13862089440226555 Engine time: 0.11369630740955472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6512620230205357,
    "estimated_duration": 3599.57988629213,
    "input_throughput": 1183.8070371010442,
    "output_throughput": 1010.3490170755017,
    "total_throughput": 2194.1560541765457,
    "itl": 27.643263560022184,
    "ttft": 7177.376386180128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.775265738200094,
    "arrivals": 17165,
    "finished_requests": 17131,
    "scheduler_time": 0.012213906895017723
}
#Debug simulation 
Total elapsed time: 1.651341593824327. Arrivals time: 0.053413922898471355 Scheduler time: 1.1733941924758255 Scheduler overhead time: 0.11442230688408017 Adapter cache time: 0.13898727344349027 Engine time: 0.1148576564155519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6759592602029443,
    "estimated_duration": 3599.5841581999834,
    "input_throughput": 1183.8056321847105,
    "output_throughput": 1010.3478180153573,
    "total_throughput": 2194.1534502000677,
    "itl": 27.631432039255273,
    "ttft": 7177.17379256518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.76880553254885,
    "arrivals": 17165,
    "finished_requests": 17131,
    "scheduler_time": 0.012114329544000671
}
#Debug simulation 
Total elapsed time: 1.6760541182011366. Arrivals time: 0.054712009616196156 Scheduler time: 1.1972630061209202 Scheduler overhead time: 0.11456282204017043 Adapter cache time: 0.14005602523684502 Engine time: 0.11305905925109982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6806463790126145,
    "estimated_duration": 3599.5825841434325,
    "input_throughput": 1183.806149849458,
    "output_throughput": 1010.3482598289744,
    "total_throughput": 2194.1544096784323,
    "itl": 27.6210835578887,
    "ttft": 7177.104027061444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.77011746881137,
    "arrivals": 17165,
    "finished_requests": 17131,
    "scheduler_time": 0.012016295042997779
}
#Debug simulation 
Total elapsed time: 1.6807194179855287. Arrivals time: 0.053336361423134804 Scheduler time: 1.2020803457126021 Scheduler overhead time: 0.11497773230075836 Adapter cache time: 0.14014999149367213 Engine time: 0.1136554186232388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.620606908109039,
    "estimated_duration": 3599.628529772679,
    "input_throughput": 1078.1559730123283,
    "output_throughput": 964.9070650685568,
    "total_throughput": 2043.0630380808852,
    "itl": 27.028838360072523,
    "ttft": 6382.190469541696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.194301026761696,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0010527766708103403
}
#Debug simulation 
Total elapsed time: 1.6206874940544367. Arrivals time: 0.05036162165924907 Scheduler time: 1.1505577168427408 Scheduler overhead time: 0.11612500576302409 Adapter cache time: 0.12819572305306792 Engine time: 0.11812369432300329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.608167867641896,
    "estimated_duration": 3599.616325915645,
    "input_throughput": 1078.1596283078277,
    "output_throughput": 964.9103364138356,
    "total_throughput": 2043.0699647216632,
    "itl": 27.037744600484096,
    "ttft": 6382.160029119165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.935507537312816,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0010640771089250618
}
#Debug simulation 
Total elapsed time: 1.6082391990348697. Arrivals time: 0.050413011107593775 Scheduler time: 1.1387048652395606 Scheduler overhead time: 0.11655964283272624 Adapter cache time: 0.12902729213237762 Engine time: 0.11624597292393446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6035582162439823,
    "estimated_duration": 3599.623343160466,
    "input_throughput": 1078.1575265017923,
    "output_throughput": 964.9084553803453,
    "total_throughput": 2043.0659818821375,
    "itl": 27.033236348059138,
    "ttft": 6382.189599470174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.480171058066179,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0010453959187329857
}
#Debug simulation 
Total elapsed time: 1.6036486430093646. Arrivals time: 0.05049690790474415 Scheduler time: 1.1366263451054692 Scheduler overhead time: 0.11620648019015789 Adapter cache time: 0.12749847071245313 Engine time: 0.11503261188045144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6167976139113307,
    "estimated_duration": 3599.6170275965947,
    "input_throughput": 1078.1594181398941,
    "output_throughput": 964.9101483218259,
    "total_throughput": 2043.0695664617201,
    "itl": 27.026504039435657,
    "ttft": 6382.187027483212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.945705983340705,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0010494407267742348
}
#Debug simulation 
Total elapsed time: 1.6168812927789986. Arrivals time: 0.05044689495116472 Scheduler time: 1.144356219097972 Scheduler overhead time: 0.11770847858861089 Adapter cache time: 0.12888952950015664 Engine time: 0.11798104690387845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.5664689280092716,
    "estimated_duration": 3599.6984749403673,
    "input_throughput": 1045.549794295576,
    "output_throughput": 920.3851442181932,
    "total_throughput": 1965.9349385137693,
    "itl": 26.618106413776086,
    "ttft": 7335.3220590395285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.145980463032677,
    "arrivals": 15306,
    "finished_requests": 15275,
    "scheduler_time": 0.0001994468140600434
}
#Debug simulation 
Total elapsed time: 1.566539242863655. Arrivals time: 0.0485346307978034 Scheduler time: 1.1050613173283637 Scheduler overhead time: 0.11670205742120743 Adapter cache time: 0.12132941652089357 Engine time: 0.11704504489898682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.5675012641586363,
    "estimated_duration": 3599.69398986425,
    "input_throughput": 1045.5510970092025,
    "output_throughput": 920.3862909816238,
    "total_throughput": 1965.9373879908264,
    "itl": 26.416679322036085,
    "ttft": 7335.125514370812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.554399340068926,
    "arrivals": 15306,
    "finished_requests": 15275,
    "scheduler_time": 0.0001385244494335383
}
#Debug simulation 
Total elapsed time: 1.567573837004602. Arrivals time: 0.04894821858033538 Scheduler time: 1.1008868701756 Scheduler overhead time: 0.11765485676005483 Adapter cache time: 0.12193168234080076 Engine time: 0.11969833076000214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5386137589812279,
    "estimated_duration": 3599.689843899145,
    "input_throughput": 1045.5523012291635,
    "output_throughput": 920.3873510422432,
    "total_throughput": 1965.9396522714067,
    "itl": 26.618163888963977,
    "ttft": 7335.342236924618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.28924913416616,
    "arrivals": 15306,
    "finished_requests": 15275,
    "scheduler_time": 0.000198612828051017
}
#Debug simulation 
Total elapsed time: 1.5387014336884022. Arrivals time: 0.0489932531490922 Scheduler time: 1.0781209846027195 Scheduler overhead time: 0.11706748278811574 Adapter cache time: 0.11940883612260222 Engine time: 0.11738933576270938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10043533 . Total output tokens: 8874859
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.520182671956718,
    "estimated_duration": 3599.69704912058,
    "input_throughput": 1045.5502084319785,
    "output_throughput": 920.3855087775805,
    "total_throughput": 1965.935717209559,
    "itl": 26.615416984479886,
    "ttft": 7335.482160756243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.996334508797135,
    "arrivals": 15306,
    "finished_requests": 15275,
    "scheduler_time": 0.0001962359920278205
}
#Debug simulation 
Total elapsed time: 1.5202575325965881. Arrivals time: 0.04726847028359771 Scheduler time: 1.0630229329690337 Scheduler overhead time: 0.11708833137527108 Adapter cache time: 0.1195117817260325 Engine time: 0.11478176340460777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.4184855460189283,
    "estimated_duration": 3599.866541112261,
    "input_throughput": 915.2917093926367,
    "output_throughput": 810.2928168828012,
    "total_throughput": 1725.5845262754378,
    "itl": 25.326196090488974,
    "ttft": 7248.718933454362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.015765982899042,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4185573221184313. Arrivals time: 0.04395268205553293 Scheduler time: 0.9613008773885667 Scheduler overhead time: 0.12224183138459921 Adapter cache time: 0.11196767026558518 Engine time: 0.1190176447853446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4545863349922001,
    "estimated_duration": 3599.86821174026,
    "input_throughput": 915.2912846237655,
    "output_throughput": 810.2924408418497,
    "total_throughput": 1725.5837254656153,
    "itl": 25.333183778806703,
    "ttft": 7248.590317540114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.717330379798086,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4546594079583883. Arrivals time: 0.0449532731436193 Scheduler time: 0.9929343336261809 Scheduler overhead time: 0.1213358505629003 Adapter cache time: 0.1130396113730967 Engine time: 0.12226882623508573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4772409806028008,
    "estimated_duration": 3599.8769026449554,
    "input_throughput": 915.3499103202502,
    "output_throughput": 810.382432203883,
    "total_throughput": 1725.7323425241332,
    "itl": 25.3300496531561,
    "ttft": 6981.780473227768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.27809536830521,
    "arrivals": 13488,
    "finished_requests": 13462,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.477322795893997. Arrivals time: 0.044853081461042166 Scheduler time: 1.0155841456726193 Scheduler overhead time: 0.1223411881364882 Adapter cache time: 0.11237593786790967 Engine time: 0.12095799203962088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8844216 . Total output tokens: 7806017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.4240051968954504,
    "estimated_duration": 3599.8570547226277,
    "input_throughput": 915.2941213811272,
    "output_throughput": 810.2949521768589,
    "total_throughput": 1725.5890735579862,
    "itl": 25.324870920500768,
    "ttft": 7248.606931691076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.773340117945302,
    "arrivals": 13488,
    "finished_requests": 13461,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4240742390975356. Arrivals time: 0.044081742875277996 Scheduler time: 0.9666240951046348 Scheduler overhead time: 0.12224535085260868 Adapter cache time: 0.11185639118775725 Engine time: 0.11882386403158307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3742960840463638,
    "estimated_duration": 3599.6357644809354,
    "input_throughput": 874.3948571290705,
    "output_throughput": 765.5621791493608,
    "total_throughput": 1639.9570362784311,
    "itl": 24.825341102078813,
    "ttft": 5073.0704460096795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.046794327553425,
    "arrivals": 12878,
    "finished_requests": 12860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3743936019018292. Arrivals time: 0.04310765257105231 Scheduler time: 0.9173891078680754 Scheduler overhead time: 0.12373141525313258 Adapter cache time: 0.1063671731390059 Engine time: 0.1224447232671082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.401570072863251,
    "estimated_duration": 3599.6273862463718,
    "input_throughput": 874.3968923078344,
    "output_throughput": 765.5639610169881,
    "total_throughput": 1639.9608533248224,
    "itl": 24.828992290750612,
    "ttft": 5072.97224111281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.452530458141123,
    "arrivals": 12878,
    "finished_requests": 12860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4016303266398609. Arrivals time: 0.04353925073519349 Scheduler time: 0.9409472397528589 Scheduler overhead time: 0.12410211563110352 Adapter cache time: 0.10750258434563875 Engine time: 0.12400421826168895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.374253205023706,
    "estimated_duration": 3599.6299486989324,
    "input_throughput": 874.3962698548079,
    "output_throughput": 765.5634160383763,
    "total_throughput": 1639.9596858931843,
    "itl": 24.827026338219028,
    "ttft": 5072.994389518375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.199874240998174,
    "arrivals": 12878,
    "finished_requests": 12860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3743382571265101. Arrivals time: 0.045549587812274694 Scheduler time: 0.9177592531777918 Scheduler overhead time: 0.12327322922647 Adapter cache time: 0.10647489596158266 Engine time: 0.12012061104178429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8457498 . Total output tokens: 7443353
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3795190718956292,
    "estimated_duration": 3599.6209643013076,
    "input_throughput": 874.3984522856382,
    "output_throughput": 765.5653268301527,
    "total_throughput": 1639.9637791157909,
    "itl": 24.825208853141202,
    "ttft": 5073.033222525628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.906959615629148,
    "arrivals": 12878,
    "finished_requests": 12860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3796012490056455. Arrivals time: 0.04528940888121724 Scheduler time: 0.9223834564909339 Scheduler overhead time: 0.12313810037449002 Adapter cache time: 0.10574294440448284 Engine time: 0.12199910217896104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.2855569142848253,
    "estimated_duration": 3599.8835714527595,
    "input_throughput": 794.6709784409873,
    "output_throughput": 689.8225875115883,
    "total_throughput": 1484.4935659525754,
    "itl": 24.185448343484772,
    "ttft": 6533.663870179573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5773132862849644,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2856525941751897. Arrivals time: 0.04254265921190381 Scheduler time: 0.8300692867487669 Scheduler overhead time: 0.125625382643193 Adapter cache time: 0.09731474006548524 Engine time: 0.12598430830985308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.310338940937072,
    "estimated_duration": 3599.884693021268,
    "input_throughput": 794.6707308558505,
    "output_throughput": 689.8223725926792,
    "total_throughput": 1484.4931034485298,
    "itl": 24.188160825152593,
    "ttft": 6533.862819996563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.939578569508162,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3104442558251321. Arrivals time: 0.042494245339185 Scheduler time: 0.8549320278689265 Scheduler overhead time: 0.12587183713912964 Adapter cache time: 0.09883587807416916 Engine time: 0.12567770713940263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.2945058750919998,
    "estimated_duration": 3599.8608211155915,
    "input_throughput": 794.6760005886745,
    "output_throughput": 689.8269470402566,
    "total_throughput": 1484.5029476289312,
    "itl": 24.18651543653116,
    "ttft": 6533.80528387597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7035810040449673,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2946025552228093. Arrivals time: 0.04216392990201712 Scheduler time: 0.8416797248646617 Scheduler overhead time: 0.12600244348868728 Adapter cache time: 0.09799756482243538 Engine time: 0.12407019315287471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7619191 . Total output tokens: 6755576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.2947583580389619,
    "estimated_duration": 3599.8620987525032,
    "input_throughput": 794.6757185480398,
    "output_throughput": 689.8267022118865,
    "total_throughput": 1484.5024207599263,
    "itl": 24.18421538724888,
    "ttft": 6533.706829253041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.453701228848643,
    "arrivals": 11642,
    "finished_requests": 11621,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2948514306917787. Arrivals time: 0.04176154779270291 Scheduler time: 0.8419499411247671 Scheduler overhead time: 0.12650567293167114 Adapter cache time: 0.09745225310325623 Engine time: 0.12367683695629239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5573030 . Total output tokens: 4945441
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0884962743148208,
    "estimated_duration": 3599.9909950087736,
    "input_throughput": 582.0250669807283,
    "output_throughput": 510.96933368732414,
    "total_throughput": 1092.9944006680523,
    "itl": 22.681877190110676,
    "ttft": 5510.2744646490955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.465409797071652,
    "arrivals": 8553,
    "finished_requests": 8540,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0885718972422183. Arrivals time: 0.03410968603566289 Scheduler time: 0.6437733499333262 Scheduler overhead time: 0.13049252657219768 Adapter cache time: 0.08589158020913601 Engine time: 0.12731884559616446 
