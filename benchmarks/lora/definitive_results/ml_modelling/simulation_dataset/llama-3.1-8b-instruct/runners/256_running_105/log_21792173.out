INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:06 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141459455 . Total output tokens: 124670563
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.560055367648602,
    "estimated_duration": 3600.0406527577784,
    "input_throughput": 4440.033472331867,
    "output_throughput": 3869.849077767445,
    "total_throughput": 8309.882550099312,
    "itl": 123.11577189617972,
    "ttft": 1901385.5852397855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.799761485844519,
    "arrivals": 211085,
    "finished_requests": 64556,
    "scheduler_time": 141.34027663136638
}
#Debug simulation 
Total elapsed time: 11.560237559955567. Arrivals time: 0.25081317918375134 Scheduler time: 11.15376685000956 Scheduler overhead time: 0.047141910064965487 Adapter cache time: 0.04016536008566618 Engine time: 0.04717894643545151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141459455 . Total output tokens: 124670563
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.053608899004757,
    "estimated_duration": 3600.0945784612095,
    "input_throughput": 3909.757839199963,
    "output_throughput": 3423.629777323308,
    "total_throughput": 7333.387616523271,
    "itl": 100.20260083856819,
    "ttft": 2006006.889829446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3952,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.1188885014516,
    "arrivals": 211085,
    "finished_requests": 57065,
    "scheduler_time": 154.77829419230673
}
#Debug simulation 
Total elapsed time: 7.053728341124952. Arrivals time: 0.21906465711072087 Scheduler time: 6.6352755930274725 Scheduler overhead time: 0.05290019977837801 Adapter cache time: 0.06878589978441596 Engine time: 0.053339339792728424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.713353259023279,
    "estimated_duration": 3600.0863455060326,
    "input_throughput": 4659.735459106612,
    "output_throughput": 4042.8671990516323,
    "total_throughput": 8702.602658158245,
    "itl": 135.42781406826487,
    "ttft": 1838757.876357437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.039163146675788,
    "arrivals": 201527,
    "finished_requests": 67875,
    "scheduler_time": 135.39332277824616
}
#Debug simulation 
Total elapsed time: 15.713448893278837. Arrivals time: 0.270962119102478 Scheduler time: 15.30138311162591 Scheduler overhead time: 0.04574616486206651 Adapter cache time: 0.02976088598370552 Engine time: 0.04583076061680913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.847882010042667,
    "estimated_duration": 3600.0350314657753,
    "input_throughput": 4470.067613049833,
    "output_throughput": 3876.8250525377375,
    "total_throughput": 8346.892665587571,
    "itl": 123.83570374546258,
    "ttft": 1876599.908180344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.750003907559126,
    "arrivals": 201527,
    "finished_requests": 65068,
    "scheduler_time": 140.3207253389178
}
#Debug simulation 
Total elapsed time: 10.847980126272887. Arrivals time: 0.2627484486438334 Scheduler time: 10.428947323933244 Scheduler overhead time: 0.04657751088961959 Adapter cache time: 0.04210982518270612 Engine time: 0.046730606351047754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.582911050878465,
    "estimated_duration": 3600.0777350840226,
    "input_throughput": 3937.761916040721,
    "output_throughput": 3424.590774763439,
    "total_throughput": 7362.35269080416,
    "itl": 100.34933347880364,
    "ttft": 1988946.8830693478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.718828212941588,
    "arrivals": 201527,
    "finished_requests": 57412,
    "scheduler_time": 153.9632903197326
}
#Debug simulation 
Total elapsed time: 6.5830080402083695. Arrivals time: 0.22825032798573375 Scheduler time: 6.15225232578814 Scheduler overhead time: 0.05299138277769089 Adapter cache time: 0.07227670820429921 Engine time: 0.05294151371344924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.457961508072913,
    "estimated_duration": 3600.135577509829,
    "input_throughput": 4471.409382625133,
    "output_throughput": 3879.8494387984933,
    "total_throughput": 8351.258821423626,
    "itl": 124.05910305506184,
    "ttft": 1876961.4586206558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.171625020746472,
    "arrivals": 201527,
    "finished_requests": 65100,
    "scheduler_time": 140.18314182311948
}
#Debug simulation 
Total elapsed time: 10.458058590069413. Arrivals time: 0.2634994010441005 Scheduler time: 10.034305554348975 Scheduler overhead time: 0.046244805213063955 Adapter cache time: 0.04603881994262338 Engine time: 0.047286426182836294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.6951120449230075,
    "estimated_duration": 3600.0980317585463,
    "input_throughput": 3940.249369562553,
    "output_throughput": 3427.033622740935,
    "total_throughput": 7367.282992303488,
    "itl": 100.33344612573893,
    "ttft": 1988961.6080928624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.217643554905905,
    "arrivals": 201527,
    "finished_requests": 57454,
    "scheduler_time": 153.9605227994721
}
#Debug simulation 
Total elapsed time: 6.69520775321871. Arrivals time: 0.21988415019586682 Scheduler time: 6.272315517067909 Scheduler overhead time: 0.05307270819321275 Adapter cache time: 0.07235275860875845 Engine time: 0.053277166560292244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.954207923728973,
    "estimated_duration": 3600.0943984237256,
    "input_throughput": 4470.610828162426,
    "output_throughput": 3880.473524837763,
    "total_throughput": 8351.084353000188,
    "itl": 123.81673042577364,
    "ttft": 1877357.6038964172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.323243002971372,
    "arrivals": 201527,
    "finished_requests": 65127,
    "scheduler_time": 140.37434912026882
}
#Debug simulation 
Total elapsed time: 10.954327885992825. Arrivals time: 0.27166375052183867 Scheduler time: 10.526345566380769 Scheduler overhead time: 0.04696652898564935 Adapter cache time: 0.04147365037351847 Engine time: 0.04689585277810693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.554592506960034,
    "estimated_duration": 3600.089578876831,
    "input_throughput": 3938.918098927991,
    "output_throughput": 3426.0844708892137,
    "total_throughput": 7365.002569817205,
    "itl": 100.363606722942,
    "ttft": 1989176.8380854195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.05142856078371,
    "arrivals": 201527,
    "finished_requests": 57433,
    "scheduler_time": 153.9276585106581
}
#Debug simulation 
Total elapsed time: 6.554690250661224. Arrivals time: 0.21998021891340613 Scheduler time: 6.129910311661661 Scheduler overhead time: 0.05311783263459802 Adapter cache time: 0.07358087925240397 Engine time: 0.05386460991576314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 13.365556939970702,
    "estimated_duration": 3600.0030689204254,
    "input_throughput": 4606.717739541621,
    "output_throughput": 4032.172395995493,
    "total_throughput": 8638.890135537114,
    "itl": 134.24927691386938,
    "ttft": 1833139.4593081388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.731939858855027,
    "arrivals": 196873,
    "finished_requests": 67469,
    "scheduler_time": 135.5779574957754
}
#Debug simulation 
Total elapsed time: 13.365664356853813. Arrivals time: 0.27917465986683965 Scheduler time: 12.94161883695051 Scheduler overhead time: 0.04516144748777151 Adapter cache time: 0.03459209017455578 Engine time: 0.04539183620363474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.082400702871382,
    "estimated_duration": 3600.0064752620415,
    "input_throughput": 4430.697863908418,
    "output_throughput": 3876.052750428543,
    "total_throughput": 8306.750614336961,
    "itl": 123.57251986415186,
    "ttft": 1872793.6724075994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.02702457451228,
    "arrivals": 196873,
    "finished_requests": 64863,
    "scheduler_time": 140.07382470393483
}
#Debug simulation 
Total elapsed time: 10.082521385978907. Arrivals time: 0.2580863181501627 Scheduler time: 9.66891129128635 Scheduler overhead time: 0.04622463462874293 Adapter cache time: 0.04197960114106536 Engine time: 0.046425234992057085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.433028932195157,
    "estimated_duration": 3600.1104317246754,
    "input_throughput": 3912.733308364601,
    "output_throughput": 3430.1892217467444,
    "total_throughput": 7342.922530111345,
    "itl": 100.35285546310156,
    "ttft": 1981981.0167236228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.93636881863813,
    "arrivals": 196873,
    "finished_requests": 57300,
    "scheduler_time": 153.70873811513027
}
#Debug simulation 
Total elapsed time: 6.4331481251865625. Arrivals time: 0.21836279425770044 Scheduler time: 6.016385707072914 Scheduler overhead time: 0.05277480883523822 Adapter cache time: 0.06827752711251378 Engine time: 0.05303874937817454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.445612946990877,
    "estimated_duration": 3600.091571320345,
    "input_throughput": 4431.0556228850255,
    "output_throughput": 3875.6425284156912,
    "total_throughput": 8306.698151300716,
    "itl": 123.64742680647892,
    "ttft": 1873156.1669739215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.311249722075033,
    "arrivals": 196873,
    "finished_requests": 64892,
    "scheduler_time": 140.02152337395788
}
#Debug simulation 
Total elapsed time: 9.445710092782974. Arrivals time: 0.25006063003093004 Scheduler time: 9.037381696514785 Scheduler overhead time: 0.04613270564004779 Adapter cache time: 0.04500223370268941 Engine time: 0.046360418666154146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.462570028845221,
    "estimated_duration": 3600.029598285521,
    "input_throughput": 3914.6572591268687,
    "output_throughput": 3430.2070754865513,
    "total_throughput": 7344.8643346134195,
    "itl": 100.30658665691769,
    "ttft": 1981687.5402479372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.36387037702024,
    "arrivals": 196873,
    "finished_requests": 57288,
    "scheduler_time": 153.69510763335435
}
#Debug simulation 
Total elapsed time: 6.462684039026499. Arrivals time: 0.22018435318022966 Scheduler time: 6.042768405750394 Scheduler overhead time: 0.05301697226241231 Adapter cache time: 0.0696060131303966 Engine time: 0.05281865270808339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.897367881145328,
    "estimated_duration": 3600.0186810245436,
    "input_throughput": 4427.594524443894,
    "output_throughput": 3877.46432360939,
    "total_throughput": 8305.058848053284,
    "itl": 123.52530975526162,
    "ttft": 1870420.6264142618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.568107586382792,
    "arrivals": 196873,
    "finished_requests": 64863,
    "scheduler_time": 140.1427678971727
}
#Debug simulation 
Total elapsed time: 9.897528612054884. Arrivals time: 0.2561434260569513 Scheduler time: 9.483983683399856 Scheduler overhead time: 0.046520790085196495 Adapter cache time: 0.04367494955658913 Engine time: 0.04629434086382389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.72204374987632,
    "estimated_duration": 3600.108654806197,
    "input_throughput": 3905.256854187044,
    "output_throughput": 3422.3480959530266,
    "total_throughput": 7327.60495014007,
    "itl": 99.94084769937245,
    "ttft": 1983669.435829894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.40221176488435,
    "arrivals": 196873,
    "finished_requests": 57142,
    "scheduler_time": 154.02123968037063
}
#Debug simulation 
Total elapsed time: 6.722108684014529. Arrivals time: 0.22218203032389283 Scheduler time: 6.3019181145355105 Scheduler overhead time: 0.05306419776752591 Adapter cache time: 0.06738993059843779 Engine time: 0.05320728616788983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.887601355090737,
    "estimated_duration": 3600.10528833804,
    "input_throughput": 4659.754550607692,
    "output_throughput": 4038.897153119787,
    "total_throughput": 8698.651703727479,
    "itl": 135.02770988978997,
    "ttft": 1825549.7128574108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.931838365989059,
    "arrivals": 194481,
    "finished_requests": 67779,
    "scheduler_time": 135.05300501056735
}
#Debug simulation 
Total elapsed time: 11.887759247794747. Arrivals time: 0.26671988097950816 Scheduler time: 11.481682847253978 Scheduler overhead time: 0.0440514856018126 Adapter cache time: 0.030940980650484562 Engine time: 0.044724924489855766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.35903482278809,
    "estimated_duration": 3600.009128091742,
    "input_throughput": 4469.170056946031,
    "output_throughput": 3877.396279658622,
    "total_throughput": 8346.566336604654,
    "itl": 123.60863780355595,
    "ttft": 1863919.2945325074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.545898050199948,
    "arrivals": 194481,
    "finished_requests": 65024,
    "scheduler_time": 139.9371576231437
}
#Debug simulation 
Total elapsed time: 9.359132370911539. Arrivals time: 0.25419319747015834 Scheduler time: 8.954174226149917 Scheduler overhead time: 0.04612609976902604 Adapter cache time: 0.03823417657986283 Engine time: 0.0457155192270875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.280122075229883,
    "estimated_duration": 3600.0942115840257,
    "input_throughput": 3936.39281838812,
    "output_throughput": 3421.680177247353,
    "total_throughput": 7358.0729956354735,
    "itl": 99.8078001964228,
    "ttft": 1977335.444986602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.48627737757846,
    "arrivals": 194481,
    "finished_requests": 57354,
    "scheduler_time": 153.884978066566
}
#Debug simulation 
Total elapsed time: 6.280244642402977. Arrivals time: 0.2189699225127697 Scheduler time: 5.865441789384931 Scheduler overhead time: 0.0530189024284482 Adapter cache time: 0.06516999052837491 Engine time: 0.05328843602910638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.121720558963716,
    "estimated_duration": 3600.0773802724957,
    "input_throughput": 4470.496686596723,
    "output_throughput": 3878.594131480335,
    "total_throughput": 8349.090818077057,
    "itl": 123.78651698370318,
    "ttft": 1862314.1329009759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.78545470654526,
    "arrivals": 194481,
    "finished_requests": 65046,
    "scheduler_time": 139.8301526626162
}
#Debug simulation 
Total elapsed time: 9.121817792765796. Arrivals time: 0.25215648440644145 Scheduler time: 8.715813589282334 Scheduler overhead time: 0.045824761502444744 Adapter cache time: 0.04120382573455572 Engine time: 0.045945389196276665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.184953053016216,
    "estimated_duration": 3600.0652444566776,
    "input_throughput": 3936.5397673893576,
    "output_throughput": 3418.9783140604186,
    "total_throughput": 7355.518081449776,
    "itl": 99.81940437435821,
    "ttft": 1977600.4274372049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.283503931421922,
    "arrivals": 194481,
    "finished_requests": 57334,
    "scheduler_time": 153.82476176168342
}
#Debug simulation 
Total elapsed time: 6.185051437001675. Arrivals time: 0.21522183157503605 Scheduler time: 5.77271512709558 Scheduler overhead time: 0.053172556683421135 Adapter cache time: 0.06663529388606548 Engine time: 0.053024363704025745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.793632216751575,
    "estimated_duration": 3600.0687578167112,
    "input_throughput": 4468.071606986498,
    "output_throughput": 3876.895953638503,
    "total_throughput": 8344.967560625002,
    "itl": 123.7458952137883,
    "ttft": 1863151.9560908529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.855384028708505,
    "arrivals": 194481,
    "finished_requests": 65010,
    "scheduler_time": 139.85217046358648
}
#Debug simulation 
Total elapsed time: 8.793740398716182. Arrivals time: 0.25522722071036696 Scheduler time: 8.382327824365348 Scheduler overhead time: 0.04580734996125102 Adapter cache time: 0.04373254952952266 Engine time: 0.045971667394042015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.291385019663721,
    "estimated_duration": 3600.009395016523,
    "input_throughput": 3944.4294283389854,
    "output_throughput": 3425.1316168977405,
    "total_throughput": 7369.561045236726,
    "itl": 100.05963782401587,
    "ttft": 1975231.4251937873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.27634930607028,
    "arrivals": 194481,
    "finished_requests": 57445,
    "scheduler_time": 153.68653666545814
}
#Debug simulation 
Total elapsed time: 6.291497999802232. Arrivals time: 0.22480022022500634 Scheduler time: 5.869199462234974 Scheduler overhead time: 0.05320342956110835 Adapter cache time: 0.06631080340594053 Engine time: 0.05364446388557553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.090443735942245,
    "estimated_duration": 3600.0574399081843,
    "input_throughput": 4645.689764446243,
    "output_throughput": 4037.0653087053706,
    "total_throughput": 8682.755073151615,
    "itl": 135.08500311911268,
    "ttft": 1823236.9536268604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.680566822774953,
    "arrivals": 193337,
    "finished_requests": 67692,
    "scheduler_time": 134.93672811840423
}
#Debug simulation 
Total elapsed time: 12.090603901073337. Arrivals time: 0.27400897862389684 Scheduler time: 11.67745215864852 Scheduler overhead time: 0.04424133338034153 Adapter cache time: 0.030721272341907024 Engine time: 0.04450178751721978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.338687689043581,
    "estimated_duration": 3600.030559044064,
    "input_throughput": 4461.43879519313,
    "output_throughput": 3878.0748582609785,
    "total_throughput": 8339.513653454109,
    "itl": 123.67372988240567,
    "ttft": 1862425.9908126788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.693936840067327,
    "arrivals": 193337,
    "finished_requests": 65034,
    "scheduler_time": 139.80272564129447
}
#Debug simulation 
Total elapsed time: 9.33880656119436. Arrivals time: 0.253332931548357 Scheduler time: 8.931294221431017 Scheduler overhead time: 0.045930215157568455 Adapter cache time: 0.04152745008468628 Engine time: 0.04594492958858609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.213308991864324,
    "estimated_duration": 3600.0025617017786,
    "input_throughput": 3933.556367611571,
    "output_throughput": 3427.612560966335,
    "total_throughput": 7361.168928577907,
    "itl": 100.16891224043076,
    "ttft": 1972674.9621566704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.55568632774617,
    "arrivals": 193337,
    "finished_requests": 57367,
    "scheduler_time": 153.47439936080403
}
#Debug simulation 
Total elapsed time: 6.213403771165758. Arrivals time: 0.22167437570169568 Scheduler time: 5.7956142304465175 Scheduler overhead time: 0.053076854441314936 Adapter cache time: 0.06555888941511512 Engine time: 0.0532433339394629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.887529961764812,
    "estimated_duration": 3600.048777764836,
    "input_throughput": 4466.850032510988,
    "output_throughput": 3883.865709364382,
    "total_throughput": 8350.71574187537,
    "itl": 124.01172925590427,
    "ttft": 1861858.0320795784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.342744903625235,
    "arrivals": 193337,
    "finished_requests": 65139,
    "scheduler_time": 139.64555645603477
}
#Debug simulation 
Total elapsed time: 8.887674073688686. Arrivals time: 0.2506300020031631 Scheduler time: 8.484020974487066 Scheduler overhead time: 0.04595716763287783 Adapter cache time: 0.040121656376868486 Engine time: 0.046236850786954165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.300627287942916,
    "estimated_duration": 3600.0077382418494,
    "input_throughput": 3937.5170918167937,
    "output_throughput": 3431.160402458606,
    "total_throughput": 7368.6774942754,
    "itl": 100.1344488783864,
    "ttft": 1972833.159887388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.756934250430966,
    "arrivals": 193337,
    "finished_requests": 57412,
    "scheduler_time": 153.52554080420478
}
#Debug simulation 
Total elapsed time: 6.300746263004839. Arrivals time: 0.2154196728952229 Scheduler time: 5.891346141230315 Scheduler overhead time: 0.052888167556375265 Adapter cache time: 0.06370531348511577 Engine time: 0.05310246767476201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.424726219382137,
    "estimated_duration": 3600.0798846406587,
    "input_throughput": 4453.8853341584845,
    "output_throughput": 3873.4365477536858,
    "total_throughput": 8327.32188191217,
    "itl": 123.49006796105975,
    "ttft": 1863455.6292944802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.80020432791307,
    "arrivals": 193337,
    "finished_requests": 64926,
    "scheduler_time": 139.86455793910622
}
#Debug simulation 
Total elapsed time: 8.424841080326587. Arrivals time: 0.2434824868105352 Scheduler time: 8.02185834152624 Scheduler overhead time: 0.04586246237158775 Adapter cache time: 0.04671110678464174 Engine time: 0.04612363921478391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.32549752201885,
    "estimated_duration": 3600.0376584693554,
    "input_throughput": 3927.8047458014853,
    "output_throughput": 3424.9144508233635,
    "total_throughput": 7352.719196624848,
    "itl": 99.83573363909652,
    "ttft": 1973704.8783103789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.358064278364914,
    "arrivals": 193337,
    "finished_requests": 57294,
    "scheduler_time": 153.7807823722636
}
#Debug simulation 
Total elapsed time: 6.325588334351778. Arrivals time: 0.21540778828784823 Scheduler time: 5.917175466194749 Scheduler overhead time: 0.05289327446371317 Adapter cache time: 0.06271348567679524 Engine time: 0.05310247279703617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.560046180151403,
    "estimated_duration": 3600.009947160834,
    "input_throughput": 4595.931189870354,
    "output_throughput": 4049.340477933054,
    "total_throughput": 8645.271667803407,
    "itl": 135.18871053634433,
    "ttft": 1798538.8591629742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.435907688592797,
    "arrivals": 182454,
    "finished_requests": 67371,
    "scheduler_time": 134.20291663085266
}
#Debug simulation 
Total elapsed time: 15.560113545972854. Arrivals time: 0.27860746532678604 Scheduler time: 15.13792528770864 Scheduler overhead time: 0.04587115114554763 Adapter cache time: 0.03154302388429642 Engine time: 0.046402047388255596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.53618510812521,
    "estimated_duration": 3600.052191870378,
    "input_throughput": 4405.490297005963,
    "output_throughput": 3881.141232216636,
    "total_throughput": 8286.631529222599,
    "itl": 123.98704159145373,
    "ttft": 1839994.4424360155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.748615076927997,
    "arrivals": 182454,
    "finished_requests": 64528,
    "scheduler_time": 138.81356819043066
}
#Debug simulation 
Total elapsed time: 10.53625042270869. Arrivals time: 0.26071987580507994 Scheduler time: 10.1137097007595 Scheduler overhead time: 0.04652564832940698 Adapter cache time: 0.047860787715762854 Engine time: 0.046670487616211176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.513527596835047,
    "estimated_duration": 3600.0470233802007,
    "input_throughput": 3885.5189693789516,
    "output_throughput": 3426.397188672855,
    "total_throughput": 7311.916158051807,
    "itl": 100.46991430533329,
    "ttft": 1958826.1518368514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.99140906778295,
    "arrivals": 182454,
    "finished_requests": 56901,
    "scheduler_time": 152.24047014597951
}
#Debug simulation 
Total elapsed time: 6.513635248877108. Arrivals time: 0.21925317496061325 Scheduler time: 6.089702826924622 Scheduler overhead time: 0.05295613966882229 Adapter cache time: 0.07460470404475927 Engine time: 0.05285326577723026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.276127795688808,
    "estimated_duration": 3600.0304331447574,
    "input_throughput": 4402.396117011581,
    "output_throughput": 3883.8549450222895,
    "total_throughput": 8286.25106203387,
    "itl": 124.05870849708054,
    "ttft": 1839893.28419799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.697543319366261,
    "arrivals": 182454,
    "finished_requests": 64545,
    "scheduler_time": 138.8034552048473
}
#Debug simulation 
Total elapsed time: 10.276223088614643. Arrivals time: 0.25286805257201195 Scheduler time: 9.864167606458068 Scheduler overhead time: 0.04699786426499486 Adapter cache time: 0.044428483583033085 Engine time: 0.04682304756715894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.333899456076324,
    "estimated_duration": 3600.048559045144,
    "input_throughput": 3885.2106494113004,
    "output_throughput": 3425.65601483748,
    "total_throughput": 7310.866664248781,
    "itl": 100.49421170922362,
    "ttft": 1958895.8719759579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.866172135315296,
    "arrivals": 182454,
    "finished_requests": 56907,
    "scheduler_time": 152.22529915332285
}
#Debug simulation 
Total elapsed time: 6.333994267974049. Arrivals time: 0.21306376857683063 Scheduler time: 5.915259805973619 Scheduler overhead time: 0.053006996400654316 Adapter cache time: 0.07508250093087554 Engine time: 0.05326608847826719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.65630560182035,
    "estimated_duration": 3600.0294106924025,
    "input_throughput": 4407.052329316539,
    "output_throughput": 3881.1213482038474,
    "total_throughput": 8288.173677520386,
    "itl": 123.75342569335149,
    "ttft": 1840224.5618072003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.691677671923356,
    "arrivals": 182454,
    "finished_requests": 64549,
    "scheduler_time": 139.0020782398089
}
#Debug simulation 
Total elapsed time: 10.656402630731463. Arrivals time: 0.25863617938011885 Scheduler time: 10.236204621382058 Scheduler overhead time: 0.046849974896758795 Adapter cache time: 0.046905930154025555 Engine time: 0.04685029108077288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.368897486012429,
    "estimated_duration": 3600.000436241093,
    "input_throughput": 3884.740084810205,
    "output_throughput": 3422.61180747669,
    "total_throughput": 7307.351892286895,
    "itl": 100.24464282669952,
    "ttft": 1959956.6053518504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.79511689482405,
    "arrivals": 182454,
    "finished_requests": 56881,
    "scheduler_time": 152.43158071818175
}
#Debug simulation 
Total elapsed time: 6.368992967996746. Arrivals time: 0.2166628371924162 Scheduler time: 5.947642839513719 Scheduler overhead time: 0.0530308336019516 Adapter cache time: 0.07407694961875677 Engine time: 0.05324410367757082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.80523128528148,
    "estimated_duration": 3600.0564063485867,
    "input_throughput": 4700.568293918405,
    "output_throughput": 4034.6395613095788,
    "total_throughput": 8735.207855227984,
    "itl": 134.52179375236145,
    "ttft": 1784614.490479124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.03305820197368,
    "arrivals": 177727,
    "finished_requests": 67805,
    "scheduler_time": 133.8520081024056
}
#Debug simulation 
Total elapsed time: 12.805350729264319. Arrivals time: 0.282674940302968 Scheduler time: 12.373099354561418 Scheduler overhead time: 0.045774446334689856 Adapter cache time: 0.038841561414301395 Engine time: 0.045095831621438265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.106632049195468,
    "estimated_duration": 3600.0834270536925,
    "input_throughput": 4495.152495186508,
    "output_throughput": 3867.1012164275508,
    "total_throughput": 8362.25371161406,
    "itl": 123.11802551391389,
    "ttft": 1828353.6493533007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.46558806022118,
    "arrivals": 177727,
    "finished_requests": 64917,
    "scheduler_time": 138.6242511080856
}
#Debug simulation 
Total elapsed time: 9.106773088220507. Arrivals time: 0.25369052356109023 Scheduler time: 8.690750082023442 Scheduler overhead time: 0.046082280576229095 Adapter cache time: 0.04900807607918978 Engine time: 0.04642100678756833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.257514533121139,
    "estimated_duration": 3600.0815939083036,
    "input_throughput": 3975.754889616694,
    "output_throughput": 3418.737236629833,
    "total_throughput": 7394.492126246528,
    "itl": 99.55251849078768,
    "ttft": 1946384.1607622777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.324927035235916,
    "arrivals": 177727,
    "finished_requests": 57411,
    "scheduler_time": 152.46121552442872
}
#Debug simulation 
Total elapsed time: 6.257611173670739. Arrivals time: 0.2170667345635593 Scheduler time: 5.84333136677742 Scheduler overhead time: 0.053394162096083164 Adapter cache time: 0.06603957526385784 Engine time: 0.053358934819698334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.698555869981647,
    "estimated_duration": 3600.118200378533,
    "input_throughput": 4495.949049200144,
    "output_throughput": 3866.4622174173105,
    "total_throughput": 8362.411266617455,
    "itl": 122.7572316941669,
    "ttft": 1827518.5072422696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.97760480370404,
    "arrivals": 177727,
    "finished_requests": 64926,
    "scheduler_time": 138.9023618679816
}
#Debug simulation 
Total elapsed time: 9.698653429746628. Arrivals time: 0.25346125615760684 Scheduler time: 9.286174105480313 Scheduler overhead time: 0.04657598631456494 Adapter cache time: 0.044538569170981646 Engine time: 0.04687652410939336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.160678223241121,
    "estimated_duration": 3600.0876080252688,
    "input_throughput": 3969.1197981256755,
    "output_throughput": 3415.807152189083,
    "total_throughput": 7384.926950314758,
    "itl": 99.51233997216644,
    "ttft": 1947150.696434499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.19139499717986,
    "arrivals": 177727,
    "finished_requests": 57349,
    "scheduler_time": 152.455231375181
}
#Debug simulation 
Total elapsed time: 6.160831016022712. Arrivals time: 0.22393069695681334 Scheduler time: 5.735024135559797 Scheduler overhead time: 0.053234475664794445 Adapter cache time: 0.07050167536363006 Engine time: 0.05353656969964504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.681769793853164,
    "estimated_duration": 3600.0588215480825,
    "input_throughput": 4494.693504213868,
    "output_throughput": 3865.1857343865213,
    "total_throughput": 8359.87923860039,
    "itl": 122.73253028553616,
    "ttft": 1828360.872711972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.966186272367926,
    "arrivals": 177727,
    "finished_requests": 64895,
    "scheduler_time": 138.8917063748959
}
#Debug simulation 
Total elapsed time: 9.68185762828216. Arrivals time: 0.25739665469154716 Scheduler time: 9.263273932039738 Scheduler overhead time: 0.04635017365217209 Adapter cache time: 0.04735905071720481 Engine time: 0.04656489612534642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.184996908996254,
    "estimated_duration": 3600.019158094856,
    "input_throughput": 3968.18860474064,
    "output_throughput": 3416.9132051257507,
    "total_throughput": 7385.101809866391,
    "itl": 99.4817937300482,
    "ttft": 1947609.355160147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.870144930371293,
    "arrivals": 177727,
    "finished_requests": 57332,
    "scheduler_time": 152.54112910584377
}
#Debug simulation 
Total elapsed time: 6.185107482597232. Arrivals time: 0.219313632696867 Scheduler time: 5.766934118233621 Scheduler overhead time: 0.053186820819973946 Adapter cache time: 0.06790505535900593 Engine time: 0.053415092173963785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.215967875905335,
    "estimated_duration": 3600.1074269426904,
    "input_throughput": 4661.297569736976,
    "output_throughput": 4045.4248367716395,
    "total_throughput": 8706.722406508616,
    "itl": 134.56226104917332,
    "ttft": 1765962.137174484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.609356559599028,
    "arrivals": 175481,
    "finished_requests": 67892,
    "scheduler_time": 133.5951901622301
}
#Debug simulation 
Total elapsed time: 15.216117028612643. Arrivals time: 0.28267128160223365 Scheduler time: 14.791444721166044 Scheduler overhead time: 0.04671205347403884 Adapter cache time: 0.02887146919965744 Engine time: 0.046188236214220524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.81406767712906,
    "estimated_duration": 3600.104632645885,
    "input_throughput": 4464.257470258049,
    "output_throughput": 3872.975766749466,
    "total_throughput": 8337.233237007515,
    "itl": 123.02643993396009,
    "ttft": 1815145.860810656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.272211009119399,
    "arrivals": 175481,
    "finished_requests": 65044,
    "scheduler_time": 138.33378829023403
}
#Debug simulation 
Total elapsed time: 9.81418951926753. Arrivals time: 0.24939885782077909 Scheduler time: 9.411976482253522 Scheduler overhead time: 0.046676880680024624 Adapter cache time: 0.038512188009917736 Engine time: 0.04656790383160114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.99604222131893,
    "estimated_duration": 3600.0604823643066,
    "input_throughput": 3950.9161220143787,
    "output_throughput": 3425.1874546012646,
    "total_throughput": 7376.103576615643,
    "itl": 99.75857623220381,
    "ttft": 1933420.1330243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.395397610939945,
    "arrivals": 175481,
    "finished_requests": 57496,
    "scheduler_time": 151.85936170189612
}
#Debug simulation 
Total elapsed time: 5.996160434093326. Arrivals time: 0.2097371332347393 Scheduler time: 5.5925818625837564 Scheduler overhead time: 0.05310043599456549 Adapter cache time: 0.06328092655166984 Engine time: 0.05304890125989914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.71333850407973,
    "estimated_duration": 3600.1320273621304,
    "input_throughput": 4478.915739047158,
    "output_throughput": 3885.195291087321,
    "total_throughput": 8364.11103013448,
    "itl": 123.26651043885664,
    "ttft": 1813366.1274268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.200343760350037,
    "arrivals": 175481,
    "finished_requests": 65207,
    "scheduler_time": 138.34431492687415
}
#Debug simulation 
Total elapsed time: 9.713462410960346. Arrivals time: 0.2512415088713169 Scheduler time: 9.307518150657415 Scheduler overhead time: 0.04652889212593436 Adapter cache time: 0.04061537701636553 Engine time: 0.04671392356976867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.984308858867735,
    "estimated_duration": 3600.015096670993,
    "input_throughput": 3954.158973711922,
    "output_throughput": 3425.0859146124512,
    "total_throughput": 7379.244888324373,
    "itl": 99.75431720551101,
    "ttft": 1934187.5551946266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.072790264320545,
    "arrivals": 175481,
    "finished_requests": 57519,
    "scheduler_time": 151.83216278152142
}
#Debug simulation 
Total elapsed time: 5.984406006056815. Arrivals time: 0.21438263729214668 Scheduler time: 5.573889778926969 Scheduler overhead time: 0.05310308048501611 Adapter cache time: 0.06552182650193572 Engine time: 0.053174829576164484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.756505961995572,
    "estimated_duration": 3600.1411863513927,
    "input_throughput": 4478.89101158883,
    "output_throughput": 3879.0328704172484,
    "total_throughput": 8357.923882006078,
    "itl": 122.8010648111863,
    "ttft": 1815626.7280663012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.563556411043377,
    "arrivals": 175481,
    "finished_requests": 65180,
    "scheduler_time": 138.56693661997656
}
#Debug simulation 
Total elapsed time: 9.756602398119867. Arrivals time: 0.25858416547998786 Scheduler time: 9.343883752822876 Scheduler overhead time: 0.0467368895187974 Adapter cache time: 0.039597522001713514 Engine time: 0.04683228163048625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.2257073489017785,
    "estimated_duration": 3600.0325149085024,
    "input_throughput": 3955.353997785185,
    "output_throughput": 3424.8471226136594,
    "total_throughput": 7380.201120398845,
    "itl": 99.7142741530832,
    "ttft": 1934391.8949319604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.768271882143665,
    "arrivals": 175481,
    "finished_requests": 57518,
    "scheduler_time": 151.90039324887576
}
#Debug simulation 
Total elapsed time: 6.225814539939165. Arrivals time: 0.21626728726550937 Scheduler time: 5.815513187553734 Scheduler overhead time: 0.052978167310357094 Adapter cache time: 0.06348838564008474 Engine time: 0.05326711991801858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.491191839799285,
    "estimated_duration": 3600.034200313017,
    "input_throughput": 4621.827758901093,
    "output_throughput": 4041.3318847734818,
    "total_throughput": 8663.159643674575,
    "itl": 134.10056604090943,
    "ttft": 1783534.2699193074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.41454422532142,
    "arrivals": 174302,
    "finished_requests": 67385,
    "scheduler_time": 133.9972009521223
}
#Debug simulation 
Total elapsed time: 11.491291384678334. Arrivals time: 0.27665109327062964 Scheduler time: 11.072461678646505 Scheduler overhead time: 0.04456366552039981 Adapter cache time: 0.033216582145541906 Engine time: 0.04474423313513398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.090447993017733,
    "estimated_duration": 3600.0976813680572,
    "input_throughput": 4427.663472159651,
    "output_throughput": 3876.003996285291,
    "total_throughput": 8303.66746844494,
    "itl": 123.08982666860288,
    "ttft": 1824883.6892999308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.819490850898212,
    "arrivals": 174302,
    "finished_requests": 64595,
    "scheduler_time": 138.62277909080146
}
#Debug simulation 
Total elapsed time: 9.090546002611518. Arrivals time: 0.24970468692481518 Scheduler time: 8.689247761387378 Scheduler overhead time: 0.04607504839077592 Adapter cache time: 0.038382179103791714 Engine time: 0.04632492549717426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.773194277193397,
    "estimated_duration": 3600.0398192866487,
    "input_throughput": 3903.0054403076615,
    "output_throughput": 3413.5030768729184,
    "total_throughput": 7316.5085171805795,
    "itl": 99.21886344595113,
    "ttft": 1947207.690102158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.10341002456446,
    "arrivals": 174302,
    "finished_requests": 56861,
    "scheduler_time": 152.54836070630378
}
#Debug simulation 
Total elapsed time: 5.7732878611423075. Arrivals time: 0.21082295291125774 Scheduler time: 5.369404573459178 Scheduler overhead time: 0.053233890794217587 Adapter cache time: 0.06181817455217242 Engine time: 0.053526545874774456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.48598437383771,
    "estimated_duration": 3600.013120561676,
    "input_throughput": 4439.284376137652,
    "output_throughput": 3885.549727612543,
    "total_throughput": 8324.834103750194,
    "itl": 123.09971014361129,
    "ttft": 1823337.1889880726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.061966187646771,
    "arrivals": 174302,
    "finished_requests": 64753,
    "scheduler_time": 138.7571072006337
}
#Debug simulation 
Total elapsed time: 9.486081185750663. Arrivals time: 0.25080786598846316 Scheduler time: 9.084351581986994 Scheduler overhead time: 0.0464632292278111 Adapter cache time: 0.036917098332196474 Engine time: 0.046642875764518976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.879479025024921,
    "estimated_duration": 3600.0635128234094,
    "input_throughput": 3909.938796874348,
    "output_throughput": 3419.6605021406685,
    "total_throughput": 7329.599299015017,
    "itl": 99.42612244412832,
    "ttft": 1946013.7844192071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.88726791195627,
    "arrivals": 174302,
    "finished_requests": 56968,
    "scheduler_time": 152.40645879422323
}
#Debug simulation 
Total elapsed time: 5.879573924001306. Arrivals time: 0.2147847623564303 Scheduler time: 5.474340796936303 Scheduler overhead time: 0.05285427672788501 Adapter cache time: 0.060009547509253025 Engine time: 0.053192402236163616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.213981683366,
    "estimated_duration": 3600.021306732721,
    "input_throughput": 4431.065163466359,
    "output_throughput": 3874.1967926456755,
    "total_throughput": 8305.261956112034,
    "itl": 122.98640957112771,
    "ttft": 1824827.0124515975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.705835417337104,
    "arrivals": 174302,
    "finished_requests": 64583,
    "scheduler_time": 138.65658924191527
}
#Debug simulation 
Total elapsed time: 9.214078218210489. Arrivals time: 0.24488498643040657 Scheduler time: 8.820939155295491 Scheduler overhead time: 0.04593680566176772 Adapter cache time: 0.03511714283376932 Engine time: 0.046268712263554335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.835442848037928,
    "estimated_duration": 3600.0434455511963,
    "input_throughput": 3914.7844222313784,
    "output_throughput": 3425.166442154439,
    "total_throughput": 7339.950864385817,
    "itl": 99.76355640991078,
    "ttft": 1944426.6788469949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.929115383756088,
    "arrivals": 174302,
    "finished_requests": 57068,
    "scheduler_time": 152.12119740191827
}
#Debug simulation 
Total elapsed time: 5.835537084843963. Arrivals time: 0.2089259414933622 Scheduler time: 5.434039740823209 Scheduler overhead time: 0.05303124664351344 Adapter cache time: 0.062100949697196484 Engine time: 0.053150773514062166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 13.3859947421588,
    "estimated_duration": 3600.133550117676,
    "input_throughput": 4668.3693163134585,
    "output_throughput": 4045.3390956910366,
    "total_throughput": 8713.708412004495,
    "itl": 134.91905062553622,
    "ttft": 1751869.6719136639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.78992530396705,
    "arrivals": 168141,
    "finished_requests": 67850,
    "scheduler_time": 132.58464772390508
}
#Debug simulation 
Total elapsed time: 13.386113984044641. Arrivals time: 0.27006625663489103 Scheduler time: 12.969855387229472 Scheduler overhead time: 0.045300126541405916 Adapter cache time: 0.03528862539678812 Engine time: 0.04578530555590987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.403659333940595,
    "estimated_duration": 3600.1143301210814,
    "input_throughput": 4474.755389076266,
    "output_throughput": 3881.2992362745454,
    "total_throughput": 8356.054625350811,
    "itl": 123.70428216429286,
    "ttft": 1796359.9188138417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.402854350641977,
    "arrivals": 168141,
    "finished_requests": 65052,
    "scheduler_time": 137.12384081110656
}
#Debug simulation 
Total elapsed time: 9.403813792858273. Arrivals time: 0.24840569449588656 Scheduler time: 8.999526164028794 Scheduler overhead time: 0.046159747522324324 Adapter cache time: 0.04290158860385418 Engine time: 0.04607139993458986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.926950560882688,
    "estimated_duration": 3600.0227618611425,
    "input_throughput": 3940.9420268957815,
    "output_throughput": 3436.0257749051193,
    "total_throughput": 7376.967801800901,
    "itl": 100.10635917796309,
    "ttft": 1918292.3708468329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.139607986575797,
    "arrivals": 168141,
    "finished_requests": 57438,
    "scheduler_time": 150.75059320768852
}
#Debug simulation 
Total elapsed time: 5.927043801639229. Arrivals time: 0.21000765170902014 Scheduler time: 5.5233593177981675 Scheduler overhead time: 0.05294259870424867 Adapter cache time: 0.06342541519552469 Engine time: 0.052870103158056736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.759375595953315,
    "estimated_duration": 3600.022487209967,
    "input_throughput": 4473.129003280248,
    "output_throughput": 3879.3724343715357,
    "total_throughput": 8352.501437651783,
    "itl": 123.67161778610452,
    "ttft": 1796699.2801851195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.68595565266942,
    "arrivals": 168141,
    "finished_requests": 65002,
    "scheduler_time": 137.11506639880454
}
#Debug simulation 
Total elapsed time: 8.759495906997472. Arrivals time: 0.24118376430124044 Scheduler time: 8.360349785536528 Scheduler overhead time: 0.04589456971734762 Adapter cache time: 0.045133611653000116 Engine time: 0.0461420938372612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.874066923279315,
    "estimated_duration": 3600.014324254421,
    "input_throughput": 3939.9948784752623,
    "output_throughput": 3435.142165041571,
    "total_throughput": 7375.137043516833,
    "itl": 100.13311067859206,
    "ttft": 1917690.5475432815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.52787263272882,
    "arrivals": 168141,
    "finished_requests": 57439,
    "scheduler_time": 150.72520134865442
}
#Debug simulation 
Total elapsed time: 5.874162323307246. Arrivals time: 0.2143535246141255 Scheduler time: 5.464773857966065 Scheduler overhead time: 0.05282795615494251 Adapter cache time: 0.06451198365539312 Engine time: 0.053399610333144665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.190176269970834,
    "estimated_duration": 3600.1253276913203,
    "input_throughput": 4477.359684124327,
    "output_throughput": 3882.9909315864243,
    "total_throughput": 8360.350615710751,
    "itl": 123.61121788906506,
    "ttft": 1796107.2567096418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.425385738020514,
    "arrivals": 168141,
    "finished_requests": 65085,
    "scheduler_time": 137.23804978669315
}
#Debug simulation 
Total elapsed time: 9.190297935158014. Arrivals time: 0.24513448681682348 Scheduler time: 8.791797084268183 Scheduler overhead time: 0.0460555050522089 Adapter cache time: 0.04060652246698737 Engine time: 0.04583336692303419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.842768407892436,
    "estimated_duration": 3600.0539279548784,
    "input_throughput": 3942.455664285785,
    "output_throughput": 3434.342442482146,
    "total_throughput": 7376.798106767931,
    "itl": 100.10540485663225,
    "ttft": 1918380.7343605396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.93311861183587,
    "arrivals": 168141,
    "finished_requests": 57450,
    "scheduler_time": 150.72169463197167
}
#Debug simulation 
Total elapsed time: 5.842869161162525. Arrivals time: 0.21310091204941273 Scheduler time: 5.433491379953921 Scheduler overhead time: 0.05296093923971057 Adapter cache time: 0.06579380063340068 Engine time: 0.05310953687876463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 13.697442283853889,
    "estimated_duration": 3600.031165636943,
    "input_throughput": 4699.781535643041,
    "output_throughput": 4058.9484723015394,
    "total_throughput": 8758.730007944581,
    "itl": 134.36905455989074,
    "ttft": 1740258.4550211676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.848929520924761,
    "arrivals": 165887,
    "finished_requests": 68414,
    "scheduler_time": 132.77502988896035
}
#Debug simulation 
Total elapsed time: 13.697592138778418. Arrivals time: 0.2826821184717119 Scheduler time: 13.275863037910312 Scheduler overhead time: 0.04572994448244572 Adapter cache time: 0.027488500345498323 Engine time: 0.04589025164023042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.822880232241005,
    "estimated_duration": 3600.037618997239,
    "input_throughput": 4495.251081433883,
    "output_throughput": 3884.856904327456,
    "total_throughput": 8380.107985761339,
    "itl": 123.62021018042176,
    "ttft": 1785848.445724957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.74454587370601,
    "arrivals": 165887,
    "finished_requests": 65454,
    "scheduler_time": 136.93710347896774
}
#Debug simulation 
Total elapsed time: 8.822998811956495. Arrivals time: 0.24585985578596592 Scheduler time: 8.42676654085517 Scheduler overhead time: 0.046041848603636026 Adapter cache time: 0.03765179589390755 Engine time: 0.04595852084457874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.675428010057658,
    "estimated_duration": 3600.102489335594,
    "input_throughput": 3960.3916950240236,
    "output_throughput": 3433.4047535077743,
    "total_throughput": 7393.796448531798,
    "itl": 99.88983513578705,
    "ttft": 1909317.1640882185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.810465395581534,
    "arrivals": 165887,
    "finished_requests": 57719,
    "scheduler_time": 150.62577892867668
}
#Debug simulation 
Total elapsed time: 5.675537182018161. Arrivals time: 0.20897339098155499 Scheduler time: 5.277255300898105 Scheduler overhead time: 0.053014000877738 Adapter cache time: 0.05885983211919665 Engine time: 0.05310932453721762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.799671464134008,
    "estimated_duration": 3600.0679720881676,
    "input_throughput": 4498.407287184239,
    "output_throughput": 3886.9596653430344,
    "total_throughput": 8385.366952527274,
    "itl": 123.69188416362636,
    "ttft": 1784158.832350354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1876,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.824438699204677,
    "arrivals": 165887,
    "finished_requests": 65481,
    "scheduler_time": 136.920666028839
}
#Debug simulation 
Total elapsed time: 8.799840988125652. Arrivals time: 0.24674747604876757 Scheduler time: 8.40271068410948 Scheduler overhead time: 0.046045851428061724 Adapter cache time: 0.03718569967895746 Engine time: 0.046211834996938705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.649657262023538,
    "estimated_duration": 3600.1064883212184,
    "input_throughput": 3965.484645054814,
    "output_throughput": 3437.3833218946297,
    "total_throughput": 7402.867966949444,
    "itl": 100.03368028198457,
    "ttft": 1908296.554081441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.78236528118197,
    "arrivals": 165887,
    "finished_requests": 57791,
    "scheduler_time": 150.51107880407557
}
#Debug simulation 
Total elapsed time: 5.649791186675429. Arrivals time: 0.2084218510426581 Scheduler time: 5.251552438829094 Scheduler overhead time: 0.05304428096860647 Adapter cache time: 0.05976503947749734 Engine time: 0.05272670276463032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.86077261576429,
    "estimated_duration": 3600.106158596651,
    "input_throughput": 4496.390463749548,
    "output_throughput": 3884.521840170219,
    "total_throughput": 8380.912303919768,
    "itl": 123.46897878525286,
    "ttft": 1785026.857806641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.861325107580525,
    "arrivals": 165887,
    "finished_requests": 65450,
    "scheduler_time": 137.04015037895397
}
#Debug simulation 
Total elapsed time: 8.860876262653619. Arrivals time: 0.2455850369296968 Scheduler time: 8.466421773191541 Scheduler overhead time: 0.04594656126573682 Adapter cache time: 0.03622802346944809 Engine time: 0.045883916318416595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.689169072080404,
    "estimated_duration": 3600.0535892956927,
    "input_throughput": 3961.8057471167613,
    "output_throughput": 3434.1086023718517,
    "total_throughput": 7395.914349488613,
    "itl": 99.83677011044502,
    "ttft": 1909431.390170849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.53480844765956,
    "arrivals": 165887,
    "finished_requests": 57734,
    "scheduler_time": 150.6617370185204
}
#Debug simulation 
Total elapsed time: 5.689290105830878. Arrivals time: 0.2117901463061571 Scheduler time: 5.286548356991261 Scheduler overhead time: 0.05301915621384978 Adapter cache time: 0.06035282602533698 Engine time: 0.05317734833806753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.480061305686831,
    "estimated_duration": 3600.0485971006788,
    "input_throughput": 4609.197501768044,
    "output_throughput": 4051.3078106073463,
    "total_throughput": 8660.50531237539,
    "itl": 134.86629011272152,
    "ttft": 1737303.0195735563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1045,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.90996743838784,
    "arrivals": 164660,
    "finished_requests": 67450,
    "scheduler_time": 132.24557937354004
}
#Debug simulation 
Total elapsed time: 12.480215672869235. Arrivals time: 0.2704786863178015 Scheduler time: 12.075801843311638 Scheduler overhead time: 0.04455556161701679 Adapter cache time: 0.024357322603464127 Engine time: 0.045210578478872776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.805269830860198,
    "estimated_duration": 3600.1281942556056,
    "input_throughput": 4403.838736992029,
    "output_throughput": 3882.641185473179,
    "total_throughput": 8286.479922465209,
    "itl": 123.46909592684807,
    "ttft": 1784387.2929471582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.514526761397612,
    "arrivals": 164660,
    "finished_requests": 64568,
    "scheduler_time": 136.9406466916175
}
#Debug simulation 
Total elapsed time: 8.805362627841532. Arrivals time: 0.23940965766087174 Scheduler time: 8.420453404076397 Scheduler overhead time: 0.045963339041918516 Adapter cache time: 0.0329110287129879 Engine time: 0.04590617027133703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.543593232985586,
    "estimated_duration": 3600.0726862828305,
    "input_throughput": 3888.1812173778712,
    "output_throughput": 3434.942313003203,
    "total_throughput": 7323.1235303810745,
    "itl": 99.83648282051823,
    "ttft": 1906189.5313260085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.538649332807672,
    "arrivals": 164660,
    "finished_requests": 57028,
    "scheduler_time": 150.60105945592895
}
#Debug simulation 
Total elapsed time: 5.543711136095226. Arrivals time: 0.20592998946085572 Scheduler time: 5.1526014362461865 Scheduler overhead time: 0.05272388504818082 Adapter cache time: 0.05468229250982404 Engine time: 0.05341525189578533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.692685735877603,
    "estimated_duration": 3600.1013000762673,
    "input_throughput": 4410.718109421979,
    "output_throughput": 3885.447889953449,
    "total_throughput": 8296.165999375427,
    "itl": 123.54714307071234,
    "ttft": 1783539.6144825567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.524319129982153,
    "arrivals": 164660,
    "finished_requests": 64655,
    "scheduler_time": 136.9397394863691
}
#Debug simulation 
Total elapsed time: 8.692804366815835. Arrivals time: 0.2422021683305502 Scheduler time: 8.304206865373999 Scheduler overhead time: 0.045625180937349796 Adapter cache time: 0.03408751497045159 Engine time: 0.04596666805446148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.578564309049398,
    "estimated_duration": 3600.088649707403,
    "input_throughput": 3892.6449772671504,
    "output_throughput": 3437.8031221553088,
    "total_throughput": 7330.44809942246,
    "itl": 99.94723872291588,
    "ttft": 1905658.5712305196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.96324848365992,
    "arrivals": 164660,
    "finished_requests": 57094,
    "scheduler_time": 150.5129062834725
}
#Debug simulation 
Total elapsed time: 5.578664015047252. Arrivals time: 0.20754626812413335 Scheduler time: 5.185949286445975 Scheduler overhead time: 0.052771234419196844 Adapter cache time: 0.054706303868442774 Engine time: 0.05330884829163551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.23181313695386,
    "estimated_duration": 3600.0339570208375,
    "input_throughput": 4412.13116032507,
    "output_throughput": 3888.6638757110395,
    "total_throughput": 8300.79503603611,
    "itl": 123.46350988954636,
    "ttft": 1782135.3734251196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.097087340313115,
    "arrivals": 164660,
    "finished_requests": 64665,
    "scheduler_time": 137.0142591916917
}
#Debug simulation 
Total elapsed time: 9.231964892242104. Arrivals time: 0.2502543954178691 Scheduler time: 8.83795802295208 Scheduler overhead time: 0.04595401044934988 Adapter cache time: 0.03068305505439639 Engine time: 0.04626580514013767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.582561899907887,
    "estimated_duration": 3600.087559234277,
    "input_throughput": 3894.2594504512344,
    "output_throughput": 3439.833836328681,
    "total_throughput": 7334.093286779916,
    "itl": 100.08266914503888,
    "ttft": 1904693.3029634338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.289870955907066,
    "arrivals": 164660,
    "finished_requests": 57113,
    "scheduler_time": 150.41608229221677
}
#Debug simulation 
Total elapsed time: 5.582657525781542. Arrivals time: 0.2090544030070305 Scheduler time: 5.188691911753267 Scheduler overhead time: 0.052733344957232475 Adapter cache time: 0.05483398353680968 Engine time: 0.05305839888751507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.304766156245023,
    "estimated_duration": 3600.0966610576893,
    "input_throughput": 4680.782930714196,
    "output_throughput": 4057.3135599388665,
    "total_throughput": 8738.096490653063,
    "itl": 134.8104184009819,
    "ttft": 1718722.0795540763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.597657977710655,
    "arrivals": 161177,
    "finished_requests": 68099,
    "scheduler_time": 131.8950310381524
}
#Debug simulation 
Total elapsed time: 11.304875482339412. Arrivals time: 0.26513466611504555 Scheduler time: 10.90622593741864 Scheduler overhead time: 0.04401572560891509 Adapter cache time: 0.025448234751820564 Engine time: 0.044335087295621634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.982834875117987,
    "estimated_duration": 3600.0031854363797,
    "input_throughput": 4481.106590477791,
    "output_throughput": 3885.1937844339936,
    "total_throughput": 8366.300374911783,
    "itl": 123.49860296417495,
    "ttft": 1765380.6103431708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.238440849557362,
    "arrivals": 161177,
    "finished_requests": 65206,
    "scheduler_time": 136.4138319506778
}
#Debug simulation 
Total elapsed time: 7.982965451665223. Arrivals time: 0.23638173984363675 Scheduler time: 7.60112562449649 Scheduler overhead time: 0.04535287618637085 Adapter cache time: 0.03381871758028865 Engine time: 0.04560590349137783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.315950016025454,
    "estimated_duration": 3600.0269419283177,
    "input_throughput": 3968.682798897921,
    "output_throughput": 3437.824271773584,
    "total_throughput": 7406.507070671505,
    "itl": 99.8515999485983,
    "ttft": 1889291.8979941749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.739912083419256,
    "arrivals": 161177,
    "finished_requests": 57718,
    "scheduler_time": 150.0883971060446
}
#Debug simulation 
Total elapsed time: 5.316047823987901. Arrivals time: 0.21766746835783124 Scheduler time: 4.91561762848869 Scheduler overhead time: 0.05295925820246339 Adapter cache time: 0.05207319790497422 Engine time: 0.05333795165643096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.370813014451414,
    "estimated_duration": 3600.129997480521,
    "input_throughput": 4483.541153040636,
    "output_throughput": 3887.1115792467203,
    "total_throughput": 8370.652732287357,
    "itl": 123.48787704738338,
    "ttft": 1764018.7161504773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.849549959814281,
    "arrivals": 161177,
    "finished_requests": 65249,
    "scheduler_time": 136.45484582922376
}
#Debug simulation 
Total elapsed time: 8.370908110402524. Arrivals time: 0.2386652841232717 Scheduler time: 7.987001242116094 Scheduler overhead time: 0.04581932071596384 Adapter cache time: 0.03297538077458739 Engine time: 0.045759943313896656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.318316280841827,
    "estimated_duration": 3600.0662489241095,
    "input_throughput": 3968.5780794366647,
    "output_throughput": 3438.2920046816434,
    "total_throughput": 7406.870084118308,
    "itl": 99.84756897317936,
    "ttft": 1889109.861638064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2710,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.156597830150428,
    "arrivals": 161177,
    "finished_requests": 57722,
    "scheduler_time": 150.1127290446338
}
#Debug simulation 
Total elapsed time: 5.318417058791965. Arrivals time: 0.205780737567693 Scheduler time: 4.930398334749043 Scheduler overhead time: 0.052815822418779135 Adapter cache time: 0.05182945355772972 Engine time: 0.053350409492850304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.08562396792695,
    "estimated_duration": 3600.0574367747054,
    "input_throughput": 4490.526410735066,
    "output_throughput": 3888.672401999818,
    "total_throughput": 8379.198812734883,
    "itl": 123.62676479068449,
    "ttft": 1764802.8339286337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.463246421595391,
    "arrivals": 161177,
    "finished_requests": 65322,
    "scheduler_time": 136.37634318108232
}
#Debug simulation 
Total elapsed time: 8.085720743983984. Arrivals time: 0.2344589615240693 Scheduler time: 7.706195320934057 Scheduler overhead time: 0.04568571224808693 Adapter cache time: 0.03324333857744932 Engine time: 0.045559671241790056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.283781812991947,
    "estimated_duration": 3600.053296044101,
    "input_throughput": 3968.8006885065215,
    "output_throughput": 3438.0949342057675,
    "total_throughput": 7406.895622712289,
    "itl": 99.85443254567305,
    "ttft": 1889203.2865264358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.551449550073784,
    "arrivals": 161177,
    "finished_requests": 57716,
    "scheduler_time": 150.0965061920664
}
#Debug simulation 
Total elapsed time: 5.283898863941431. Arrivals time: 0.2101132501848042 Scheduler time: 4.891111032105982 Scheduler overhead time: 0.05296079209074378 Adapter cache time: 0.05233768746256828 Engine time: 0.05305337766185403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.773597630206496,
    "estimated_duration": 3600.0110756242775,
    "input_throughput": 4668.164804766821,
    "output_throughput": 4069.3638692374266,
    "total_throughput": 8737.528674004248,
    "itl": 134.29622188931808,
    "ttft": 1723321.063290158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.731432394525186,
    "arrivals": 159905,
    "finished_requests": 68083,
    "scheduler_time": 132.45575511274706
}
#Debug simulation 
Total elapsed time: 10.77374258916825. Arrivals time: 0.26802271977066994 Scheduler time: 10.374348022975028 Scheduler overhead time: 0.04399407282471657 Adapter cache time: 0.023880249354988337 Engine time: 0.04392426460981369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.913898604921997,
    "estimated_duration": 3600.0791531525465,
    "input_throughput": 4458.8211306252415,
    "output_throughput": 3889.5461472667967,
    "total_throughput": 8348.367277892039,
    "itl": 123.56684465322267,
    "ttft": 1770258.966766151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.282665962255475,
    "arrivals": 159905,
    "finished_requests": 65090,
    "scheduler_time": 136.49330735512217
}
#Debug simulation 
Total elapsed time: 7.913990810979158. Arrivals time: 0.23470023227855563 Scheduler time: 7.537480070721358 Scheduler overhead time: 0.045726238284260035 Adapter cache time: 0.029928232543170452 Engine time: 0.045527331065386534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.177714551798999,
    "estimated_duration": 3600.070113347817,
    "input_throughput": 3945.8825947114424,
    "output_throughput": 3433.599794117603,
    "total_throughput": 7379.482388829046,
    "itl": 99.59850900965552,
    "ttft": 1896104.3225198449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.183724646172408,
    "arrivals": 159905,
    "finished_requests": 57500,
    "scheduler_time": 150.37340135229826
}
#Debug simulation 
Total elapsed time: 5.177808211650699. Arrivals time: 0.20418498944491148 Scheduler time: 4.794536869972944 Scheduler overhead time: 0.05292465956881642 Adapter cache time: 0.048460704274475574 Engine time: 0.05330930510535836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 7.661571033764631,
    "estimated_duration": 3600.0319472578926,
    "input_throughput": 4452.371599704519,
    "output_throughput": 3883.1910951923987,
    "total_throughput": 8335.562694896918,
    "itl": 123.19299765988029,
    "ttft": 1771428.8439634133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.622977669127353,
    "arrivals": 159905,
    "finished_requests": 64989,
    "scheduler_time": 136.6654418456595
}
#Debug simulation 
Total elapsed time: 7.661665226798505. Arrivals time: 0.24228485627099872 Scheduler time: 7.277231261599809 Scheduler overhead time: 0.0457108267582953 Adapter cache time: 0.030159192625433207 Engine time: 0.045640597119927406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.3521976680494845,
    "estimated_duration": 3600.04156846447,
    "input_throughput": 3952.4101956603363,
    "output_throughput": 3440.177499195515,
    "total_throughput": 7392.587694855852,
    "itl": 99.88727128801358,
    "ttft": 1894930.1749091998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.622428849013495,
    "arrivals": 159905,
    "finished_requests": 57619,
    "scheduler_time": 150.15906510611944
}
#Debug simulation 
Total elapsed time: 5.352259982842952. Arrivals time: 0.2072651870548725 Scheduler time: 4.965513454284519 Scheduler overhead time: 0.05293876538053155 Adapter cache time: 0.04921538522467017 Engine time: 0.053060628939419985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.00840539066121,
    "estimated_duration": 3600.014402428381,
    "input_throughput": 4453.594682617096,
    "output_throughput": 3886.594728777159,
    "total_throughput": 8340.189411394256,
    "itl": 123.18013258102047,
    "ttft": 1770196.6704003022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.592757586007975,
    "arrivals": 159905,
    "finished_requests": 65014,
    "scheduler_time": 136.75266187641333
}
#Debug simulation 
Total elapsed time: 8.008513976819813. Arrivals time: 0.2462726985104382 Scheduler time: 7.621058597229421 Scheduler overhead time: 0.045489690732210875 Adapter cache time: 0.029399193823337555 Engine time: 0.045665510930120945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.149027199018747,
    "estimated_duration": 3600.0776345075133,
    "input_throughput": 3951.503396383301,
    "output_throughput": 3439.6136020255476,
    "total_throughput": 7391.116998408849,
    "itl": 99.89055157788727,
    "ttft": 1894683.4355599617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.298583453334796,
    "arrivals": 159905,
    "finished_requests": 57598,
    "scheduler_time": 150.16868949317762
}
#Debug simulation 
Total elapsed time: 5.14914657920599. Arrivals time: 0.2061004010029137 Scheduler time: 4.763609977904707 Scheduler overhead time: 0.05264885351061821 Adapter cache time: 0.04930221429094672 Engine time: 0.05310315592214465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.70452529238537,
    "estimated_duration": 3600.0040786298673,
    "input_throughput": 4639.929465401417,
    "output_throughput": 4050.587077542935,
    "total_throughput": 8690.516542944351,
    "itl": 135.32513835932613,
    "ttft": 1711557.2981608543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.533060123566681,
    "arrivals": 157567,
    "finished_requests": 67839,
    "scheduler_time": 131.03335277731358
}
#Debug simulation 
Total elapsed time: 8.70464848401025. Arrivals time: 0.24571286980062723 Scheduler time: 8.330799273215234 Scheduler overhead time: 0.04276310792192817 Adapter cache time: 0.023476101458072662 Engine time: 0.042618319392204285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.865937361028045,
    "estimated_duration": 3600.0395069221095,
    "input_throughput": 4447.705912452487,
    "output_throughput": 3886.3545728035006,
    "total_throughput": 8334.060485255986,
    "itl": 123.4567928447834,
    "ttft": 1755411.1499760863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.757503415667392,
    "arrivals": 157567,
    "finished_requests": 65035,
    "scheduler_time": 136.0295266137271
}
#Debug simulation 
Total elapsed time: 6.866065009031445. Arrivals time: 0.22574771847575903 Scheduler time: 6.499351820908487 Scheduler overhead time: 0.04545321874320507 Adapter cache time: 0.029646055307239294 Engine time: 0.04521068651229143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.935483575798571,
    "estimated_duration": 3600.024346637146,
    "input_throughput": 3934.26672606544,
    "output_throughput": 3446.6836346789414,
    "total_throughput": 7380.950360744381,
    "itl": 100.00600804045864,
    "ttft": 1878763.7478265446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.24908992810144,
    "arrivals": 157567,
    "finished_requests": 57680,
    "scheduler_time": 149.51302306884034
}
#Debug simulation 
Total elapsed time: 4.935654593165964. Arrivals time: 0.20594353135675192 Scheduler time: 4.555168047081679 Scheduler overhead time: 0.05262297485023737 Adapter cache time: 0.04475141130387783 Engine time: 0.05285249324515462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.95403293101117,
    "estimated_duration": 3600.0447651808254,
    "input_throughput": 4453.174625786842,
    "output_throughput": 3891.5438317601893,
    "total_throughput": 8344.718457547031,
    "itl": 123.75600143770463,
    "ttft": 1754320.026146698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.023436806956326,
    "arrivals": 157567,
    "finished_requests": 65139,
    "scheduler_time": 135.8728499464594
}
#Debug simulation 
Total elapsed time: 6.954140339978039. Arrivals time: 0.24263931903988123 Scheduler time: 6.571340677328408 Scheduler overhead time: 0.04503332497552037 Adapter cache time: 0.029338145162910223 Engine time: 0.0452148481272161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9259549542330205,
    "estimated_duration": 3600.005450036624,
    "input_throughput": 3926.7168331248463,
    "output_throughput": 3438.56701657884,
    "total_throughput": 7365.283849703686,
    "itl": 99.61091673732986,
    "ttft": 1881897.3079634665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.01262673251763,
    "arrivals": 157567,
    "finished_requests": 57549,
    "scheduler_time": 149.80862603311598
}
#Debug simulation 
Total elapsed time: 4.92603314621374. Arrivals time: 0.1945032891817391 Scheduler time: 4.557634775992483 Scheduler overhead time: 0.05320874135941267 Adapter cache time: 0.04300521221011877 Engine time: 0.05328229442238808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.851144861895591,
    "estimated_duration": 3600.096485025733,
    "input_throughput": 4452.757326554101,
    "output_throughput": 3893.881749644218,
    "total_throughput": 8346.63907619832,
    "itl": 123.7785860179128,
    "ttft": 1754392.1683813103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.401239957790834,
    "arrivals": 157567,
    "finished_requests": 65132,
    "scheduler_time": 135.8825047704698
}
#Debug simulation 
Total elapsed time: 6.8512566038407385. Arrivals time: 0.21848083287477493 Scheduler time: 6.493187422398478 Scheduler overhead time: 0.04516240768134594 Adapter cache time: 0.02884991141036153 Engine time: 0.04506132937967777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.934300001244992,
    "estimated_duration": 3600.017728611858,
    "input_throughput": 3931.7345266124025,
    "output_throughput": 3444.4449818810695,
    "total_throughput": 7376.179508493472,
    "itl": 99.8182734733001,
    "ttft": 1880360.2282760353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.792167856543925,
    "arrivals": 157567,
    "finished_requests": 57632,
    "scheduler_time": 149.6620604111914
}
#Debug simulation 
Total elapsed time: 4.93438212107867. Arrivals time: 0.19757425505667925 Scheduler time: 4.563027381431311 Scheduler overhead time: 0.052613664884120226 Adapter cache time: 0.04374813009053469 Engine time: 0.053018642123788595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.52413413580507,
    "estimated_duration": 3600.1029309625187,
    "input_throughput": 4487.713354262482,
    "output_throughput": 3835.1478457057888,
    "total_throughput": 8322.86119996827,
    "itl": 115.96258206309948,
    "ttft": 251879.56628143246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2868,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.96438910363217,
    "arrivals": 67679,
    "finished_requests": 64774,
    "scheduler_time": 58.560909842059665
}
#Debug simulation 
Total elapsed time: 14.524252156727016. Arrivals time: 0.18196475971490145 Scheduler time: 14.17165071098134 Scheduler overhead time: 0.04952410841360688 Adapter cache time: 0.049379775766283274 Engine time: 0.0497608189471066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.949573871679604,
    "estimated_duration": 3600.0735645180657,
    "input_throughput": 4439.716220671077,
    "output_throughput": 3795.28772263549,
    "total_throughput": 8235.003943306567,
    "itl": 113.16162837816832,
    "ttft": 303541.2588791067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.86075807993712,
    "arrivals": 67679,
    "finished_requests": 64032,
    "scheduler_time": 59.09471030052164
}
#Debug simulation 
Total elapsed time: 12.94969876576215. Arrivals time: 0.18049961933866143 Scheduler time: 12.592811265029013 Scheduler overhead time: 0.05090824328362942 Adapter cache time: 0.0519167254678905 Engine time: 0.05094307195395231 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.008847973309457,
    "estimated_duration": 3600.023348475208,
    "input_throughput": 4062.89587154902,
    "output_throughput": 3478.332162846592,
    "total_throughput": 7541.228034395612,
    "itl": 96.79723142519794,
    "ttft": 687220.6418786295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.332238316541787,
    "arrivals": 67679,
    "finished_requests": 58592,
    "scheduler_time": 66.09536292786342
}
#Debug simulation 
Total elapsed time: 8.00897654145956. Arrivals time: 0.18057619268074632 Scheduler time: 7.620649219024926 Scheduler overhead time: 0.05656050844117999 Adapter cache time: 0.06904299883171916 Engine time: 0.05673821084201336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 12.728064923081547,
    "estimated_duration": 3600.09956772304,
    "input_throughput": 4445.623988706098,
    "output_throughput": 3801.8426275517277,
    "total_throughput": 8247.466616257825,
    "itl": 113.4637415459053,
    "ttft": 296400.84784694074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.893328182460337,
    "arrivals": 67679,
    "finished_requests": 64158,
    "scheduler_time": 59.02147107210616
}
#Debug simulation 
Total elapsed time: 12.72816442605108. Arrivals time: 0.18024167465046048 Scheduler time: 12.371321046259254 Scheduler overhead time: 0.050560517236590385 Adapter cache time: 0.05288923205807805 Engine time: 0.05071544414386153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_96_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.927890913095325,
    "estimated_duration": 3600.00817466466,
    "input_throughput": 4056.3360668924734,
    "output_throughput": 3474.427388255893,
    "total_throughput": 7530.763455148366,
    "itl": 96.61919111227955,
    "ttft": 693000.1014980286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.17832744785236,
    "arrivals": 67679,
    "finished_requests": 58504,
    "scheduler_time": 66.24668734812288
}
#Debug simulation 
Total elapsed time: 7.927967299241573. Arrivals time: 0.1773423384875059 Scheduler time: 7.545462009496987 Scheduler overhead time: 0.05627893935889006 Adapter cache time: 0.06701045576483011 Engine time: 0.05643358174711466 
