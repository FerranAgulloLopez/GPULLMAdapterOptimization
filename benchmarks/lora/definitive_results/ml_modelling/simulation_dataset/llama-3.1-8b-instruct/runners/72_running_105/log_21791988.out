INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431747992 . Total output tokens: 380047635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.06922416202724,
    "estimated_duration": 3600.034270272141,
    "input_throughput": 4875.70108566581,
    "output_throughput": 4210.347141738234,
    "total_throughput": 9086.048227404044,
    "itl": 128.94011870379933,
    "ttft": 2119114.8895396423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 644954,
    "finished_requests": 71025,
    "scheduler_time": 31.163093338538516
}
#Debug simulation 
Total elapsed time: 5.069347430020571. Arrivals time: 0.29509982373565435 Scheduler time: 4.654260541778058 Scheduler overhead time: 0.040287941694259644 Adapter cache time: 0.017958072014153004 Engine time: 0.042326117400079966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431747992 . Total output tokens: 380047635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.006509623024613,
    "estimated_duration": 3600.126588775235,
    "input_throughput": 4742.3254652298865,
    "output_throughput": 4096.085133777682,
    "total_throughput": 8838.410599007568,
    "itl": 117.79373818333193,
    "ttft": 2135789.36006638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 644954,
    "finished_requests": 69096,
    "scheduler_time": 26.507246660468734
}
#Debug simulation 
Total elapsed time: 5.006621174048632. Arrivals time: 0.2380045298486948 Scheduler time: 4.634870030451566 Scheduler overhead time: 0.04365640599280596 Adapter cache time: 0.024140074849128723 Engine time: 0.04495439724996686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431747992 . Total output tokens: 380047635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.70028224773705,
    "estimated_duration": 3600.048245428432,
    "input_throughput": 4307.563661040465,
    "output_throughput": 3727.2578269025735,
    "total_throughput": 8034.821487943039,
    "itl": 92.25235012971872,
    "ttft": 2188377.6588687813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 644954,
    "finished_requests": 62812,
    "scheduler_time": 11.70778760379492
}
#Debug simulation 
Total elapsed time: 4.70043687382713. Arrivals time: 0.2603687606751919 Scheduler time: 4.262743624392897 Scheduler overhead time: 0.053185641299933195 Adapter cache time: 0.04297130927443504 Engine time: 0.05540916323661804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431747992 . Total output tokens: 380047635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.276933120097965,
    "estimated_duration": 3600.089358866955,
    "input_throughput": 4743.860859435725,
    "output_throughput": 4097.866894238166,
    "total_throughput": 8841.727753673891,
    "itl": 117.9045196064234,
    "ttft": 2135817.9337625448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 644954,
    "finished_requests": 69122,
    "scheduler_time": 26.561594250425124
}
#Debug simulation 
Total elapsed time: 5.277003922034055. Arrivals time: 0.31334397196769714 Scheduler time: 4.830265840981156 Scheduler overhead time: 0.04356142785400152 Adapter cache time: 0.02392612025141716 Engine time: 0.04502519965171814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431747992 . Total output tokens: 380047635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.667377896141261,
    "estimated_duration": 3600.041690778034,
    "input_throughput": 4307.571503886824,
    "output_throughput": 3727.264613177316,
    "total_throughput": 8034.83611706414,
    "itl": 92.25218137569458,
    "ttft": 2188373.0272822822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 644954,
    "finished_requests": 62812,
    "scheduler_time": 11.70786070304852
}
#Debug simulation 
Total elapsed time: 4.667480523232371. Arrivals time: 0.2236193474382162 Scheduler time: 4.266628485172987 Scheduler overhead time: 0.05332856113091111 Adapter cache time: 0.04334647161886096 Engine time: 0.054804814513772726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431747992 . Total output tokens: 380047635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.981848167255521,
    "estimated_duration": 3600.1121661518873,
    "input_throughput": 4741.186999805237,
    "output_throughput": 4095.3499001002983,
    "total_throughput": 8836.536899905535,
    "itl": 117.72252739142816,
    "ttft": 2136041.2922590324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 644954,
    "finished_requests": 69081,
    "scheduler_time": 26.477463760625557
}
#Debug simulation 
Total elapsed time: 4.982002688106149. Arrivals time: 0.3038000203669071 Scheduler time: 4.543940230738372 Scheduler overhead time: 0.04371055122464895 Adapter cache time: 0.024557682685554028 Engine time: 0.04498694930225611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431747992 . Total output tokens: 380047635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.687450467143208,
    "estimated_duration": 3600.0351343657144,
    "input_throughput": 4307.579348869948,
    "output_throughput": 3727.271401300964,
    "total_throughput": 8034.850750170912,
    "itl": 92.2520164956279,
    "ttft": 2188368.396213656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 644954,
    "finished_requests": 62812,
    "scheduler_time": 11.707932040380646
}
#Debug simulation 
Total elapsed time: 4.687551409937441. Arrivals time: 0.22512789722532034 Scheduler time: 4.284283401910216 Scheduler overhead time: 0.05352635262534022 Adapter cache time: 0.04330619936808944 Engine time: 0.05551154585555196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400794013 . Total output tokens: 353045135
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.239164767321199,
    "estimated_duration": 3600.1328973690324,
    "input_throughput": 4996.990809185661,
    "output_throughput": 4347.263405591918,
    "total_throughput": 9344.25421477758,
    "itl": 126.45056660057585,
    "ttft": 2096632.8379698116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 599169,
    "finished_requests": 72788,
    "scheduler_time": 32.55926893358044
}
#Debug simulation 
Total elapsed time: 5.239261410199106. Arrivals time: 0.30596624594181776 Scheduler time: 4.802914361003786 Scheduler overhead time: 0.041634129360318184 Adapter cache time: 0.026004254817962646 Engine time: 0.04286696668714285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400794013 . Total output tokens: 353045135
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.127524111885577,
    "estimated_duration": 3600.0047944492735,
    "input_throughput": 4856.742420720786,
    "output_throughput": 4226.034094026086,
    "total_throughput": 9082.77651474687,
    "itl": 114.27587178518256,
    "ttft": 2113549.2057936727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 599169,
    "finished_requests": 70711,
    "scheduler_time": 27.391684861650564
}
#Debug simulation 
Total elapsed time: 5.127674235031009. Arrivals time: 0.30690471455454826 Scheduler time: 4.676231861580163 Scheduler overhead time: 0.04505440080538392 Adapter cache time: 0.03136315802112222 Engine time: 0.0463998899795115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400794013 . Total output tokens: 353045135
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.161240132059902,
    "estimated_duration": 3600.0345105558113,
    "input_throughput": 4441.870752380971,
    "output_throughput": 3871.432054091119,
    "total_throughput": 8313.30280647209,
    "itl": 89.01395032377813,
    "ttft": 2164285.796659623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 599169,
    "finished_requests": 64660,
    "scheduler_time": 12.257828373460262
}
#Debug simulation 
Total elapsed time: 5.161308504175395. Arrivals time: 0.5423225667327642 Scheduler time: 4.43373067304492 Scheduler overhead time: 0.055418591015040874 Adapter cache time: 0.04590406455099583 Engine time: 0.057301961816847324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400794013 . Total output tokens: 353045135
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.134050570894033,
    "estimated_duration": 3600.091178956317,
    "input_throughput": 4856.720880349724,
    "output_throughput": 4226.241848799746,
    "total_throughput": 9082.962729149469,
    "itl": 114.27420492080435,
    "ttft": 2113612.1923225233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 599169,
    "finished_requests": 70717,
    "scheduler_time": 27.393107015156314
}
#Debug simulation 
Total elapsed time: 5.134146729949862. Arrivals time: 0.2446927851997316 Scheduler time: 4.745685589499772 Scheduler overhead time: 0.044963602907955647 Adapter cache time: 0.030644513200968504 Engine time: 0.04648430924862623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400794013 . Total output tokens: 353045135
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.814880118705332,
    "estimated_duration": 3600.027960535579,
    "input_throughput": 4441.878834080228,
    "output_throughput": 3871.4390979137115,
    "total_throughput": 8313.317931993939,
    "itl": 89.01380364795087,
    "ttft": 2164281.135105339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 599169,
    "finished_requests": 64660,
    "scheduler_time": 12.257906102879588
}
#Debug simulation 
Total elapsed time: 4.815023258794099. Arrivals time: 0.2891086428426206 Scheduler time: 4.341136089060456 Scheduler overhead time: 0.05510114412754774 Adapter cache time: 0.045864601619541645 Engine time: 0.05709583219140768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400794013 . Total output tokens: 353045135
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.161600525025278,
    "estimated_duration": 3600.047173337635,
    "input_throughput": 4856.780247073774,
    "output_throughput": 4226.293508785935,
    "total_throughput": 9083.073755859708,
    "itl": 114.27320967347507,
    "ttft": 2113580.132210345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 599169,
    "finished_requests": 70717,
    "scheduler_time": 27.393524467620246
}
#Debug simulation 
Total elapsed time: 5.161696972325444. Arrivals time: 0.30230180034413934 Scheduler time: 4.714826020412147 Scheduler overhead time: 0.045158626511693 Adapter cache time: 0.030916355550289154 Engine time: 0.04675115551799536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400794013 . Total output tokens: 353045135
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.116566583048552,
    "estimated_duration": 3600.0214124821428,
    "input_throughput": 4441.886913382163,
    "output_throughput": 3871.4461396468523,
    "total_throughput": 8313.333053029015,
    "itl": 89.0136469681496,
    "ttft": 2164276.475273355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 599169,
    "finished_requests": 64660,
    "scheduler_time": 12.257985799094971
}
#Debug simulation 
Total elapsed time: 5.116634861100465. Arrivals time: 0.5325145525857806 Scheduler time: 4.398811301216483 Scheduler overhead time: 0.055062221363186836 Adapter cache time: 0.0463209873996675 Engine time: 0.057344671338796616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377699300 . Total output tokens: 332726037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.566037226002663,
    "estimated_duration": 3600.0165638799376,
    "input_throughput": 5425.148649580312,
    "output_throughput": 4690.054531805509,
    "total_throughput": 10115.203181385821,
    "itl": 117.02034443746297,
    "ttft": 2048521.5759512158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 564644,
    "finished_requests": 78617,
    "scheduler_time": 35.099772270165566
}
#Debug simulation 
Total elapsed time: 5.566214246209711. Arrivals time: 0.31225213408470154 Scheduler time: 5.119724155869335 Scheduler overhead time: 0.044308497570455074 Adapter cache time: 0.022754143923521042 Engine time: 0.045787527691572905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377699300 . Total output tokens: 332726037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.469099614303559,
    "estimated_duration": 3600.072993449926,
    "input_throughput": 5251.296302712856,
    "output_throughput": 4549.854136236094,
    "total_throughput": 9801.15043894895,
    "itl": 106.0790532687897,
    "ttft": 2064739.5428141044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 564644,
    "finished_requests": 76148,
    "scheduler_time": 29.50204256894242
}
#Debug simulation 
Total elapsed time: 5.4691955940797925. Arrivals time: 0.30873547634109855 Scheduler time: 5.013967298902571 Scheduler overhead time: 0.04818458668887615 Adapter cache time: 0.025147777050733566 Engine time: 0.04994836775586009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377699300 . Total output tokens: 332726037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.066918764729053,
    "estimated_duration": 3600.0067821054045,
    "input_throughput": 4767.806295620876,
    "output_throughput": 4132.848047385812,
    "total_throughput": 8900.654343006689,
    "itl": 83.57696541847392,
    "ttft": 2122655.598531235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 564644,
    "finished_requests": 69229,
    "scheduler_time": 13.289391869779761
}
#Debug simulation 
Total elapsed time: 5.067018995992839. Arrivals time: 0.29374551493674517 Scheduler time: 4.59516161493957 Scheduler overhead time: 0.05816245637834072 Adapter cache time: 0.03128845151513815 Engine time: 0.06043521873652935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377699300 . Total output tokens: 332726037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.4474108084104955,
    "estimated_duration": 3600.0289846906626,
    "input_throughput": 5251.360497483451,
    "output_throughput": 4549.909756186993,
    "total_throughput": 9801.270253670444,
    "itl": 106.07802189934728,
    "ttft": 2064707.017006534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 564644,
    "finished_requests": 76148,
    "scheduler_time": 29.502456880825328
}
#Debug simulation 
Total elapsed time: 5.447578588034958. Arrivals time: 0.25188354030251503 Scheduler time: 5.049435607623309 Scheduler overhead time: 0.048144124913960695 Adapter cache time: 0.025068112649023533 Engine time: 0.04975014878436923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377699300 . Total output tokens: 332726037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.0449529038742185,
    "estimated_duration": 3600.0002271681824,
    "input_throughput": 4767.814976917816,
    "output_throughput": 4132.855572540753,
    "total_throughput": 8900.67054945857,
    "itl": 83.57683224097053,
    "ttft": 2122650.8714577826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 564644,
    "finished_requests": 69229,
    "scheduler_time": 13.289464682208934
}
#Debug simulation 
Total elapsed time: 5.045047956053168. Arrivals time: 0.293251967523247 Scheduler time: 4.574539409019053 Scheduler overhead time: 0.057917483150959015 Adapter cache time: 0.03102302737534046 Engine time: 0.06032611057162285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377699300 . Total output tokens: 332726037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.440319704823196,
    "estimated_duration": 3600.0995701224597,
    "input_throughput": 5251.368089065636,
    "output_throughput": 4549.833603475258,
    "total_throughput": 9801.201692540895,
    "itl": 106.07718033033076,
    "ttft": 2064699.7237450804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 564644,
    "finished_requests": 76149,
    "scheduler_time": 29.50373257247716
}
#Debug simulation 
Total elapsed time: 5.440417069941759. Arrivals time: 0.31013002479448915 Scheduler time: 4.984399909153581 Scheduler overhead time: 0.04802091885358095 Adapter cache time: 0.02500224206596613 Engine time: 0.049717579036951065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377699300 . Total output tokens: 332726037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.038627102971077,
    "estimated_duration": 3600.086186184441,
    "input_throughput": 4767.861132289185,
    "output_throughput": 4133.022164052631,
    "total_throughput": 8900.883296341815,
    "itl": 83.57700483392824,
    "ttft": 2122635.9789001276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 564644,
    "finished_requests": 69231,
    "scheduler_time": 13.289820411103786
}
#Debug simulation 
Total elapsed time: 5.038803408388048. Arrivals time: 0.29112360533326864 Scheduler time: 4.569879616145045 Scheduler overhead time: 0.05816490761935711 Adapter cache time: 0.031162237748503685 Engine time: 0.06019594939425588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373826914 . Total output tokens: 329331925
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.640457978006452,
    "estimated_duration": 3600.0550843480496,
    "input_throughput": 5546.344300900035,
    "output_throughput": 4810.782222554906,
    "total_throughput": 10357.126523454941,
    "itl": 114.39263084197322,
    "ttft": 2028219.54512467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 558915,
    "finished_requests": 80458,
    "scheduler_time": 36.067599803378116
}
#Debug simulation 
Total elapsed time: 5.640552022028714. Arrivals time: 0.26280779018998146 Scheduler time: 5.246293105185032 Scheduler overhead time: 0.045218652579933405 Adapter cache time: 0.01750842249020934 Engine time: 0.04681716114282608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373826914 . Total output tokens: 329331925
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.5209755641408265,
    "estimated_duration": 3600.0359900211283,
    "input_throughput": 5364.9288655824375,
    "output_throughput": 4656.3667825725315,
    "total_throughput": 10021.29564815497,
    "itl": 103.82162472972134,
    "ttft": 2047354.8891533266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 558915,
    "finished_requests": 77807,
    "scheduler_time": 30.23369549845694
}
#Debug simulation 
Total elapsed time: 5.5210761851631105. Arrivals time: 0.25633155927062035 Scheduler time: 5.121464257128537 Scheduler overhead time: 0.04925811477005482 Adapter cache time: 0.01935167098417878 Engine time: 0.05087984958663583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373826914 . Total output tokens: 329331925
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.384792630095035,
    "estimated_duration": 3600.0483007595394,
    "input_throughput": 4843.6502911144435,
    "output_throughput": 4209.283802332008,
    "total_throughput": 9052.934093446453,
    "itl": 82.00295163304413,
    "ttft": 2106058.7572511537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 558915,
    "finished_requests": 70166,
    "scheduler_time": 13.435424632848344
}
#Debug simulation 
Total elapsed time: 5.384907110128552. Arrivals time: 0.24196344939991832 Scheduler time: 4.968563003465533 Scheduler overhead time: 0.059142672922462225 Adapter cache time: 0.025099647231400013 Engine time: 0.06139404280111194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373826914 . Total output tokens: 329331925
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.490293598268181,
    "estimated_duration": 3600.0360195053354,
    "input_throughput": 5365.076597943015,
    "output_throughput": 4656.44979916156,
    "total_throughput": 10021.526397104575,
    "itl": 103.81976087913681,
    "ttft": 2047249.7638373342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 558915,
    "finished_requests": 77809,
    "scheduler_time": 30.234595746250264
}
#Debug simulation 
Total elapsed time: 5.490418791305274. Arrivals time: 0.25659791100770235 Scheduler time: 5.091531098354608 Scheduler overhead time: 0.04902412369847298 Adapter cache time: 0.018917410168796778 Engine time: 0.05075693316757679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373826914 . Total output tokens: 329331925
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.105567313730717,
    "estimated_duration": 3600.041616380424,
    "input_throughput": 4843.659284564603,
    "output_throughput": 4209.291617921865,
    "total_throughput": 9052.950902486467,
    "itl": 82.00283547205855,
    "ttft": 2106053.9802785553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 558915,
    "finished_requests": 70166,
    "scheduler_time": 13.435496186763892
}
#Debug simulation 
Total elapsed time: 5.105664639733732. Arrivals time: 0.23847099719569087 Scheduler time: 4.6920233350247145 Scheduler overhead time: 0.059394982643425465 Adapter cache time: 0.025211838074028492 Engine time: 0.06177350413054228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373826914 . Total output tokens: 329331925
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.802578845992684,
    "estimated_duration": 3600.1167322720153,
    "input_throughput": 5364.502441511603,
    "output_throughput": 4656.045413677849,
    "total_throughput": 10020.547855189452,
    "itl": 103.78422199137442,
    "ttft": 2047376.7928495565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 558915,
    "finished_requests": 77803,
    "scheduler_time": 30.212347404673746
}
#Debug simulation 
Total elapsed time: 5.802716463804245. Arrivals time: 0.25647857086732984 Scheduler time: 5.404161596670747 Scheduler overhead time: 0.048946636728942394 Adapter cache time: 0.018884564749896526 Engine time: 0.050483794417232275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373826914 . Total output tokens: 329331925
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.081430823076516,
    "estimated_duration": 3600.0291457383523,
    "input_throughput": 4843.97356078167,
    "output_throughput": 4209.461197818146,
    "total_throughput": 9053.434758599815,
    "itl": 82.00397896946954,
    "ttft": 2105978.350387908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 558915,
    "finished_requests": 70169,
    "scheduler_time": 13.436421324021351
}
#Debug simulation 
Total elapsed time: 5.081524370238185. Arrivals time: 0.2381721935234964 Scheduler time: 4.668699248228222 Scheduler overhead time: 0.05920407362282276 Adapter cache time: 0.02523219771683216 Engine time: 0.0614311289973557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 371857167 . Total output tokens: 327615916
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.70981317339465,
    "estimated_duration": 3600.068457761575,
    "input_throughput": 5593.508633588776,
    "output_throughput": 4885.812646722981,
    "total_throughput": 10479.321280311757,
    "itl": 112.92193562399234,
    "ttft": 2021435.6445804392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 556029,
    "finished_requests": 81498,
    "scheduler_time": 36.7115874594635
}
#Debug simulation 
Total elapsed time: 5.709909543395042. Arrivals time: 0.263850930146873 Scheduler time: 5.316544396802783 Scheduler overhead time: 0.045719766058027744 Adapter cache time: 0.014456951525062323 Engine time: 0.047251323238015175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 371857167 . Total output tokens: 327615916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.572278067003936,
    "estimated_duration": 3600.0770007277015,
    "input_throughput": 5411.502586211917,
    "output_throughput": 4723.535634533005,
    "total_throughput": 10135.038220744922,
    "itl": 102.63309081038615,
    "ttft": 2042693.3946576861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 556029,
    "finished_requests": 78802,
    "scheduler_time": 30.779488475975153
}
#Debug simulation 
Total elapsed time: 5.572461445815861. Arrivals time: 0.2520079864189029 Scheduler time: 5.179691838100553 Scheduler overhead time: 0.04976119287312031 Adapter cache time: 0.015372228808701038 Engine time: 0.051595209166407585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 371857167 . Total output tokens: 327615916
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.128053943626583,
    "estimated_duration": 3600.0818745199467,
    "input_throughput": 4869.702304294876,
    "output_throughput": 4254.734623790327,
    "total_throughput": 9124.436928085202,
    "itl": 81.41945107549637,
    "ttft": 2102916.346974816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 556029,
    "finished_requests": 70858,
    "scheduler_time": 13.733227559631459
}
#Debug simulation 
Total elapsed time: 5.128172124736011. Arrivals time: 0.23809378454461694 Scheduler time: 4.717304614372551 Scheduler overhead time: 0.05978417117148638 Adapter cache time: 0.02201335597783327 Engine time: 0.06197196617722511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 371857167 . Total output tokens: 327615916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.554411245975643,
    "estimated_duration": 3600.036588771111,
    "input_throughput": 5411.90666249607,
    "output_throughput": 4723.893377374017,
    "total_throughput": 10135.800039870088,
    "itl": 102.62913156787849,
    "ttft": 2042664.7189983763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 556029,
    "finished_requests": 78806,
    "scheduler_time": 30.77871556914105
}
#Debug simulation 
Total elapsed time: 5.554534824099392. Arrivals time: 0.2569571794010699 Scheduler time: 5.157528245821595 Scheduler overhead time: 0.04948918800801039 Adapter cache time: 0.015407348982989788 Engine time: 0.051189237739890814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 371857167 . Total output tokens: 327615916
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.128743113018572,
    "estimated_duration": 3600.0669545160617,
    "input_throughput": 4869.7966514227455,
    "output_throughput": 4254.87975460698,
    "total_throughput": 9124.676406029726,
    "itl": 81.42045415162295,
    "ttft": 2102905.030654646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 556029,
    "finished_requests": 70858,
    "scheduler_time": 13.733901790005083
}
#Debug simulation 
Total elapsed time: 5.128891272004694. Arrivals time: 0.24083679215982556 Scheduler time: 4.71510444348678 Scheduler overhead time: 0.05967017496004701 Adapter cache time: 0.02192952251061797 Engine time: 0.06228722259402275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 371857167 . Total output tokens: 327615916
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.551514768972993,
    "estimated_duration": 3600.053586770468,
    "input_throughput": 5411.738611779216,
    "output_throughput": 4723.704686644777,
    "total_throughput": 10135.443298423994,
    "itl": 102.62827636286036,
    "ttft": 2042639.0367123317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 556029,
    "finished_requests": 78804,
    "scheduler_time": 30.77978229203289
}
#Debug simulation 
Total elapsed time: 5.551629664842039. Arrivals time: 0.26159252133220434 Scheduler time: 5.149394745472819 Scheduler overhead time: 0.04982371674850583 Adapter cache time: 0.015507284551858902 Engine time: 0.05122097721323371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 371857167 . Total output tokens: 327615916
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.152673936914653,
    "estimated_duration": 3600.0576424719893,
    "input_throughput": 4869.242868001214,
    "output_throughput": 4254.454100763519,
    "total_throughput": 9123.696968764732,
    "itl": 81.42190337345826,
    "ttft": 2103053.7861971827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 556029,
    "finished_requests": 70851,
    "scheduler_time": 13.734595469373298
}
#Debug simulation 
Total elapsed time: 5.152775237802416. Arrivals time: 0.24095363076776266 Scheduler time: 4.738987473305315 Scheduler overhead time: 0.0596955050714314 Adapter cache time: 0.021853674668818712 Engine time: 0.06228482164442539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 370889297 . Total output tokens: 326771370
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.814388013910502,
    "estimated_duration": 3600.0347595264716,
    "input_throughput": 5665.56918541609,
    "output_throughput": 4931.8904360621755,
    "total_throughput": 10597.459621478265,
    "itl": 111.58258116871552,
    "ttft": 2009557.1098762427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 554568,
    "finished_requests": 82465,
    "scheduler_time": 37.023333179129615
}
#Debug simulation 
Total elapsed time: 5.814537629950792. Arrivals time: 0.26550586707890034 Scheduler time: 5.421381005551666 Scheduler overhead time: 0.04602118069306016 Adapter cache time: 0.011849036440253258 Engine time: 0.04751796368509531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 370889297 . Total output tokens: 326771370
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.976651278324425,
    "estimated_duration": 3600.085284590305,
    "input_throughput": 5472.618408328097,
    "output_throughput": 4763.944641370284,
    "total_throughput": 10236.563049698381,
    "itl": 101.60676844174273,
    "ttft": 2031004.2197007407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 554568,
    "finished_requests": 79669,
    "scheduler_time": 31.0339126283849
}
#Debug simulation 
Total elapsed time: 5.9767427570186555. Arrivals time: 0.32403277745470405 Scheduler time: 5.5121972118504345 Scheduler overhead time: 0.0499898437410593 Adapter cache time: 0.01479232357814908 Engine time: 0.05163770355284214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 370889297 . Total output tokens: 326771370
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.2388091729953885,
    "estimated_duration": 3600.0007998164106,
    "input_throughput": 4912.784464076212,
    "output_throughput": 4284.5140481042645,
    "total_throughput": 9197.298512180478,
    "itl": 80.8190119403504,
    "ttft": 2093342.8654508302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 554568,
    "finished_requests": 71563,
    "scheduler_time": 13.900022999046627
}
#Debug simulation 
Total elapsed time: 5.238908850122243. Arrivals time: 0.23976968880742788 Scheduler time: 4.8285520425997674 Scheduler overhead time: 0.06022515520453453 Adapter cache time: 0.019224961753934622 Engine time: 0.061977959237992764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 370889297 . Total output tokens: 326771370
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.690221547614783,
    "estimated_duration": 3600.111433760392,
    "input_throughput": 5472.517271339346,
    "output_throughput": 4763.801431025772,
    "total_throughput": 10236.318702365117,
    "itl": 101.60463723251989,
    "ttft": 2030976.0009392716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407826,
    "arrivals": 554568,
    "finished_requests": 79668,
    "scheduler_time": 31.034925161772666
}
#Debug simulation 
Total elapsed time: 5.690360391046852. Arrivals time: 0.31520679127424955 Scheduler time: 5.236087447032332 Scheduler overhead time: 0.04997084615752101 Adapter cache time: 0.012899573426693678 Engine time: 0.05191400507465005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 370889297 . Total output tokens: 326771370
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.484562081750482,
    "estimated_duration": 3600.079737732803,
    "input_throughput": 4912.909793253228,
    "output_throughput": 4284.894258957358,
    "total_throughput": 9197.804052210586,
    "itl": 80.81745527186179,
    "ttft": 2093235.8689587463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 554568,
    "finished_requests": 71568,
    "scheduler_time": 13.899434773942438
}
#Debug simulation 
Total elapsed time: 5.4846297088079154. Arrivals time: 0.5374469179660082 Scheduler time: 4.778056319337338 Scheduler overhead time: 0.05954540241509676 Adapter cache time: 0.018842181656509638 Engine time: 0.06178199592977762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 370889297 . Total output tokens: 326771370
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.6792314779013395,
    "estimated_duration": 3600.0276632603545,
    "input_throughput": 5472.644613557563,
    "output_throughput": 4763.9122818484,
    "total_throughput": 10236.556895405964,
    "itl": 101.60355504118988,
    "ttft": 2030952.789298606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 554568,
    "finished_requests": 79668,
    "scheduler_time": 31.034325336337577
}
#Debug simulation 
Total elapsed time: 5.679333261679858. Arrivals time: 0.3140931981615722 Scheduler time: 5.225700845941901 Scheduler overhead time: 0.05024817679077387 Adapter cache time: 0.013122758828103542 Engine time: 0.051978655625134706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 370889297 . Total output tokens: 326771370
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.174027540255338,
    "estimated_duration": 3600.05901732712,
    "input_throughput": 4912.774183666372,
    "output_throughput": 4284.561982389978,
    "total_throughput": 9197.33616605635,
    "itl": 80.81890677568826,
    "ttft": 2093353.878472471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 554568,
    "finished_requests": 71565,
    "scheduler_time": 13.901723957386737
}
#Debug simulation 
Total elapsed time: 5.174184734001756. Arrivals time: 0.23779703304171562 Scheduler time: 4.767031966242939 Scheduler overhead time: 0.059583776630461216 Adapter cache time: 0.018886991310864687 Engine time: 0.062091284431517124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370385274 . Total output tokens: 326338748
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.849008934106678,
    "estimated_duration": 3600.0805792887722,
    "input_throughput": 5671.426666798018,
    "output_throughput": 4945.7754091486395,
    "total_throughput": 10617.202075946658,
    "itl": 111.34852131696937,
    "ttft": 2010026.7432514743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 553859,
    "finished_requests": 82498,
    "scheduler_time": 37.12318419560009
}
#Debug simulation 
Total elapsed time: 5.849106474779546. Arrivals time: 0.3513754610903561 Scheduler time: 5.371034630108625 Scheduler overhead time: 0.04618863807991147 Adapter cache time: 0.010530661791563034 Engine time: 0.04770755534991622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370385274 . Total output tokens: 326338748
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.680299344006926,
    "estimated_duration": 3600.0798865725455,
    "input_throughput": 5469.435573760626,
    "output_throughput": 4776.3856752553465,
    "total_throughput": 10245.821249015973,
    "itl": 101.32499290698475,
    "ttft": 2031044.3731129523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 553859,
    "finished_requests": 79580,
    "scheduler_time": 31.025117870495876
}
#Debug simulation 
Total elapsed time: 5.6803965610452. Arrivals time: 0.25726085528731346 Scheduler time: 5.284593749791384 Scheduler overhead time: 0.05019193375483155 Adapter cache time: 0.011898552067577839 Engine time: 0.05205383896827698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370385274 . Total output tokens: 326338748
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.2420975510030985,
    "estimated_duration": 3600.051286744159,
    "input_throughput": 4906.308992051656,
    "output_throughput": 4288.7033462135305,
    "total_throughput": 9195.012338265185,
    "itl": 80.60374487430857,
    "ttft": 2093781.062528636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 553859,
    "finished_requests": 71340,
    "scheduler_time": 13.720385943445038
}
#Debug simulation 
Total elapsed time: 5.242254075128585. Arrivals time: 0.27050946932286024 Scheduler time: 4.801835871301591 Scheduler overhead time: 0.06005766661837697 Adapter cache time: 0.01823079213500023 Engine time: 0.062419208232313395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370385274 . Total output tokens: 326338748
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.7014416214078665,
    "estimated_duration": 3600.020504851416,
    "input_throughput": 5471.704112088942,
    "output_throughput": 4778.2141731745405,
    "total_throughput": 10249.918285263482,
    "itl": 101.3974698924347,
    "ttft": 2031318.3136265373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407822,
    "arrivals": 553859,
    "finished_requests": 79613,
    "scheduler_time": 31.078322128567095
}
#Debug simulation 
Total elapsed time: 5.701537899207324. Arrivals time: 0.3165567498654127 Scheduler time: 5.246282402891666 Scheduler overhead time: 0.050200704485177994 Adapter cache time: 0.011932871770113707 Engine time: 0.05223375279456377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370385274 . Total output tokens: 326338748
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.243172246962786,
    "estimated_duration": 3600.0623345569525,
    "input_throughput": 4892.613616971624,
    "output_throughput": 4275.870962632766,
    "total_throughput": 9168.48457960439,
    "itl": 80.18950906647594,
    "ttft": 2095126.8473812065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 553859,
    "finished_requests": 71151,
    "scheduler_time": 13.298175622196867
}
#Debug simulation 
Total elapsed time: 5.243267585989088. Arrivals time: 0.27012602146714926 Scheduler time: 4.801069424953312 Scheduler overhead time: 0.060495509300380945 Adapter cache time: 0.01850721426308155 Engine time: 0.06378531875088811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370385274 . Total output tokens: 326338748
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.69721591565758,
    "estimated_duration": 3600.088391229103,
    "input_throughput": 5470.905394429967,
    "output_throughput": 4777.597695074326,
    "total_throughput": 10248.503089504293,
    "itl": 101.36167371813673,
    "ttft": 2031217.353149603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 553859,
    "finished_requests": 79603,
    "scheduler_time": 31.054865480390724
}
#Debug simulation 
Total elapsed time: 5.697363759856671. Arrivals time: 0.25902331434190273 Scheduler time: 5.2994636432267725 Scheduler overhead time: 0.050290701910853386 Adapter cache time: 0.011978245805948973 Engine time: 0.05221431748941541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370385274 . Total output tokens: 326338748
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.233036925084889,
    "estimated_duration": 3600.0625992443124,
    "input_throughput": 4909.432131460713,
    "output_throughput": 4291.35232349652,
    "total_throughput": 9200.784454957233,
    "itl": 80.65837243575098,
    "ttft": 2094255.3824296305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 553859,
    "finished_requests": 71384,
    "scheduler_time": 13.793617913129117
}
#Debug simulation 
Total elapsed time: 5.233134178910404. Arrivals time: 0.32724361354485154 Scheduler time: 4.736071400810033 Scheduler overhead time: 0.06010812195017934 Adapter cache time: 0.018252867739647627 Engine time: 0.062350066378712654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370154558 . Total output tokens: 326122796
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.874894004780799,
    "estimated_duration": 3600.069396071571,
    "input_throughput": 5694.418563811608,
    "output_throughput": 4966.3567650973555,
    "total_throughput": 10660.775328908963,
    "itl": 110.74786546703092,
    "ttft": 2010221.2926585774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 90,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5951168128754938,
    "arrivals": 553508,
    "finished_requests": 83115,
    "scheduler_time": 37.31782882956216
}
#Debug simulation 
Total elapsed time: 5.874992800876498. Arrivals time: 0.3219569087959826 Scheduler time: 5.42610722174868 Scheduler overhead time: 0.046919746324419975 Adapter cache time: 0.009375849273055792 Engine time: 0.04820369277149439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370154558 . Total output tokens: 326122796
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.718714879825711,
    "estimated_duration": 3600.0825072547764,
    "input_throughput": 5492.52328527276,
    "output_throughput": 4793.627914144551,
    "total_throughput": 10286.15119941731,
    "itl": 100.8907486525267,
    "ttft": 2032017.103160201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 90,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6564579220768068,
    "arrivals": 553508,
    "finished_requests": 80142,
    "scheduler_time": 31.239000254510792
}
#Debug simulation 
Total elapsed time: 5.718861803878099. Arrivals time: 0.3135604951530695 Scheduler time: 5.267670273780823 Scheduler overhead time: 0.050471159629523754 Adapter cache time: 0.010657365899533033 Engine time: 0.052146465983241796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370154558 . Total output tokens: 326122796
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.224630068056285,
    "estimated_duration": 3600.0626411555413,
    "input_throughput": 4918.731634712945,
    "output_throughput": 4302.334582441731,
    "total_throughput": 9221.066217154676,
    "itl": 80.34035770951286,
    "ttft": 2095338.4630201976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 88,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6594302650447936,
    "arrivals": 553508,
    "finished_requests": 71833,
    "scheduler_time": 13.941744450336829
}
#Debug simulation 
Total elapsed time: 5.224723367020488. Arrivals time: 0.29398708092048764 Scheduler time: 4.761856827419251 Scheduler overhead time: 0.06012862268835306 Adapter cache time: 0.017023120541125536 Engine time: 0.0626473119482398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370154558 . Total output tokens: 326122796
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.74021582910791,
    "estimated_duration": 3600.043908936105,
    "input_throughput": 5492.582174044519,
    "output_throughput": 4793.679309622636,
    "total_throughput": 10286.261483667155,
    "itl": 100.89002669792107,
    "ttft": 2031992.9683854762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 90,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6175877348240465,
    "arrivals": 553508,
    "finished_requests": 80142,
    "scheduler_time": 31.239272123091297
}
#Debug simulation 
Total elapsed time: 5.740313732996583. Arrivals time: 0.3186682346276939 Scheduler time: 5.283903521951288 Scheduler overhead time: 0.05054913414642215 Adapter cache time: 0.010750732850283384 Engine time: 0.052008486818522215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370154558 . Total output tokens: 326122796
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.29342493833974,
    "estimated_duration": 3600.057096686577,
    "input_throughput": 4918.739210080269,
    "output_throughput": 4302.341208492353,
    "total_throughput": 9221.080418572621,
    "itl": 80.34025608388366,
    "ttft": 2095335.0329688496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 88,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6538381012761967,
    "arrivals": 553508,
    "finished_requests": 71833,
    "scheduler_time": 13.941792145141306
}
#Debug simulation 
Total elapsed time: 5.293595619034022. Arrivals time: 0.24189148843288422 Scheduler time: 4.881843140814453 Scheduler overhead time: 0.06055798940360546 Adapter cache time: 0.017165182158350945 Engine time: 0.06262395298108459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370154558 . Total output tokens: 326122796
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.679566448088735,
    "estimated_duration": 3600.001173202834,
    "input_throughput": 5492.647376669593,
    "output_throughput": 4793.736215548635,
    "total_throughput": 10286.383592218228,
    "itl": 100.88928985474561,
    "ttft": 2031965.0756241195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 90,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5745528846513482,
    "arrivals": 553508,
    "finished_requests": 80142,
    "scheduler_time": 31.239571239992227
}
#Debug simulation 
Total elapsed time: 5.6796648828312755. Arrivals time: 0.25708533450961113 Scheduler time: 5.28600843809545 Scheduler overhead time: 0.05009748786687851 Adapter cache time: 0.010619113221764565 Engine time: 0.05164783354848623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370154558 . Total output tokens: 326122796
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.226580439135432,
    "estimated_duration": 3600.0507316570665,
    "input_throughput": 4918.747906602223,
    "output_throughput": 4302.348815198702,
    "total_throughput": 9221.096721800926,
    "itl": 80.34015329339323,
    "ttft": 2095331.0599818532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 88,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6474174688011408,
    "arrivals": 553508,
    "finished_requests": 71833,
    "scheduler_time": 13.941847748104944
}
#Debug simulation 
Total elapsed time: 5.226679648272693. Arrivals time: 0.24033020297065377 Scheduler time: 4.817831690888852 Scheduler overhead time: 0.06011079903692007 Adapter cache time: 0.01700426684692502 Engine time: 0.06224619131535292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339077557 . Total output tokens: 298769094
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.189914975780994,
    "estimated_duration": 3600.059922824429,
    "input_throughput": 4989.564725330274,
    "output_throughput": 4320.674748046016,
    "total_throughput": 9310.23947337629,
    "itl": 126.7046047059876,
    "ttft": 2069784.0086444488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 507133,
    "finished_requests": 72581,
    "scheduler_time": 32.385043238580835
}
#Debug simulation 
Total elapsed time: 5.190070359967649. Arrivals time: 0.24437198881059885 Scheduler time: 4.813329630065709 Scheduler overhead time: 0.04128151712939143 Adapter cache time: 0.02871327241882682 Engine time: 0.04248869186267257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339077557 . Total output tokens: 298769094
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.107053151819855,
    "estimated_duration": 3600.0178095672863,
    "input_throughput": 4860.390955150068,
    "output_throughput": 4208.477791342111,
    "total_throughput": 9068.86874649218,
    "itl": 114.76477432050626,
    "ttft": 2086734.2398111355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 507133,
    "finished_requests": 70683,
    "scheduler_time": 27.44642199420233
}
#Debug simulation 
Total elapsed time: 5.107146705966443. Arrivals time: 0.23831736855208874 Scheduler time: 4.7210243893787265 Scheduler overhead time: 0.044779653660953045 Adapter cache time: 0.035396762657910585 Engine time: 0.04594767326489091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339077557 . Total output tokens: 298769094
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.139564659912139,
    "estimated_duration": 3600.0211271086187,
    "input_throughput": 4465.622681751264,
    "output_throughput": 3875.4528119131933,
    "total_throughput": 8341.075493664459,
    "itl": 88.40538797854965,
    "ttft": 2135518.3054508315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 507133,
    "finished_requests": 64954,
    "scheduler_time": 12.182198339542174
}
#Debug simulation 
Total elapsed time: 5.139630943071097. Arrivals time: 0.5171023369766772 Scheduler time: 4.426681467331946 Scheduler overhead time: 0.05592628242447972 Adapter cache time: 0.05510743707418442 Engine time: 0.05802635569125414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339077557 . Total output tokens: 298769094
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.1211677747778594,
    "estimated_duration": 3600.0359200854004,
    "input_throughput": 4865.527841617892,
    "output_throughput": 4212.797132213122,
    "total_throughput": 9078.324973831013,
    "itl": 114.64641797156533,
    "ttft": 2086380.5916856367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 507133,
    "finished_requests": 70765,
    "scheduler_time": 27.481791939552952
}
#Debug simulation 
Total elapsed time: 5.121333745773882. Arrivals time: 0.2883027894422412 Scheduler time: 4.683216128963977 Scheduler overhead time: 0.04520385339856148 Adapter cache time: 0.03609482478350401 Engine time: 0.046760221011936665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339077557 . Total output tokens: 298769094
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.870068966411054,
    "estimated_duration": 3600.01459328214,
    "input_throughput": 4465.6307866083325,
    "output_throughput": 3875.459845644736,
    "total_throughput": 8341.090632253068,
    "itl": 88.40517778295613,
    "ttft": 2135513.6400453257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 507133,
    "finished_requests": 64954,
    "scheduler_time": 12.182281272776075
}
#Debug simulation 
Total elapsed time: 4.87016852106899. Arrivals time: 0.27917081117630005 Scheduler time: 4.395345761906356 Scheduler overhead time: 0.055777647998183966 Adapter cache time: 0.055177319794893265 Engine time: 0.057693037670105696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339077557 . Total output tokens: 298769094
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.1180668962188065,
    "estimated_duration": 3600.037207025349,
    "input_throughput": 4866.307483103922,
    "output_throughput": 4213.746449730286,
    "total_throughput": 9080.05393283421,
    "itl": 114.75866858612008,
    "ttft": 2086125.8411131266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 507133,
    "finished_requests": 70782,
    "scheduler_time": 27.530962500801596
}
#Debug simulation 
Total elapsed time: 5.11816555634141. Arrivals time: 0.29053676733747125 Scheduler time: 4.6787631483748555 Scheduler overhead time: 0.044998353347182274 Adapter cache time: 0.03616812080144882 Engine time: 0.04609164921566844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339077557 . Total output tokens: 298769094
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.8781406339257956,
    "estimated_duration": 3600.0080447370046,
    "input_throughput": 4465.638909752614,
    "output_throughput": 3875.4668952466827,
    "total_throughput": 8341.105804999297,
    "itl": 88.40501273870817,
    "ttft": 2135508.9750365214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 507133,
    "finished_requests": 64954,
    "scheduler_time": 12.182360477292441
}
#Debug simulation 
Total elapsed time: 4.878308072686195. Arrivals time: 0.278930792119354 Scheduler time: 4.402957883197814 Scheduler overhead time: 0.05584807274863124 Adapter cache time: 0.05548692587763071 Engine time: 0.05799066321924329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 315854953 . Total output tokens: 278377465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.5869406927376986,
    "estimated_duration": 3600.101615906117,
    "input_throughput": 5373.644708951042,
    "output_throughput": 4671.312866752858,
    "total_throughput": 10044.9575757039,
    "itl": 117.70110202771052,
    "ttft": 2013071.655243563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 472666,
    "finished_requests": 78147,
    "scheduler_time": 35.212476097805144
}
#Debug simulation 
Total elapsed time: 5.587037848774344. Arrivals time: 0.31973880901932716 Scheduler time: 5.128470299299806 Scheduler overhead time: 0.04425922501832247 Adapter cache time: 0.027835626620799303 Engine time: 0.04550747433677316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 315854953 . Total output tokens: 278377465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.46999626327306,
    "estimated_duration": 3600.050017827974,
    "input_throughput": 5228.799851885694,
    "output_throughput": 4543.230210414691,
    "total_throughput": 9772.030062300386,
    "itl": 106.02460458904697,
    "ttft": 2032852.647537167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 472666,
    "finished_requests": 75975,
    "scheduler_time": 29.5784108818548
}
#Debug simulation 
Total elapsed time: 5.470096301287413. Arrivals time: 0.247280593495816 Scheduler time: 5.068969249725342 Scheduler overhead time: 0.04840978654101491 Adapter cache time: 0.03209686046466231 Engine time: 0.04990503378212452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 315854953 . Total output tokens: 278377465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.076874954160303,
    "estimated_duration": 3600.0613413958076,
    "input_throughput": 4789.048398079631,
    "output_throughput": 4163.784885450912,
    "total_throughput": 8952.833283530543,
    "itl": 82.77370210388611,
    "ttft": 2088818.819147149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 472666,
    "finished_requests": 69554,
    "scheduler_time": 13.48097895703972
}
#Debug simulation 
Total elapsed time: 5.077022417914122. Arrivals time: 0.2365491329692304 Scheduler time: 4.649194173980504 Scheduler overhead time: 0.05870569311082363 Adapter cache time: 0.04274023184552789 Engine time: 0.061351194977760315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 315854953 . Total output tokens: 278377465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.476018264889717,
    "estimated_duration": 3600.005286706497,
    "input_throughput": 5229.584820199988,
    "output_throughput": 4543.998327004034,
    "total_throughput": 9773.58314720402,
    "itl": 106.11371701413984,
    "ttft": 2032964.8542168282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407826,
    "arrivals": 472666,
    "finished_requests": 75987,
    "scheduler_time": 29.628128799548662
}
#Debug simulation 
Total elapsed time: 5.47612004680559. Arrivals time: 0.2959536942653358 Scheduler time: 5.026651214808226 Scheduler overhead time: 0.048335473984479904 Adapter cache time: 0.03204273758456111 Engine time: 0.049789085518568754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 315854953 . Total output tokens: 278377465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.097293315920979,
    "estimated_duration": 3600.0233132496173,
    "input_throughput": 4789.345095778411,
    "output_throughput": 4163.932756998957,
    "total_throughput": 8953.277852777368,
    "itl": 82.7701540047153,
    "ttft": 2088694.9953430577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 472666,
    "finished_requests": 69557,
    "scheduler_time": 13.479651977883035
}
#Debug simulation 
Total elapsed time: 5.097389962058514. Arrivals time: 0.23562721023336053 Scheduler time: 4.670159487053752 Scheduler overhead time: 0.059158066753298044 Adapter cache time: 0.0425419295206666 Engine time: 0.06118201604112983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 315854953 . Total output tokens: 278377465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.447851428296417,
    "estimated_duration": 3600.0119655274,
    "input_throughput": 5231.665666766977,
    "output_throughput": 4546.001834636246,
    "total_throughput": 9777.667501403223,
    "itl": 106.32466665824701,
    "ttft": 2032412.245838533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 472666,
    "finished_requests": 76022,
    "scheduler_time": 29.74249391548295
}
#Debug simulation 
Total elapsed time: 5.4479977251030505. Arrivals time: 0.2932540765032172 Scheduler time: 5.00176858715713 Scheduler overhead time: 0.04814738314598799 Adapter cache time: 0.031807240564376116 Engine time: 0.04976898618042469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 315854953 . Total output tokens: 278377465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.135372999124229,
    "estimated_duration": 3600.0167591318927,
    "input_throughput": 4789.353815163258,
    "output_throughput": 4163.940337770746,
    "total_throughput": 8953.294152934004,
    "itl": 82.77003774730886,
    "ttft": 2088690.281784567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 472666,
    "finished_requests": 69557,
    "scheduler_time": 13.47972560981057
}
#Debug simulation 
Total elapsed time: 5.135469635017216. Arrivals time: 0.2591715585440397 Scheduler time: 4.68406688561663 Scheduler overhead time: 0.059006161987781525 Adapter cache time: 0.043098065070807934 Engine time: 0.06143272342160344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 311955384 . Total output tokens: 274989602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.665897958911955,
    "estimated_duration": 3600.004126938591,
    "input_throughput": 5522.7472799892,
    "output_throughput": 4809.766430663695,
    "total_throughput": 10332.513710652896,
    "itl": 114.55083791226389,
    "ttft": 1982039.3013815286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 466828,
    "finished_requests": 80650,
    "scheduler_time": 36.33176914751281
}
#Debug simulation 
Total elapsed time: 5.665996560826898. Arrivals time: 0.30056257173419 Scheduler time: 5.229246175847948 Scheduler overhead time: 0.04523453349247575 Adapter cache time: 0.022572360932826996 Engine time: 0.04672194179147482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 311955384 . Total output tokens: 274989602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.534227014053613,
    "estimated_duration": 3600.085535155627,
    "input_throughput": 5363.85922262962,
    "output_throughput": 4671.235123660202,
    "total_throughput": 10035.094346289821,
    "itl": 103.74758020374976,
    "ttft": 2003016.0447678186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867946,
    "arrivals": 466828,
    "finished_requests": 78324,
    "scheduler_time": 30.67899201368546
}
#Debug simulation 
Total elapsed time: 5.534370750654489. Arrivals time: 0.29334234818816185 Scheduler time: 5.091763167176396 Scheduler overhead time: 0.04896411672234535 Adapter cache time: 0.02598296059295535 Engine time: 0.05055694142356515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 311955384 . Total output tokens: 274989602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.212245034985244,
    "estimated_duration": 3600.0380908808297,
    "input_throughput": 4890.291867909788,
    "output_throughput": 4263.11044843554,
    "total_throughput": 9153.402316345328,
    "itl": 81.30583795928848,
    "ttft": 2061835.4303255377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 466828,
    "finished_requests": 71436,
    "scheduler_time": 14.133448917140957
}
#Debug simulation 
Total elapsed time: 5.212349479086697. Arrivals time: 0.278605405241251 Scheduler time: 4.745598463341594 Scheduler overhead time: 0.059996070340275764 Adapter cache time: 0.0371492225676775 Engine time: 0.062117249239236116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 311955384 . Total output tokens: 274989602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.543099282775074,
    "estimated_duration": 3600.1039316187316,
    "input_throughput": 5364.04430727561,
    "output_throughput": 4671.542910828695,
    "total_throughput": 10035.587218104305,
    "itl": 103.74603078780389,
    "ttft": 2002992.351019227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407826,
    "arrivals": 466828,
    "finished_requests": 78328,
    "scheduler_time": 30.679015196318666
}
#Debug simulation 
Total elapsed time: 5.543224941007793. Arrivals time: 0.2519485563971102 Scheduler time: 5.141988191753626 Scheduler overhead time: 0.048997311387211084 Adapter cache time: 0.02538876887410879 Engine time: 0.05122102005407214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 311955384 . Total output tokens: 274989602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.4830083549022675,
    "estimated_duration": 3600.052341348275,
    "input_throughput": 4890.748614339847,
    "output_throughput": 4263.502734032924,
    "total_throughput": 9154.25134837277,
    "itl": 81.30045277238484,
    "ttft": 2061736.4367864798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 466828,
    "finished_requests": 71443,
    "scheduler_time": 14.131606602589969
}
#Debug simulation 
Total elapsed time: 5.483142982237041. Arrivals time: 0.2913162661716342 Scheduler time: 5.003199155908078 Scheduler overhead time: 0.05996972881257534 Adapter cache time: 0.037243588361889124 Engine time: 0.06225619791075587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 311955384 . Total output tokens: 274989602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.64852544432506,
    "estimated_duration": 3600.0268823005954,
    "input_throughput": 5364.063000457225,
    "output_throughput": 4671.472894461508,
    "total_throughput": 10035.535894918732,
    "itl": 103.74496282175471,
    "ttft": 2002950.2256130483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 466828,
    "finished_requests": 78326,
    "scheduler_time": 30.680093451223918
}
#Debug simulation 
Total elapsed time: 5.648646987043321. Arrivals time: 0.33822704246267676 Scheduler time: 5.16140970075503 Scheduler overhead time: 0.049178664572536945 Adapter cache time: 0.025432239286601543 Engine time: 0.05081739695742726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 311955384 . Total output tokens: 274989602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.2329530557617545,
    "estimated_duration": 3600.089815315907,
    "input_throughput": 4890.48882200042,
    "output_throughput": 4263.3000251004,
    "total_throughput": 9153.788847100821,
    "itl": 81.30180233248795,
    "ttft": 2061858.4056695162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 466828,
    "finished_requests": 71440,
    "scheduler_time": 14.13320668414801
}
#Debug simulation 
Total elapsed time: 5.233075641095638. Arrivals time: 0.28646225249394774 Scheduler time: 4.758431538008153 Scheduler overhead time: 0.059966526459902525 Adapter cache time: 0.036832837387919426 Engine time: 0.062287918757647276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310039748 . Total output tokens: 273276434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.780610071029514,
    "estimated_duration": 3600.0080389120585,
    "input_throughput": 5578.234210296039,
    "output_throughput": 4890.249079921584,
    "total_throughput": 10468.483290217624,
    "itl": 113.06962952667884,
    "ttft": 1981932.145461335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 463915,
    "finished_requests": 81647,
    "scheduler_time": 37.01712681549329
}
#Debug simulation 
Total elapsed time: 5.780780463013798. Arrivals time: 0.30390274059027433 Scheduler time: 5.342501794919372 Scheduler overhead time: 0.045866383239626884 Adapter cache time: 0.01911761937662959 Engine time: 0.04717490542680025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310039748 . Total output tokens: 273276434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.655717329587787,
    "estimated_duration": 3600.0812572001446,
    "input_throughput": 5398.299541470477,
    "output_throughput": 4738.509433886262,
    "total_throughput": 10136.80897535674,
    "itl": 102.56757789761541,
    "ttft": 2002066.4679792908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867947,
    "arrivals": 463915,
    "finished_requests": 79035,
    "scheduler_time": 31.179768444780986
}
#Debug simulation 
Total elapsed time: 5.65584035590291. Arrivals time: 0.3207950876094401 Scheduler time: 5.188058920670301 Scheduler overhead time: 0.04972893372178078 Adapter cache time: 0.021737152244895697 Engine time: 0.05140977259725332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310039748 . Total output tokens: 273276434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.5297385938465595,
    "estimated_duration": 3600.017824429892,
    "input_throughput": 4905.170991145434,
    "output_throughput": 4310.832822739604,
    "total_throughput": 9216.003813885038,
    "itl": 80.56962499600316,
    "ttft": 2062797.0560386397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 463915,
    "finished_requests": 71817,
    "scheduler_time": 14.309936233588074
}
#Debug simulation 
Total elapsed time: 5.529837280977517. Arrivals time: 0.5223475764505565 Scheduler time: 4.821760330814868 Scheduler overhead time: 0.060303505044430494 Adapter cache time: 0.03336941823363304 Engine time: 0.06286674784496427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310039748 . Total output tokens: 273276434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.658371226396412,
    "estimated_duration": 3600.025812356825,
    "input_throughput": 5398.446848156571,
    "output_throughput": 4738.950743475676,
    "total_throughput": 10137.397591632247,
    "itl": 102.56447675810122,
    "ttft": 2002015.8086594634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 463915,
    "finished_requests": 79039,
    "scheduler_time": 31.17891056767615
}
#Debug simulation 
Total elapsed time: 5.658544926438481. Arrivals time: 0.29808460595086217 Scheduler time: 5.21305178059265 Scheduler overhead time: 0.04972599633038044 Adapter cache time: 0.021899119019508362 Engine time: 0.05161679815500975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310039748 . Total output tokens: 273276434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.249330406077206,
    "estimated_duration": 3600.0058752501345,
    "input_throughput": 4905.177550237483,
    "output_throughput": 4310.915742303251,
    "total_throughput": 9216.093292540734,
    "itl": 80.56913117394002,
    "ttft": 2062908.2992719754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 463915,
    "finished_requests": 71817,
    "scheduler_time": 14.308939050896159
}
#Debug simulation 
Total elapsed time: 5.2494534607976675. Arrivals time: 0.24172941036522388 Scheduler time: 4.821931084617972 Scheduler overhead time: 0.06035792361944914 Adapter cache time: 0.0333471167832613 Engine time: 0.06286114593967795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310039748 . Total output tokens: 273276434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.645312617067248,
    "estimated_duration": 3600.093293599621,
    "input_throughput": 5398.86536678224,
    "output_throughput": 4739.231072242732,
    "total_throughput": 10138.096439024972,
    "itl": 102.56092288942173,
    "ttft": 2002075.1604173582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 463915,
    "finished_requests": 79045,
    "scheduler_time": 31.17942196294277
}
#Debug simulation 
Total elapsed time: 5.645436306949705. Arrivals time: 0.2582839257083833 Scheduler time: 5.239669769536704 Scheduler overhead time: 0.049887082539498806 Adapter cache time: 0.021863272413611412 Engine time: 0.05160396033897996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310039748 . Total output tokens: 273276434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.271649735979736,
    "estimated_duration": 3600.037555030631,
    "input_throughput": 4905.085219270651,
    "output_throughput": 4310.868084782508,
    "total_throughput": 9215.953304053159,
    "itl": 80.56826204683104,
    "ttft": 2062777.8318410155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 463915,
    "finished_requests": 71816,
    "scheduler_time": 14.309143524015841
}
#Debug simulation 
Total elapsed time: 5.27181851118803. Arrivals time: 0.2406397359445691 Scheduler time: 4.844480444211513 Scheduler overhead time: 0.06057706940919161 Adapter cache time: 0.03370910743251443 Engine time: 0.06289805984124541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309082126 . Total output tokens: 272412582
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.870258125010878,
    "estimated_duration": 3600.037965792597,
    "input_throughput": 5671.369078327176,
    "output_throughput": 4946.78727536119,
    "total_throughput": 10618.156353688366,
    "itl": 111.94159542754626,
    "ttft": 1967422.4215755952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 462529,
    "finished_requests": 82691,
    "scheduler_time": 37.51213043104096
}
#Debug simulation 
Total elapsed time: 5.870378073304892. Arrivals time: 0.3105399259366095 Scheduler time: 5.426416368223727 Scheduler overhead time: 0.04640067461878061 Adapter cache time: 0.0165261784568429 Engine time: 0.048139684833586216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309082126 . Total output tokens: 272412582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.721658174879849,
    "estimated_duration": 3600.0648080245737,
    "input_throughput": 5479.923293610146,
    "output_throughput": 4781.6816968486355,
    "total_throughput": 10261.604990458782,
    "itl": 101.42982621638254,
    "ttft": 1988798.7795949136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 462529,
    "finished_requests": 79882,
    "scheduler_time": 31.393829040943178
}
#Debug simulation 
Total elapsed time: 5.721781947184354. Arrivals time: 0.30017141066491604 Scheduler time: 5.275808461941779 Scheduler overhead time: 0.05046783620491624 Adapter cache time: 0.018781131133437157 Engine time: 0.05225300509482622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309082126 . Total output tokens: 272412582
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.254959957674146,
    "estimated_duration": 3600.009790036546,
    "input_throughput": 4960.746509475105,
    "output_throughput": 4332.704050741389,
    "total_throughput": 9293.450560216494,
    "itl": 79.97779909017669,
    "ttft": 2051025.9562029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 462529,
    "finished_requests": 72344,
    "scheduler_time": 14.303886403647946
}
#Debug simulation 
Total elapsed time: 5.25510508287698. Arrivals time: 0.28767845081165433 Scheduler time: 4.784296025522053 Scheduler overhead time: 0.06088335206732154 Adapter cache time: 0.029668171424418688 Engine time: 0.06316315941512585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309082126 . Total output tokens: 272412582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.693355277180672,
    "estimated_duration": 3600.0795267600897,
    "input_throughput": 5485.786037002759,
    "output_throughput": 4786.093715964801,
    "total_throughput": 10271.87975296756,
    "itl": 101.65585803579097,
    "ttft": 1988356.0796806316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 462529,
    "finished_requests": 79964,
    "scheduler_time": 31.559446396956854
}
#Debug simulation 
Total elapsed time: 5.693453032989055. Arrivals time: 0.25619937479496 Scheduler time: 5.2910471386276186 Scheduler overhead time: 0.05037800222635269 Adapter cache time: 0.01926171127706766 Engine time: 0.05230432888492942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309082126 . Total output tokens: 272412582
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.282097562216222,
    "estimated_duration": 3600.013881168483,
    "input_throughput": 4964.541412878946,
    "output_throughput": 4336.519390012144,
    "total_throughput": 9301.06080289109,
    "itl": 80.16666890191817,
    "ttft": 2049749.6472639109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 462529,
    "finished_requests": 72404,
    "scheduler_time": 14.49252630590924
}
#Debug simulation 
Total elapsed time: 5.282196099869907. Arrivals time: 0.28771091997623444 Scheduler time: 4.811314932536334 Scheduler overhead time: 0.06051316251978278 Adapter cache time: 0.029842615593224764 Engine time: 0.06331703392788768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309082126 . Total output tokens: 272412582
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.712685598060489,
    "estimated_duration": 3600.103632770089,
    "input_throughput": 5485.782636985895,
    "output_throughput": 4786.218053045809,
    "total_throughput": 10272.000690031704,
    "itl": 101.65206961063674,
    "ttft": 1988368.862578062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 462529,
    "finished_requests": 79965,
    "scheduler_time": 31.558648316372537
}
#Debug simulation 
Total elapsed time: 5.712830238044262. Arrivals time: 0.32240548403933644 Scheduler time: 5.2453463668935 Scheduler overhead time: 0.05007227789610624 Adapter cache time: 0.018935872707515955 Engine time: 0.05180947342887521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309082126 . Total output tokens: 272412582
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.277343490161002,
    "estimated_duration": 3600.0321634881384,
    "input_throughput": 4964.655644265854,
    "output_throughput": 4336.685421408302,
    "total_throughput": 9301.341065674156,
    "itl": 80.16932178512532,
    "ttft": 2049715.0777114176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 462529,
    "finished_requests": 72407,
    "scheduler_time": 14.494023667017723
}
#Debug simulation 
Total elapsed time: 5.277472627349198. Arrivals time: 0.2864167666994035 Scheduler time: 4.808016228955239 Scheduler overhead time: 0.06053537502884865 Adapter cache time: 0.029777368996292353 Engine time: 0.06326607707887888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308590362 . Total output tokens: 271978574
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.847568282857537,
    "estimated_duration": 3600.0935947232256,
    "input_throughput": 5718.7096552646135,
    "output_throughput": 4966.522544360297,
    "total_throughput": 10685.23219962491,
    "itl": 110.62590888922117,
    "ttft": 1960703.2464314993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 461810,
    "finished_requests": 83167,
    "scheduler_time": 37.45905212408416
}
#Debug simulation 
Total elapsed time: 5.847697165794671. Arrivals time: 0.3055011108517647 Scheduler time: 5.409833824727684 Scheduler overhead time: 0.046734509989619255 Adapter cache time: 0.014826887287199497 Engine time: 0.048319293186068535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308590362 . Total output tokens: 271978574
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.740792075172067,
    "estimated_duration": 3600.036765126862,
    "input_throughput": 5531.179623744288,
    "output_throughput": 4806.302026582293,
    "total_throughput": 10337.481650326581,
    "itl": 100.47477852785407,
    "ttft": 1982411.1949683102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 461810,
    "finished_requests": 80446,
    "scheduler_time": 31.46076959831911
}
#Debug simulation 
Total elapsed time: 5.740970332175493. Arrivals time: 0.3022136534564197 Scheduler time: 5.292988527100533 Scheduler overhead time: 0.05063061788678169 Adapter cache time: 0.018126568756997585 Engine time: 0.05250025633722544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308590362 . Total output tokens: 271978574
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.268772271927446,
    "estimated_duration": 3600.075093758167,
    "input_throughput": 4999.799040638877,
    "output_throughput": 4358.759356771931,
    "total_throughput": 9358.558397410809,
    "itl": 79.27799789014975,
    "ttft": 2045280.4101563045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 461810,
    "finished_requests": 72867,
    "scheduler_time": 14.350320661963973
}
#Debug simulation 
Total elapsed time: 5.268901716917753. Arrivals time: 0.282040124759078 Scheduler time: 4.803334864322096 Scheduler overhead time: 0.061088867485523224 Adapter cache time: 0.029454119503498077 Engine time: 0.06333767902106047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308590362 . Total output tokens: 271978574
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.033017442096025,
    "estimated_duration": 3600.0483701322137,
    "input_throughput": 5531.059017206682,
    "output_throughput": 4806.177645708843,
    "total_throughput": 10337.236662915526,
    "itl": 100.4759466730138,
    "ttft": 1982389.62712832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 461810,
    "finished_requests": 80445,
    "scheduler_time": 31.46198218635835
}
#Debug simulation 
Total elapsed time: 6.033133854158223. Arrivals time: 0.5382186081260443 Scheduler time: 5.349105631001294 Scheduler overhead time: 0.050715419463813305 Adapter cache time: 0.01795677049085498 Engine time: 0.05257096886634827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308590362 . Total output tokens: 271978574
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.323956516105682,
    "estimated_duration": 3600.054858025051,
    "input_throughput": 4999.880199012997,
    "output_throughput": 4358.787745975733,
    "total_throughput": 9358.66794498873,
    "itl": 79.27819449132646,
    "ttft": 2045233.9938927973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 461810,
    "finished_requests": 72868,
    "scheduler_time": 14.34958621618617
}
#Debug simulation 
Total elapsed time: 5.324138216674328. Arrivals time: 0.2878314508125186 Scheduler time: 4.851310503203422 Scheduler overhead time: 0.06138240871950984 Adapter cache time: 0.029641536995768547 Engine time: 0.0639831256121397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308590362 . Total output tokens: 271978574
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.738510798662901,
    "estimated_duration": 3600.072602558858,
    "input_throughput": 5531.124562834271,
    "output_throughput": 4806.25418156886,
    "total_throughput": 10337.378744403131,
    "itl": 100.47233593839756,
    "ttft": 1982334.8635791333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 461810,
    "finished_requests": 80446,
    "scheduler_time": 31.461304914550823
}
#Debug simulation 
Total elapsed time: 5.73864117776975. Arrivals time: 0.26389706786721945 Scheduler time: 5.3290006732568145 Scheduler overhead time: 0.05065789492800832 Adapter cache time: 0.018007068894803524 Engine time: 0.05256487708538771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308590362 . Total output tokens: 271978574
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.288077863864601,
    "estimated_duration": 3600.0258944283355,
    "input_throughput": 4999.817370163171,
    "output_throughput": 4358.776703324729,
    "total_throughput": 9358.5940734879,
    "itl": 79.2774267975371,
    "ttft": 2045303.295613484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 461810,
    "finished_requests": 72866,
    "scheduler_time": 14.349841776761606
}
#Debug simulation 
Total elapsed time: 5.288208932150155. Arrivals time: 0.28439154056832194 Scheduler time: 4.819726038724184 Scheduler overhead time: 0.06145751429721713 Adapter cache time: 0.029202371835708618 Engine time: 0.06366471480578184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308361283 . Total output tokens: 271776137
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.885959786828607,
    "estimated_duration": 3600.090058374778,
    "input_throughput": 5721.174933412132,
    "output_throughput": 4978.173242724555,
    "total_throughput": 10699.348176136687,
    "itl": 110.34751300898319,
    "ttft": 1964583.0381949926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6281788580352434,
    "arrivals": 461464,
    "finished_requests": 83318,
    "scheduler_time": 37.56539420616446
}
#Debug simulation 
Total elapsed time: 5.886141533963382. Arrivals time: 0.30803863145411015 Scheduler time: 5.446301969699562 Scheduler overhead time: 0.04669203283265233 Adapter cache time: 0.014020723756402731 Engine time: 0.04832873772829771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308361283 . Total output tokens: 271776137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.709424229338765,
    "estimated_duration": 3600.02125144684,
    "input_throughput": 5530.846517085906,
    "output_throughput": 4816.32934612026,
    "total_throughput": 10347.175863206166,
    "itl": 100.20686134055032,
    "ttft": 1986823.8024488667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.695318631646224,
    "arrivals": 461464,
    "finished_requests": 80525,
    "scheduler_time": 31.504200055158737
}
#Debug simulation 
Total elapsed time: 5.709551212377846. Arrivals time: 0.3031684053130448 Scheduler time: 5.261494950391352 Scheduler overhead time: 0.05060298880562186 Adapter cache time: 0.017425871454179287 Engine time: 0.052174949552863836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308361283 . Total output tokens: 271776137
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.287228646222502,
    "estimated_duration": 3600.0413521358705,
    "input_throughput": 5008.177750320335,
    "output_throughput": 4358.817709327181,
    "total_throughput": 9366.995459647515,
    "itl": 79.14867671497971,
    "ttft": 2051755.259958906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7061778988922016,
    "arrivals": 461464,
    "finished_requests": 72923,
    "scheduler_time": 14.296235935620338
}
#Debug simulation 
Total elapsed time: 5.287355178035796. Arrivals time: 0.28536155074834824 Scheduler time: 4.819337347056717 Scheduler overhead time: 0.06139930570498109 Adapter cache time: 0.027632647659629583 Engine time: 0.06373208528384566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308361283 . Total output tokens: 271776137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.7030989630147815,
    "estimated_duration": 3600.0723129636817,
    "input_throughput": 5531.082508619843,
    "output_throughput": 4816.555472388626,
    "total_throughput": 10347.637981008469,
    "itl": 100.20520376979026,
    "ttft": 1986768.1116351492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6508955605002119,
    "arrivals": 461464,
    "finished_requests": 80529,
    "scheduler_time": 31.50458832076119
}
#Debug simulation 
Total elapsed time: 5.703292780090123. Arrivals time: 0.30487542040646076 Scheduler time: 5.253908850252628 Scheduler overhead time: 0.05066876485943794 Adapter cache time: 0.01712512830272317 Engine time: 0.05212851893156767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308361283 . Total output tokens: 271776137
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.267600793857127,
    "estimated_duration": 3600.0018696847583,
    "input_throughput": 5008.275454473255,
    "output_throughput": 4358.820236216733,
    "total_throughput": 9367.095690689988,
    "itl": 79.1473081937228,
    "ttft": 2051785.9996563424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.699550149240531,
    "arrivals": 461464,
    "finished_requests": 72923,
    "scheduler_time": 14.295897682016397
}
#Debug simulation 
Total elapsed time: 5.267684320919216. Arrivals time: 0.2625691583380103 Scheduler time: 4.82250660052523 Scheduler overhead time: 0.06117754289880395 Adapter cache time: 0.02787124877795577 Engine time: 0.06385349109768867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308361283 . Total output tokens: 271776137
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.6877210810780525,
    "estimated_duration": 3600.10513118264,
    "input_throughput": 5530.941534882035,
    "output_throughput": 4816.394624093641,
    "total_throughput": 10347.336158975675,
    "itl": 100.20332754251085,
    "ttft": 1986722.9812807778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6064724893542007,
    "arrivals": 461464,
    "finished_requests": 80529,
    "scheduler_time": 31.50430167469919
}
#Debug simulation 
Total elapsed time: 5.687838435173035. Arrivals time: 0.28018449526280165 Scheduler time: 5.26293256925419 Scheduler overhead time: 0.0506312339566648 Adapter cache time: 0.01741977408528328 Engine time: 0.052149593364447355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308361283 . Total output tokens: 271776137
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.280250533018261,
    "estimated_duration": 3600.06327365286,
    "input_throughput": 5008.046145174084,
    "output_throughput": 4358.516172433533,
    "total_throughput": 9366.562317607617,
    "itl": 79.14890247438352,
    "ttft": 2051733.9987520394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6931295167654754,
    "arrivals": 461464,
    "finished_requests": 72921,
    "scheduler_time": 14.297763614690291
}
#Debug simulation 
Total elapsed time: 5.28040840709582. Arrivals time: 0.23507260531187057 Scheduler time: 4.862948759458959 Scheduler overhead time: 0.06124188378453255 Adapter cache time: 0.027540297713130713 Engine time: 0.06371558411046863 
