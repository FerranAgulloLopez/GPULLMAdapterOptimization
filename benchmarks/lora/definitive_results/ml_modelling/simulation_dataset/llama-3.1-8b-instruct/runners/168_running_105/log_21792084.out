INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.083087380975485,
    "estimated_duration": 3600.0143909775625,
    "input_throughput": 2470.915122532198,
    "output_throughput": 2144.738093089507,
    "total_throughput": 4615.653215621705,
    "itl": 34.09086224536232,
    "ttft": 60576.64095562571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.040727513506106,
    "arrivals": 36267,
    "finished_requests": 35922,
    "scheduler_time": 17.030568091773738
}
#Debug simulation 
Total elapsed time: 4.083227743860334. Arrivals time: 0.10304566752165556 Scheduler time: 3.6551739368587732 Scheduler overhead time: 0.11471300013363361 Adapter cache time: 0.05423114215955138 Engine time: 0.10540660656988621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.7991337990388274,
    "estimated_duration": 3600.0244707773586,
    "input_throughput": 2436.8753799347573,
    "output_throughput": 2096.356583479106,
    "total_throughput": 4533.231963413863,
    "itl": 33.7638283965786,
    "ttft": 55691.73893626282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.777200263859314,
    "arrivals": 35501,
    "finished_requests": 35170,
    "scheduler_time": 15.363472891360933
}
#Debug simulation 
Total elapsed time: 3.799232349731028. Arrivals time: 0.09397003659978509 Scheduler time: 3.392922982573509 Scheduler overhead time: 0.1065770024433732 Adapter cache time: 0.054889165330678225 Engine time: 0.10183561826124787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.8009519297629595,
    "estimated_duration": 3600.0267170540214,
    "input_throughput": 2437.214690223183,
    "output_throughput": 2096.3886085200825,
    "total_throughput": 4533.603298743265,
    "itl": 33.80356571715686,
    "ttft": 55014.97145244881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.71832362634932,
    "arrivals": 35501,
    "finished_requests": 35177,
    "scheduler_time": 15.396932372767862
}
#Debug simulation 
Total elapsed time: 3.801063175778836. Arrivals time: 0.09403755562379956 Scheduler time: 3.393507863394916 Scheduler overhead time: 0.10615594126284122 Adapter cache time: 0.055313009303063154 Engine time: 0.10310085071250796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.818980347365141,
    "estimated_duration": 3599.9942354679756,
    "input_throughput": 2436.7419574102914,
    "output_throughput": 2096.246134410548,
    "total_throughput": 4532.988091820839,
    "itl": 33.820381280613645,
    "ttft": 55803.54386499222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.94392337816158,
    "arrivals": 35501,
    "finished_requests": 35169,
    "scheduler_time": 15.394628375687368
}
#Debug simulation 
Total elapsed time: 3.8190650609321892. Arrivals time: 0.09474371559917927 Scheduler time: 3.4094625585712492 Scheduler overhead time: 0.10686191404238343 Adapter cache time: 0.055782674346119165 Engine time: 0.10331736179068685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8367655402980745,
    "estimated_duration": 3600.0238781779226,
    "input_throughput": 2436.389117629767,
    "output_throughput": 2097.006924248766,
    "total_throughput": 4533.396041878533,
    "itl": 33.76571820414465,
    "ttft": 54489.98617384957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.916884224523464,
    "arrivals": 35501,
    "finished_requests": 35181,
    "scheduler_time": 15.355186494362075
}
#Debug simulation 
Total elapsed time: 3.836841398384422. Arrivals time: 0.09433367429301143 Scheduler time: 3.426644559483975 Scheduler overhead time: 0.10673228930681944 Adapter cache time: 0.05556011060252786 Engine time: 0.10447526816278696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.8336539058946073,
    "estimated_duration": 3600.0121344524355,
    "input_throughput": 2436.6053980910256,
    "output_throughput": 2096.1023791514945,
    "total_throughput": 4532.70777724252,
    "itl": 33.81956199521781,
    "ttft": 56397.382630662076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.530307024683374,
    "arrivals": 35501,
    "finished_requests": 35163,
    "scheduler_time": 15.388520286041237
}
#Debug simulation 
Total elapsed time: 3.833750248886645. Arrivals time: 0.09641735022887588 Scheduler time: 3.422663982026279 Scheduler overhead time: 0.10650605009868741 Adapter cache time: 0.055489197839051485 Engine time: 0.10371870500966907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.8580681467428803,
    "estimated_duration": 3600.007300001157,
    "input_throughput": 2436.6531145637346,
    "output_throughput": 2096.598804118418,
    "total_throughput": 4533.251918682152,
    "itl": 33.73412428286198,
    "ttft": 54780.644927653775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.2889250559449,
    "arrivals": 35501,
    "finished_requests": 35178,
    "scheduler_time": 15.338333948717361
}
#Debug simulation 
Total elapsed time: 3.8581602619960904. Arrivals time: 0.09584027156233788 Scheduler time: 3.447803304065019 Scheduler overhead time: 0.10699027357622981 Adapter cache time: 0.055985232815146446 Engine time: 0.10260576754808426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.95483461022377,
    "estimated_duration": 3600.0016502534113,
    "input_throughput": 2437.028605079231,
    "output_throughput": 2096.8870943346997,
    "total_throughput": 4533.91569941393,
    "itl": 33.81519476714751,
    "ttft": 55516.226711156254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.971326916272425,
    "arrivals": 35501,
    "finished_requests": 35173,
    "scheduler_time": 15.413010985139568
}
#Debug simulation 
Total elapsed time: 3.9549615811556578. Arrivals time: 0.09745887340977788 Scheduler time: 3.543093755841255 Scheduler overhead time: 0.10748053761199117 Adapter cache time: 0.05568243470042944 Engine time: 0.10230580298230052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.4784724400378764,
    "estimated_duration": 3599.974629509421,
    "input_throughput": 2160.3910583836096,
    "output_throughput": 1912.3670882475544,
    "total_throughput": 4072.758146631164,
    "itl": 32.89203584163541,
    "ttft": 51875.647058711205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.59459397580175,
    "arrivals": 31858,
    "finished_requests": 31579,
    "scheduler_time": 11.563943159282902
}
#Debug simulation 
Total elapsed time: 3.478559914045036. Arrivals time: 0.08758285408839583 Scheduler time: 3.0678387759253383 Scheduler overhead time: 0.10828927950933576 Adapter cache time: 0.061929609160870314 Engine time: 0.10304139601066709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.4834427288733423,
    "estimated_duration": 3599.962113529784,
    "input_throughput": 2160.4782924712445,
    "output_throughput": 1912.702351539076,
    "total_throughput": 4073.1806440103205,
    "itl": 32.9525060154603,
    "ttft": 51895.6390663677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.41043008623941,
    "arrivals": 31858,
    "finished_requests": 31580,
    "scheduler_time": 11.620361475161694
}
#Debug simulation 
Total elapsed time: 3.4835588969290257. Arrivals time: 0.08815896697342396 Scheduler time: 3.0715569094754755 Scheduler overhead time: 0.10796879325062037 Adapter cache time: 0.061885425355285406 Engine time: 0.10395131260156631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.4748183973133564,
    "estimated_duration": 3599.9730214827405,
    "input_throughput": 2159.7372962527566,
    "output_throughput": 1912.0662735313783,
    "total_throughput": 4071.8035697841347,
    "itl": 32.968592303567874,
    "ttft": 52817.625076433345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.74560956067567,
    "arrivals": 31858,
    "finished_requests": 31572,
    "scheduler_time": 11.61306047627303
}
#Debug simulation 
Total elapsed time: 3.4749202053062618. Arrivals time: 0.08840313320979476 Scheduler time: 3.0638869563117623 Scheduler overhead time: 0.1075877002440393 Adapter cache time: 0.06193580897524953 Engine time: 0.10332464333623648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.49907592497766,
    "estimated_duration": 3599.9771524624866,
    "input_throughput": 2160.658990482594,
    "output_throughput": 1912.0643572117026,
    "total_throughput": 4072.7233476942965,
    "itl": 32.90820268295091,
    "ttft": 52322.97838297539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.13698607580446,
    "arrivals": 31858,
    "finished_requests": 31576,
    "scheduler_time": 11.593951466851632
}
#Debug simulation 
Total elapsed time: 3.4991494906134903. Arrivals time: 0.08696887223049998 Scheduler time: 3.0876728957518935 Scheduler overhead time: 0.10831458028405905 Adapter cache time: 0.061892523895949125 Engine time: 0.10405298648402095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.4758110009133816,
    "estimated_duration": 3599.960118667605,
    "input_throughput": 2160.8653272745496,
    "output_throughput": 1913.1181382501063,
    "total_throughput": 4073.9834655246555,
    "itl": 32.96245506164943,
    "ttft": 51283.19265344586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.29211734401696,
    "arrivals": 31858,
    "finished_requests": 31586,
    "scheduler_time": 11.633468577059125
}
#Debug simulation 
Total elapsed time: 3.4758983058854938. Arrivals time: 0.08691421756520867 Scheduler time: 3.065527644008398 Scheduler overhead time: 0.10762145975604653 Adapter cache time: 0.06161524262279272 Engine time: 0.10406451020389795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.487120228353888,
    "estimated_duration": 3599.9871330895603,
    "input_throughput": 2160.680778135017,
    "output_throughput": 1913.0465597218752,
    "total_throughput": 4073.727337856892,
    "itl": 32.87657259530201,
    "ttft": 50895.22982187468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.96650635978257,
    "arrivals": 31858,
    "finished_requests": 31588,
    "scheduler_time": 11.568064742363417
}
#Debug simulation 
Total elapsed time: 3.4872132600285113. Arrivals time: 0.08852155599743128 Scheduler time: 3.073723003733903 Scheduler overhead time: 0.10725990543141961 Adapter cache time: 0.062102246563881636 Engine time: 0.10527861583977938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.5082432539202273,
    "estimated_duration": 3599.9638338590753,
    "input_throughput": 2160.696151122638,
    "output_throughput": 1912.2153215135545,
    "total_throughput": 4072.9114726361927,
    "itl": 32.95033660750652,
    "ttft": 51600.64529352359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.94438732916196,
    "arrivals": 31858,
    "finished_requests": 31583,
    "scheduler_time": 11.622787468361244
}
#Debug simulation 
Total elapsed time: 3.508356766309589. Arrivals time: 0.08870892133563757 Scheduler time: 3.094652578700334 Scheduler overhead time: 0.10840427549555898 Adapter cache time: 0.062217376194894314 Engine time: 0.10430368175730109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.1606535855680704,
    "estimated_duration": 3600.0028163852203,
    "input_throughput": 2067.0908828543857,
    "output_throughput": 1811.668304901156,
    "total_throughput": 3878.759187755542,
    "itl": 32.339651508756106,
    "ttft": 37502.85782005429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.61137873054709,
    "arrivals": 30402,
    "finished_requests": 30218,
    "scheduler_time": 8.954775401435603
}
#Debug simulation 
Total elapsed time: 3.1607973156496882. Arrivals time: 0.08552373806014657 Scheduler time: 2.7451319843530655 Scheduler overhead time: 0.11062295315787196 Adapter cache time: 0.06395695405080914 Engine time: 0.1049621906131506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.165037936065346,
    "estimated_duration": 3600.0036959457198,
    "input_throughput": 2066.034545569018,
    "output_throughput": 1811.5342512965938,
    "total_throughput": 3877.5687968656116,
    "itl": 32.39165256856371,
    "ttft": 38526.36611911458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.441395370804926,
    "arrivals": 30402,
    "finished_requests": 30210,
    "scheduler_time": 8.998469588030048
}
#Debug simulation 
Total elapsed time: 3.1651226091198623. Arrivals time: 0.08309196634218097 Scheduler time: 2.755984273273498 Scheduler overhead time: 0.1078981920145452 Adapter cache time: 0.06387162115424871 Engine time: 0.1039203735999763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.163899761158973,
    "estimated_duration": 3600.0071444619844,
    "input_throughput": 2067.0614533216744,
    "output_throughput": 1811.5366826513994,
    "total_throughput": 3878.5981359730736,
    "itl": 32.41233052016856,
    "ttft": 37831.16389885601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.19397916705934,
    "arrivals": 30402,
    "finished_requests": 30215,
    "scheduler_time": 8.99872782291962
}
#Debug simulation 
Total elapsed time: 3.1639887671917677. Arrivals time: 0.08423817437142134 Scheduler time: 2.753493325319141 Scheduler overhead time: 0.10786311747506261 Adapter cache time: 0.06421309150755405 Engine time: 0.1039308700710535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.1606616461649537,
    "estimated_duration": 3599.9902508075306,
    "input_throughput": 2067.16143143185,
    "output_throughput": 1811.8985179298295,
    "total_throughput": 3879.0599493616796,
    "itl": 32.36224591058902,
    "ttft": 37564.9509670538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.4124762833277,
    "arrivals": 30402,
    "finished_requests": 30217,
    "scheduler_time": 8.963936028157201
}
#Debug simulation 
Total elapsed time: 3.1607461380772293. Arrivals time: 0.0850413660518825 Scheduler time: 2.748962989076972 Scheduler overhead time: 0.10835746116936207 Adapter cache time: 0.06395999109372497 Engine time: 0.10373620968312025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.165826079901308,
    "estimated_duration": 3599.974253729351,
    "input_throughput": 2067.1178390487075,
    "output_throughput": 1811.6401786050992,
    "total_throughput": 3878.7580176538067,
    "itl": 32.402294780830374,
    "ttft": 37883.9364449912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.49722324630377,
    "arrivals": 30402,
    "finished_requests": 30215,
    "scheduler_time": 9.002439026071949
}
#Debug simulation 
Total elapsed time: 3.165915912948549. Arrivals time: 0.08598180394619703 Scheduler time: 2.7538324524648488 Scheduler overhead time: 0.10814565559849143 Adapter cache time: 0.06387897301465273 Engine time: 0.10359011357650161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.1657400680705905,
    "estimated_duration": 3599.9870554581635,
    "input_throughput": 2067.1896552286044,
    "output_throughput": 1811.6940143191564,
    "total_throughput": 3878.8836695477607,
    "itl": 32.32245412187082,
    "ttft": 37708.35362893497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.86253087913227,
    "arrivals": 30402,
    "finished_requests": 30216,
    "scheduler_time": 8.945903878423637
}
#Debug simulation 
Total elapsed time: 3.165831461083144. Arrivals time: 0.08493165671825409 Scheduler time: 2.745085501577705 Scheduler overhead time: 0.11128839245066047 Adapter cache time: 0.06441072002053261 Engine time: 0.10880904272198677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.174190985970199,
    "estimated_duration": 3599.9969992856286,
    "input_throughput": 2067.11700078547,
    "output_throughput": 1811.4237321014516,
    "total_throughput": 3878.5407328869214,
    "itl": 32.39995965576937,
    "ttft": 37928.33170314447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.03663232836546,
    "arrivals": 30402,
    "finished_requests": 30215,
    "scheduler_time": 9.000335797947255
}
#Debug simulation 
Total elapsed time: 3.1742778341285884. Arrivals time: 0.08425095910206437 Scheduler time: 2.764074702747166 Scheduler overhead time: 0.10771315824240446 Adapter cache time: 0.06372492900118232 Engine time: 0.10423455061390996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.9943446088582277,
    "estimated_duration": 3600.0196824304303,
    "input_throughput": 2005.0645931821211,
    "output_throughput": 1744.9957372896665,
    "total_throughput": 3750.060330471788,
    "itl": 32.01233895384359,
    "ttft": 38685.91314470822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.25634234332786,
    "arrivals": 29640,
    "finished_requests": 29423,
    "scheduler_time": 7.257629609309685
}
#Debug simulation 
Total elapsed time: 2.994454230181873. Arrivals time: 0.08236466767266393 Scheduler time: 2.5786874876357615 Scheduler overhead time: 0.109264703001827 Adapter cache time: 0.06641707941889763 Engine time: 0.10635379143059254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.965580503921956,
    "estimated_duration": 3600.0244586481867,
    "input_throughput": 2003.9980513657486,
    "output_throughput": 1744.3278711384105,
    "total_throughput": 3748.325922504159,
    "itl": 32.06804800998962,
    "ttft": 39036.13163248019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.48247472873714,
    "arrivals": 29640,
    "finished_requests": 29421,
    "scheduler_time": 7.30756248045774
}
#Debug simulation 
Total elapsed time: 2.9657215727493167. Arrivals time: 0.08154806587845087 Scheduler time: 2.5536764981225133 Scheduler overhead time: 0.10931396065279841 Adapter cache time: 0.06618322664871812 Engine time: 0.10419431049376726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.9580645742826164,
    "estimated_duration": 3600.028653763607,
    "input_throughput": 2004.253769607299,
    "output_throughput": 1744.8036124471523,
    "total_throughput": 3749.0573820544514,
    "itl": 32.08687188278405,
    "ttft": 38842.803143792386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.75295323049261,
    "arrivals": 29640,
    "finished_requests": 29423,
    "scheduler_time": 7.323741769595355
}
#Debug simulation 
Total elapsed time: 2.9581523281522095. Arrivals time: 0.08120222017168999 Scheduler time: 2.546808543615043 Scheduler overhead time: 0.10908210324123502 Adapter cache time: 0.0655753780156374 Engine time: 0.10451122419908643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.9749471247196198,
    "estimated_duration": 3600.0068249143774,
    "input_throughput": 2003.8906454494231,
    "output_throughput": 1744.4722483684086,
    "total_throughput": 3748.3628938178317,
    "itl": 32.01899318280235,
    "ttft": 39596.246842571396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.93112214820194,
    "arrivals": 29640,
    "finished_requests": 29416,
    "scheduler_time": 7.275901697252994
}
#Debug simulation 
Total elapsed time: 2.975033904891461. Arrivals time: 0.08190487418323755 Scheduler time: 2.560825441032648 Scheduler overhead time: 0.10886416537687182 Adapter cache time: 0.06632170174270868 Engine time: 0.10615375591441989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.9845416517928243,
    "estimated_duration": 3600.030255861364,
    "input_throughput": 2004.4628759025327,
    "output_throughput": 1744.4320057519653,
    "total_throughput": 3748.894881654498,
    "itl": 32.07484553164999,
    "ttft": 38703.97624082159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.269120382099295,
    "arrivals": 29640,
    "finished_requests": 29424,
    "scheduler_time": 7.31439225623573
}
#Debug simulation 
Total elapsed time: 2.984631445724517. Arrivals time: 0.08194474782794714 Scheduler time: 2.571125151589513 Scheduler overhead time: 0.10984865063801408 Adapter cache time: 0.06551463855430484 Engine time: 0.10503489430993795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.9821272171102464,
    "estimated_duration": 3600.005842473959,
    "input_throughput": 2003.7473036551548,
    "output_throughput": 1744.3685579367013,
    "total_throughput": 3748.115861591856,
    "itl": 31.990591505634644,
    "ttft": 40206.957641593384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.5565455160534,
    "arrivals": 29640,
    "finished_requests": 29410,
    "scheduler_time": 7.236832214154779
}
#Debug simulation 
Total elapsed time: 2.982200911734253. Arrivals time: 0.08209152147173882 Scheduler time: 2.567009586840868 Scheduler overhead time: 0.10957968002185225 Adapter cache time: 0.06636579660698771 Engine time: 0.10599908884614706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.959560431074351,
    "estimated_duration": 3600.01602961298,
    "input_throughput": 2005.6382917762235,
    "output_throughput": 1745.2116735923066,
    "total_throughput": 3750.84996536853,
    "itl": 32.070232508595794,
    "ttft": 37908.33266918536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8052,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.11856325786177,
    "arrivals": 29640,
    "finished_requests": 29430,
    "scheduler_time": 7.303739157658461
}
#Debug simulation 
Total elapsed time: 2.9596496359445155. Arrivals time: 0.08163997251540422 Scheduler time: 2.546553569380194 Scheduler overhead time: 0.10904424358159304 Adapter cache time: 0.06599417561665177 Engine time: 0.10553627600893378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.6819703499786556,
    "estimated_duration": 3600.0092934459863,
    "input_throughput": 1871.1648917861519,
    "output_throughput": 1639.804100158102,
    "total_throughput": 3510.968991944254,
    "itl": 31.476841092313656,
    "ttft": 30230.73651847847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.25837604383403,
    "arrivals": 27529,
    "finished_requests": 27366,
    "scheduler_time": 4.838785892443845
}
#Debug simulation 
Total elapsed time: 2.6820538607425988. Arrivals time: 0.07642225734889507 Scheduler time: 2.2717365892603993 Scheduler overhead time: 0.10997003596276045 Adapter cache time: 0.06757131917402148 Engine time: 0.10465545859187841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6629764130339026,
    "estimated_duration": 3600.023680045505,
    "input_throughput": 1871.4082458243279,
    "output_throughput": 1639.8036581596543,
    "total_throughput": 3511.211903983982,
    "itl": 31.535740226137804,
    "ttft": 30027.490092056083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.790026169761994,
    "arrivals": 27529,
    "finished_requests": 27368,
    "scheduler_time": 4.881918084682411
}
#Debug simulation 
Total elapsed time: 2.66304778913036. Arrivals time: 0.07663667667657137 Scheduler time: 2.249667913187295 Scheduler overhead time: 0.11043883301317692 Adapter cache time: 0.0678576035425067 Engine time: 0.10686463536694646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.7208004808053374,
    "estimated_duration": 3600.0290498603385,
    "input_throughput": 1871.1646230358417,
    "output_throughput": 1639.8123232447301,
    "total_throughput": 3510.976946280572,
    "itl": 31.549682487478165,
    "ttft": 30190.652144083157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.32810866320972,
    "arrivals": 27529,
    "finished_requests": 27367,
    "scheduler_time": 4.897248347342013
}
#Debug simulation 
Total elapsed time: 2.720934684854001. Arrivals time: 0.07743819151073694 Scheduler time: 2.3041949165053666 Scheduler overhead time: 0.10954744461923838 Adapter cache time: 0.06817394681274891 Engine time: 0.11019479436799884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.685023772995919,
    "estimated_duration": 3600.010602109296,
    "input_throughput": 1871.2806001329316,
    "output_throughput": 1639.852948361059,
    "total_throughput": 3511.1335484939905,
    "itl": 31.498853824949638,
    "ttft": 30126.148571907353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.222534210739866,
    "arrivals": 27529,
    "finished_requests": 27367,
    "scheduler_time": 4.852324475949723
}
#Debug simulation 
Total elapsed time: 2.685132982674986. Arrivals time: 0.07680254615843296 Scheduler time: 2.271782430820167 Scheduler overhead time: 0.11069968296214938 Adapter cache time: 0.06808894500136375 Engine time: 0.10643981723114848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.698436318896711,
    "estimated_duration": 3600.021350093649,
    "input_throughput": 1871.1686251040614,
    "output_throughput": 1639.8158304940146,
    "total_throughput": 3510.984455598076,
    "itl": 31.539869019970016,
    "ttft": 30180.939742672046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.831168501400434,
    "arrivals": 27529,
    "finished_requests": 27367,
    "scheduler_time": 4.8902868549850815
}
#Debug simulation 
Total elapsed time: 2.698526611085981. Arrivals time: 0.07701305160298944 Scheduler time: 2.287093956489116 Scheduler overhead time: 0.110138981603086 Adapter cache time: 0.0676598772406578 Engine time: 0.105055364780128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.6611552219837904,
    "estimated_duration": 3600.0177719083476,
    "input_throughput": 1871.160484974266,
    "output_throughput": 1639.8002382279049,
    "total_throughput": 3510.960723202171,
    "itl": 31.457082552071775,
    "ttft": 30193.833815309135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.403774255548235,
    "arrivals": 27529,
    "finished_requests": 27366,
    "scheduler_time": 4.821769607669623
}
#Debug simulation 
Total elapsed time: 2.6612505838274956. Arrivals time: 0.07698847213760018 Scheduler time: 2.2484545106999576 Scheduler overhead time: 0.11126669682562351 Adapter cache time: 0.06757028540596366 Engine time: 0.10521861305460334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6889814538881183,
    "estimated_duration": 3600.0267785059427,
    "input_throughput": 1871.4066351461943,
    "output_throughput": 1639.8022468182746,
    "total_throughput": 3511.208881964469,
    "itl": 31.535002154821765,
    "ttft": 30032.99260667887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.3152242905601,
    "arrivals": 27529,
    "finished_requests": 27368,
    "scheduler_time": 4.8856581674868815
}
#Debug simulation 
Total elapsed time: 2.6890681060031056. Arrivals time: 0.07730254530906677 Scheduler time: 2.2759321434423327 Scheduler overhead time: 0.1099012428894639 Adapter cache time: 0.06770626734942198 Engine time: 0.10680410452187061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.553316480014473,
    "estimated_duration": 3599.98910836757,
    "input_throughput": 1826.5246927321048,
    "output_throughput": 1592.3095396806168,
    "total_throughput": 3418.8342324127216,
    "itl": 31.259826479379687,
    "ttft": 21416.04620013149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.673431576671746,
    "arrivals": 26760,
    "finished_requests": 26653,
    "scheduler_time": 3.732539329282018
}
#Debug simulation 
Total elapsed time: 2.553397727198899. Arrivals time: 0.0754770040512085 Scheduler time: 2.1395600303076208 Scheduler overhead time: 0.11102508520707488 Adapter cache time: 0.06859152158722281 Engine time: 0.10687931440770626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.554566961247474,
    "estimated_duration": 3599.976495446992,
    "input_throughput": 1826.531092165799,
    "output_throughput": 1592.3151185153079,
    "total_throughput": 3418.846210681107,
    "itl": 31.31869776870772,
    "ttft": 21445.28476726952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.36552328720961,
    "arrivals": 26760,
    "finished_requests": 26653,
    "scheduler_time": 3.775123579752836
}
#Debug simulation 
Total elapsed time: 2.5546521642245352. Arrivals time: 0.07517072046175599 Scheduler time: 2.143961816560477 Scheduler overhead time: 0.1100469995290041 Adapter cache time: 0.06894675362855196 Engine time: 0.10510865319520235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.529430329333991,
    "estimated_duration": 3599.974533280051,
    "input_throughput": 1826.578476934038,
    "output_throughput": 1592.386542461702,
    "total_throughput": 3418.96501939574,
    "itl": 31.335949791879674,
    "ttft": 21462.701620205968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.98941885978014,
    "arrivals": 26760,
    "finished_requests": 26653,
    "scheduler_time": 3.7872907252166192
}
#Debug simulation 
Total elapsed time: 2.5295190699398518. Arrivals time: 0.07568874629214406 Scheduler time: 2.1165270172059536 Scheduler overhead time: 0.11073934845626354 Adapter cache time: 0.06893495190888643 Engine time: 0.10607122490182519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.558627925813198,
    "estimated_duration": 3599.9932027744458,
    "input_throughput": 1826.606504404558,
    "output_throughput": 1592.3832843856535,
    "total_throughput": 3418.9897887902116,
    "itl": 31.277515604467858,
    "ttft": 21275.90578385456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.76969076942862,
    "arrivals": 26760,
    "finished_requests": 26654,
    "scheduler_time": 3.7433919615779363
}
#Debug simulation 
Total elapsed time: 2.558751433622092. Arrivals time: 0.07586120860651135 Scheduler time: 2.1406814474612474 Scheduler overhead time: 0.1110613071359694 Adapter cache time: 0.06926703546196222 Engine time: 0.11009113676846027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.537360276095569,
    "estimated_duration": 3599.990391919412,
    "input_throughput": 1826.336818775371,
    "output_throughput": 1592.4045277641753,
    "total_throughput": 3418.741346539546,
    "itl": 31.327573754049055,
    "ttft": 21612.516291685723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.42005188600164,
    "arrivals": 26760,
    "finished_requests": 26652,
    "scheduler_time": 3.7816106588561067
}
#Debug simulation 
Total elapsed time: 2.537444850895554. Arrivals time: 0.07467251177877188 Scheduler time: 2.127304586581886 Scheduler overhead time: 0.11054313974454999 Adapter cache time: 0.06883237371221185 Engine time: 0.10453761368989944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.5417548790574074,
    "estimated_duration": 3599.986038630567,
    "input_throughput": 1826.5262502243775,
    "output_throughput": 1592.3108974557479,
    "total_throughput": 3418.8371476801253,
    "itl": 31.237826705044387,
    "ttft": 21368.315582439034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.69971020648423,
    "arrivals": 26760,
    "finished_requests": 26653,
    "scheduler_time": 3.7144638970071826
}
#Debug simulation 
Total elapsed time: 2.541837233118713. Arrivals time: 0.07495343452319503 Scheduler time: 2.1304903840646148 Scheduler overhead time: 0.11102554900571704 Adapter cache time: 0.06875471631065011 Engine time: 0.10505980905145407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.5362433129921556,
    "estimated_duration": 3599.98298637778,
    "input_throughput": 1826.5277988483178,
    "output_throughput": 1592.312247499732,
    "total_throughput": 3418.84004634805,
    "itl": 31.323653209978104,
    "ttft": 21465.394764880504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.78203508538648,
    "arrivals": 26760,
    "finished_requests": 26653,
    "scheduler_time": 3.7785841403932663
}
#Debug simulation 
Total elapsed time: 2.536331493873149. Arrivals time: 0.07580720540136099 Scheduler time: 2.1240923376753926 Scheduler overhead time: 0.11117450054734945 Adapter cache time: 0.06838551070541143 Engine time: 0.10508553357794881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.3553826161660254,
    "estimated_duration": 3599.883393528627,
    "input_throughput": 1704.078251819969,
    "output_throughput": 1510.431146123945,
    "total_throughput": 3214.509397943914,
    "itl": 30.886507445270215,
    "ttft": 14607.748793724852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.50354264234717,
    "arrivals": 25342,
    "finished_requests": 25269,
    "scheduler_time": 2.0793718521904436
}
#Debug simulation 
Total elapsed time: 2.355464636813849. Arrivals time: 0.07253115577623248 Scheduler time: 1.9392073499038815 Scheduler overhead time: 0.1111516747623682 Adapter cache time: 0.07124550919979811 Engine time: 0.10922284284606576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.348044996149838,
    "estimated_duration": 3599.8972568872973,
    "input_throughput": 1704.06807812739,
    "output_throughput": 1510.3353268201952,
    "total_throughput": 3214.403404947585,
    "itl": 30.946225917447244,
    "ttft": 14657.484160939659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.2791886017689,
    "arrivals": 25342,
    "finished_requests": 25269,
    "scheduler_time": 2.11383502955968
}
#Debug simulation 
Total elapsed time: 2.348132028244436. Arrivals time: 0.07259607082232833 Scheduler time: 1.9293325929902494 Scheduler overhead time: 0.11232044687494636 Adapter cache time: 0.07382736122235656 Engine time: 0.10787036316469312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.345091428142041,
    "estimated_duration": 3599.906973371324,
    "input_throughput": 1704.0670898934472,
    "output_throughput": 1510.4212526102808,
    "total_throughput": 3214.4883425037283,
    "itl": 30.96050925477059,
    "ttft": 14678.727711739757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.00327663032492,
    "arrivals": 25342,
    "finished_requests": 25269,
    "scheduler_time": 2.1294924194302918
}
#Debug simulation 
Total elapsed time: 2.345199947245419. Arrivals time: 0.07202257448807359 Scheduler time: 1.9316970235668123 Scheduler overhead time: 0.11183747695758939 Adapter cache time: 0.07149025611579418 Engine time: 0.10572851030156016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.3417932339943945,
    "estimated_duration": 3599.8947234646157,
    "input_throughput": 1704.069277363771,
    "output_throughput": 1510.3363897173263,
    "total_throughput": 3214.4056670810974,
    "itl": 30.903795163226096,
    "ttft": 14638.773376392088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.57368662709588,
    "arrivals": 25342,
    "finished_requests": 25269,
    "scheduler_time": 2.092418804613927
}
#Debug simulation 
Total elapsed time: 2.3418782050721347. Arrivals time: 0.07221973408013582 Scheduler time: 1.9269411084242165 Scheduler overhead time: 0.11158175161108375 Adapter cache time: 0.07108572078868747 Engine time: 0.10764391720294952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.3618609928525984,
    "estimated_duration": 3599.894877587045,
    "input_throughput": 1704.0172584460902,
    "output_throughput": 1510.3482698484802,
    "total_throughput": 3214.3655282945706,
    "itl": 30.954801084986354,
    "ttft": 14805.700434001756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.28346835838285,
    "arrivals": 25342,
    "finished_requests": 25268,
    "scheduler_time": 2.119783095187004
}
#Debug simulation 
Total elapsed time: 2.361950029153377. Arrivals time: 0.07284171599894762 Scheduler time: 1.9468863788060844 Scheduler overhead time: 0.11131483735516667 Adapter cache time: 0.07090767193585634 Engine time: 0.10786148020997643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.3583197006955743,
    "estimated_duration": 3599.895740847418,
    "input_throughput": 1704.0168498202077,
    "output_throughput": 1510.3479076647104,
    "total_throughput": 3214.364757484918,
    "itl": 30.86525137818447,
    "ttft": 14753.827837888284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.457564052811065,
    "arrivals": 25342,
    "finished_requests": 25268,
    "scheduler_time": 2.069708353988118
}
#Debug simulation 
Total elapsed time: 2.358396728988737. Arrivals time: 0.07231226982548833 Scheduler time: 1.9421981456689537 Scheduler overhead time: 0.11242006672546268 Adapter cache time: 0.07152365846559405 Engine time: 0.10759784001857042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.344275379087776,
    "estimated_duration": 3599.8755435403323,
    "input_throughput": 1704.0783565442366,
    "output_throughput": 1510.3444367004086,
    "total_throughput": 3214.422793244645,
    "itl": 30.94827627373189,
    "ttft": 14671.630756140252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.77848902703822,
    "arrivals": 25342,
    "finished_requests": 25269,
    "scheduler_time": 2.120940620467176
}
#Debug simulation 
Total elapsed time: 2.3443567538633943. Arrivals time: 0.07212842395529151 Scheduler time: 1.9329596082679927 Scheduler overhead time: 0.11070602759718895 Adapter cache time: 0.07074481062591076 Engine time: 0.10576564725488424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.0103620062582195,
    "estimated_duration": 3599.505797805397,
    "input_throughput": 1380.6195292225705,
    "output_throughput": 1204.3692227536103,
    "total_throughput": 2584.988751976181,
    "itl": 29.82018289366295,
    "ttft": 20225.274391809064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13011,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 86.03405391468988,
    "arrivals": 20309,
    "finished_requests": 20222,
    "scheduler_time": 0.037390783235000176
}
#Debug simulation 
Total elapsed time: 2.010446425061673. Arrivals time: 0.060325813479721546 Scheduler time: 1.5833764588460326 Scheduler overhead time: 0.11155934352427721 Adapter cache time: 0.09244240680709481 Engine time: 0.10900559043511748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.9873583638109267,
    "estimated_duration": 3599.5130363268727,
    "input_throughput": 1380.595638867613,
    "output_throughput": 1204.332073880656,
    "total_throughput": 2584.927712748269,
    "itl": 29.897823161336483,
    "ttft": 20694.959074994364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 94.33618493746174,
    "arrivals": 20309,
    "finished_requests": 20220,
    "scheduler_time": 0.03834054451557003
}
#Debug simulation 
Total elapsed time: 1.9874387849122286. Arrivals time: 0.06085193017497659 Scheduler time: 1.5627816044725478 Scheduler overhead time: 0.11136768804863095 Adapter cache time: 0.09131179936230183 Engine time: 0.10797532740980387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.0147777781821787,
    "estimated_duration": 3599.5161166079547,
    "input_throughput": 1380.5944574247494,
    "output_throughput": 1204.3310432751016,
    "total_throughput": 2584.925500699851,
    "itl": 29.926824427585654,
    "ttft": 20731.889596145476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 96.66707269126059,
    "arrivals": 20309,
    "finished_requests": 20220,
    "scheduler_time": 0.03939422795223249
}
#Debug simulation 
Total elapsed time: 2.014859741088003. Arrivals time: 0.06020061578601599 Scheduler time: 1.5885255630128086 Scheduler overhead time: 0.11139159370213747 Adapter cache time: 0.0918753040023148 Engine time: 0.10851388005539775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9960991749539971,
    "estimated_duration": 3599.4997032128,
    "input_throughput": 1380.6215890403712,
    "output_throughput": 1204.3370905491965,
    "total_throughput": 2584.9586795895675,
    "itl": 29.849239596278842,
    "ttft": 20441.186796445203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.90315045499663,
    "arrivals": 20309,
    "finished_requests": 20221,
    "scheduler_time": 0.03773508531496029
}
#Debug simulation 
Total elapsed time: 1.9961773338727653. Arrivals time: 0.06006999081000686 Scheduler time: 1.5706876367330551 Scheduler overhead time: 0.11142644844949245 Adapter cache time: 0.09165768185630441 Engine time: 0.10838030558079481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.996301765087992,
    "estimated_duration": 3599.503053828109,
    "input_throughput": 1380.5994676723262,
    "output_throughput": 1204.3354138537743,
    "total_throughput": 2584.9348815261005,
    "itl": 29.9229406274522,
    "ttft": 20720.37992790998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 95.84770780273661,
    "arrivals": 20309,
    "finished_requests": 20220,
    "scheduler_time": 0.03963223567781438
}
#Debug simulation 
Total elapsed time: 1.996384657919407. Arrivals time: 0.06000020680949092 Scheduler time: 1.5743045243434608 Scheduler overhead time: 0.11098360223695636 Adapter cache time: 0.0913768233731389 Engine time: 0.10647992137819529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.0137266227975488,
    "estimated_duration": 3599.525152786059,
    "input_throughput": 1380.669613088652,
    "output_throughput": 1204.3633023774184,
    "total_throughput": 2585.032915466071,
    "itl": 29.792278824387978,
    "ttft": 19999.789426560703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.22717730220664,
    "arrivals": 20309,
    "finished_requests": 20223,
    "scheduler_time": 0.03638861938869435
}
#Debug simulation 
Total elapsed time: 2.0138379079289734. Arrivals time: 0.06048345612362027 Scheduler time: 1.584206077735871 Scheduler overhead time: 0.1119349580258131 Adapter cache time: 0.09377854783087969 Engine time: 0.10987264849245548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.0098220142535865,
    "estimated_duration": 3599.517007198386,
    "input_throughput": 1380.5941158388612,
    "output_throughput": 1204.3307453002062,
    "total_throughput": 2584.9248611390676,
    "itl": 29.910409373116853,
    "ttft": 20712.128177162704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 95.02290150909604,
    "arrivals": 20309,
    "finished_requests": 20220,
    "scheduler_time": 0.040093513581243856
}
#Debug simulation 
Total elapsed time: 2.009908472187817. Arrivals time: 0.060102762654423714 Scheduler time: 1.5858103432692587 Scheduler overhead time: 0.11092493496835232 Adapter cache time: 0.09105202276259661 Engine time: 0.10890551516786218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8635569256730378,
    "estimated_duration": 3600.025715774352,
    "input_throughput": 1292.271880063314,
    "output_throughput": 1146.4673660288647,
    "total_throughput": 2438.7392460921787,
    "itl": 29.450271553745306,
    "ttft": 10015.882163926854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.72327069018847,
    "arrivals": 18908,
    "finished_requests": 18868,
    "scheduler_time": 0.0036482173043343373
}
#Debug simulation 
Total elapsed time: 1.8636828837916255. Arrivals time: 0.0584385059773922 Scheduler time: 1.4395940005779266 Scheduler overhead time: 0.11175292218104005 Adapter cache time: 0.09090458042919636 Engine time: 0.10884131863713264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8458945690654218,
    "estimated_duration": 3600.039238353035,
    "input_throughput": 1292.2670259917272,
    "output_throughput": 1146.4630596327013,
    "total_throughput": 2438.7300856244287,
    "itl": 29.545929825071934,
    "ttft": 10088.754049796053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12929,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 94.11825320001783,
    "arrivals": 18908,
    "finished_requests": 18868,
    "scheduler_time": 0.003608433672006226
}
#Debug simulation 
Total elapsed time: 1.8459831490181386. Arrivals time: 0.05699735879898071 Scheduler time: 1.4255553758703172 Scheduler overhead time: 0.11098864581435919 Adapter cache time: 0.09093595575541258 Engine time: 0.10764566157013178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8737575421109796,
    "estimated_duration": 3600.030638046143,
    "input_throughput": 1292.2701131579568,
    "output_throughput": 1146.4657984799903,
    "total_throughput": 2438.735911637947,
    "itl": 29.562563614116062,
    "ttft": 10109.2265898933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12914,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 96.46295184110713,
    "arrivals": 18908,
    "finished_requests": 18868,
    "scheduler_time": 0.00409486134512263
}
#Debug simulation 
Total elapsed time: 1.873851171694696. Arrivals time: 0.0597153096459806 Scheduler time: 1.4518297738395631 Scheduler overhead time: 0.10999542009085417 Adapter cache time: 0.09106884943321347 Engine time: 0.10810639755800366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8341526286676526,
    "estimated_duration": 3600.0288479750966,
    "input_throughput": 1292.270755723728,
    "output_throughput": 1146.4663685463197,
    "total_throughput": 2438.737124270048,
    "itl": 29.47250810019022,
    "ttft": 10040.33738741291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.47814732782453,
    "arrivals": 18908,
    "finished_requests": 18868,
    "scheduler_time": 0.0037272940783241305
}
#Debug simulation 
Total elapsed time: 1.8342370321042836. Arrivals time: 0.0571065410040319 Scheduler time: 1.4132096278481185 Scheduler overhead time: 0.111653923522681 Adapter cache time: 0.0901278150267899 Engine time: 0.1086171492934227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.8503697928972542,
    "estimated_duration": 3600.0004992794043,
    "input_throughput": 1292.2809318863183,
    "output_throughput": 1146.4753965523464,
    "total_throughput": 2438.7563284386647,
    "itl": 29.548985761292588,
    "ttft": 9913.441688149273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12920,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 95.64555474513607,
    "arrivals": 18908,
    "finished_requests": 18868,
    "scheduler_time": 0.0040154705799793355
}
#Debug simulation 
Total elapsed time: 1.8504769559949636. Arrivals time: 0.056428898591548204 Scheduler time: 1.4316893019713461 Scheduler overhead time: 0.11129627004265785 Adapter cache time: 0.09022456780076027 Engine time: 0.10748255532234907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8614623718895018,
    "estimated_duration": 3600.025675925396,
    "input_throughput": 1292.271894367569,
    "output_throughput": 1146.4673787191987,
    "total_throughput": 2438.7392730867678,
    "itl": 29.41684713606113,
    "ttft": 9993.103083330625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12973,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 82.81860636201053,
    "arrivals": 18908,
    "finished_requests": 18868,
    "scheduler_time": 0.0035152866070632415
}
#Debug simulation 
Total elapsed time: 1.861545239109546. Arrivals time: 0.05697900988161564 Scheduler time: 1.439392643980682 Scheduler overhead time: 0.11136821238324046 Adapter cache time: 0.09118413552641869 Engine time: 0.10926008317619562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.851848527789116,
    "estimated_duration": 3600.0000312879447,
    "input_throughput": 1292.2810998797722,
    "output_throughput": 1146.475545591427,
    "total_throughput": 2438.756645471199,
    "itl": 29.53827317289258,
    "ttft": 9902.979842338735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 94.7531965551236,
    "arrivals": 18908,
    "finished_requests": 18868,
    "scheduler_time": 0.0038364381166407415
}
#Debug simulation 
Total elapsed time: 1.8519415790215135. Arrivals time: 0.05726449657231569 Scheduler time: 1.43028095504269 Scheduler overhead time: 0.11134899128228426 Adapter cache time: 0.09069459000602365 Engine time: 0.10867959726601839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.7317805415950716,
    "estimated_duration": 3599.630797477941,
    "input_throughput": 1251.766432034371,
    "output_throughput": 1080.786119155833,
    "total_throughput": 2332.552551190204,
    "itl": 28.859720281702984,
    "ttft": 8671.449608431954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 86.0076042785621,
    "arrivals": 18247,
    "finished_requests": 18207,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7318622199818492. Arrivals time: 0.05558352777734399 Scheduler time: 1.3101829485967755 Scheduler overhead time: 0.11235846532508731 Adapter cache time: 0.09097846085205674 Engine time: 0.10895054694265127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7075015371665359,
    "estimated_duration": 3599.637038744075,
    "input_throughput": 1251.7642616468136,
    "output_throughput": 1080.784245224175,
    "total_throughput": 2332.5485068709886,
    "itl": 28.950426011127295,
    "ttft": 8697.31026792122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 94.36386405777715,
    "arrivals": 18247,
    "finished_requests": 18207,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7075826898217201. Arrivals time: 0.05489729577675462 Scheduler time: 1.2874826840125024 Scheduler overhead time: 0.11389560392126441 Adapter cache time: 0.08989252662286162 Engine time: 0.10749288182705641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7276425170712173,
    "estimated_duration": 3599.6463911467736,
    "input_throughput": 1251.7610093819558,
    "output_throughput": 1080.7814371901648,
    "total_throughput": 2332.5424465721208,
    "itl": 28.976333830297268,
    "ttft": 8704.76506031696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12978,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 96.74571406096196,
    "arrivals": 18247,
    "finished_requests": 18207,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7277234657667577. Arrivals time: 0.05548142781481147 Scheduler time: 1.3041033283807337 Scheduler overhead time: 0.11281757988035679 Adapter cache time: 0.09109282260760665 Engine time: 0.11032465845346451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7147666183300316,
    "estimated_duration": 3599.648049844965,
    "input_throughput": 1251.7604325773088,
    "output_throughput": 1080.7809391719722,
    "total_throughput": 2332.541371749281,
    "itl": 28.890017520785584,
    "ttft": 8680.092343274704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.8445523656287,
    "arrivals": 18247,
    "finished_requests": 18207,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7148461900651455. Arrivals time: 0.05528666917234659 Scheduler time: 1.2945682113058865 Scheduler overhead time: 0.11145616509020329 Adapter cache time: 0.09118591621518135 Engine time: 0.10866834176704288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7301963288336992,
    "estimated_duration": 3599.6516189803683,
    "input_throughput": 1251.7591914287343,
    "output_throughput": 1080.7798675534043,
    "total_throughput": 2332.5390589821386,
    "itl": 28.967697195331713,
    "ttft": 8702.063382929644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 95.93018736438775,
    "arrivals": 18247,
    "finished_requests": 18207,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7302758768200874. Arrivals time: 0.05538763292133808 Scheduler time: 1.304564199410379 Scheduler overhead time: 0.11694364249706268 Adapter cache time: 0.09080565767362714 Engine time: 0.10810498613864183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.6975923031568527,
    "estimated_duration": 3599.64369591935,
    "input_throughput": 1251.9114058729235,
    "output_throughput": 1080.7828020340726,
    "total_throughput": 2332.694207906996,
    "itl": 28.826563129820137,
    "ttft": 8465.964290848318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13011,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.06119535775197,
    "arrivals": 18247,
    "finished_requests": 18208,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6976738632656634. Arrivals time: 0.05451227631419897 Scheduler time: 1.278528810478747 Scheduler overhead time: 0.11371391825377941 Adapter cache time: 0.0901417126879096 Engine time: 0.10651667742058635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.722731964662671,
    "estimated_duration": 3599.6511280355885,
    "input_throughput": 1251.7593621521235,
    "output_throughput": 1080.7800149574764,
    "total_throughput": 2332.5393771095996,
    "itl": 28.955627745393954,
    "ttft": 8699.69372049204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 95.04771444032818,
    "arrivals": 18247,
    "finished_requests": 18207,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7228082697838545. Arrivals time: 0.05550006218254566 Scheduler time: 1.3002442042343318 Scheduler overhead time: 0.11227292520925403 Adapter cache time: 0.09005083609372377 Engine time: 0.10985258687287569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5257209311239421,
    "estimated_duration": 3600.003748804722,
    "input_throughput": 1099.1610776277116,
    "output_throughput": 954.0317843114284,
    "total_throughput": 2053.19286193914,
    "itl": 27.678541333390836,
    "ttft": 5362.18201044034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.35348709192266,
    "arrivals": 16073,
    "finished_requests": 16049,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5258003929629922. Arrivals time: 0.04920286126434803 Scheduler time: 1.1156144826672971 Scheduler overhead time: 0.11479800706729293 Adapter cache time: 0.08155856840312481 Engine time: 0.10952401207759976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5211108168587089,
    "estimated_duration": 3600.0118207474984,
    "input_throughput": 1099.2613905301855,
    "output_throughput": 954.0793672413073,
    "total_throughput": 2053.340757771493,
    "itl": 27.523316663803207,
    "ttft": 5081.176190126281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.69294067441344,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.521188453771174. Arrivals time: 0.04902150621637702 Scheduler time: 1.1097829532809556 Scheduler overhead time: 0.1156062912195921 Adapter cache time: 0.08195179188624024 Engine time: 0.10947404848411679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5575190703384578,
    "estimated_duration": 3600.0252791167127,
    "input_throughput": 1099.2572810408042,
    "output_throughput": 954.0758005018017,
    "total_throughput": 2053.333081542606,
    "itl": 27.55052627978569,
    "ttft": 5306.252743404481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.942684212895,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5575928259640932. Arrivals time: 0.0504823331721127 Scheduler time: 1.1395560097880661 Scheduler overhead time: 0.11481419345363975 Adapter cache time: 0.08331548236310482 Engine time: 0.11385139636695385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.5518156639300287,
    "estimated_duration": 3600.0112226877695,
    "input_throughput": 1099.2615731473854,
    "output_throughput": 954.0795257398265,
    "total_throughput": 2053.341098887212,
    "itl": 27.47056481788237,
    "ttft": 5078.085672703101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.61455450090834,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5518952389247715. Arrivals time: 0.0494633074849844 Scheduler time: 1.129941170103848 Scheduler overhead time: 0.11592131946235895 Adapter cache time: 0.08339594909921288 Engine time: 0.11728144437074661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5207684198394418,
    "estimated_duration": 3600.0139295099984,
    "input_throughput": 1099.260746621233,
    "output_throughput": 954.0788083749165,
    "total_throughput": 2053.3395549961497,
    "itl": 27.54195898155089,
    "ttft": 5082.128598082612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.13084908041132,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.520841266028583. Arrivals time: 0.0493445610627532 Scheduler time: 1.1075926623307168 Scheduler overhead time: 0.11521139414981008 Adapter cache time: 0.08277440955862403 Engine time: 0.11050653969869018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5503691611811519,
    "estimated_duration": 3600.023063813668,
    "input_throughput": 1099.257957477582,
    "output_throughput": 954.076387599992,
    "total_throughput": 2053.334345077574,
    "itl": 27.651368821966305,
    "ttft": 5359.638637286279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.72790294264699,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.550448962021619. Arrivals time: 0.049897091928869486 Scheduler time: 1.1363485688343644 Scheduler overhead time: 0.11540372623130679 Adapter cache time: 0.08294063247740269 Engine time: 0.1104472354054451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5524874618276954,
    "estimated_duration": 3600.032356593869,
    "input_throughput": 1099.2551199579236,
    "output_throughput": 954.0739248381925,
    "total_throughput": 2053.3290447961162,
    "itl": 27.53430164112898,
    "ttft": 5305.1287999432725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 84.40779104473471,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5525639979168773. Arrivals time: 0.050319830887019634 Scheduler time: 1.1312605985440314 Scheduler overhead time: 0.1155562112107873 Adapter cache time: 0.08358710817992687 Engine time: 0.11608505668118596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5096025047823787,
    "estimated_duration": 3600.0139609239,
    "input_throughput": 1039.79041210144,
    "output_throughput": 928.2377891507957,
    "total_throughput": 1968.028201252236,
    "itl": 27.162749614212487,
    "ttft": 5022.508401962752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 70.58085400703483,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5096835349686444. Arrivals time: 0.04848076216876507 Scheduler time: 1.0973268812522292 Scheduler overhead time: 0.11728674452751875 Adapter cache time: 0.0785706271417439 Engine time: 0.11166355339810252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.492989961989224,
    "estimated_duration": 3600.0007230401616,
    "input_throughput": 1039.7942356075023,
    "output_throughput": 928.2412024567586,
    "total_throughput": 1968.0354380642607,
    "itl": 27.241405303166356,
    "ttft": 5025.157396166226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 77.6443541596614,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4930682736448944. Arrivals time: 0.047813227865844965 Scheduler time: 1.0831868927925825 Scheduler overhead time: 0.11678709415718913 Adapter cache time: 0.077949324157089 Engine time: 0.11126829963177443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.518079651053995,
    "estimated_duration": 3599.9945086773287,
    "input_throughput": 1039.796030515421,
    "output_throughput": 928.2428048002107,
    "total_throughput": 1968.0388353156318,
    "itl": 27.26434225168823,
    "ttft": 5026.040731186438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.66845371779246,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5181631399318576. Arrivals time: 0.048848068341612816 Scheduler time: 1.100856692995876 Scheduler overhead time: 0.11689310148358345 Adapter cache time: 0.07963408017531037 Engine time: 0.1151511617936194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.5012604119256139,
    "estimated_duration": 3599.993711664631,
    "input_throughput": 1039.7962607187785,
    "output_throughput": 928.2430103064869,
    "total_throughput": 1968.0392710252654,
    "itl": 27.191988377058443,
    "ttft": 5023.556072209968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.0207472814802,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5013410388492048. Arrivals time: 0.04791260976344347 Scheduler time: 1.0882131764665246 Scheduler overhead time: 0.11689860047772527 Adapter cache time: 0.07909298595041037 Engine time: 0.11294427933171391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5197400581091642,
    "estimated_duration": 3600.0074424115555,
    "input_throughput": 1039.7922948438359,
    "output_throughput": 928.2394699055119,
    "total_throughput": 1968.031764749348,
    "itl": 27.254271472761634,
    "ttft": 5025.751954274776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.99102195028843,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5198127101175487. Arrivals time: 0.048534867353737354 Scheduler time: 1.1061377646401525 Scheduler overhead time: 0.11737218359485269 Adapter cache time: 0.07907472737133503 Engine time: 0.1123064374551177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5061475681141019,
    "estimated_duration": 3600.0089120177377,
    "input_throughput": 1039.79187037678,
    "output_throughput": 928.2390909768768,
    "total_throughput": 1968.0309613536567,
    "itl": 27.140861445015293,
    "ttft": 5021.677439572737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.14835604059381,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.506224004086107. Arrivals time: 0.04825470270588994 Scheduler time: 1.0907886712811887 Scheduler overhead time: 0.11840334441512823 Adapter cache time: 0.0787836848758161 Engine time: 0.11360530462116003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5188848562538624,
    "estimated_duration": 3600.007327990983,
    "input_throughput": 1039.792327891999,
    "output_throughput": 928.239499408144,
    "total_throughput": 1968.031827300143,
    "itl": 27.247977752101118,
    "ttft": 5025.425973195193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.22386776942892,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5189643041230738. Arrivals time: 0.04876492032781243 Scheduler time: 1.1018565795384347 Scheduler overhead time: 0.1168172974139452 Adapter cache time: 0.07936377776786685 Engine time: 0.11566056217998266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.3840991258621216,
    "estimated_duration": 3599.9233994266406,
    "input_throughput": 935.0810077059244,
    "output_throughput": 827.2334351542875,
    "total_throughput": 1762.3144428602118,
    "itl": 26.233809500681676,
    "ttft": 7582.787231549472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.344844825580324,
    "arrivals": 13872,
    "finished_requests": 13843,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3841930190101266. Arrivals time: 0.04484377568587661 Scheduler time: 0.9766062330454588 Scheduler overhead time: 0.1189345046877861 Adapter cache time: 0.07166761672124267 Engine time: 0.11460942542180419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.3898241352289915,
    "estimated_duration": 3599.927622289639,
    "input_throughput": 935.0799108174859,
    "output_throughput": 827.2324647754824,
    "total_throughput": 1762.3123755929682,
    "itl": 26.02454421326273,
    "ttft": 7578.708275372983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.48975427474214,
    "arrivals": 13872,
    "finished_requests": 13843,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3899016082286835. Arrivals time: 0.044592945370823145 Scheduler time: 0.9800122217275202 Scheduler overhead time: 0.12091194512322545 Adapter cache time: 0.07082677539438009 Engine time: 0.11557660065591335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.3889177646487951,
    "estimated_duration": 3599.910164335891,
    "input_throughput": 934.9316639463686,
    "output_throughput": 827.235920913425,
    "total_throughput": 1762.1675848597938,
    "itl": 26.039366146873643,
    "ttft": 7838.284637824895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.19037984577143,
    "arrivals": 13872,
    "finished_requests": 13842,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3889939147047698. Arrivals time: 0.044716352596879005 Scheduler time: 0.9750576396472752 Scheduler overhead time: 0.12229477101936936 Adapter cache time: 0.07039144216105342 Engine time: 0.11753057735040784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.3964127819053829,
    "estimated_duration": 3599.9112159735437,
    "input_throughput": 934.9313908259272,
    "output_throughput": 827.235679254009,
    "total_throughput": 1762.1670700799361,
    "itl": 26.25556639380193,
    "ttft": 7842.619884135946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.59756023676353,
    "arrivals": 13872,
    "finished_requests": 13842,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3965115081518888. Arrivals time: 0.04474785923957825 Scheduler time: 0.9875970482826233 Scheduler overhead time: 0.11924849497154355 Adapter cache time: 0.07173126935958862 Engine time: 0.11556457402184606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.3811460947617888,
    "estimated_duration": 3599.931275116136,
    "input_throughput": 935.0789619980742,
    "output_throughput": 827.2316253881621,
    "total_throughput": 1762.3105873862362,
    "itl": 26.034057834651897,
    "ttft": 7578.825255934536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.58229129780192,
    "arrivals": 13872,
    "finished_requests": 13843,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3812233950011432. Arrivals time: 0.04428365873172879 Scheduler time: 0.9721423937007785 Scheduler overhead time: 0.12073413655161858 Adapter cache time: 0.07081094803288579 Engine time: 0.1153084128163755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.3818664839491248,
    "estimated_duration": 3599.908518066559,
    "input_throughput": 934.9320914987129,
    "output_throughput": 827.2362992155736,
    "total_throughput": 1762.1683907142865,
    "itl": 26.214165476144828,
    "ttft": 7842.0965863807305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.29158210835621,
    "arrivals": 13872,
    "finished_requests": 13842,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3819367792457342. Arrivals time: 0.044084517285227776 Scheduler time: 0.9694350459612906 Scheduler overhead time: 0.1240982343442738 Adapter cache time: 0.07107149716466665 Engine time: 0.11481783725321293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.3894842020235956,
    "estimated_duration": 3599.92786932779,
    "input_throughput": 935.0798466494191,
    "output_throughput": 827.2324080082399,
    "total_throughput": 1762.312254657659,
    "itl": 26.0262055160062,
    "ttft": 7578.731562902893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.99003206932525,
    "arrivals": 13872,
    "finished_requests": 13843,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3895513019524515. Arrivals time: 0.04487241106107831 Scheduler time: 0.9789093169383705 Scheduler overhead time: 0.12025002436712384 Adapter cache time: 0.07055407436564565 Engine time: 0.11689439276233315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1718291197903454,
    "estimated_duration": 3599.254526662725,
    "input_throughput": 688.9287716751571,
    "output_throughput": 608.3026314979934,
    "total_throughput": 1297.2314031731505,
    "itl": 24.04601012537372,
    "ttft": 5000.476438274902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.65461312142023,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1718955598771572. Arrivals time: 0.0370427742600441 Scheduler time: 0.7592821270227432 Scheduler overhead time: 0.12732433434575796 Adapter cache time: 0.06282853288576007 Engine time: 0.12357168458402157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.165452241897583,
    "estimated_duration": 3599.238266745149,
    "input_throughput": 688.9318839795429,
    "output_throughput": 608.3053795657556,
    "total_throughput": 1297.2372635452984,
    "itl": 24.096327189165482,
    "ttft": 5001.154592868255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7960,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.03059508524652,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1655096840113401. Arrivals time: 0.03631617221981287 Scheduler time: 0.7531587439589202 Scheduler overhead time: 0.12663363805040717 Adapter cache time: 0.06611494207754731 Engine time: 0.12163360556587577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1560408021323383,
    "estimated_duration": 3599.249526150911,
    "input_throughput": 688.9297288181494,
    "output_throughput": 608.3034766254215,
    "total_throughput": 1297.2332054435708,
    "itl": 24.108407872351243,
    "ttft": 5001.3581868184365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7962,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.57855532646705,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1561339059844613. Arrivals time: 0.03639449365437031 Scheduler time: 0.7470999606885016 Scheduler overhead time: 0.12691302224993706 Adapter cache time: 0.06217159843072295 Engine time: 0.12201764527708292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1535106338560581,
    "estimated_duration": 3599.2437764554606,
    "input_throughput": 688.9308293649235,
    "output_throughput": 608.304448373919,
    "total_throughput": 1297.2352777388426,
    "itl": 24.06515227017692,
    "ttft": 5000.707659129524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.47758043061666,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1535797659307718. Arrivals time: 0.036643415223807096 Scheduler time: 0.7436014134436846 Scheduler overhead time: 0.1263450849801302 Adapter cache time: 0.0624145595356822 Engine time: 0.12314025219529867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1568529950454831,
    "estimated_duration": 3599.2545259735994,
    "input_throughput": 688.9287718070617,
    "output_throughput": 608.302631614461,
    "total_throughput": 1297.2314034215228,
    "itl": 24.108221537552094,
    "ttft": 5001.338584426296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.03963792942997,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1569163701497018. Arrivals time: 0.03615419287234545 Scheduler time: 0.7472339607775211 Scheduler overhead time: 0.12669015815481544 Adapter cache time: 0.062185829505324364 Engine time: 0.12267384072765708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1666636811569333,
    "estimated_duration": 3599.2385749252726,
    "input_throughput": 688.931824990646,
    "output_throughput": 608.3053274803983,
    "total_throughput": 1297.2371524710443,
    "itl": 24.034645235012512,
    "ttft": 5000.256923925634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7962,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.82877852882826,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1667410722002387. Arrivals time: 0.036345692817121744 Scheduler time: 0.756122961640358 Scheduler overhead time: 0.12729689059779048 Adapter cache time: 0.0627982895821333 Engine time: 0.12247176980599761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.160381758119911,
    "estimated_duration": 3599.2306642281983,
    "input_throughput": 688.9333391839502,
    "output_throughput": 608.3066644658886,
    "total_throughput": 1297.2400036498389,
    "itl": 24.101028089930917,
    "ttft": 5001.295206542164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.50982919862102,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1604875209741294. Arrivals time: 0.0365357524715364 Scheduler time: 0.7495294492691755 Scheduler overhead time: 0.12731684232130647 Adapter cache time: 0.06260236399248242 Engine time: 0.12307639606297016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1263519967906177,
    "estimated_duration": 3599.7827587710253,
    "input_throughput": 640.772000582472,
    "output_throughput": 568.6193132106724,
    "total_throughput": 1209.3913137931443,
    "itl": 23.665612185853114,
    "ttft": 5756.988725416381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.62918225713677,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1264165681786835. Arrivals time: 0.03519459301605821 Scheduler time: 0.7159586455672979 Scheduler overhead time: 0.12827803939580917 Adapter cache time: 0.05933349300175905 Engine time: 0.12507234513759613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1243933076038957,
    "estimated_duration": 3599.7850006718845,
    "input_throughput": 640.7716015177227,
    "output_throughput": 568.61895908171,
    "total_throughput": 1209.3905605994328,
    "itl": 23.70730937979,
    "ttft": 5757.473016137428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.39391313656556,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1244838116690516. Arrivals time: 0.035836344584822655 Scheduler time: 0.7146015986800194 Scheduler overhead time: 0.12786310259252787 Adapter cache time: 0.05921565229073167 Engine time: 0.12450946029275656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1238213297910988,
    "estimated_duration": 3599.778398386773,
    "input_throughput": 640.7727767447329,
    "output_throughput": 568.6200019749308,
    "total_throughput": 1209.3927787196637,
    "itl": 23.717519816612164,
    "ttft": 5757.669632778894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.77643850501835,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1238853088580072. Arrivals time: 0.03471898892894387 Scheduler time: 0.7143891667947173 Scheduler overhead time: 0.128647037781775 Adapter cache time: 0.05941081093624234 Engine time: 0.1239644456654787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1152324536815286,
    "estimated_duration": 3599.7692894823626,
    "input_throughput": 640.774398164747,
    "output_throughput": 568.6214408185975,
    "total_throughput": 1209.3958389833444,
    "itl": 23.679921735247202,
    "ttft": 5757.309024908281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.21516096080369,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1152928657829762. Arrivals time: 0.03480127500370145 Scheduler time: 0.7080611437559128 Scheduler overhead time: 0.12826466094702482 Adapter cache time: 0.0586749529466033 Engine time: 0.12323946598917246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1252082460559905,
    "estimated_duration": 3599.7685168491425,
    "input_throughput": 640.7745356968089,
    "output_throughput": 568.6215628641714,
    "total_throughput": 1209.3960985609804,
    "itl": 23.711901629256943,
    "ttft": 5757.712861096144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.28754158202308,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1252910639159381. Arrivals time: 0.03495004214346409 Scheduler time: 0.7136957761831582 Scheduler overhead time: 0.12878812476992607 Adapter cache time: 0.059108491986989975 Engine time: 0.1252542519941926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1192043302580714,
    "estimated_duration": 3599.791788831736,
    "input_throughput": 640.770393208933,
    "output_throughput": 568.6178868318092,
    "total_throughput": 1209.3882800407423,
    "itl": 23.65362202842273,
    "ttft": 5756.767899309134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.98976645587515,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1192907360382378. Arrivals time: 0.035362737718969584 Scheduler time: 0.7108881347812712 Scheduler overhead time: 0.12780839344486594 Adapter cache time: 0.05904786940664053 Engine time: 0.12408166145905852 
