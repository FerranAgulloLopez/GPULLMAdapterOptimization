INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.738690016325563,
    "estimated_duration": 3600.0717736042952,
    "input_throughput": 3988.641311343568,
    "output_throughput": 3477.1242872936996,
    "total_throughput": 7465.765598637267,
    "itl": 99.25985511332085,
    "ttft": 2261589.107581381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.214949856363038,
    "arrivals": 923294,
    "finished_requests": 58219,
    "scheduler_time": 121.30923709881475
}
#Debug simulation 
Total elapsed time: 4.73879742436111. Arrivals time: 0.2717466866597533 Scheduler time: 4.29311155108735 Scheduler overhead time: 0.05175720155239105 Adapter cache time: 0.04513462632894516 Engine time: 0.05294389184564352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.889242295641452,
    "estimated_duration": 3600.1270202774704,
    "input_throughput": 4670.6240933421395,
    "output_throughput": 4082.2256873779147,
    "total_throughput": 8752.849780720055,
    "itl": 135.26396545757075,
    "ttft": 2183901.1358579136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.0172922190745695,
    "arrivals": 921863,
    "finished_requests": 68154,
    "scheduler_time": 111.5728813291436
}
#Debug simulation 
Total elapsed time: 5.8893482787534595. Arrivals time: 0.32742651365697384 Scheduler time: 5.439785003662109 Scheduler overhead time: 0.041075433138757944 Adapter cache time: 0.020482569467276335 Engine time: 0.04165527084842324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.517384365666658,
    "estimated_duration": 3600.0220222357525,
    "input_throughput": 4491.726133930039,
    "output_throughput": 3925.7084853117335,
    "total_throughput": 8417.434619241772,
    "itl": 123.62332830187931,
    "ttft": 2204719.8255296256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.19003333788831,
    "arrivals": 921863,
    "finished_requests": 65549,
    "scheduler_time": 114.14204216011849
}
#Debug simulation 
Total elapsed time: 5.5174817349761724. Arrivals time: 0.32785159815102816 Scheduler time: 5.056455981917679 Scheduler overhead time: 0.04402960417792201 Adapter cache time: 0.024587260093539953 Engine time: 0.04423885978758335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.714474006090313,
    "estimated_duration": 3600.0366468670313,
    "input_throughput": 3975.0370353739777,
    "output_throughput": 3476.804051673396,
    "total_throughput": 7451.841087047374,
    "itl": 99.55057421159624,
    "ttft": 2263888.8249929287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.291166073083698,
    "arrivals": 921863,
    "finished_requests": 57920,
    "scheduler_time": 121.3178608131112
}
#Debug simulation 
Total elapsed time: 4.714576941914856. Arrivals time: 0.3090438353829086 Scheduler time: 4.231400588527322 Scheduler overhead time: 0.05167321767657995 Adapter cache time: 0.045623577665537596 Engine time: 0.0525855366140604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.547010710928589,
    "estimated_duration": 3600.0640159656573,
    "input_throughput": 4488.783790603061,
    "output_throughput": 3924.228551866609,
    "total_throughput": 8413.01234246967,
    "itl": 123.48190000714122,
    "ttft": 2204249.979999223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.583683058721931,
    "arrivals": 921863,
    "finished_requests": 65505,
    "scheduler_time": 114.1956994722558
}
#Debug simulation 
Total elapsed time: 5.547122317831963. Arrivals time: 0.24802964832633734 Scheduler time: 5.165769929531962 Scheduler overhead time: 0.04393319273367524 Adapter cache time: 0.024715587496757507 Engine time: 0.044431861490011215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.725080093834549,
    "estimated_duration": 3600.081682588935,
    "input_throughput": 3975.318690465978,
    "output_throughput": 3476.8797220730235,
    "total_throughput": 7452.198412539002,
    "itl": 99.54657867135981,
    "ttft": 2263919.5805646023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.132100081443593,
    "arrivals": 921863,
    "finished_requests": 57923,
    "scheduler_time": 121.32478736802534
}
#Debug simulation 
Total elapsed time: 4.725177505984902. Arrivals time: 0.21879075095057487 Scheduler time: 4.332544863689691 Scheduler overhead time: 0.05154397198930383 Adapter cache time: 0.045587314292788506 Engine time: 0.052611024118959904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.468221792019904,
    "estimated_duration": 3600.1159946252237,
    "input_throughput": 4493.002732175542,
    "output_throughput": 3927.245961271267,
    "total_throughput": 8420.248693446809,
    "itl": 123.59305730524966,
    "ttft": 2204556.003813891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1946789000229545,
    "arrivals": 921863,
    "finished_requests": 65573,
    "scheduler_time": 114.17501243157594
}
#Debug simulation 
Total elapsed time: 5.468341482337564. Arrivals time: 0.3380265748128295 Scheduler time: 4.9980647270567715 Scheduler overhead time: 0.04361743852496147 Adapter cache time: 0.024440700188279152 Engine time: 0.04403806431218982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.712313582189381,
    "estimated_duration": 3600.031291408952,
    "input_throughput": 3975.7104428940715,
    "output_throughput": 3477.080610346851,
    "total_throughput": 7452.791053240922,
    "itl": 99.54085613134903,
    "ttft": 2263936.3768989276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.979661839455154,
    "arrivals": 921863,
    "finished_requests": 57926,
    "scheduler_time": 121.32816246990768
}
#Debug simulation 
Total elapsed time: 4.712454521097243. Arrivals time: 0.30866248020902276 Scheduler time: 4.230263013858348 Scheduler overhead time: 0.05163502413779497 Adapter cache time: 0.04563704691827297 Engine time: 0.052111181896179914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.189076853916049,
    "estimated_duration": 3600.0807198391844,
    "input_throughput": 4668.3367146142045,
    "output_throughput": 4076.426097650264,
    "total_throughput": 8744.76281226447,
    "itl": 134.55535403519514,
    "ttft": 2178194.752363901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.646997313285361,
    "arrivals": 921076,
    "finished_requests": 68107,
    "scheduler_time": 111.64661542100937
}
#Debug simulation 
Total elapsed time: 6.18917400483042. Arrivals time: 0.6947182035073638 Scheduler time: 5.373875843826681 Scheduler overhead time: 0.040743240155279636 Adapter cache time: 0.019695176742970943 Engine time: 0.041359382681548595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.531228665262461,
    "estimated_duration": 3600.056725043972,
    "input_throughput": 4484.623224875103,
    "output_throughput": 3917.8352112848233,
    "total_throughput": 8402.458436159926,
    "itl": 122.779099330954,
    "ttft": 2198160.4924064996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.749533315305608,
    "arrivals": 921076,
    "finished_requests": 65437,
    "scheduler_time": 114.28058677897474
}
#Debug simulation 
Total elapsed time: 5.531341781374067. Arrivals time: 0.3288838262669742 Scheduler time: 5.06931909872219 Scheduler overhead time: 0.04429375799372792 Adapter cache time: 0.02381016407161951 Engine time: 0.04459859291091561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.735515101347119,
    "estimated_duration": 3600.010713660507,
    "input_throughput": 3958.6665522751387,
    "output_throughput": 3473.5638292823287,
    "total_throughput": 7432.230381557467,
    "itl": 99.00673930899076,
    "ttft": 2259006.711306394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.924651214484836,
    "arrivals": 921076,
    "finished_requests": 57920,
    "scheduler_time": 121.39697159160858
}
#Debug simulation 
Total elapsed time: 4.735609166324139. Arrivals time: 0.3106751558370888 Scheduler time: 4.251647642813623 Scheduler overhead time: 0.0520305261015892 Adapter cache time: 0.044213596265763044 Engine time: 0.052832034416496754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.494911465793848,
    "estimated_duration": 3600.1290233676614,
    "input_throughput": 4486.161161216419,
    "output_throughput": 3919.9325658609296,
    "total_throughput": 8406.093727077348,
    "itl": 122.85358074056103,
    "ttft": 2197666.6418076265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.595619863555753,
    "arrivals": 921076,
    "finished_requests": 65460,
    "scheduler_time": 114.26857067465467
}
#Debug simulation 
Total elapsed time: 5.495002471841872. Arrivals time: 0.32974595902487636 Scheduler time: 5.031479601748288 Scheduler overhead time: 0.04414729680866003 Adapter cache time: 0.02467151079326868 Engine time: 0.044451108667999506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.717744048219174,
    "estimated_duration": 3600.0722281221997,
    "input_throughput": 3958.9400147768974,
    "output_throughput": 3473.704750230226,
    "total_throughput": 7432.644765007124,
    "itl": 99.00293233446179,
    "ttft": 2258941.039248083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.76309981672535,
    "arrivals": 921076,
    "finished_requests": 57923,
    "scheduler_time": 121.40437172144188
}
#Debug simulation 
Total elapsed time: 4.717890934087336. Arrivals time: 0.21889468701556325 Scheduler time: 4.3256410588510334 Scheduler overhead time: 0.05173975229263306 Adapter cache time: 0.044717841781675816 Engine time: 0.05256941495463252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.532244544010609,
    "estimated_duration": 3600.0455657436614,
    "input_throughput": 4487.140983356717,
    "output_throughput": 3921.013148922212,
    "total_throughput": 8408.154132278929,
    "itl": 122.83907061259909,
    "ttft": 2197649.0625582733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1180718487361085,
    "arrivals": 921076,
    "finished_requests": 65478,
    "scheduler_time": 114.28023923823196
}
#Debug simulation 
Total elapsed time: 5.532332898583263. Arrivals time: 0.2422447488643229 Scheduler time: 5.1560171456076205 Scheduler overhead time: 0.04412675695493817 Adapter cache time: 0.024602628778666258 Engine time: 0.04492890276014805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.697130053304136,
    "estimated_duration": 3600.0440357072835,
    "input_throughput": 3959.1262936315097,
    "output_throughput": 3473.8283409755622,
    "total_throughput": 7432.954634607072,
    "itl": 98.99909614895991,
    "ttft": 2258885.4318132354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.623035239837805,
    "arrivals": 921076,
    "finished_requests": 57924,
    "scheduler_time": 121.40795251123872
}
#Debug simulation 
Total elapsed time: 4.697223830036819. Arrivals time: 0.21376060973852873 Scheduler time: 4.310289313085377 Scheduler overhead time: 0.051684622187167406 Adapter cache time: 0.0446763401851058 Engine time: 0.05254183150827885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.834771600086242,
    "estimated_duration": 3600.0018667310933,
    "input_throughput": 4702.196172851166,
    "output_throughput": 4079.0073293306077,
    "total_throughput": 8781.203502181774,
    "itl": 135.08260828232633,
    "ttft": 2172859.4839479555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.123598227915613,
    "arrivals": 851723,
    "finished_requests": 68409,
    "scheduler_time": 111.35350834460797
}
#Debug simulation 
Total elapsed time: 5.834876439999789. Arrivals time: 0.2494054907001555 Scheduler time: 5.455601417925209 Scheduler overhead time: 0.040956060867756605 Adapter cache time: 0.0288551882840693 Engine time: 0.04112692968919873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.480344284325838,
    "estimated_duration": 3600.110434540975,
    "input_throughput": 4518.805824375841,
    "output_throughput": 3920.9477755367284,
    "total_throughput": 8439.75359991257,
    "itl": 123.51417560485632,
    "ttft": 2193788.7352278624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.974659836054546,
    "arrivals": 851723,
    "finished_requests": 65730,
    "scheduler_time": 113.86739971879074
}
#Debug simulation 
Total elapsed time: 5.480452976189554. Arrivals time: 0.24480409268289804 Scheduler time: 5.091227571014315 Scheduler overhead time: 0.04407315468415618 Adapter cache time: 0.03549860883504152 Engine time: 0.04450785741209984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.617920912336558,
    "estimated_duration": 3600.01328311287,
    "input_throughput": 4002.9477301093025,
    "output_throughput": 3466.4713762415136,
    "total_throughput": 7469.419106350816,
    "itl": 99.36817524086834,
    "ttft": 2255328.8525206554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.286523085693748,
    "arrivals": 851723,
    "finished_requests": 58113,
    "scheduler_time": 120.94330124801282
}
#Debug simulation 
Total elapsed time: 4.618018353357911. Arrivals time: 0.22637844271957874 Scheduler time: 4.202459016814828 Scheduler overhead time: 0.051554582081735134 Adapter cache time: 0.06088193040341139 Engine time: 0.052487877663224936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.825367414858192,
    "estimated_duration": 3600.032577374609,
    "input_throughput": 4519.934931218482,
    "output_throughput": 3922.0881190739155,
    "total_throughput": 8442.023050292399,
    "itl": 123.48407173266726,
    "ttft": 2193640.2446331102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.038441716116147,
    "arrivals": 851723,
    "finished_requests": 65751,
    "scheduler_time": 113.89341237189453
}
#Debug simulation 
Total elapsed time: 5.825431799981743. Arrivals time: 0.5605016956105828 Scheduler time: 5.121144191361964 Scheduler overhead time: 0.04369814973324537 Adapter cache time: 0.03527904534712434 Engine time: 0.04449063679203391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.574980864766985,
    "estimated_duration": 3600.086253459424,
    "input_throughput": 4003.531578208741,
    "output_throughput": 3466.786660460403,
    "total_throughput": 7470.318238669143,
    "itl": 99.35828701661056,
    "ttft": 2255438.3140538945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.041089231405305,
    "arrivals": 851723,
    "finished_requests": 58122,
    "scheduler_time": 120.95404501705592
}
#Debug simulation 
Total elapsed time: 4.575074624735862. Arrivals time: 0.21278557507321239 Scheduler time: 4.173026031814516 Scheduler overhead time: 0.05142821976915002 Adapter cache time: 0.061375696677714586 Engine time: 0.05239012138918042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.528284138068557,
    "estimated_duration": 3600.033752114807,
    "input_throughput": 4520.517339716601,
    "output_throughput": 3922.709055631555,
    "total_throughput": 8443.226395348156,
    "itl": 123.4565064403243,
    "ttft": 2193478.522815522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.186905075549666,
    "arrivals": 851723,
    "finished_requests": 65759,
    "scheduler_time": 113.91917582387131
}
#Debug simulation 
Total elapsed time: 5.528373266104609. Arrivals time: 0.2325544124469161 Scheduler time: 5.149490003939718 Scheduler overhead time: 0.04487387230619788 Adapter cache time: 0.03582269512116909 Engine time: 0.045037658885121346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.611326653044671,
    "estimated_duration": 3600.0606335957173,
    "input_throughput": 4003.701733657697,
    "output_throughput": 3466.811887424886,
    "total_throughput": 7470.513621082583,
    "itl": 99.35100998808747,
    "ttft": 2255461.1086522904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.803111595474995,
    "arrivals": 851723,
    "finished_requests": 58123,
    "scheduler_time": 120.96112707313169
}
#Debug simulation 
Total elapsed time: 4.6114470032043755. Arrivals time: 0.2133323885500431 Scheduler time: 4.20841013872996 Scheduler overhead time: 0.05167362978681922 Adapter cache time: 0.06133566331118345 Engine time: 0.05247778259217739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.519789758138359,
    "estimated_duration": 3600.071551685284,
    "input_throughput": 4653.562508266656,
    "output_throughput": 4074.5365166793003,
    "total_throughput": 8728.099024945956,
    "itl": 135.26451808039272,
    "ttft": 2172091.010159345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.996436220133033,
    "arrivals": 839966,
    "finished_requests": 67999,
    "scheduler_time": 111.34933730363412
}
#Debug simulation 
Total elapsed time: 5.519883751869202. Arrivals time: 0.23463583644479513 Scheduler time: 5.153313055168837 Scheduler overhead time: 0.041021900717169046 Adapter cache time: 0.03078456223011017 Engine time: 0.04124975483864546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.18836994888261,
    "estimated_duration": 3600.0527905873805,
    "input_throughput": 4472.830243517831,
    "output_throughput": 3917.8703259233926,
    "total_throughput": 8390.700569441224,
    "itl": 123.77111750455431,
    "ttft": 2193609.816714283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.294223976586665,
    "arrivals": 839966,
    "finished_requests": 65384,
    "scheduler_time": 113.83794770787229
}
#Debug simulation 
Total elapsed time: 5.188486922997981. Arrivals time: 0.2310425085015595 Scheduler time: 4.810768240131438 Scheduler overhead time: 0.043905703350901604 Adapter cache time: 0.03797967033460736 Engine time: 0.044428542256355286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.778439802117646,
    "estimated_duration": 3600.1090625307693,
    "input_throughput": 3964.980991427395,
    "output_throughput": 3471.9678717769875,
    "total_throughput": 7436.948863204382,
    "itl": 99.66017616338769,
    "ttft": 2255998.197752241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.638134742468655,
    "arrivals": 839966,
    "finished_requests": 57890,
    "scheduler_time": 120.97452864854067
}
#Debug simulation 
Total elapsed time: 4.778502907138318. Arrivals time: 0.5398590886034071 Scheduler time: 4.0472367173060775 Scheduler overhead time: 0.051212544552981853 Adapter cache time: 0.06400869600474834 Engine time: 0.052144605666399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.235372812021524,
    "estimated_duration": 3600.0936063007885,
    "input_throughput": 4473.5120141913385,
    "output_throughput": 3918.566999288557,
    "total_throughput": 8392.079013479895,
    "itl": 123.73535418554597,
    "ttft": 2193552.051491281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.271105119255648,
    "arrivals": 839966,
    "finished_requests": 65400,
    "scheduler_time": 113.87117748820228
}
#Debug simulation 
Total elapsed time: 5.235492929816246. Arrivals time: 0.2307494143024087 Scheduler time: 4.857700476422906 Scheduler overhead time: 0.043846466578543186 Adapter cache time: 0.03833990404382348 Engine time: 0.04445750033482909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.516307782847434,
    "estimated_duration": 3600.06286987738,
    "input_throughput": 3965.0443661519153,
    "output_throughput": 3472.0346426688216,
    "total_throughput": 7437.079008820737,
    "itl": 99.65289650474004,
    "ttft": 2255902.9077717937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.369710881575983,
    "arrivals": 839966,
    "finished_requests": 57891,
    "scheduler_time": 120.98186472784427
}
#Debug simulation 
Total elapsed time: 4.516397695988417. Arrivals time: 0.26271980721503496 Scheduler time: 4.061668572481722 Scheduler overhead time: 0.051422561053186655 Adapter cache time: 0.06386915547773242 Engine time: 0.05260226083919406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.180014716926962,
    "estimated_duration": 3600.115495634974,
    "input_throughput": 4474.147848737011,
    "output_throughput": 3919.4628664298566,
    "total_throughput": 8393.610715166868,
    "itl": 123.70691091415638,
    "ttft": 2193229.6287550265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.374314370495943,
    "arrivals": 839966,
    "finished_requests": 65411,
    "scheduler_time": 113.89984638299104
}
#Debug simulation 
Total elapsed time: 5.180163429118693. Arrivals time: 0.22976540075615048 Scheduler time: 4.803525694645941 Scheduler overhead time: 0.04395559709519148 Adapter cache time: 0.038040620274841785 Engine time: 0.04444720456376672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.470810753758997,
    "estimated_duration": 3600.0604525924637,
    "input_throughput": 3965.180081829019,
    "output_throughput": 3472.2147487824573,
    "total_throughput": 7437.394830611476,
    "itl": 99.64683045340215,
    "ttft": 2255831.9156065406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.145401482787936,
    "arrivals": 839966,
    "finished_requests": 57893,
    "scheduler_time": 120.98919923674552
}
#Debug simulation 
Total elapsed time: 4.470904218964279. Arrivals time: 0.21252487832680345 Scheduler time: 4.065964471548796 Scheduler overhead time: 0.051516885869205 Adapter cache time: 0.064144984818995 Engine time: 0.052444560918956995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.44741339283064,
    "estimated_duration": 3600.149532018062,
    "input_throughput": 4689.345220207176,
    "output_throughput": 4077.269532682943,
    "total_throughput": 8766.614752890118,
    "itl": 135.00629086477497,
    "ttft": 2167184.188248886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.321970498874117,
    "arrivals": 834363,
    "finished_requests": 68549,
    "scheduler_time": 111.35108035478413
}
#Debug simulation 
Total elapsed time: 5.447512673214078. Arrivals time: 0.33039005333557725 Scheduler time: 4.987101790960878 Scheduler overhead time: 0.040754325222224 Adapter cache time: 0.02903149090707302 Engine time: 0.04122676234692335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.2125955750234425,
    "estimated_duration": 3600.022470588245,
    "input_throughput": 4502.696339379046,
    "output_throughput": 3915.666114633065,
    "total_throughput": 8418.36245401211,
    "itl": 123.2954395021813,
    "ttft": 2188217.1182698812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.54976990463189,
    "arrivals": 834363,
    "finished_requests": 65820,
    "scheduler_time": 113.88430574604746
}
#Debug simulation 
Total elapsed time: 5.212720932904631. Arrivals time: 0.3656441937200725 Scheduler time: 4.701414759270847 Scheduler overhead time: 0.04406001139432192 Adapter cache time: 0.03641302138566971 Engine time: 0.04472752660512924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.886047136038542,
    "estimated_duration": 3600.035719616301,
    "input_throughput": 4002.1730677537917,
    "output_throughput": 3479.395199260701,
    "total_throughput": 7481.568267014492,
    "itl": 99.2037930607886,
    "ttft": 2252053.915881683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.74417229358197,
    "arrivals": 834363,
    "finished_requests": 58542,
    "scheduler_time": 121.22092482534353
}
#Debug simulation 
Total elapsed time: 4.88614415936172. Arrivals time: 0.6415869784541428 Scheduler time: 4.0524010974913836 Scheduler overhead time: 0.051589058712124825 Adapter cache time: 0.06342048104852438 Engine time: 0.0528601398691535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.175434057135135,
    "estimated_duration": 3600.128308060223,
    "input_throughput": 4508.458757889494,
    "output_throughput": 3920.2752769676868,
    "total_throughput": 8428.734034857182,
    "itl": 123.4811008960688,
    "ttft": 2188075.0686280956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1966,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.397603362882752,
    "arrivals": 834363,
    "finished_requests": 65912,
    "scheduler_time": 113.86878828961665
}
#Debug simulation 
Total elapsed time: 5.175581371411681. Arrivals time: 0.3175487946718931 Scheduler time: 4.712856211699545 Scheduler overhead time: 0.04389588441699743 Adapter cache time: 0.03596310596913099 Engine time: 0.04466600902378559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.52445086510852,
    "estimated_duration": 3600.1078910822716,
    "input_throughput": 4002.29616331538,
    "output_throughput": 3479.4812763887076,
    "total_throughput": 7481.777439704088,
    "itl": 99.19741419581024,
    "ttft": 2251989.0087700975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.49169645528863,
    "arrivals": 834363,
    "finished_requests": 58545,
    "scheduler_time": 121.23183627967121
}
#Debug simulation 
Total elapsed time: 4.52456857310608. Arrivals time: 0.29797087982296944 Scheduler time: 4.034420917276293 Scheduler overhead time: 0.05142285814508796 Adapter cache time: 0.06384103046730161 Engine time: 0.052597285714000463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.169605055823922,
    "estimated_duration": 3600.1084967689744,
    "input_throughput": 4509.472704661602,
    "output_throughput": 3921.1504355130787,
    "total_throughput": 8430.62314017468,
    "itl": 123.45423577903414,
    "ttft": 2187839.193240757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1966,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.550788569162235,
    "arrivals": 834363,
    "finished_requests": 65925,
    "scheduler_time": 113.89415810554507
}
#Debug simulation 
Total elapsed time: 5.169723965693265. Arrivals time: 0.3165563466027379 Scheduler time: 4.708596548065543 Scheduler overhead time: 0.04377748258411884 Adapter cache time: 0.03613262576982379 Engine time: 0.044300530571490526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.515135690104216,
    "estimated_duration": 3600.099319252015,
    "input_throughput": 4002.4612440397286,
    "output_throughput": 3479.5848361768744,
    "total_throughput": 7482.0460802166035,
    "itl": 99.19161712163454,
    "ttft": 2251899.98411214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.26780278736812,
    "arrivals": 834363,
    "finished_requests": 58548,
    "scheduler_time": 121.23901345373353
}
#Debug simulation 
Total elapsed time: 4.51522650802508. Arrivals time: 0.3017877000384033 Scheduler time: 4.022050439380109 Scheduler overhead time: 0.05122389039024711 Adapter cache time: 0.06357430620118976 Engine time: 0.05245025688782334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.245589618105441,
    "estimated_duration": 3600.1188925309025,
    "input_throughput": 4669.652170343065,
    "output_throughput": 4078.4836385438803,
    "total_throughput": 8748.135808886946,
    "itl": 135.11919944263744,
    "ttft": 2170819.9623247394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.077311364691962,
    "arrivals": 831492,
    "finished_requests": 68193,
    "scheduler_time": 111.36442463563722
}
#Debug simulation 
Total elapsed time: 5.24568331008777. Arrivals time: 0.23584726871922612 Scheduler time: 4.879826596006751 Scheduler overhead time: 0.04064647760242224 Adapter cache time: 0.029293242376297712 Engine time: 0.04109613038599491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.011689629871398,
    "estimated_duration": 3600.0476516293616,
    "input_throughput": 4483.619818947275,
    "output_throughput": 3918.746462596112,
    "total_throughput": 8402.366281543387,
    "itl": 123.59395875073783,
    "ttft": 2191345.4409311265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.031538985227032,
    "arrivals": 831492,
    "finished_requests": 65511,
    "scheduler_time": 113.85558260284543
}
#Debug simulation 
Total elapsed time: 5.011834632139653. Arrivals time: 0.22652703244239092 Scheduler time: 4.641834325157106 Scheduler overhead time: 0.04345534602180123 Adapter cache time: 0.03550675045698881 Engine time: 0.04421822912991047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.391495241783559,
    "estimated_duration": 3600.0879680651037,
    "input_throughput": 3981.38604588142,
    "output_throughput": 3489.5650082550474,
    "total_throughput": 7470.951054136467,
    "itl": 99.33750231974595,
    "ttft": 2250474.271086533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.986112244530354,
    "arrivals": 831492,
    "finished_requests": 58218,
    "scheduler_time": 121.41432844774171
}
#Debug simulation 
Total elapsed time: 4.391586881130934. Arrivals time: 0.2106372364796698 Scheduler time: 3.9915573806501925 Scheduler overhead time: 0.05078216316178441 Adapter cache time: 0.06255101831629872 Engine time: 0.05199821200221777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.311379382852465,
    "estimated_duration": 3600.0820847956925,
    "input_throughput": 4485.177176429952,
    "output_throughput": 3919.97923036271,
    "total_throughput": 8405.156406792663,
    "itl": 123.56463925666927,
    "ttft": 2191272.679830603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.113924921867648,
    "arrivals": 831492,
    "finished_requests": 65530,
    "scheduler_time": 113.88487889107968
}
#Debug simulation 
Total elapsed time: 5.311445613857359. Arrivals time: 0.5597125836648047 Scheduler time: 4.608551804441959 Scheduler overhead time: 0.043470578733831644 Adapter cache time: 0.03551569581031799 Engine time: 0.04402896109968424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.443500460591167,
    "estimated_duration": 3600.0724719411833,
    "input_throughput": 3981.6262343938133,
    "output_throughput": 3489.798357649634,
    "total_throughput": 7471.424592043447,
    "itl": 99.33146785447215,
    "ttft": 2250377.002875563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.746684788363734,
    "arrivals": 831492,
    "finished_requests": 58222,
    "scheduler_time": 121.42167703563824
}
#Debug simulation 
Total elapsed time: 4.443617197684944. Arrivals time: 0.21198217198252678 Scheduler time: 4.040842674672604 Scheduler overhead time: 0.05133568961173296 Adapter cache time: 0.06281181517988443 Engine time: 0.05251390067860484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.051291229669005,
    "estimated_duration": 3600.0883006167924,
    "input_throughput": 4485.7674733237,
    "output_throughput": 3920.636612602469,
    "total_throughput": 8406.404085926168,
    "itl": 123.5388595246879,
    "ttft": 2191042.622427506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.30181565247995,
    "arrivals": 831492,
    "finished_requests": 65538,
    "scheduler_time": 113.91000837577148
}
#Debug simulation 
Total elapsed time: 5.051381703931838. Arrivals time: 0.281085938680917 Scheduler time: 4.626611582934856 Scheduler overhead time: 0.043565018102526665 Adapter cache time: 0.03542998246848583 Engine time: 0.04439568519592285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.426301412284374,
    "estimated_duration": 3600.088215188602,
    "input_throughput": 3981.743263824171,
    "output_throughput": 3490.1891978615704,
    "total_throughput": 7471.932461685742,
    "itl": 99.32491933474157,
    "ttft": 2250381.683568663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.539153377395785,
    "arrivals": 831492,
    "finished_requests": 58228,
    "scheduler_time": 121.42904399613543
}
#Debug simulation 
Total elapsed time: 4.426392639987171. Arrivals time: 0.2116713784635067 Scheduler time: 4.02508695749566 Scheduler overhead time: 0.05109051102772355 Adapter cache time: 0.06210175435990095 Engine time: 0.05231904052197933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.252008086070418,
    "estimated_duration": 3600.104425299762,
    "input_throughput": 4679.8614733507775,
    "output_throughput": 4074.262373313988,
    "total_throughput": 8754.123846664766,
    "itl": 134.53988387557104,
    "ttft": 2176253.504181332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.01118727437246,
    "arrivals": 830076,
    "finished_requests": 68175,
    "scheduler_time": 111.44762444792502
}
#Debug simulation 
Total elapsed time: 5.252099065110087. Arrivals time: 0.24400185141712427 Scheduler time: 4.877746054902673 Scheduler overhead time: 0.041032664477825165 Adapter cache time: 0.02867879206314683 Engine time: 0.04174097580835223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.97422623867169,
    "estimated_duration": 3600.0137140015695,
    "input_throughput": 4498.768417745238,
    "output_throughput": 3919.20562555775,
    "total_throughput": 8417.97404330299,
    "itl": 123.32438973997574,
    "ttft": 2196665.589216956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1871,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.647663214062138,
    "arrivals": 830076,
    "finished_requests": 65516,
    "scheduler_time": 113.88382281452225
}
#Debug simulation 
Total elapsed time: 4.974318108055741. Arrivals time: 0.23512585135176778 Scheduler time: 4.59707320574671 Scheduler overhead time: 0.04352314630523324 Adapter cache time: 0.034569313284009695 Engine time: 0.04378735739737749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.405821563210338,
    "estimated_duration": 3600.0498769793335,
    "input_throughput": 3996.1904672474034,
    "output_throughput": 3490.157478190997,
    "total_throughput": 7486.3479454384005,
    "itl": 98.87509412016371,
    "ttft": 2254443.3626254373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.719459920605413,
    "arrivals": 830076,
    "finished_requests": 58197,
    "scheduler_time": 121.59565910748708
}
#Debug simulation 
Total elapsed time: 4.405911304056644. Arrivals time: 0.21949446946382523 Scheduler time: 3.9973150230944157 Scheduler overhead time: 0.05113022355362773 Adapter cache time: 0.06128896214067936 Engine time: 0.052655994426459074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.9934867369011045,
    "estimated_duration": 3600.1231907362708,
    "input_throughput": 4497.8174751537845,
    "output_throughput": 3918.451745290127,
    "total_throughput": 8416.269220443912,
    "itl": 123.18928683380955,
    "ttft": 2196532.850241372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.747264986308497,
    "arrivals": 830076,
    "finished_requests": 65507,
    "scheduler_time": 113.9419712183777
}
#Debug simulation 
Total elapsed time: 4.993583937641233. Arrivals time: 0.22977445600554347 Scheduler time: 4.619810496456921 Scheduler overhead time: 0.04393751407042146 Adapter cache time: 0.03525177063420415 Engine time: 0.04424957511946559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.421422989107668,
    "estimated_duration": 3600.0329339405644,
    "input_throughput": 3996.209552520032,
    "output_throughput": 3490.274180977103,
    "total_throughput": 7486.483733497134,
    "itl": 98.8688376401312,
    "ttft": 2254376.0317623853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.485831745384008,
    "arrivals": 830076,
    "finished_requests": 58198,
    "scheduler_time": 121.60286876045824
}
#Debug simulation 
Total elapsed time: 4.421575214713812. Arrivals time: 0.21349279722198844 Scheduler time: 4.019002648536116 Scheduler overhead time: 0.051198200322687626 Adapter cache time: 0.06129929330199957 Engine time: 0.05238082818686962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.96594017976895,
    "estimated_duration": 3600.008285076024,
    "input_throughput": 4498.528813707439,
    "output_throughput": 3918.933203150133,
    "total_throughput": 8417.462016857573,
    "itl": 123.16368184958739,
    "ttft": 2196272.991315143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.937932158867381,
    "arrivals": 830076,
    "finished_requests": 65514,
    "scheduler_time": 113.96296994176907
}
#Debug simulation 
Total elapsed time: 4.966035427991301. Arrivals time: 0.22618442820385098 Scheduler time: 4.596946633886546 Scheduler overhead time: 0.04355807229876518 Adapter cache time: 0.034832453820854425 Engine time: 0.044130397494882345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.507805065717548,
    "estimated_duration": 3600.0365290801433,
    "input_throughput": 3996.265005587594,
    "output_throughput": 3490.389027583189,
    "total_throughput": 7486.654033170783,
    "itl": 98.8631731339905,
    "ttft": 2254311.2272504936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.27395087370715,
    "arrivals": 830076,
    "finished_requests": 58200,
    "scheduler_time": 121.61006735643659
}
#Debug simulation 
Total elapsed time: 4.507901198696345. Arrivals time: 0.20860507665202022 Scheduler time: 4.109843518584967 Scheduler overhead time: 0.05104899499565363 Adapter cache time: 0.061190633568912745 Engine time: 0.05310395639389753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.178162612020969,
    "estimated_duration": 3600.046979815533,
    "input_throughput": 4678.399224907617,
    "output_throughput": 4070.6649335867564,
    "total_throughput": 8749.064158494373,
    "itl": 134.45155823830618,
    "ttft": 2166645.528143258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.097148591787812,
    "arrivals": 829350,
    "finished_requests": 68203,
    "scheduler_time": 111.4435373948458
}
#Debug simulation 
Total elapsed time: 5.178253397811204. Arrivals time: 0.23227977845817804 Scheduler time: 4.816125074401498 Scheduler overhead time: 0.040888098534196615 Adapter cache time: 0.028935848269611597 Engine time: 0.04109459137544036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.936100725084543,
    "estimated_duration": 3600.0780357100193,
    "input_throughput": 4493.077605416358,
    "output_throughput": 3914.523479828018,
    "total_throughput": 8407.601085244376,
    "itl": 123.00467993174452,
    "ttft": 2188324.416703793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.132019646181536,
    "arrivals": 829350,
    "finished_requests": 65550,
    "scheduler_time": 113.9406484174667
}
#Debug simulation 
Total elapsed time: 4.936208426952362. Arrivals time: 0.229499788954854 Scheduler time: 4.562423957046121 Scheduler overhead time: 0.04376488132402301 Adapter cache time: 0.035517639480531216 Engine time: 0.044653024058789015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.411754248663783,
    "estimated_duration": 3600.1006978960727,
    "input_throughput": 3991.1828045246507,
    "output_throughput": 3490.066821559421,
    "total_throughput": 7481.249626084072,
    "itl": 98.59293617326878,
    "ttft": 2246199.160623041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.227145500817024,
    "arrivals": 829350,
    "finished_requests": 58340,
    "scheduler_time": 121.80837823639023
}
#Debug simulation 
Total elapsed time: 4.411888659000397. Arrivals time: 0.20850196573883295 Scheduler time: 4.013066763058305 Scheduler overhead time: 0.05124417692422867 Adapter cache time: 0.061760630924254656 Engine time: 0.05308099975809455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.951692148111761,
    "estimated_duration": 3600.133122671564,
    "input_throughput": 4493.954653541843,
    "output_throughput": 3915.2699413348655,
    "total_throughput": 8409.224594876709,
    "itl": 122.9764979619066,
    "ttft": 2187985.3530143932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.226899571581994,
    "arrivals": 829350,
    "finished_requests": 65568,
    "scheduler_time": 113.97017271625026
}
#Debug simulation 
Total elapsed time: 4.95178146706894. Arrivals time: 0.22943390300497413 Scheduler time: 4.57830646308139 Scheduler overhead time: 0.04381605703383684 Adapter cache time: 0.03557116258889437 Engine time: 0.04434870649129152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.434496894013137,
    "estimated_duration": 3600.086832291544,
    "input_throughput": 3991.282341057813,
    "output_throughput": 3490.0894298714197,
    "total_throughput": 7481.371770929233,
    "itl": 98.58651082536781,
    "ttft": 2246227.5618028273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.994345794302077,
    "arrivals": 829350,
    "finished_requests": 58341,
    "scheduler_time": 121.81562368086054
}
#Debug simulation 
Total elapsed time: 4.43459064187482. Arrivals time: 0.21605616668239236 Scheduler time: 4.027791688684374 Scheduler overhead time: 0.05159258237108588 Adapter cache time: 0.06217424711212516 Engine time: 0.05270594730973244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.93171067815274,
    "estimated_duration": 3600.111412010455,
    "input_throughput": 4495.142274211653,
    "output_throughput": 3916.6885094052336,
    "total_throughput": 8411.830783616886,
    "itl": 122.95039960123495,
    "ttft": 2187842.7582295025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.39119054564795,
    "arrivals": 829350,
    "finished_requests": 65588,
    "scheduler_time": 113.99502575403945
}
#Debug simulation 
Total elapsed time: 4.9318321803584695. Arrivals time: 0.22924591647461057 Scheduler time: 4.5587385590188205 Scheduler overhead time: 0.043762026354670525 Adapter cache time: 0.03530285833403468 Engine time: 0.044379767030477524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.42841301811859,
    "estimated_duration": 3600.0991125151345,
    "input_throughput": 3991.523441686799,
    "output_throughput": 3490.2722417610044,
    "total_throughput": 7481.795683447803,
    "itl": 98.5810636687209,
    "ttft": 2246162.9255536757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.788057086393813,
    "arrivals": 829350,
    "finished_requests": 58343,
    "scheduler_time": 121.82284147807354
}
#Debug simulation 
Total elapsed time: 4.428500563837588. Arrivals time: 0.2178010563366115 Scheduler time: 4.021194458473474 Scheduler overhead time: 0.05127571290358901 Adapter cache time: 0.06167775532230735 Engine time: 0.05239662108942866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.090898205060512,
    "estimated_duration": 3600.0322293507897,
    "input_throughput": 4854.844869861572,
    "output_throughput": 4217.487798085084,
    "total_throughput": 9072.332667946657,
    "itl": 130.28598755477628,
    "ttft": 2143587.268355162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.869781676680294,
    "arrivals": 771049,
    "finished_requests": 70690,
    "scheduler_time": 115.17716130833506
}
#Debug simulation 
Total elapsed time: 5.091052713803947. Arrivals time: 0.23751809867098927 Scheduler time: 4.708430465776473 Scheduler overhead time: 0.0406341478228569 Adapter cache time: 0.04348291177302599 Engine time: 0.041739825159311295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.037456856109202,
    "estimated_duration": 3600.106950620577,
    "input_throughput": 4730.45446526648,
    "output_throughput": 4111.972839431396,
    "total_throughput": 8842.427304697876,
    "itl": 117.53796813183654,
    "ttft": 2158013.888829013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.193657943275397,
    "arrivals": 771049,
    "finished_requests": 68922,
    "scheduler_time": 119.41874911656278
}
#Debug simulation 
Total elapsed time: 5.037549112923443. Arrivals time: 0.24295552261173725 Scheduler time: 4.638049046974629 Scheduler overhead time: 0.04444095538929105 Adapter cache time: 0.04529987648129463 Engine time: 0.045720445457845926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.7012795698828995,
    "estimated_duration": 3600.0937031960516,
    "input_throughput": 4340.882290404363,
    "output_throughput": 3771.40877970659,
    "total_throughput": 8112.291070110953,
    "itl": 91.6819669288174,
    "ttft": 2204731.872473985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.290548114762327,
    "arrivals": 771049,
    "finished_requests": 63219,
    "scheduler_time": 131.14649483274908
}
#Debug simulation 
Total elapsed time: 4.701399004086852. Arrivals time: 0.221767068374902 Scheduler time: 4.292844356968999 Scheduler overhead time: 0.05415631225332618 Adapter cache time: 0.050646898336708546 Engine time: 0.056143993511796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.026076406240463,
    "estimated_duration": 3600.083322141902,
    "input_throughput": 4732.861568843544,
    "output_throughput": 4113.503403912685,
    "total_throughput": 8846.364972756228,
    "itl": 117.54921218220476,
    "ttft": 2157871.6849314612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.052814156334257,
    "arrivals": 771049,
    "finished_requests": 68950,
    "scheduler_time": 119.43814186142545
}
#Debug simulation 
Total elapsed time: 5.026167769916356. Arrivals time: 0.23599245538935065 Scheduler time: 4.633332623634487 Scheduler overhead time: 0.04442317318171263 Adapter cache time: 0.04546853853389621 Engine time: 0.0459220833145082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.739520876668394,
    "estimated_duration": 3600.0371875368505,
    "input_throughput": 4340.950436318245,
    "output_throughput": 3771.467985665362,
    "total_throughput": 8112.418421983607,
    "itl": 91.67779383258049,
    "ttft": 2204643.4549960867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.13251770900529,
    "arrivals": 771049,
    "finished_requests": 63219,
    "scheduler_time": 131.14999081321452
}
#Debug simulation 
Total elapsed time: 4.739609057083726. Arrivals time: 0.22275397507473826 Scheduler time: 4.329504608176649 Scheduler overhead time: 0.05435886699706316 Adapter cache time: 0.05071656685322523 Engine time: 0.05648817680776119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.045851218979806,
    "estimated_duration": 3600.0276534439636,
    "input_throughput": 4733.831414793955,
    "output_throughput": 4114.810892029883,
    "total_throughput": 8848.642306823838,
    "itl": 117.51630491347038,
    "ttft": 2157701.0530195613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.02136597316336,
    "arrivals": 771049,
    "finished_requests": 68965,
    "scheduler_time": 119.47125978246235
}
#Debug simulation 
Total elapsed time: 5.046012848149985. Arrivals time: 0.23633399792015553 Scheduler time: 4.652765751816332 Scheduler overhead time: 0.04449700517579913 Adapter cache time: 0.04569123778492212 Engine time: 0.045621843077242374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.727727234829217,
    "estimated_duration": 3600.0965953220566,
    "input_throughput": 4341.092130779875,
    "output_throughput": 3771.676576024013,
    "total_throughput": 8112.768706803888,
    "itl": 91.6746220840457,
    "ttft": 2204613.1765463557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.989192622787897,
    "arrivals": 771049,
    "finished_requests": 63222,
    "scheduler_time": 131.1571645397644
}
#Debug simulation 
Total elapsed time: 4.727816505823284. Arrivals time: 0.2692343979142606 Scheduler time: 4.27264995733276 Scheduler overhead time: 0.05397802451625466 Adapter cache time: 0.0505348164588213 Engine time: 0.055758267641067505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.2550573269836605,
    "estimated_duration": 3600.098908784625,
    "input_throughput": 5000.991210565956,
    "output_throughput": 4298.1544096586695,
    "total_throughput": 9299.145620224626,
    "itl": 127.99173273944261,
    "ttft": 2132259.870741144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1929,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.755337022631773,
    "arrivals": 765271,
    "finished_requests": 72425,
    "scheduler_time": 117.30163464151673
}
#Debug simulation 
Total elapsed time: 5.255149754229933. Arrivals time: 0.31945914682000875 Scheduler time: 4.794529487844557 Scheduler overhead time: 0.0412729037925601 Adapter cache time: 0.0379797350615263 Engine time: 0.042448482010513544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.19006583141163,
    "estimated_duration": 3600.107280310998,
    "input_throughput": 4868.165483803586,
    "output_throughput": 4183.890597476534,
    "total_throughput": 9052.05608128012,
    "itl": 115.53909175269541,
    "ttft": 2147516.046639125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.80422042019177,
    "arrivals": 765271,
    "finished_requests": 70489,
    "scheduler_time": 121.47412882172347
}
#Debug simulation 
Total elapsed time: 5.190153974108398. Arrivals time: 0.32192677445709705 Scheduler time: 4.71608570497483 Scheduler overhead time: 0.045057499315589666 Adapter cache time: 0.03908034786581993 Engine time: 0.04665164602920413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.847741578239948,
    "estimated_duration": 3600.0219179260826,
    "input_throughput": 4449.163467656663,
    "output_throughput": 3818.7217504274845,
    "total_throughput": 8267.885218084148,
    "itl": 90.42545540434857,
    "ttft": 2197150.9252292956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.92101705977206,
    "arrivals": 765271,
    "finished_requests": 64408,
    "scheduler_time": 132.87174513603202
}
#Debug simulation 
Total elapsed time: 4.847859003115445. Arrivals time: 0.346922290045768 Scheduler time: 4.3205191674642265 Scheduler overhead time: 0.054520856123417616 Adapter cache time: 0.043373117223381996 Engine time: 0.05638163955882192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.159073621034622,
    "estimated_duration": 3600.0428411925272,
    "input_throughput": 4865.9832042990865,
    "output_throughput": 4182.394394787919,
    "total_throughput": 9048.377599087005,
    "itl": 115.26116005110376,
    "ttft": 2147523.1122777336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.880496289013175,
    "arrivals": 765271,
    "finished_requests": 70463,
    "scheduler_time": 121.59625873547199
}
#Debug simulation 
Total elapsed time: 5.159227218013257. Arrivals time: 0.3144110217690468 Scheduler time: 4.691898094024509 Scheduler overhead time: 0.04511519894003868 Adapter cache time: 0.039641368202865124 Engine time: 0.04669635044410825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.794544278178364,
    "estimated_duration": 3600.085162673415,
    "input_throughput": 4449.26280246806,
    "output_throughput": 3818.811883269653,
    "total_throughput": 8268.074685737713,
    "itl": 90.42232664403079,
    "ttft": 2197112.6939302953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.794261347683866,
    "arrivals": 765271,
    "finished_requests": 64410,
    "scheduler_time": 132.8789217641399
}
#Debug simulation 
Total elapsed time: 4.794635255821049. Arrivals time: 0.3017707192339003 Scheduler time: 4.312429423909634 Scheduler overhead time: 0.0546109639108181 Adapter cache time: 0.04333419492468238 Engine time: 0.05644995765760541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.241254528053105,
    "estimated_duration": 3600.1011359809536,
    "input_throughput": 4870.664833481714,
    "output_throughput": 4185.994068162126,
    "total_throughput": 9056.65890164384,
    "itl": 115.50668058884577,
    "ttft": 2147261.712710191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.052842735797666,
    "arrivals": 765271,
    "finished_requests": 70525,
    "scheduler_time": 121.52174154208903
}
#Debug simulation 
Total elapsed time: 5.241346809081733. Arrivals time: 0.3670570934191346 Scheduler time: 4.722011188976467 Scheduler overhead time: 0.045131620950996876 Adapter cache time: 0.039301122073084116 Engine time: 0.04647217644378543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.825556993950158,
    "estimated_duration": 3600.0309457197777,
    "input_throughput": 4448.961478801327,
    "output_throughput": 3818.4330099561344,
    "total_throughput": 8267.394488757462,
    "itl": 90.38117449774798,
    "ttft": 2197175.143186244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.683867892548234,
    "arrivals": 765271,
    "finished_requests": 64404,
    "scheduler_time": 132.9025209538083
}
#Debug simulation 
Total elapsed time: 4.825680287089199. Arrivals time: 0.3000720529817045 Scheduler time: 4.344026193022728 Scheduler overhead time: 0.05490671098232269 Adapter cache time: 0.043741676956415176 Engine time: 0.05685100378468633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.239146583713591,
    "estimated_duration": 3600.142322745595,
    "input_throughput": 4970.415443563146,
    "output_throughput": 4350.306070137755,
    "total_throughput": 9320.7215137009,
    "itl": 126.47034115124109,
    "ttft": 2132338.2098857597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.758389494982827,
    "arrivals": 762397,
    "finished_requests": 72347,
    "scheduler_time": 118.81653292134945
}
#Debug simulation 
Total elapsed time: 5.239238891750574. Arrivals time: 0.2409491608850658 Scheduler time: 4.858355881180614 Scheduler overhead time: 0.041985852643847466 Adapter cache time: 0.034954396076500416 Engine time: 0.04322137637063861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.141045764088631,
    "estimated_duration": 3600.070877978192,
    "input_throughput": 4828.776040588084,
    "output_throughput": 4227.070942710529,
    "total_throughput": 9055.846983298612,
    "itl": 114.3783514876062,
    "ttft": 2147073.7470042165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.58918840778515,
    "arrivals": 762397,
    "finished_requests": 70293,
    "scheduler_time": 122.87086064693266
}
#Debug simulation 
Total elapsed time: 5.1411955072544515. Arrivals time: 0.23418231215327978 Scheduler time: 4.754427195992321 Scheduler overhead time: 0.04679003171622753 Adapter cache time: 0.036592711228877306 Engine time: 0.047401553485542536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.765185467898846,
    "estimated_duration": 3600.0917218961836,
    "input_throughput": 4396.614926150607,
    "output_throughput": 3849.0619324280638,
    "total_throughput": 8245.67685857867,
    "itl": 89.83084039106487,
    "ttft": 2197498.008937396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.015247896998089,
    "arrivals": 762397,
    "finished_requests": 64023,
    "scheduler_time": 134.01747603120404
}
#Debug simulation 
Total elapsed time: 4.765271770767868. Arrivals time: 0.219931669998914 Scheduler time: 4.365442631300539 Scheduler overhead time: 0.05517886904999614 Adapter cache time: 0.04142241785302758 Engine time: 0.05695970915257931 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.123831863049418,
    "estimated_duration": 3600.0211617462346,
    "input_throughput": 4829.921886227419,
    "output_throughput": 4227.873480781746,
    "total_throughput": 9057.795367009167,
    "itl": 114.35417699436168,
    "ttft": 2146873.8002840825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.81733754662344,
    "arrivals": 762397,
    "finished_requests": 70305,
    "scheduler_time": 122.89530940435536
}
#Debug simulation 
Total elapsed time: 5.123949168715626. Arrivals time: 0.23447052529081702 Scheduler time: 4.739056299906224 Scheduler overhead time: 0.04544332763180137 Adapter cache time: 0.036333165131509304 Engine time: 0.047074178233742714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.767142171040177,
    "estimated_duration": 3600.0810128447965,
    "input_throughput": 4397.028273397478,
    "output_throughput": 3849.2903216779428,
    "total_throughput": 8246.318595075421,
    "itl": 89.82697964364479,
    "ttft": 2197522.5268203686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.910239488454437,
    "arrivals": 762397,
    "finished_requests": 64027,
    "scheduler_time": 134.02095736269152
}
#Debug simulation 
Total elapsed time: 4.767229137942195. Arrivals time: 0.22598856035619974 Scheduler time: 4.3603334915824234 Scheduler overhead time: 0.055550971534103155 Adapter cache time: 0.04142615245655179 Engine time: 0.05758264660835266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.188236794900149,
    "estimated_duration": 3600.0697317691724,
    "input_throughput": 4830.418657322551,
    "output_throughput": 4228.433651066856,
    "total_throughput": 9058.852308389407,
    "itl": 114.33188133529542,
    "ttft": 2146716.354446525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.144050374566822,
    "arrivals": 762397,
    "finished_requests": 70317,
    "scheduler_time": 122.91977161123792
}
#Debug simulation 
Total elapsed time: 5.188340965192765. Arrivals time: 0.24794756015762687 Scheduler time: 4.789076808374375 Scheduler overhead time: 0.04574158554896712 Adapter cache time: 0.036406394094228745 Engine time: 0.04740831069648266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.736324260942638,
    "estimated_duration": 3600.0893112561694,
    "input_throughput": 4397.118135515498,
    "output_throughput": 3849.4045013468003,
    "total_throughput": 8246.522636862297,
    "itl": 89.82407068758887,
    "ttft": 2197569.654096071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.823248777761957,
    "arrivals": 762397,
    "finished_requests": 64030,
    "scheduler_time": 134.0244634013725
}
#Debug simulation 
Total elapsed time: 4.7364136930555105. Arrivals time: 0.22110270848497748 Scheduler time: 4.33630860503763 Scheduler overhead time: 0.0548296426422894 Adapter cache time: 0.041180703323334455 Engine time: 0.05686457781121135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.26104559795931,
    "estimated_duration": 3600.0834338825352,
    "input_throughput": 5084.2038347595735,
    "output_throughput": 4389.5377121739275,
    "total_throughput": 9473.741546933501,
    "itl": 124.99916379452173,
    "ttft": 2126152.5321879163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.475582142784498,
    "arrivals": 760968,
    "finished_requests": 73586,
    "scheduler_time": 119.9329387603322
}
#Debug simulation 
Total elapsed time: 5.26113648712635. Arrivals time: 0.24312709691002965 Scheduler time: 4.879591424949467 Scheduler overhead time: 0.04207045631483197 Adapter cache time: 0.03303350042551756 Engine time: 0.0434227054938674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.22745966212824,
    "estimated_duration": 3600.0917820687464,
    "input_throughput": 4927.947139671347,
    "output_throughput": 4263.781850355858,
    "total_throughput": 9191.728990027204,
    "itl": 113.17851591063526,
    "ttft": 2141136.4835907347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.217145723388468,
    "arrivals": 760968,
    "finished_requests": 71395,
    "scheduler_time": 123.89931749244303
}
#Debug simulation 
Total elapsed time: 5.227548632770777. Arrivals time: 0.28944176342338324 Scheduler time: 4.7883065468631685 Scheduler overhead time: 0.0460488679818809 Adapter cache time: 0.034408840816468 Engine time: 0.04756827000528574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.756785240024328,
    "estimated_duration": 3600.0266708782206,
    "input_throughput": 4469.606053244795,
    "output_throughput": 3871.294374771993,
    "total_throughput": 8340.900428016788,
    "itl": 89.15708557023297,
    "ttft": 2193220.1807139856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.488586224187117,
    "arrivals": 760968,
    "finished_requests": 64837,
    "scheduler_time": 134.7670528366157
}
#Debug simulation 
Total elapsed time: 4.756910744123161. Arrivals time: 0.2209155079908669 Scheduler time: 4.358627529814839 Scheduler overhead time: 0.05521730938926339 Adapter cache time: 0.038688452914357185 Engine time: 0.05719227949157357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.173174887895584,
    "estimated_duration": 3600.051452547161,
    "input_throughput": 4928.7323344908655,
    "output_throughput": 4264.550438338181,
    "total_throughput": 9193.282772829047,
    "itl": 113.15877677488655,
    "ttft": 2140881.262174139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.563293644958236,
    "arrivals": 760968,
    "finished_requests": 71404,
    "scheduler_time": 123.91959393081376
}
#Debug simulation 
Total elapsed time: 5.173293311614543. Arrivals time: 0.25188926327973604 Scheduler time: 4.772335099522024 Scheduler overhead time: 0.045945670921355486 Adapter cache time: 0.034119096118956804 Engine time: 0.047259362414479256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.833391309715807,
    "estimated_duration": 3600.0353470657337,
    "input_throughput": 4469.686947133798,
    "output_throughput": 3871.3822661101553,
    "total_throughput": 8341.069213243953,
    "itl": 89.1549247390641,
    "ttft": 2193276.315872397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.399732955419411,
    "arrivals": 760968,
    "finished_requests": 64838,
    "scheduler_time": 134.77056794921242
}
#Debug simulation 
Total elapsed time: 4.8335594167001545. Arrivals time: 0.2702736002393067 Scheduler time: 4.38384013203904 Scheduler overhead time: 0.0553037254139781 Adapter cache time: 0.038875870406627655 Engine time: 0.058793858624994755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.174486024305224,
    "estimated_duration": 3600.058984397486,
    "input_throughput": 4929.540898333397,
    "output_throughput": 4264.994842180265,
    "total_throughput": 9194.535740513662,
    "itl": 113.1408961179149,
    "ttft": 2140777.6898481594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.956641079620544,
    "arrivals": 760968,
    "finished_requests": 71413,
    "scheduler_time": 123.93990452282029
}
#Debug simulation 
Total elapsed time: 5.174608164001256. Arrivals time: 0.24045438785105944 Scheduler time: 4.785224860999733 Scheduler overhead time: 0.04589500464498997 Adapter cache time: 0.0340225244872272 Engine time: 0.04733950411900878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.767113728448749,
    "estimated_duration": 3600.050234626518,
    "input_throughput": 4469.6842964107545,
    "output_throughput": 3871.4940324842255,
    "total_throughput": 8341.17832889498,
    "itl": 89.1529463629309,
    "ttft": 2193240.9604961877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.317093201950149,
    "arrivals": 760968,
    "finished_requests": 64839,
    "scheduler_time": 134.7740809197818
}
#Debug simulation 
Total elapsed time: 4.767229549121112. Arrivals time: 0.22340272413566709 Scheduler time: 4.3657338921912014 Scheduler overhead time: 0.0554047841578722 Adapter cache time: 0.03891614405438304 Engine time: 0.05735226580873132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.329921827185899,
    "estimated_duration": 3600.0136820628945,
    "input_throughput": 5094.086472885691,
    "output_throughput": 4423.822075830035,
    "total_throughput": 9517.908548715726,
    "itl": 124.45824774211358,
    "ttft": 2120412.4538078057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.536620060247577,
    "arrivals": 760248,
    "finished_requests": 74214,
    "scheduler_time": 120.67741158377626
}
#Debug simulation 
Total elapsed time: 5.330015781335533. Arrivals time: 0.2437359979376197 Scheduler time: 4.947080804500729 Scheduler overhead time: 0.04258911684155464 Adapter cache time: 0.03232466150075197 Engine time: 0.04420090839266777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.206368254031986,
    "estimated_duration": 3600.017810493629,
    "input_throughput": 4944.726092218732,
    "output_throughput": 4294.7731966581505,
    "total_throughput": 9239.499288876883,
    "itl": 112.69377557847292,
    "ttft": 2137235.210270427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.126288368864886,
    "arrivals": 760248,
    "finished_requests": 72062,
    "scheduler_time": 124.60186175913923
}
#Debug simulation 
Total elapsed time: 5.206489006057382. Arrivals time: 0.24113857420161366 Scheduler time: 4.816811884287745 Scheduler overhead time: 0.046110042836517096 Adapter cache time: 0.03275879891589284 Engine time: 0.047747652977705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.808228726964444,
    "estimated_duration": 3600.001347936026,
    "input_throughput": 4481.791933008664,
    "output_throughput": 3896.5738187966035,
    "total_throughput": 8378.365751805268,
    "itl": 88.74674295545992,
    "ttft": 2190070.919762963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.469150270116499,
    "arrivals": 760248,
    "finished_requests": 65307,
    "scheduler_time": 135.4612049113206
}
#Debug simulation 
Total elapsed time: 4.808394224848598. Arrivals time: 0.2242049160413444 Scheduler time: 4.406448426190764 Scheduler overhead time: 0.05594700621441007 Adapter cache time: 0.03765931539237499 Engine time: 0.05756777850911021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.207084553781897,
    "estimated_duration": 3600.0484148119344,
    "input_throughput": 4946.415977833523,
    "output_throughput": 4295.996113932242,
    "total_throughput": 9242.412091765766,
    "itl": 112.67445287230821,
    "ttft": 2137458.1828313405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.541847339100215,
    "arrivals": 760248,
    "finished_requests": 72080,
    "scheduler_time": 124.62279176690491
}
#Debug simulation 
Total elapsed time: 5.20717744063586. Arrivals time: 0.2399822766892612 Scheduler time: 4.818851695396006 Scheduler overhead time: 0.04609145550057292 Adapter cache time: 0.0326686748303473 Engine time: 0.0476994956843555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.805560756940395,
    "estimated_duration": 3600.02291619019,
    "input_throughput": 4481.821470479663,
    "output_throughput": 3896.6560287470393,
    "total_throughput": 8378.477499226701,
    "itl": 88.74511664928639,
    "ttft": 2190066.7370440867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.391481328885988,
    "arrivals": 760248,
    "finished_requests": 65309,
    "scheduler_time": 135.46483579145408
}
#Debug simulation 
Total elapsed time: 4.805676167365164. Arrivals time: 0.22499203542247415 Scheduler time: 4.403518636710942 Scheduler overhead time: 0.055595718789845705 Adapter cache time: 0.03737480053678155 Engine time: 0.05768831027671695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.1706883469596505,
    "estimated_duration": 3600.0124984890144,
    "input_throughput": 4947.907266287608,
    "output_throughput": 4296.838415558963,
    "total_throughput": 9244.74568184657,
    "itl": 112.6539842369584,
    "ttft": 2137554.853544208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.005436859475408,
    "arrivals": 760248,
    "finished_requests": 72099,
    "scheduler_time": 124.63930920662379
}
#Debug simulation 
Total elapsed time: 5.170807345304638. Arrivals time: 0.24006859073415399 Scheduler time: 4.783115457743406 Scheduler overhead time: 0.045930092222988605 Adapter cache time: 0.03264177404344082 Engine time: 0.04725855262950063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.78768688486889,
    "estimated_duration": 3600.048898186581,
    "input_throughput": 4482.209396691284,
    "output_throughput": 3896.8792915748104,
    "total_throughput": 8379.088688266094,
    "itl": 88.74375109601517,
    "ttft": 2190028.403801319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.318576082717616,
    "arrivals": 760248,
    "finished_requests": 65312,
    "scheduler_time": 135.46841704526673
}
#Debug simulation 
Total elapsed time: 4.78777509694919. Arrivals time: 0.22382706543430686 Scheduler time: 4.3877322426997125 Scheduler overhead time: 0.05537322163581848 Adapter cache time: 0.03735308442264795 Engine time: 0.05726388143375516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.384382000193,
    "estimated_duration": 3600.0749139065665,
    "input_throughput": 5116.381864401958,
    "output_throughput": 4467.350925913926,
    "total_throughput": 9583.732790315886,
    "itl": 123.40263988832483,
    "ttft": 2117271.400641154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.250760235698193,
    "arrivals": 753816,
    "finished_requests": 74601,
    "scheduler_time": 121.8688532799969
}
#Debug simulation 
Total elapsed time: 5.384515232406557. Arrivals time: 0.24421844957396388 Scheduler time: 5.0002703703939915 Scheduler overhead time: 0.04296771856024861 Adapter cache time: 0.0305074667558074 Engine time: 0.04623881354928017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.2502662050537765,
    "estimated_duration": 3600.0375578589096,
    "input_throughput": 4960.294917206486,
    "output_throughput": 4332.562577285002,
    "total_throughput": 9292.857494491487,
    "itl": 111.81252728277214,
    "ttft": 2132898.027150799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.93874631314532,
    "arrivals": 753816,
    "finished_requests": 72285,
    "scheduler_time": 125.75407941993386
}
#Debug simulation 
Total elapsed time: 5.250358124263585. Arrivals time: 0.24047722062096 Scheduler time: 4.861823453567922 Scheduler overhead time: 0.04643724672496319 Adapter cache time: 0.03162250109016895 Engine time: 0.047997497487813234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.854333906900138,
    "estimated_duration": 3600.036668241356,
    "input_throughput": 4478.732436877232,
    "output_throughput": 3918.675641404385,
    "total_throughput": 8397.408078281616,
    "itl": 88.1853197263489,
    "ttft": 2181690.926772621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.352228894033413,
    "arrivals": 753816,
    "finished_requests": 65265,
    "scheduler_time": 136.41631745487513
}
#Debug simulation 
Total elapsed time: 4.854425369761884. Arrivals time: 0.22589117661118507 Scheduler time: 4.451904611196369 Scheduler overhead time: 0.056083332281559706 Adapter cache time: 0.035628131590783596 Engine time: 0.05811709724366665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.255570363253355,
    "estimated_duration": 3600.006803075149,
    "input_throughput": 4961.102569235111,
    "output_throughput": 4333.335977774916,
    "total_throughput": 9294.438547010026,
    "itl": 111.79352205916089,
    "ttft": 2132622.2261720626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.286282455688387,
    "arrivals": 753816,
    "finished_requests": 72298,
    "scheduler_time": 125.77499137658741
}
#Debug simulation 
Total elapsed time: 5.255659752059728. Arrivals time: 0.24012518720701337 Scheduler time: 4.86734109185636 Scheduler overhead time: 0.04640086414292455 Adapter cache time: 0.031458213459700346 Engine time: 0.048251351341605186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.818752366118133,
    "estimated_duration": 3600.0414988147936,
    "input_throughput": 4478.936147071767,
    "output_throughput": 3918.9298247380593,
    "total_throughput": 8397.865971809826,
    "itl": 88.18342948822882,
    "ttft": 2181724.0683619278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.262961390912476,
    "arrivals": 753816,
    "finished_requests": 65268,
    "scheduler_time": 136.41981935561643
}
#Debug simulation 
Total elapsed time: 4.81884185411036. Arrivals time: 0.2236734707839787 Scheduler time: 4.419429572764784 Scheduler overhead time: 0.05580609058961272 Adapter cache time: 0.035538547206670046 Engine time: 0.05784803535789251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.228680639993399,
    "estimated_duration": 3600.0377600391075,
    "input_throughput": 4962.414338622363,
    "output_throughput": 4334.760088691536,
    "total_throughput": 9297.1744273139,
    "itl": 111.77181111754791,
    "ttft": 2132575.184538066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.694900321057117,
    "arrivals": 753816,
    "finished_requests": 72317,
    "scheduler_time": 125.79607779608733
}
#Debug simulation 
Total elapsed time: 5.228772111237049. Arrivals time: 0.2363587599247694 Scheduler time: 4.844802941195667 Scheduler overhead time: 0.0463318875990808 Adapter cache time: 0.0312723065726459 Engine time: 0.04800029704347253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.827362782787532,
    "estimated_duration": 3600.0557740587074,
    "input_throughput": 4478.98921905343,
    "output_throughput": 3918.9603954646755,
    "total_throughput": 8397.949614518106,
    "itl": 88.18087429809847,
    "ttft": 2181730.0331159476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.182599926385977,
    "arrivals": 753816,
    "finished_requests": 65271,
    "scheduler_time": 136.42334109339382
}
#Debug simulation 
Total elapsed time: 4.827451057732105. Arrivals time: 0.2275083507411182 Scheduler time: 4.423901449888945 Scheduler overhead time: 0.05590708740055561 Adapter cache time: 0.03560994612053037 Engine time: 0.057921732775866985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.466921343002468,
    "estimated_duration": 3600.0756939731596,
    "input_throughput": 5187.744255284884,
    "output_throughput": 4525.432625562307,
    "total_throughput": 9713.176880847192,
    "itl": 121.89604403370952,
    "ttft": 2105014.674085387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.134789345474145,
    "arrivals": 750836,
    "finished_requests": 75616,
    "scheduler_time": 123.28906165894456
}
#Debug simulation 
Total elapsed time: 5.467013794928789. Arrivals time: 0.24813150940462947 Scheduler time: 5.08399978838861 Scheduler overhead time: 0.04315381683409214 Adapter cache time: 0.026450080797076225 Engine time: 0.04485280252993107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.265416224021465,
    "estimated_duration": 3600.061579475425,
    "input_throughput": 5026.297634230099,
    "output_throughput": 4387.721612890214,
    "total_throughput": 9414.019247120312,
    "itl": 110.49310825214853,
    "ttft": 2121986.3558820523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.549403030443947,
    "arrivals": 750836,
    "finished_requests": 73260,
    "scheduler_time": 127.17219375020693
}
#Debug simulation 
Total elapsed time: 5.265564636792988. Arrivals time: 0.24422832764685154 Scheduler time: 4.877930658869445 Scheduler overhead time: 0.04652249300852418 Adapter cache time: 0.02673657052218914 Engine time: 0.04806551244109869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.857584597077221,
    "estimated_duration": 3600.068683076283,
    "input_throughput": 4528.419992828942,
    "output_throughput": 3963.174943598063,
    "total_throughput": 8491.594936427005,
    "itl": 87.27768912405374,
    "ttft": 2175842.9742873902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.030247584623302,
    "arrivals": 750836,
    "finished_requests": 66063,
    "scheduler_time": 137.7336027783131
}
#Debug simulation 
Total elapsed time: 4.85767768509686. Arrivals time: 0.22310060961171985 Scheduler time: 4.462460828479379 Scheduler overhead time: 0.05623244261369109 Adapter cache time: 0.0310026491060853 Engine time: 0.058122831862419844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.318566677160561,
    "estimated_duration": 3600.0609835904993,
    "input_throughput": 5027.1181745232925,
    "output_throughput": 4388.45843779103,
    "total_throughput": 9415.576612314322,
    "itl": 110.47876185929562,
    "ttft": 2121859.3947696113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.069078573677676,
    "arrivals": 750836,
    "finished_requests": 73271,
    "scheduler_time": 127.1885208924545
}
#Debug simulation 
Total elapsed time: 5.318661044817418. Arrivals time: 0.24273073906078935 Scheduler time: 4.93087008735165 Scheduler overhead time: 0.04705957742407918 Adapter cache time: 0.027060185559093952 Engine time: 0.04853786947205663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.926286855712533,
    "estimated_duration": 3600.002064259918,
    "input_throughput": 4528.503792219759,
    "output_throughput": 3963.2482830070626,
    "total_throughput": 8491.752075226821,
    "itl": 87.27605386847472,
    "ttft": 2175817.9003407676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9637629709299835,
    "arrivals": 750836,
    "finished_requests": 66063,
    "scheduler_time": 137.73346857564158
}
#Debug simulation 
Total elapsed time: 4.926377236843109. Arrivals time: 0.2729789996519685 Scheduler time: 4.480525580234826 Scheduler overhead time: 0.056466320529580116 Adapter cache time: 0.031202649232000113 Engine time: 0.058358531445264816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.254528838675469,
    "estimated_duration": 3600.0897175048,
    "input_throughput": 5027.56748310839,
    "output_throughput": 4388.89978857282,
    "total_throughput": 9416.46727168121,
    "itl": 110.46266452440315,
    "ttft": 2121928.563854811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.613742094431039,
    "arrivals": 750836,
    "finished_requests": 73281,
    "scheduler_time": 127.20469027465637
}
#Debug simulation 
Total elapsed time: 5.254623705986887. Arrivals time: 0.2425799947232008 Scheduler time: 4.8679896467365324 Scheduler overhead time: 0.046502919401973486 Adapter cache time: 0.027281233575195074 Engine time: 0.04810373904183507 
