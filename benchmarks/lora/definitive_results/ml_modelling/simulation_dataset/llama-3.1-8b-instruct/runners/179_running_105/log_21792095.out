INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.929970947559923,
    "estimated_duration": 3600.0340012513198,
    "input_throughput": 4528.493895983595,
    "output_throughput": 3963.25645675588,
    "total_throughput": 8491.750352739475,
    "itl": 87.27463843806433,
    "ttft": 2175759.8076255787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.902042052298802,
    "arrivals": 750836,
    "finished_requests": 66064,
    "scheduler_time": 137.73701878766792
}
#Debug simulation 
Total elapsed time: 4.930116463918239. Arrivals time: 0.27479641046375036 Scheduler time: 4.483569387812167 Scheduler overhead time: 0.056725171860307455 Adapter cache time: 0.03000191692262888 Engine time: 0.05788716394454241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.546048555988818,
    "estimated_duration": 3600.051623331851,
    "input_throughput": 5249.483056720588,
    "output_throughput": 4581.72874330462,
    "total_throughput": 9831.211800025209,
    "itl": 120.3182661129791,
    "ttft": 2103633.8297503227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 876,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.792470311988264,
    "arrivals": 749460,
    "finished_requests": 76683,
    "scheduler_time": 124.92622734348215
}
#Debug simulation 
Total elapsed time: 5.546169694047421. Arrivals time: 0.31843308825045824 Scheduler time: 5.09457278624177 Scheduler overhead time: 0.04429637920111418 Adapter cache time: 0.023475293070077896 Engine time: 0.04467588011175394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.408674458041787,
    "estimated_duration": 3600.1026008091444,
    "input_throughput": 5076.123384898165,
    "output_throughput": 4433.9233544100425,
    "total_throughput": 9510.046739308207,
    "itl": 109.22311866745065,
    "ttft": 2120863.1606702185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.108799289795577,
    "arrivals": 749460,
    "finished_requests": 74169,
    "scheduler_time": 128.648258002552
}
#Debug simulation 
Total elapsed time: 5.408779447898269. Arrivals time: 0.2446022336371243 Scheduler time: 5.020415181759745 Scheduler overhead time: 0.04786540474742651 Adapter cache time: 0.024387577082961798 Engine time: 0.048921539448201656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.947025295346975,
    "estimated_duration": 3600.0609634026473,
    "input_throughput": 4570.68426542632,
    "output_throughput": 3993.199044721885,
    "total_throughput": 8563.883310148205,
    "itl": 86.63294104089972,
    "ttft": 2175925.248998275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.826770749352894,
    "arrivals": 749460,
    "finished_requests": 66732,
    "scheduler_time": 138.8366480892441
}
#Debug simulation 
Total elapsed time: 4.9471565191634. Arrivals time: 0.30136998649686575 Scheduler time: 4.476464740931988 Scheduler overhead time: 0.05695579154416919 Adapter cache time: 0.027327098418027163 Engine time: 0.05805938085541129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.38675747718662,
    "estimated_duration": 3600.0522702302833,
    "input_throughput": 5076.519346990193,
    "output_throughput": 4434.185062257133,
    "total_throughput": 9510.704409247326,
    "itl": 109.21080073250569,
    "ttft": 2120840.93783594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.693721218775014,
    "arrivals": 749460,
    "finished_requests": 74174,
    "scheduler_time": 128.66045890217688
}
#Debug simulation 
Total elapsed time: 5.386888156179339. Arrivals time: 0.31730008171871305 Scheduler time: 4.926286322064698 Scheduler overhead time: 0.047586698085069656 Adapter cache time: 0.024396643042564392 Engine time: 0.04889893624931574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.989036021288484,
    "estimated_duration": 3600.0042477473985,
    "input_throughput": 4570.756273494981,
    "output_throughput": 3993.2619548977555,
    "total_throughput": 8564.018228392735,
    "itl": 86.63154059708069,
    "ttft": 2175902.9048430356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.770227760137081,
    "arrivals": 749460,
    "finished_requests": 66732,
    "scheduler_time": 138.8364754232115
}
#Debug simulation 
Total elapsed time: 4.989176339004189. Arrivals time: 0.2995455642230809 Scheduler time: 4.519191154744476 Scheduler overhead time: 0.05718656862154603 Adapter cache time: 0.02754692966118455 Engine time: 0.05841732583940029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.4046045411378145,
    "estimated_duration": 3600.0892612666935,
    "input_throughput": 5077.199111882227,
    "output_throughput": 4434.964202632648,
    "total_throughput": 9512.163314514875,
    "itl": 109.20153104814867,
    "ttft": 2120779.376070539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.368877511019792,
    "arrivals": 749460,
    "finished_requests": 74186,
    "scheduler_time": 128.67256440606263
}
#Debug simulation 
Total elapsed time: 5.404740252997726. Arrivals time: 0.3180029569193721 Scheduler time: 4.943081364501268 Scheduler overhead time: 0.04775267746299505 Adapter cache time: 0.024521909188479185 Engine time: 0.0488691134378314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.950396663043648,
    "estimated_duration": 3600.049912313922,
    "input_throughput": 4570.698296075501,
    "output_throughput": 3993.2113026621955,
    "total_throughput": 8563.909598737697,
    "itl": 86.63038182387474,
    "ttft": 2175869.310065822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.724040629752003,
    "arrivals": 749460,
    "finished_requests": 66732,
    "scheduler_time": 138.83993602485245
}
#Debug simulation 
Total elapsed time: 4.950587354134768. Arrivals time: 0.2983933053910732 Scheduler time: 4.481883076485246 Scheduler overhead time: 0.057130600325763226 Adapter cache time: 0.027412092313170433 Engine time: 0.05863068159669638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.856367792934179,
    "estimated_duration": 3600.0357223559404,
    "input_throughput": 5303.33404233713,
    "output_throughput": 4591.777214138877,
    "total_throughput": 9895.111256476008,
    "itl": 120.18246920811627,
    "ttft": 2099750.8252211926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.243640362336402,
    "arrivals": 748703,
    "finished_requests": 77186,
    "scheduler_time": 125.03105280379603
}
#Debug simulation 
Total elapsed time: 5.856456821784377. Arrivals time: 0.5859383777715266 Scheduler time: 5.136449557263404 Scheduler overhead time: 0.04458761541172862 Adapter cache time: 0.022901555988937616 Engine time: 0.045755141880363226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.364561289083213,
    "estimated_duration": 3600.0401173164946,
    "input_throughput": 5127.588137478843,
    "output_throughput": 4443.414650591151,
    "total_throughput": 9571.002788069994,
    "itl": 109.18472796102341,
    "ttft": 2117299.940235245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.545333217564046,
    "arrivals": 748703,
    "finished_requests": 74654,
    "scheduler_time": 128.72607437687924
}
#Debug simulation 
Total elapsed time: 5.364689936861396. Arrivals time: 0.2423069654032588 Scheduler time: 4.979775267187506 Scheduler overhead time: 0.047934663482010365 Adapter cache time: 0.023300037253648043 Engine time: 0.04879035148769617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.922517525032163,
    "estimated_duration": 3600.035275410011,
    "input_throughput": 4616.045879746935,
    "output_throughput": 4000.8619077655017,
    "total_throughput": 8616.907787512437,
    "itl": 86.71803046239539,
    "ttft": 2173051.192309695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.102894925321481,
    "arrivals": 748703,
    "finished_requests": 67152,
    "scheduler_time": 138.81443781825016
}
#Debug simulation 
Total elapsed time: 4.922620971221477. Arrivals time: 0.22752638487145305 Scheduler time: 4.524535654578358 Scheduler overhead time: 0.05755277443677187 Adapter cache time: 0.026993562001734972 Engine time: 0.058776543010026217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.322448039893061,
    "estimated_duration": 3600.042876436966,
    "input_throughput": 5127.970036365548,
    "output_throughput": 4443.715130368977,
    "total_throughput": 9571.685166734525,
    "itl": 109.17476360858302,
    "ttft": 2117162.6040505283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.199666195209129,
    "arrivals": 748703,
    "finished_requests": 74658,
    "scheduler_time": 128.7383178406381
}
#Debug simulation 
Total elapsed time: 5.322574149817228. Arrivals time: 0.24148508487269282 Scheduler time: 4.938663184642792 Scheduler overhead time: 0.047671977896243334 Adapter cache time: 0.02335419226437807 Engine time: 0.04881152044981718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.188061916735023,
    "estimated_duration": 3600.0878630052352,
    "input_throughput": 4616.095393329525,
    "output_throughput": 4000.879575193594,
    "total_throughput": 8616.97496852312,
    "itl": 86.7159215596996,
    "ttft": 2173206.377191768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.057122029289632,
    "arrivals": 748703,
    "finished_requests": 67155,
    "scheduler_time": 138.81813195087682
}
#Debug simulation 
Total elapsed time: 5.188138080760837. Arrivals time: 0.5511879096738994 Scheduler time: 4.468127301894128 Scheduler overhead time: 0.05692634964361787 Adapter cache time: 0.026672445703297853 Engine time: 0.05811760947108269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.33065529121086,
    "estimated_duration": 3600.048878615791,
    "input_throughput": 5128.638144240726,
    "output_throughput": 4444.441322738939,
    "total_throughput": 9573.079466979665,
    "itl": 109.1647363313728,
    "ttft": 2117095.861003456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.858163835774152,
    "arrivals": 748703,
    "finished_requests": 74666,
    "scheduler_time": 128.7503651547173
}
#Debug simulation 
Total elapsed time: 5.3307792050763965. Arrivals time: 0.24323176639154553 Scheduler time: 4.945171676110476 Scheduler overhead time: 0.04798963479697704 Adapter cache time: 0.02318063098937273 Engine time: 0.048655591905117035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.8988375389017165,
    "estimated_duration": 3600.0413058704617,
    "input_throughput": 4616.155090471056,
    "output_throughput": 4000.9313161248137,
    "total_throughput": 8617.08640659587,
    "itl": 86.71480634163068,
    "ttft": 2173187.8813697947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0107277817279385,
    "arrivals": 748703,
    "finished_requests": 67155,
    "scheduler_time": 138.81796906366483
}
#Debug simulation 
Total elapsed time: 4.898946114815772. Arrivals time: 0.22841854114085436 Scheduler time: 4.4998667309992015 Scheduler overhead time: 0.05760906683281064 Adapter cache time: 0.026796949561685324 Engine time: 0.05894999811425805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.7367236870341,
    "estimated_duration": 3600.049356613114,
    "input_throughput": 5326.807801891164,
    "output_throughput": 4650.347076282919,
    "total_throughput": 9977.154878174084,
    "itl": 118.89146115144814,
    "ttft": 2096627.1893319166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.879957865579144,
    "arrivals": 745105,
    "finished_requests": 77603,
    "scheduler_time": 126.66335252924975
}
#Debug simulation 
Total elapsed time: 5.736918373964727. Arrivals time: 0.2541209519840777 Scheduler time: 5.350408121943474 Scheduler overhead time: 0.04495377652347088 Adapter cache time: 0.020470031071454287 Engine time: 0.04578261636197567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.439164286013693,
    "estimated_duration": 3600.024719123526,
    "input_throughput": 5144.301899268305,
    "output_throughput": 4493.492201336448,
    "total_throughput": 9637.794100604751,
    "itl": 108.15482624505054,
    "ttft": 2114618.9443111555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.243060197653256,
    "arrivals": 745105,
    "finished_requests": 74966,
    "scheduler_time": 130.18503878547187
}
#Debug simulation 
Total elapsed time: 5.439294585958123. Arrivals time: 0.2496166042983532 Scheduler time: 5.0475014774128795 Scheduler overhead time: 0.04895005701109767 Adapter cache time: 0.020721899811178446 Engine time: 0.04961248068138957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.948425652924925,
    "estimated_duration": 3600.000206226733,
    "input_throughput": 4594.92307011223,
    "output_throughput": 4025.2144916369903,
    "total_throughput": 8620.13756174922,
    "itl": 85.71876702172672,
    "ttft": 2171397.3697965327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.855649332930362,
    "arrivals": 745105,
    "finished_requests": 67010,
    "scheduler_time": 140.24708290629968
}
#Debug simulation 
Total elapsed time: 4.9485519849695265. Arrivals time: 0.2316820351406932 Scheduler time: 4.54873779322952 Scheduler overhead time: 0.05793712940067053 Adapter cache time: 0.02354965964332223 Engine time: 0.05904882727190852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.408607990946621,
    "estimated_duration": 3600.0065433059367,
    "input_throughput": 5145.069537287764,
    "output_throughput": 4494.173220347136,
    "total_throughput": 9639.2427576349,
    "itl": 108.15871935726446,
    "ttft": 2114567.9367975807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.898224212345659,
    "arrivals": 745105,
    "finished_requests": 74975,
    "scheduler_time": 130.1916052871708
}
#Debug simulation 
Total elapsed time: 5.408713465090841. Arrivals time: 0.24633019277825952 Scheduler time: 5.021732276305556 Scheduler overhead time: 0.048270163126289845 Adapter cache time: 0.02051975391805172 Engine time: 0.04918023804202676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.932576618157327,
    "estimated_duration": 3600.051362978535,
    "input_throughput": 4594.858054001223,
    "output_throughput": 4025.2359033040834,
    "total_throughput": 8620.093957305306,
    "itl": 85.71781379089137,
    "ttft": 2171389.6114580682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.808219499485597,
    "arrivals": 745105,
    "finished_requests": 67011,
    "scheduler_time": 140.25065709330178
}
#Debug simulation 
Total elapsed time: 4.932702912949026. Arrivals time: 0.2308279094286263 Scheduler time: 4.533411510288715 Scheduler overhead time: 0.058067933190613985 Adapter cache time: 0.0234260275028646 Engine time: 0.05944555113092065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.706706804223359,
    "estimated_duration": 3600.0173366584695,
    "input_throughput": 5145.17633328754,
    "output_throughput": 4494.4497447943795,
    "total_throughput": 9639.62607808192,
    "itl": 108.14969399205201,
    "ttft": 2114466.07274543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.583655235329621,
    "arrivals": 745105,
    "finished_requests": 74979,
    "scheduler_time": 130.20294021908316
}
#Debug simulation 
Total elapsed time: 5.7068440448492765. Arrivals time: 0.5677344645373523 Scheduler time: 4.998382641933858 Scheduler overhead time: 0.048158494755625725 Adapter cache time: 0.02044502506032586 Engine time: 0.04943477641791105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.966446202248335,
    "estimated_duration": 3600.0102029974646,
    "input_throughput": 4594.910588371921,
    "output_throughput": 4025.2819250163125,
    "total_throughput": 8620.192513388234,
    "itl": 85.71685257308165,
    "ttft": 2171373.095754906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.767210298515887,
    "arrivals": 745105,
    "finished_requests": 67011,
    "scheduler_time": 140.25050631320104
}
#Debug simulation 
Total elapsed time: 4.96654942817986. Arrivals time: 0.27527216263115406 Scheduler time: 4.522555842064321 Scheduler overhead time: 0.05787526769563556 Adapter cache time: 0.023600243963301182 Engine time: 0.059832092840224504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.559886687900871,
    "estimated_duration": 3600.0112294208343,
    "input_throughput": 5344.205829906587,
    "output_throughput": 4671.601539061207,
    "total_throughput": 10015.807368967795,
    "itl": 117.5712071516548,
    "ttft": 2086216.3796809667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8087476024032196,
    "arrivals": 743742,
    "finished_requests": 77932,
    "scheduler_time": 127.57868381128331
}
#Debug simulation 
Total elapsed time: 5.559991272166371. Arrivals time: 0.25182286743074656 Scheduler time: 5.177316288929433 Scheduler overhead time: 0.04489356093108654 Adapter cache time: 0.017705764155834913 Engine time: 0.0470606847666204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.363915740977973,
    "estimated_duration": 3600.1099129003837,
    "input_throughput": 5154.834282559168,
    "output_throughput": 4511.752527831625,
    "total_throughput": 9666.586810390794,
    "itl": 107.07230217011315,
    "ttft": 2104115.071315674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.08863748684526,
    "arrivals": 743742,
    "finished_requests": 75219,
    "scheduler_time": 131.05515249360508
}
#Debug simulation 
Total elapsed time: 5.364024391863495. Arrivals time: 0.24528916971758008 Scheduler time: 4.980035691987723 Scheduler overhead time: 0.048194758128374815 Adapter cache time: 0.01864536479115486 Engine time: 0.04912896128371358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.936988766305149,
    "estimated_duration": 3600.030613887032,
    "input_throughput": 4621.178202159046,
    "output_throughput": 4040.7900821413627,
    "total_throughput": 8661.968284300408,
    "itl": 85.27152613765047,
    "ttft": 2162166.856459457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8410348674469033,
    "arrivals": 743742,
    "finished_requests": 67385,
    "scheduler_time": 140.83466147032826
}
#Debug simulation 
Total elapsed time: 4.937104970216751. Arrivals time: 0.22940633399412036 Scheduler time: 4.540767686907202 Scheduler overhead time: 0.05803420161828399 Adapter cache time: 0.021848380099982023 Engine time: 0.05949771637097001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.400649253278971,
    "estimated_duration": 3600.074324923349,
    "input_throughput": 5155.2160663780605,
    "output_throughput": 4512.292117842837,
    "total_throughput": 9667.508184220897,
    "itl": 107.06364132901513,
    "ttft": 2104110.815649229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.819322618022555,
    "arrivals": 743742,
    "finished_requests": 75227,
    "scheduler_time": 131.06306487127742
}
#Debug simulation 
Total elapsed time: 5.400754441972822. Arrivals time: 0.24518806114792824 Scheduler time: 5.015784682705998 Scheduler overhead time: 0.048552978318184614 Adapter cache time: 0.018682838417589664 Engine time: 0.049705829471349716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.961005744989961,
    "estimated_duration": 3600.0866336521317,
    "input_throughput": 4621.110460089983,
    "output_throughput": 4040.758870639348,
    "total_throughput": 8661.86933072933,
    "itl": 85.27076161814679,
    "ttft": 2162241.6132461503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8041680100094855,
    "arrivals": 743742,
    "finished_requests": 67386,
    "scheduler_time": 140.83821811962972
}
#Debug simulation 
Total elapsed time: 4.961113293655217. Arrivals time: 0.22924352064728737 Scheduler time: 4.565930899232626 Scheduler overhead time: 0.05804543988779187 Adapter cache time: 0.021741630043834448 Engine time: 0.05873150285333395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.366839758120477,
    "estimated_duration": 3600.0628694427205,
    "input_throughput": 5155.550798165112,
    "output_throughput": 4512.5720269753965,
    "total_throughput": 9668.122825140508,
    "itl": 107.05675213650737,
    "ttft": 2104050.1828798926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5749957267194823,
    "arrivals": 743742,
    "finished_requests": 75231,
    "scheduler_time": 131.07084722272376
}
#Debug simulation 
Total elapsed time: 5.366946822032332. Arrivals time: 0.244210593868047 Scheduler time: 4.983580217696726 Scheduler overhead time: 0.04836287349462509 Adapter cache time: 0.018581552430987358 Engine time: 0.049447891768068075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.257167684379965,
    "estimated_duration": 3600.0529238358636,
    "input_throughput": 4621.153730782903,
    "output_throughput": 4040.7967070939767,
    "total_throughput": 8661.95043787688,
    "itl": 85.26992533411882,
    "ttft": 2162227.5621030796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7706150273979038,
    "arrivals": 743742,
    "finished_requests": 67386,
    "scheduler_time": 140.83806128597334
}
#Debug simulation 
Total elapsed time: 5.25730098830536. Arrivals time: 0.5536871631629765 Scheduler time: 4.536616776138544 Scheduler overhead time: 0.058435240760445595 Adapter cache time: 0.021635152865201235 Engine time: 0.059338553342968225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.626243053004146,
    "estimated_duration": 3600.093724310878,
    "input_throughput": 5425.263755803655,
    "output_throughput": 4703.882536625223,
    "total_throughput": 10129.146292428879,
    "itl": 117.30991842989812,
    "ttft": 2082916.3574566506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2400804256555067,
    "arrivals": 743017,
    "finished_requests": 78975,
    "scheduler_time": 128.2156423917379
}
#Debug simulation 
Total elapsed time: 5.6263513448648155. Arrivals time: 0.26263674534857273 Scheduler time: 5.233930793590844 Scheduler overhead time: 0.04534690547734499 Adapter cache time: 0.017034293618053198 Engine time: 0.0460887118242681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.494109480176121,
    "estimated_duration": 3600.093861108893,
    "input_throughput": 5232.233860202193,
    "output_throughput": 4538.247787508398,
    "total_throughput": 9770.48164771059,
    "itl": 106.86005613431935,
    "ttft": 2101488.1694742097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.485753521118318,
    "arrivals": 743017,
    "finished_requests": 76159,
    "scheduler_time": 131.60598724249076
}
#Debug simulation 
Total elapsed time: 5.4942132900469005. Arrivals time: 0.2937745354138315 Scheduler time: 5.0607283296994865 Scheduler overhead time: 0.048866286873817444 Adapter cache time: 0.017976782750338316 Engine time: 0.04987323097884655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.98716129316017,
    "estimated_duration": 3600.0675861126606,
    "input_throughput": 4676.861919189842,
    "output_throughput": 4057.264384797832,
    "total_throughput": 8734.126303987674,
    "itl": 85.10500779039154,
    "ttft": 2158046.235626635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.288302362654384,
    "arrivals": 743017,
    "finished_requests": 67946,
    "scheduler_time": 141.34256958313412
}
#Debug simulation 
Total elapsed time: 4.987265080213547. Arrivals time: 0.23256408283486962 Scheduler time: 4.587577260565013 Scheduler overhead time: 0.05859030783176422 Adapter cache time: 0.02107009245082736 Engine time: 0.05972927575930953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.463524243794382,
    "estimated_duration": 3600.109090602462,
    "input_throughput": 5232.2258925903225,
    "output_throughput": 4538.506358779734,
    "total_throughput": 9770.732251370056,
    "itl": 106.85425482605478,
    "ttft": 2101400.330499217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2705792702548164,
    "arrivals": 743017,
    "finished_requests": 76162,
    "scheduler_time": 131.6139116308581
}
#Debug simulation 
Total elapsed time: 5.46363103762269. Arrivals time: 0.2492801700718701 Scheduler time: 5.074621238280088 Scheduler overhead time: 0.04876600345596671 Adapter cache time: 0.018036500550806522 Engine time: 0.04981560865417123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.9628133797086775,
    "estimated_duration": 3600.0386691416534,
    "input_throughput": 4676.899485642025,
    "output_throughput": 4057.2969743912686,
    "total_throughput": 8734.196460033294,
    "itl": 85.10433690221325,
    "ttft": 2158034.063703072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2595130751049406,
    "arrivals": 743017,
    "finished_requests": 67946,
    "scheduler_time": 141.34244189967634
}
#Debug simulation 
Total elapsed time: 4.962920134887099. Arrivals time: 0.22936504799872637 Scheduler time: 4.566221827175468 Scheduler overhead time: 0.0584715586155653 Adapter cache time: 0.021180737763643265 Engine time: 0.05994409555569291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.459816966205835,
    "estimated_duration": 3600.1070801601645,
    "input_throughput": 5232.755743243587,
    "output_throughput": 4538.916381140815,
    "total_throughput": 9771.672124384402,
    "itl": 106.84823835199639,
    "ttft": 2101251.2393761636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0387463677115605,
    "arrivals": 743017,
    "finished_requests": 76171,
    "scheduler_time": 131.62154322623195
}
#Debug simulation 
Total elapsed time: 5.459920499008149. Arrivals time: 0.24888113467022777 Scheduler time: 5.071249061264098 Scheduler overhead time: 0.049000468105077744 Adapter cache time: 0.017926138825714588 Engine time: 0.049828202463686466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.002056012395769,
    "estimated_duration": 3600.0059752604957,
    "input_throughput": 4676.941959459297,
    "output_throughput": 4057.333821214861,
    "total_throughput": 8734.275780674157,
    "itl": 85.10356166824847,
    "ttft": 2158020.410681424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2269956783764324,
    "arrivals": 743017,
    "finished_requests": 67946,
    "scheduler_time": 141.3422654152471
}
#Debug simulation 
Total elapsed time: 5.002160824369639. Arrivals time: 0.27457010420039296 Scheduler time: 4.560001560021192 Scheduler overhead time: 0.05842665629461408 Adapter cache time: 0.021112871821969748 Engine time: 0.06036233715713024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.714676490984857,
    "estimated_duration": 3600.0462869168177,
    "input_throughput": 5468.276358429739,
    "output_throughput": 4746.85507853162,
    "total_throughput": 10215.13143696136,
    "itl": 116.15683541803448,
    "ttft": 2077473.875256531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.598676749556342,
    "arrivals": 740854,
    "finished_requests": 79732,
    "scheduler_time": 129.29590600107082
}
#Debug simulation 
Total elapsed time: 5.714831796940416. Arrivals time: 0.30262126959860325 Scheduler time: 5.284747841767967 Scheduler overhead time: 0.045473599806427956 Adapter cache time: 0.01436068257316947 Engine time: 0.046167726162821054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.4830555147491395,
    "estimated_duration": 3600.06097625919,
    "input_throughput": 5267.8799401076085,
    "output_throughput": 4578.402451707064,
    "total_throughput": 9846.282391814673,
    "itl": 105.91551661091329,
    "ttft": 2096972.997865093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7904348894720936,
    "arrivals": 740854,
    "finished_requests": 76841,
    "scheduler_time": 132.62292057302227
}
#Debug simulation 
Total elapsed time: 5.483156026806682. Arrivals time: 0.2451895629055798 Scheduler time: 5.098453591112047 Scheduler overhead time: 0.05150130856782198 Adapter cache time: 0.014815977308899164 Engine time: 0.05010442063212395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.02542314492166,
    "estimated_duration": 3600.0358933868124,
    "input_throughput": 4702.19061734814,
    "output_throughput": 4091.4933729015906,
    "total_throughput": 8793.68399024973,
    "itl": 84.65028053023386,
    "ttft": 2158215.076391284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6144287572568436,
    "arrivals": 740854,
    "finished_requests": 68592,
    "scheduler_time": 142.00204345431226
}
#Debug simulation 
Total elapsed time: 5.025527729187161. Arrivals time: 0.23211385775357485 Scheduler time: 4.627254661172628 Scheduler overhead time: 0.05911336047574878 Adapter cache time: 0.01856598537415266 Engine time: 0.060665940400213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.509027029853314,
    "estimated_duration": 3600.046704137,
    "input_throughput": 5268.379151360652,
    "output_throughput": 4578.470324026316,
    "total_throughput": 9846.849475386967,
    "itl": 105.91235086641416,
    "ttft": 2097065.633552756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.608577941968102,
    "arrivals": 740854,
    "finished_requests": 76847,
    "scheduler_time": 132.62577664438035
}
#Debug simulation 
Total elapsed time: 5.50913255661726. Arrivals time: 0.2487981398589909 Scheduler time: 5.122637591324747 Scheduler overhead time: 0.049140936229377985 Adapter cache time: 0.01494088489562273 Engine time: 0.05047580040991306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.03230634983629,
    "estimated_duration": 3600.005487005751,
    "input_throughput": 4701.0078348730485,
    "output_throughput": 4090.2312657993116,
    "total_throughput": 8791.23910067236,
    "itl": 84.60726471975178,
    "ttft": 2158220.218305309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5889533445332353,
    "arrivals": 740854,
    "finished_requests": 68572,
    "scheduler_time": 142.02700345057733
}
#Debug simulation 
Total elapsed time: 5.0324110658839345. Arrivals time: 0.23430684907361865 Scheduler time: 4.632785968948156 Scheduler overhead time: 0.05879526073113084 Adapter cache time: 0.01847073808312416 Engine time: 0.06022251537069678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.504217613954097,
    "estimated_duration": 3600.09463463466,
    "input_throughput": 5268.597613386024,
    "output_throughput": 4578.701582291262,
    "total_throughput": 9847.299195677286,
    "itl": 105.90678274026763,
    "ttft": 2097017.225156815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.432273878357363,
    "arrivals": 740854,
    "finished_requests": 76850,
    "scheduler_time": 132.6333883895796
}
#Debug simulation 
Total elapsed time: 5.5043227202259. Arrivals time: 0.24813220463693142 Scheduler time: 5.118410448543727 Scheduler overhead time: 0.04937573103234172 Adapter cache time: 0.014877299312502146 Engine time: 0.050342448987066746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.004113601986319,
    "estimated_duration": 3600.076900674236,
    "input_throughput": 4701.162910389582,
    "output_throughput": 4090.3920683589035,
    "total_throughput": 8791.554978748485,
    "itl": 84.60702486323379,
    "ttft": 2158197.963339528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5653419863991593,
    "arrivals": 740854,
    "finished_requests": 68575,
    "scheduler_time": 142.03062256881316
}
#Debug simulation 
Total elapsed time: 5.004214923363179. Arrivals time: 0.231169109698385 Scheduler time: 4.607183076441288 Scheduler overhead time: 0.05906610516831279 Adapter cache time: 0.018601772375404835 Engine time: 0.06040474213659763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.664126893971115,
    "estimated_duration": 3600.1175782465007,
    "input_throughput": 5452.884127623862,
    "output_throughput": 4765.711848877078,
    "total_throughput": 10218.59597650094,
    "itl": 115.67847646482748,
    "ttft": 2081864.938485965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2614438889268844,
    "arrivals": 740135,
    "finished_requests": 79482,
    "scheduler_time": 129.83710325699505
}
#Debug simulation 
Total elapsed time: 5.664231549948454. Arrivals time: 0.2520849360153079 Scheduler time: 5.2840048042126 Scheduler overhead time: 0.04578348947688937 Adapter cache time: 0.014029628597199917 Engine time: 0.04674838110804558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.584925387986004,
    "estimated_duration": 3600.046910283677,
    "input_throughput": 5248.876881582361,
    "output_throughput": 4591.056842283653,
    "total_throughput": 9839.933723866014,
    "itl": 105.5146313384874,
    "ttft": 2100840.6051268387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4312542873388185,
    "arrivals": 740135,
    "finished_requests": 76517,
    "scheduler_time": 133.11212455989158
}
#Debug simulation 
Total elapsed time: 5.5851090382784605. Arrivals time: 0.30189949832856655 Scheduler time: 5.144870494958013 Scheduler overhead time: 0.049483674578368664 Adapter cache time: 0.014937919098883867 Engine time: 0.05062957853078842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.977352065034211,
    "estimated_duration": 3600.028348596979,
    "input_throughput": 4678.583713532187,
    "output_throughput": 4094.5547014219337,
    "total_throughput": 8773.13841495412,
    "itl": 84.35599400051092,
    "ttft": 2161125.040211358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.227245193920106,
    "arrivals": 740135,
    "finished_requests": 68145,
    "scheduler_time": 142.41160270258845
}
#Debug simulation 
Total elapsed time: 4.977458075620234. Arrivals time: 0.2261353274807334 Scheduler time: 4.587297826074064 Scheduler overhead time: 0.05886197555810213 Adapter cache time: 0.01764016505330801 Engine time: 0.059823847375810146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.499981358181685,
    "estimated_duration": 3600.0061841167085,
    "input_throughput": 5249.1479274046105,
    "output_throughput": 4591.182390997851,
    "total_throughput": 9840.33031840246,
    "itl": 105.50982465205797,
    "ttft": 2100827.5343247117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2743853173544597,
    "arrivals": 740135,
    "finished_requests": 76519,
    "scheduler_time": 133.11579676868695
}
#Debug simulation 
Total elapsed time: 5.50008841836825. Arrivals time: 0.25058702006936073 Scheduler time: 5.111599474214017 Scheduler overhead time: 0.049411430954933167 Adapter cache time: 0.014862353447824717 Engine time: 0.050366101786494255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.99014896992594,
    "estimated_duration": 3600.008143865212,
    "input_throughput": 4678.6099716752815,
    "output_throughput": 4094.5776817531278,
    "total_throughput": 8773.18765342841,
    "itl": 84.35553482108322,
    "ttft": 2161116.5651238356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2071548277884796,
    "arrivals": 740135,
    "finished_requests": 68145,
    "scheduler_time": 142.411488336953
}
#Debug simulation 
Total elapsed time: 4.990254411939532. Arrivals time: 0.22989606019109488 Scheduler time: 4.59588373079896 Scheduler overhead time: 0.05886849109083414 Adapter cache time: 0.017858394887298346 Engine time: 0.05996721424162388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.591878375969827,
    "estimated_duration": 3600.0906377711735,
    "input_throughput": 5249.642273368023,
    "output_throughput": 4591.2082953092,
    "total_throughput": 9840.850568677222,
    "itl": 105.50548503556406,
    "ttft": 2100837.495886717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1258456732099793,
    "arrivals": 740135,
    "finished_requests": 76526,
    "scheduler_time": 133.12355700614768
}
#Debug simulation 
Total elapsed time: 5.5919912392273545. Arrivals time: 0.25495778070762753 Scheduler time: 5.198920421302319 Scheduler overhead time: 0.04940121853724122 Adapter cache time: 0.015013089403510094 Engine time: 0.050304565113037825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.989167606923729,
    "estimated_duration": 3600.082688012136,
    "input_throughput": 4678.513095292333,
    "output_throughput": 4094.4928984782,
    "total_throughput": 8773.005993770534,
    "itl": 84.3551274818576,
    "ttft": 2161138.2169297533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1872715788334682,
    "arrivals": 740135,
    "finished_requests": 68145,
    "scheduler_time": 142.41512496557664
}
#Debug simulation 
Total elapsed time: 4.989273310638964. Arrivals time: 0.2329740049317479 Scheduler time: 4.589583182241768 Scheduler overhead time: 0.05875656381249428 Adapter cache time: 0.01780646527186036 Engine time: 0.06243386911228299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.0978246298618615,
    "estimated_duration": 3600.1098686297105,
    "input_throughput": 5501.255717936829,
    "output_throughput": 4781.899060917434,
    "total_throughput": 10283.154778854263,
    "itl": 114.56672344993369,
    "ttft": 2072383.9000613203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5605285315401833,
    "arrivals": 738702,
    "finished_requests": 79998,
    "scheduler_time": 130.7004021828828
}
#Debug simulation 
Total elapsed time: 6.097922278102487. Arrivals time: 0.5882595819421113 Scheduler time: 5.382437482010573 Scheduler overhead time: 0.04634278593584895 Adapter cache time: 0.011871331371366978 Engine time: 0.04716754658147693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.605412486940622,
    "estimated_duration": 3600.0869367854943,
    "input_throughput": 5299.45757838702,
    "output_throughput": 4606.020713157021,
    "total_throughput": 9905.478291544041,
    "itl": 104.57872291792971,
    "ttft": 2092619.2176097876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6801424413220971,
    "arrivals": 738702,
    "finished_requests": 77017,
    "scheduler_time": 133.90803071671905
}
#Debug simulation 
Total elapsed time: 5.605557382106781. Arrivals time: 0.3228562995791435 Scheduler time: 5.146073138806969 Scheduler overhead time: 0.049748079385608435 Adapter cache time: 0.012718769256025553 Engine time: 0.05066241277381778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.061162605881691,
    "estimated_duration": 3600.022958360383,
    "input_throughput": 4708.531638842711,
    "output_throughput": 4091.153353840811,
    "total_throughput": 8799.684992683522,
    "itl": 83.49482905468328,
    "ttft": 2154726.1801219424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6192210233071853,
    "arrivals": 738702,
    "finished_requests": 68392,
    "scheduler_time": 143.17731617759787
}
#Debug simulation 
Total elapsed time: 5.06134024169296. Arrivals time: 0.27730360673740506 Scheduler time: 4.6193469311110675 Scheduler overhead time: 0.05938519025221467 Adapter cache time: 0.016395000275224447 Engine time: 0.060714797116816044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.525817499030381,
    "estimated_duration": 3600.0994253205818,
    "input_throughput": 5290.623882784549,
    "output_throughput": 4598.318558528661,
    "total_throughput": 9888.942441313211,
    "itl": 104.24938155050027,
    "ttft": 2092397.5388234744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5627008425164943,
    "arrivals": 738702,
    "finished_requests": 76888,
    "scheduler_time": 134.03211161454246
}
#Debug simulation 
Total elapsed time: 5.525950707029551. Arrivals time: 0.3195559489540756 Scheduler time: 5.070565650705248 Scheduler overhead time: 0.04956750385463238 Adapter cache time: 0.012466685380786657 Engine time: 0.05048765102401376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.027854744810611,
    "estimated_duration": 3600.007306388105,
    "input_throughput": 4708.55211041413,
    "output_throughput": 4091.171141198844,
    "total_throughput": 8799.723251612973,
    "itl": 83.4945003684332,
    "ttft": 2154719.3582703555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6036872350610825,
    "arrivals": 738702,
    "finished_requests": 68392,
    "scheduler_time": 143.17719799356584
}
#Debug simulation 
Total elapsed time: 5.027965541929007. Arrivals time: 0.30255672987550497 Scheduler time: 4.561847930774093 Scheduler overhead time: 0.05897795129567385 Adapter cache time: 0.016366664320230484 Engine time: 0.060273821000009775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.507234497927129,
    "estimated_duration": 3600.0042234066605,
    "input_throughput": 5290.763793042488,
    "output_throughput": 4598.440160810333,
    "total_throughput": 9889.20395385282,
    "itl": 104.24705929121697,
    "ttft": 2092348.5167016643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.468301816331218,
    "arrivals": 738702,
    "finished_requests": 76888,
    "scheduler_time": 134.03130872680396
}
#Debug simulation 
Total elapsed time: 5.507344682235271. Arrivals time: 0.2481815405189991 Scheduler time: 5.121986816637218 Scheduler overhead time: 0.04997675586491823 Adapter cache time: 0.012596675660461187 Engine time: 0.051122460048645735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.071623865049332,
    "estimated_duration": 3600.0918183364784,
    "input_throughput": 4708.662127354563,
    "output_throughput": 4091.173709787701,
    "total_throughput": 8799.835837142264,
    "itl": 83.49449479964474,
    "ttft": 2154781.782774653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5904317357577418,
    "arrivals": 738702,
    "finished_requests": 68394,
    "scheduler_time": 143.18092451196975
}
#Debug simulation 
Total elapsed time: 5.071735610254109. Arrivals time: 0.305225592572242 Scheduler time: 4.6022052322514355 Scheduler overhead time: 0.05932717630639672 Adapter cache time: 0.016400359570980072 Engine time: 0.06054434319958091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.256564563140273,
    "estimated_duration": 3600.075225032361,
    "input_throughput": 4507.650253295506,
    "output_throughput": 3934.348344032917,
    "total_throughput": 8441.998597328424,
    "itl": 124.07339633491394,
    "ttft": 2157935.826702826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.053914200915216,
    "arrivals": 644931,
    "finished_requests": 65832,
    "scheduler_time": 113.62050209389798
}
#Debug simulation 
Total elapsed time: 9.256712256930768. Arrivals time: 0.32146506616845727 Scheduler time: 8.797702505253255 Scheduler overhead time: 0.0452642971649766 Adapter cache time: 0.026634723879396915 Engine time: 0.04511058051139116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.247000148054212,
    "estimated_duration": 3600.031720306708,
    "input_throughput": 3896.4206678725977,
    "output_throughput": 3414.704079038693,
    "total_throughput": 7311.124746911291,
    "itl": 95.88086797288103,
    "ttft": 2241736.173778929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.037198025817056,
    "arrivals": 644931,
    "finished_requests": 56978,
    "scheduler_time": 122.46720469207055
}
#Debug simulation 
Total elapsed time: 15.247101924847811. Arrivals time: 0.33077054750174284 Scheduler time: 14.755748170427978 Scheduler overhead time: 0.06006669998168945 Adapter cache time: 0.01607227325439453 Engine time: 0.058589535765349865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.901944569777697,
    "estimated_duration": 3600.0688144277647,
    "input_throughput": 3963.8131201301035,
    "output_throughput": 3462.9865823777714,
    "total_throughput": 7426.799702507875,
    "itl": 98.93142279532414,
    "ttft": 2234151.664119304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.8180573160996,
    "arrivals": 644931,
    "finished_requests": 57852,
    "scheduler_time": 120.75824176907322
}
#Debug simulation 
Total elapsed time: 5.9020517859607935. Arrivals time: 0.22649834398180246 Scheduler time: 5.4909069603309035 Scheduler overhead time: 0.05316528119146824 Adapter cache time: 0.0542801208794117 Engine time: 0.05260615795850754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.083773775957525,
    "estimated_duration": 3600.1150573656637,
    "input_throughput": 4487.905453728096,
    "output_throughput": 3918.180051256974,
    "total_throughput": 8406.08550498507,
    "itl": 122.74688495225453,
    "ttft": 2165044.692918722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.848312308872313,
    "arrivals": 644931,
    "finished_requests": 65563,
    "scheduler_time": 113.82733303798986
}
#Debug simulation 
Total elapsed time: 8.08387632202357. Arrivals time: 0.31392030604183674 Scheduler time: 7.6218964564614 Scheduler overhead time: 0.044988932088017464 Adapter cache time: 0.03721629921346903 Engine time: 0.045301465317606926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.217743050772697,
    "estimated_duration": 3600.0884294022717,
    "input_throughput": 3963.887909933737,
    "output_throughput": 3463.0946557248844,
    "total_throughput": 7426.982565658621,
    "itl": 98.92643404263846,
    "ttft": 2234168.947452547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.6140468971341,
    "arrivals": 644931,
    "finished_requests": 57854,
    "scheduler_time": 120.76562194142589
}
#Debug simulation 
Total elapsed time: 6.217817903030664. Arrivals time: 0.5411417535506189 Scheduler time: 5.492745992727578 Scheduler overhead time: 0.05281946621835232 Adapter cache time: 0.05418797908350825 Engine time: 0.052377555053681135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.033523263875395,
    "estimated_duration": 3600.0669245393883,
    "input_throughput": 4488.898495148847,
    "output_throughput": 3919.0193670650015,
    "total_throughput": 8407.91786221385,
    "itl": 122.71913081856277,
    "ttft": 2164887.7785498826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.001771368273095,
    "arrivals": 644931,
    "finished_requests": 65575,
    "scheduler_time": 113.8519531322351
}
#Debug simulation 
Total elapsed time: 8.033665050752461. Arrivals time: 0.31276720482856035 Scheduler time: 7.574248271994293 Scheduler overhead time: 0.04473942704498768 Adapter cache time: 0.03671842999756336 Engine time: 0.0445729442872107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.887353009078652,
    "estimated_duration": 3600.111431474876,
    "input_throughput": 3963.8689722872787,
    "output_throughput": 3463.173359301339,
    "total_throughput": 7427.042331588617,
    "itl": 98.92135434084048,
    "ttft": 2234090.166202068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.413971704524286,
    "arrivals": 644931,
    "finished_requests": 57856,
    "scheduler_time": 120.77296027036607
}
#Debug simulation 
Total elapsed time: 5.887459028046578. Arrivals time: 0.2232118956744671 Scheduler time: 5.480268155690283 Scheduler overhead time: 0.05316445278003812 Adapter cache time: 0.053877728059887886 Engine time: 0.052577157504856586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.22626023599878,
    "estimated_duration": 3600.019891963304,
    "input_throughput": 4661.182855533802,
    "output_throughput": 4082.35410943385,
    "total_throughput": 8743.536964967652,
    "itl": 134.75528318172172,
    "ttft": 2125004.065564436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1056,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.982703937739291,
    "arrivals": 576087,
    "finished_requests": 68383,
    "scheduler_time": 111.03407941960226
}
#Debug simulation 
Total elapsed time: 9.226339634973556. Arrivals time: 0.6245775292627513 Scheduler time: 8.47414199076593 Scheduler overhead time: 0.042054031509906054 Adapter cache time: 0.024488952942192554 Engine time: 0.04204341443255544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.652151908259839,
    "estimated_duration": 3600.129312652982,
    "input_throughput": 4467.334254765488,
    "output_throughput": 3914.3582844293105,
    "total_throughput": 8381.692539194799,
    "itl": 122.26679685238545,
    "ttft": 2148796.5061858087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.487791947084391,
    "arrivals": 576087,
    "finished_requests": 65501,
    "scheduler_time": 113.83888300294683
}
#Debug simulation 
Total elapsed time: 7.652291491162032. Arrivals time: 0.30396889289841056 Scheduler time: 7.207187565974891 Scheduler overhead time: 0.045010220259428024 Adapter cache time: 0.030274154618382454 Engine time: 0.04512068070471287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.479540022090077,
    "estimated_duration": 3600.000114006526,
    "input_throughput": 3949.0598749392784,
    "output_throughput": 3479.2793342609584,
    "total_throughput": 7428.339209200237,
    "itl": 99.5429166002138,
    "ttft": 2214286.771507635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.50522989985538,
    "arrivals": 576087,
    "finished_requests": 57952,
    "scheduler_time": 120.41743277568396
}
#Debug simulation 
Total elapsed time: 5.479644150938839. Arrivals time: 0.2765254881232977 Scheduler time: 5.024351709056646 Scheduler overhead time: 0.05248544318601489 Adapter cache time: 0.049795123748481274 Engine time: 0.052099667489528656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.317193651106209,
    "estimated_duration": 3600.005261940744,
    "input_throughput": 4474.5962374832625,
    "output_throughput": 3919.2784380525277,
    "total_throughput": 8393.874675535792,
    "itl": 123.07373627215183,
    "ttft": 2148164.07959955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.93587455791432,
    "arrivals": 576087,
    "finished_requests": 65605,
    "scheduler_time": 113.51583185253303
}
#Debug simulation 
Total elapsed time: 7.3173006642609835. Arrivals time: 0.3004402373917401 Scheduler time: 6.874210634734482 Scheduler overhead time: 0.04455833276733756 Adapter cache time: 0.03276600409299135 Engine time: 0.04469877062365413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.487799192778766,
    "estimated_duration": 3600.0353279597766,
    "input_throughput": 3949.0223580824936,
    "output_throughput": 3479.381133489797,
    "total_throughput": 7428.4034915722905,
    "itl": 99.53825988782074,
    "ttft": 2214246.2582763336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.3225525500812,
    "arrivals": 576087,
    "finished_requests": 57954,
    "scheduler_time": 120.42464799088204
}
#Debug simulation 
Total elapsed time: 5.487913353834301. Arrivals time: 0.296696359757334 Scheduler time: 5.013949231710285 Scheduler overhead time: 0.05178093025460839 Adapter cache time: 0.04921295307576656 Engine time: 0.05210828594863415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.4395494712516665,
    "estimated_duration": 3600.054084172335,
    "input_throughput": 4484.165132677829,
    "output_throughput": 3923.219115539235,
    "total_throughput": 8407.384248217064,
    "itl": 123.1706322761072,
    "ttft": 2148346.839149895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.563113568974826,
    "arrivals": 576087,
    "finished_requests": 65694,
    "scheduler_time": 113.53332760371168
}
#Debug simulation 
Total elapsed time: 7.439677556976676. Arrivals time: 0.3074251622892916 Scheduler time: 6.991667789872736 Scheduler overhead time: 0.04475164646282792 Adapter cache time: 0.030883719213306904 Engine time: 0.0443680789321661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.429178580176085,
    "estimated_duration": 3600.0746794951924,
    "input_throughput": 3949.311963160065,
    "output_throughput": 3479.624762049809,
    "total_throughput": 7428.936725209874,
    "itl": 99.53405462973808,
    "ttft": 2214169.178181689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.146088715605448,
    "arrivals": 576087,
    "finished_requests": 57957,
    "scheduler_time": 120.43185011302685
}
#Debug simulation 
Total elapsed time: 5.429282717872411. Arrivals time: 0.2736353217624128 Scheduler time: 4.978063188493252 Scheduler overhead time: 0.05212414404377341 Adapter cache time: 0.04943975666537881 Engine time: 0.05181743251159787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.363872213289142,
    "estimated_duration": 3600.038279480712,
    "input_throughput": 4685.808786020266,
    "output_throughput": 4082.7446429597744,
    "total_throughput": 8768.55342898004,
    "itl": 134.63946806185155,
    "ttft": 2120443.763109545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.637332431902356,
    "arrivals": 564621,
    "finished_requests": 68404,
    "scheduler_time": 111.07989594598516
}
#Debug simulation 
Total elapsed time: 8.363993402104825. Arrivals time: 0.31676866905763745 Scheduler time: 7.919817678164691 Scheduler overhead time: 0.041803302709013224 Adapter cache time: 0.024659468326717615 Engine time: 0.04181509604677558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.212286457885057,
    "estimated_duration": 3600.109422565806,
    "input_throughput": 4501.052634242204,
    "output_throughput": 3917.495927095589,
    "total_throughput": 8418.548561337793,
    "itl": 122.72952335818643,
    "ttft": 2145579.438273418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.670527393259094,
    "arrivals": 564621,
    "finished_requests": 65626,
    "scheduler_time": 113.62522816706962
}
#Debug simulation 
Total elapsed time: 7.212410429958254. Arrivals time: 0.3063285364769399 Scheduler time: 6.770130850374699 Scheduler overhead time: 0.04428896540775895 Adapter cache time: 0.026520843617618084 Engine time: 0.044591222424060106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.285295417997986,
    "estimated_duration": 3600.100477521315,
    "input_throughput": 3986.5570668409287,
    "output_throughput": 3467.999873324669,
    "total_throughput": 7454.556940165598,
    "itl": 98.77796581400872,
    "ttft": 2215725.6635832014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.35610071607846,
    "arrivals": 564621,
    "finished_requests": 58094,
    "scheduler_time": 120.67041054290064
}
#Debug simulation 
Total elapsed time: 5.285420620813966. Arrivals time: 0.2290255161933601 Scheduler time: 4.881013894919306 Scheduler overhead time: 0.05244089383631945 Adapter cache time: 0.04548026481643319 Engine time: 0.052934990264475346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.2901607737876475,
    "estimated_duration": 3600.108815263996,
    "input_throughput": 4501.813370552673,
    "output_throughput": 3918.041293695078,
    "total_throughput": 8419.85466424775,
    "itl": 122.71090578285327,
    "ttft": 2145730.3899180396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.108297899067402,
    "arrivals": 564621,
    "finished_requests": 65636,
    "scheduler_time": 113.64196468162876
}
#Debug simulation 
Total elapsed time: 7.29027604078874. Arrivals time: 0.34686765540391207 Scheduler time: 6.806510670110583 Scheduler overhead time: 0.04475047532469034 Adapter cache time: 0.026530610863119364 Engine time: 0.044817556627094746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.265167402569205,
    "estimated_duration": 3600.0461711359867,
    "input_throughput": 3986.7399799128457,
    "output_throughput": 3468.2335743655567,
    "total_throughput": 7454.973554278402,
    "itl": 98.77395901918888,
    "ttft": 2215790.8444971675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.192892380906056,
    "arrivals": 564621,
    "finished_requests": 58096,
    "scheduler_time": 120.67389006802368
}
#Debug simulation 
Total elapsed time: 5.265346694737673. Arrivals time: 0.26846995670348406 Scheduler time: 4.822559125721455 Scheduler overhead time: 0.05220514675602317 Adapter cache time: 0.04522864753380418 Engine time: 0.05251332093030214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.518807182088494,
    "estimated_duration": 3600.119268602434,
    "input_throughput": 4501.976126555332,
    "output_throughput": 3918.276297961664,
    "total_throughput": 8420.252424516995,
    "itl": 122.69374535664153,
    "ttft": 2145501.3489225046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.558562393635473,
    "arrivals": 564621,
    "finished_requests": 65641,
    "scheduler_time": 113.65878670221255
}
#Debug simulation 
Total elapsed time: 7.518909456208348. Arrivals time: 0.2420553546398878 Scheduler time: 7.140778367873281 Scheduler overhead time: 0.0444879736751318 Adapter cache time: 0.026349045801907778 Engine time: 0.04471488716080785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.236541450023651,
    "estimated_duration": 3600.0066152709423,
    "input_throughput": 3987.194339896984,
    "output_throughput": 3468.5494596126523,
    "total_throughput": 7455.743799509636,
    "itl": 98.76887921170675,
    "ttft": 2215744.3254413763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.044594985935603,
    "arrivals": 564621,
    "finished_requests": 58101,
    "scheduler_time": 120.67737793484478
}
#Debug simulation 
Total elapsed time: 5.236647600773722. Arrivals time: 0.21633074153214693 Scheduler time: 4.8461395488120615 Scheduler overhead time: 0.05226953839883208 Adapter cache time: 0.045409712474793196 Engine time: 0.05212843418121338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.824152864981443,
    "estimated_duration": 3600.026296372581,
    "input_throughput": 4663.84009942308,
    "output_throughput": 4077.233550985401,
    "total_throughput": 8741.073650408482,
    "itl": 134.4646251428623,
    "ttft": 2117378.3298924556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.680059358445112,
    "arrivals": 558945,
    "finished_requests": 68268,
    "scheduler_time": 111.01317053291315
}
#Debug simulation 
Total elapsed time: 7.824257545173168. Arrivals time: 0.30896669439971447 Scheduler time: 7.392767315264791 Scheduler overhead time: 0.041579803451895714 Adapter cache time: 0.020527146756649017 Engine time: 0.041421730536967516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.781322777271271,
    "estimated_duration": 3600.1312414873555,
    "input_throughput": 4489.570772792831,
    "output_throughput": 3922.9561514999573,
    "total_throughput": 8412.526924292788,
    "itl": 123.18577965044148,
    "ttft": 2141131.1080607525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.311903975051823,
    "arrivals": 558945,
    "finished_requests": 65693,
    "scheduler_time": 113.45926958887621
}
#Debug simulation 
Total elapsed time: 6.781427407171577. Arrivals time: 0.3010743735358119 Scheduler time: 6.344836968462914 Scheduler overhead time: 0.04442967474460602 Adapter cache time: 0.02529088268056512 Engine time: 0.04528617672622204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.120248016901314,
    "estimated_duration": 3600.0126228653767,
    "input_throughput": 3962.4144397155446,
    "output_throughput": 3470.0481105694025,
    "total_throughput": 7432.462550284948,
    "itl": 98.87373397628129,
    "ttft": 2210808.9936194615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.559369106553142,
    "arrivals": 558945,
    "finished_requests": 57968,
    "scheduler_time": 120.64748230548473
}
#Debug simulation 
Total elapsed time: 5.120404413901269. Arrivals time: 0.2664158120751381 Scheduler time: 4.683234187308699 Scheduler overhead time: 0.0523575940169394 Adapter cache time: 0.04139174101874232 Engine time: 0.052528031170368195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.8005423857830465,
    "estimated_duration": 3600.134525189792,
    "input_throughput": 4490.424979090956,
    "output_throughput": 3923.692545698779,
    "total_throughput": 8414.117524789735,
    "itl": 123.16838349675217,
    "ttft": 2140972.570931696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.76494491156655,
    "arrivals": 558945,
    "finished_requests": 65705,
    "scheduler_time": 113.47576494356471
}
#Debug simulation 
Total elapsed time: 6.800643974915147. Arrivals time: 0.3068108675070107 Scheduler time: 6.359663133975118 Scheduler overhead time: 0.044420665595680475 Adapter cache time: 0.024977050721645355 Engine time: 0.04427128005772829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.108755742199719,
    "estimated_duration": 3600.0839926040917,
    "input_throughput": 3962.442828918954,
    "output_throughput": 3470.0573724569276,
    "total_throughput": 7432.500201375882,
    "itl": 98.8694757359567,
    "ttft": 2210863.536661907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.411487442450252,
    "arrivals": 558945,
    "finished_requests": 57970,
    "scheduler_time": 120.65470752755716
}
#Debug simulation 
Total elapsed time: 5.108859522268176. Arrivals time: 0.26453805062919855 Scheduler time: 4.673794810660183 Scheduler overhead time: 0.05242458917200565 Adapter cache time: 0.04139321809634566 Engine time: 0.05232279235497117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.79467366496101,
    "estimated_duration": 3600.00926378068,
    "input_throughput": 4492.303162302432,
    "output_throughput": 3926.4146184878095,
    "total_throughput": 8418.717780790243,
    "itl": 123.25873622280946,
    "ttft": 2140359.8282513553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.124455769676679,
    "arrivals": 558945,
    "finished_requests": 65741,
    "scheduler_time": 113.4643117807522
}
#Debug simulation 
Total elapsed time: 6.794777848757803. Arrivals time: 0.2985842078924179 Scheduler time: 6.361399138346314 Scheduler overhead time: 0.044658469036221504 Adapter cache time: 0.025017658714205027 Engine time: 0.04458595858886838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.102467508986592,
    "estimated_duration": 3600.051824714833,
    "input_throughput": 3962.5218453987063,
    "output_throughput": 3470.1786552724366,
    "total_throughput": 7432.700500671142,
    "itl": 98.8658860056794,
    "ttft": 2210808.4531572727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.270233527999029,
    "arrivals": 558945,
    "finished_requests": 57971,
    "scheduler_time": 120.65820236641486
}
#Debug simulation 
Total elapsed time: 5.102588408160955. Arrivals time: 0.27391816303133965 Scheduler time: 4.659521582070738 Scheduler overhead time: 0.05185216199606657 Adapter cache time: 0.04112902656197548 Engine time: 0.051834417041391134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.530147085431963,
    "estimated_duration": 3600.046426913565,
    "input_throughput": 4700.110218996977,
    "output_throughput": 4075.857158481111,
    "total_throughput": 8775.967377478088,
    "itl": 134.10751490611017,
    "ttft": 2112439.019945687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 799,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.283314816528103,
    "arrivals": 556042,
    "finished_requests": 68275,
    "scheduler_time": 111.0878965482661
}
#Debug simulation 
Total elapsed time: 7.530332577414811. Arrivals time: 0.2515842542052269 Scheduler time: 7.1556348986923695 Scheduler overhead time: 0.04198421165347099 Adapter cache time: 0.019635611213743687 Engine time: 0.042237733490765095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.541734017431736,
    "estimated_duration": 3600.012419188446,
    "input_throughput": 4518.564134194587,
    "output_throughput": 3917.892595264874,
    "total_throughput": 8436.456729459462,
    "itl": 122.58824028266424,
    "ttft": 2135695.3229089943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.460028137275959,
    "arrivals": 556042,
    "finished_requests": 65591,
    "scheduler_time": 113.60837489366583
}
#Debug simulation 
Total elapsed time: 6.541837349999696. Arrivals time: 0.23906821850687265 Scheduler time: 6.169309425633401 Scheduler overhead time: 0.04454738786444068 Adapter cache time: 0.0236860029399395 Engine time: 0.04462874960154295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.958651565015316,
    "estimated_duration": 3600.0775409235202,
    "input_throughput": 4001.8349150069207,
    "output_throughput": 3474.1621139614513,
    "total_throughput": 7475.997028968372,
    "itl": 98.86900551625362,
    "ttft": 2202746.6935388413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.87414371758671,
    "arrivals": 556042,
    "finished_requests": 58065,
    "scheduler_time": 120.66248380906947
}
#Debug simulation 
Total elapsed time: 4.958754080813378. Arrivals time: 0.2173942355439067 Scheduler time: 4.572647339198738 Scheduler overhead time: 0.05194382602348924 Adapter cache time: 0.04023956274613738 Engine time: 0.052217168267816305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.459802233148366,
    "estimated_duration": 3600.1160991068286,
    "input_throughput": 4518.000406718925,
    "output_throughput": 3919.3941560664366,
    "total_throughput": 8437.39456278536,
    "itl": 122.61142543742979,
    "ttft": 2134910.5773867723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.852582445624273,
    "arrivals": 556042,
    "finished_requests": 65597,
    "scheduler_time": 113.6258150386096
}
#Debug simulation 
Total elapsed time: 6.459929634816945. Arrivals time: 0.23684020526707172 Scheduler time: 6.0900259227491915 Scheduler overhead time: 0.044602017384022474 Adapter cache time: 0.0231526424176991 Engine time: 0.044751930981874466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.948725208174437,
    "estimated_duration": 3600.0495960644694,
    "input_throughput": 4002.0454206381414,
    "output_throughput": 3474.351301624682,
    "total_throughput": 7476.3967222628235,
    "itl": 98.86579262477024,
    "ttft": 2202684.666103256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.738481966904084,
    "arrivals": 556042,
    "finished_requests": 58068,
    "scheduler_time": 120.6659596072852
}
#Debug simulation 
Total elapsed time: 4.948833042755723. Arrivals time: 0.21063695335760713 Scheduler time: 4.569868613965809 Scheduler overhead time: 0.051990797743201256 Adapter cache time: 0.039990360382944345 Engine time: 0.05209324788302183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.661651818081737,
    "estimated_duration": 3600.1222406478764,
    "input_throughput": 4518.696286566214,
    "output_throughput": 3919.8918971874673,
    "total_throughput": 8438.588183753682,
    "itl": 122.59945557770044,
    "ttft": 2134914.930802366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.403072703392213,
    "arrivals": 556042,
    "finished_requests": 65602,
    "scheduler_time": 113.63892492515313
}
#Debug simulation 
Total elapsed time: 6.661756357178092. Arrivals time: 0.24054924212396145 Scheduler time: 6.287542822770774 Scheduler overhead time: 0.044669969007372856 Adapter cache time: 0.02323660673573613 Engine time: 0.04507096251472831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.995189964771271,
    "estimated_duration": 3600.0218800605794,
    "input_throughput": 4002.1298425434998,
    "output_throughput": 3474.402772182463,
    "total_throughput": 7476.532614725963,
    "itl": 98.86246358586051,
    "ttft": 2202610.8560373313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.603234450574687,
    "arrivals": 556042,
    "finished_requests": 58070,
    "scheduler_time": 120.66941878792352
}
#Debug simulation 
Total elapsed time: 4.995314474683255. Arrivals time: 0.22740982566028833 Scheduler time: 4.598882206715643 Scheduler overhead time: 0.052111306227743626 Adapter cache time: 0.04034791840240359 Engine time: 0.052257869858294725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.474420394748449,
    "estimated_duration": 3600.023757270131,
    "input_throughput": 4676.06108598712,
    "output_throughput": 4083.346108567628,
    "total_throughput": 8759.407194554748,
    "itl": 134.69720671344035,
    "ttft": 2119914.5315181008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.26500382560778,
    "arrivals": 554638,
    "finished_requests": 68297,
    "scheduler_time": 110.99469604334804
}
#Debug simulation 
Total elapsed time: 7.474557286128402. Arrivals time: 0.25057512894272804 Scheduler time: 7.1056973868981 Scheduler overhead time: 0.04126393049955368 Adapter cache time: 0.016919797752052546 Engine time: 0.04108426021412015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.45823678560555,
    "estimated_duration": 3600.0250537800875,
    "input_throughput": 4492.56956781945,
    "output_throughput": 3925.502680921972,
    "total_throughput": 8418.072248741422,
    "itl": 123.04749901419255,
    "ttft": 2143655.3841235344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.608435630304748,
    "arrivals": 554638,
    "finished_requests": 65601,
    "scheduler_time": 113.5255619044091
}
#Debug simulation 
Total elapsed time: 6.458348115906119. Arrivals time: 0.23595940228551626 Scheduler time: 6.091059962287545 Scheduler overhead time: 0.0446330402046442 Adapter cache time: 0.021620676387101412 Engine time: 0.044595088344067335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.943686904851347,
    "estimated_duration": 3600.074735869011,
    "input_throughput": 3978.741290364471,
    "output_throughput": 3482.212709390856,
    "total_throughput": 7460.9539997553275,
    "itl": 99.20141142577145,
    "ttft": 2211869.005032891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.410381825370491,
    "arrivals": 554638,
    "finished_requests": 58093,
    "scheduler_time": 120.55768821340754
}
#Debug simulation 
Total elapsed time: 4.943810577969998. Arrivals time: 0.21791598480194807 Scheduler time: 4.560547643341124 Scheduler overhead time: 0.05195131665095687 Adapter cache time: 0.03715841006487608 Engine time: 0.05189722031354904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.40254598390311,
    "estimated_duration": 3600.0319168531646,
    "input_throughput": 4492.972666236427,
    "output_throughput": 3926.1376916777194,
    "total_throughput": 8419.110357914147,
    "itl": 123.03410664884154,
    "ttft": 2143591.313494561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1997414802247555,
    "arrivals": 554638,
    "finished_requests": 65609,
    "scheduler_time": 113.53777086007113
}
#Debug simulation 
Total elapsed time: 6.402701462153345. Arrivals time: 0.23700750805437565 Scheduler time: 6.035628700628877 Scheduler overhead time: 0.04423988051712513 Adapter cache time: 0.021551694720983505 Engine time: 0.04380124621093273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.955186086706817,
    "estimated_duration": 3600.0537424666986,
    "input_throughput": 3978.930045134598,
    "output_throughput": 3482.4335681749812,
    "total_throughput": 7461.36361330958,
    "itl": 99.19833432828673,
    "ttft": 2211814.013925239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.285283050695218,
    "arrivals": 554638,
    "finished_requests": 58095,
    "scheduler_time": 120.56109648626827
}
#Debug simulation 
Total elapsed time: 4.955319365952164. Arrivals time: 0.21165011683478951 Scheduler time: 4.577228270471096 Scheduler overhead time: 0.05211852630600333 Adapter cache time: 0.037272435147315264 Engine time: 0.052610951010137796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.461114734876901,
    "estimated_duration": 3600.1246972189874,
    "input_throughput": 4494.674312948034,
    "output_throughput": 3925.964289769784,
    "total_throughput": 8420.638602717818,
    "itl": 123.04037472974775,
    "ttft": 2143074.0032647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.554011218296337,
    "arrivals": 554638,
    "finished_requests": 65622,
    "scheduler_time": 113.54333653123105
}
#Debug simulation 
Total elapsed time: 6.461244528181851. Arrivals time: 0.23599446564912796 Scheduler time: 6.09488517139107 Scheduler overhead time: 0.044463308062404394 Adapter cache time: 0.02087294263765216 Engine time: 0.044505811762064695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_192_slots_96_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.964706182014197,
    "estimated_duration": 3600.0400072412785,
    "input_throughput": 3978.9455037131106,
    "output_throughput": 3482.5410203169827,
    "total_throughput": 7461.486524030093,
    "itl": 99.19530259276632,
    "ttft": 2211799.695014703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.166397791318385,
    "arrivals": 554638,
    "finished_requests": 58096,
    "scheduler_time": 120.56453685103372
}
#Debug simulation 
Total elapsed time: 4.964810329955071. Arrivals time: 0.2107155998237431 Scheduler time: 4.58853603946045 Scheduler overhead time: 0.0521511547267437 Adapter cache time: 0.03718583472073078 Engine time: 0.051990384701639414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.336158087942749,
    "estimated_duration": 3600.100991002916,
    "input_throughput": 4701.793378103122,
    "output_throughput": 4082.898795543287,
    "total_throughput": 8784.69217364641,
    "itl": 134.4768736934577,
    "ttft": 2114882.6728330185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.099693599809026,
    "arrivals": 553841,
    "finished_requests": 68505,
    "scheduler_time": 110.99663873016698
}
#Debug simulation 
Total elapsed time: 7.336287237238139. Arrivals time: 0.2451177528128028 Scheduler time: 6.971888639498502 Scheduler overhead time: 0.04180457256734371 Adapter cache time: 0.016459436621516943 Engine time: 0.04202228272333741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.2460480886511505,
    "estimated_duration": 3600.0824583537083,
    "input_throughput": 4522.882236271328,
    "output_throughput": 3927.493929254554,
    "total_throughput": 8450.376165525882,
    "itl": 123.0195103035219,
    "ttft": 2137968.2305607395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.014985880586326,
    "arrivals": 553841,
    "finished_requests": 65923,
    "scheduler_time": 113.49510798513435
}
#Debug simulation 
Total elapsed time: 6.246227745898068. Arrivals time: 0.2384764738380909 Scheduler time: 5.87792533589527 Scheduler overhead time: 0.0443441029638052 Adapter cache time: 0.020575801376253366 Engine time: 0.04442137712612748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.935880874283612,
    "estimated_duration": 3600.0128578621075,
    "input_throughput": 4012.297336231699,
    "output_throughput": 3483.472558330608,
    "total_throughput": 7495.769894562307,
    "itl": 99.11038253198996,
    "ttft": 2208062.891323523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.066060324492652,
    "arrivals": 553841,
    "finished_requests": 58437,
    "scheduler_time": 120.54018017690521
}
#Debug simulation 
Total elapsed time: 4.9359841933473945. Arrivals time: 0.2118413746356964 Scheduler time: 4.55893944716081 Scheduler overhead time: 0.05212719738483429 Adapter cache time: 0.03683092212304473 Engine time: 0.05198824778199196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.235792514868081,
    "estimated_duration": 3600.109204758781,
    "input_throughput": 4523.376396047721,
    "output_throughput": 3928.2383382443995,
    "total_throughput": 8451.61473429212,
    "itl": 123.00750472196926,
    "ttft": 2137964.751047854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.634613333898587,
    "arrivals": 553841,
    "finished_requests": 65932,
    "scheduler_time": 113.50714798853257
}
#Debug simulation 
Total elapsed time: 6.235895013902336. Arrivals time: 0.23357909871265292 Scheduler time: 5.872547485865653 Scheduler overhead time: 0.04445298481732607 Adapter cache time: 0.020532399881631136 Engine time: 0.044198268093168736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.9452146352268755,
    "estimated_duration": 3600.0031922936205,
    "input_throughput": 4012.340608730742,
    "output_throughput": 3483.536077647223,
    "total_throughput": 7495.876686377965,
    "itl": 99.10745298040113,
    "ttft": 2208010.9148245747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.947796416645666,
    "arrivals": 553841,
    "finished_requests": 58439,
    "scheduler_time": 120.543693614775
}
#Debug simulation 
Total elapsed time: 4.945318774320185. Arrivals time: 0.2132493881508708 Scheduler time: 4.566850097384304 Scheduler overhead time: 0.052001046016812325 Adapter cache time: 0.036762017756700516 Engine time: 0.052231190726161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.258640065789223,
    "estimated_duration": 3600.0117411139554,
    "input_throughput": 4523.969134323018,
    "output_throughput": 3928.564687298424,
    "total_throughput": 8452.53382162144,
    "itl": 122.9946606289501,
    "ttft": 2137872.927740134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.266734775970664,
    "arrivals": 553841,
    "finished_requests": 65937,
    "scheduler_time": 113.51473947477356
}
#Debug simulation 
Total elapsed time: 6.25874312594533. Arrivals time: 0.23354842513799667 Scheduler time: 5.893981528934091 Scheduler overhead time: 0.04661284992471337 Adapter cache time: 0.01994572952389717 Engine time: 0.044223648961633444 
