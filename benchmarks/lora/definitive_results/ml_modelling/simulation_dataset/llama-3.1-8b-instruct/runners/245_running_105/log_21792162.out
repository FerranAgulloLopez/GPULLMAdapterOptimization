INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:06 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 621975333 . Total output tokens: 546547488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 47.53138387436047,
    "estimated_duration": 3600.0175955930436,
    "input_throughput": 5403.794143621488,
    "output_throughput": 4690.558185235285,
    "total_throughput": 10094.352328856774,
    "itl": 111.64855167136685,
    "ttft": 2116289.311140206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.54307612201663,
    "arrivals": 928080,
    "finished_requests": 78653,
    "scheduler_time": 190.17035608969633
}
#Debug simulation 
Total elapsed time: 47.5316254850477. Arrivals time: 0.7288790359161794 Scheduler time: 46.63693048758432 Scheduler overhead time: 0.06224692752584815 Adapter cache time: 0.017443496268242598 Engine time: 0.0613861158490181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 621975333 . Total output tokens: 546547488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 27.856779649853706,
    "estimated_duration": 3600.0502452439646,
    "input_throughput": 5108.123150307253,
    "output_throughput": 4432.697855004126,
    "total_throughput": 9540.82100531138,
    "itl": 99.74213862310131,
    "ttft": 2145007.1100376733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8398898801766554,
    "arrivals": 928080,
    "finished_requests": 74371,
    "scheduler_time": 200.80366474644157
}
#Debug simulation 
Total elapsed time: 27.856929302215576. Arrivals time: 0.3462640796788037 Scheduler time: 27.33738155802712 Scheduler overhead time: 0.06262474553659558 Adapter cache time: 0.024006671737879515 Engine time: 0.060933697037398815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 49.97365741990507,
    "estimated_duration": 3600.00560268098,
    "input_throughput": 5557.98579454964,
    "output_throughput": 4827.333042775827,
    "total_throughput": 10385.318837325467,
    "itl": 119.46756979732255,
    "ttft": 2096147.328626312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.37894101532646,
    "arrivals": 925677,
    "finished_requests": 80920,
    "scheduler_time": 184.2594805585485
}
#Debug simulation 
Total elapsed time: 49.9738397449255. Arrivals time: 0.40828597638756037 Scheduler time: 49.40406743483618 Scheduler overhead time: 0.061779316514730453 Adapter cache time: 0.016535490285605192 Engine time: 0.059552977327257395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 47.92993642529473,
    "estimated_duration": 3600.021516285007,
    "input_throughput": 5405.340193655509,
    "output_throughput": 4687.13337508401,
    "total_throughput": 10092.47356873952,
    "itl": 111.55659050029955,
    "ttft": 2110745.8276215657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5035170629667167,
    "arrivals": 925677,
    "finished_requests": 78677,
    "scheduler_time": 190.29264003226572
}
#Debug simulation 
Total elapsed time: 47.93011676706374. Arrivals time: 0.4175675665028393 Scheduler time: 47.34487228374928 Scheduler overhead time: 0.06373344641178846 Adapter cache time: 0.016672728583216667 Engine time: 0.0624383520334959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 28.091474095359445,
    "estimated_duration": 3600.025903521282,
    "input_throughput": 5096.453884416206,
    "output_throughput": 4427.01203466654,
    "total_throughput": 9523.465919082746,
    "itl": 99.44565292495187,
    "ttft": 2141003.9289689264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.027594763902041,
    "arrivals": 925677,
    "finished_requests": 74197,
    "scheduler_time": 201.2223187895334
}
#Debug simulation 
Total elapsed time: 28.091638264246285. Arrivals time: 0.4292092090472579 Scheduler time: 27.489396987017244 Scheduler overhead time: 0.06379574723541737 Adapter cache time: 0.02107309876009822 Engine time: 0.062028332613408566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 47.917031437158585,
    "estimated_duration": 3600.0168114384924,
    "input_throughput": 5397.176740470887,
    "output_throughput": 4683.707016707659,
    "total_throughput": 10080.883757178546,
    "itl": 111.62452589822237,
    "ttft": 2105224.633724087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.03999288667924,
    "arrivals": 925677,
    "finished_requests": 78483,
    "scheduler_time": 190.25542600400422
}
#Debug simulation 
Total elapsed time: 47.91718101594597. Arrivals time: 0.3911567027680576 Scheduler time: 47.358139601536095 Scheduler overhead time: 0.06375647895038128 Adapter cache time: 0.01815675524994731 Engine time: 0.061316265258938074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 27.61180609278381,
    "estimated_duration": 3600.0254377354304,
    "input_throughput": 5091.7792990737,
    "output_throughput": 4431.273688453415,
    "total_throughput": 9523.052987527115,
    "itl": 99.4896633845168,
    "ttft": 2139220.1626955993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.348393023479756,
    "arrivals": 925677,
    "finished_requests": 74142,
    "scheduler_time": 201.24891987536213
}
#Debug simulation 
Total elapsed time: 27.611977390944958. Arrivals time: 0.3628443698398769 Scheduler time: 27.077072901185602 Scheduler overhead time: 0.06282569654285908 Adapter cache time: 0.021669928915798664 Engine time: 0.06158074317499995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 39.23859762400389,
    "estimated_duration": 3600.02377532289,
    "input_throughput": 5387.470808650546,
    "output_throughput": 4688.6851458324245,
    "total_throughput": 10076.15595448297,
    "itl": 111.76542247871551,
    "ttft": 2109612.3148983875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9261113784508597,
    "arrivals": 925677,
    "finished_requests": 78514,
    "scheduler_time": 190.1470306177364
}
#Debug simulation 
Total elapsed time: 39.23876117123291. Arrivals time: 0.4034092300571501 Scheduler time: 38.67242113593966 Scheduler overhead time: 0.06151460250839591 Adapter cache time: 0.017940521240234375 Engine time: 0.05929732136428356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 26.929971877019852,
    "estimated_duration": 3600.055989702031,
    "input_throughput": 5080.750980629583,
    "output_throughput": 4423.412592901934,
    "total_throughput": 9504.163573531518,
    "itl": 99.22455636351141,
    "ttft": 2139049.6027993057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.523670783415462,
    "arrivals": 925677,
    "finished_requests": 73995,
    "scheduler_time": 201.4974707415162
}
#Debug simulation 
Total elapsed time: 26.930126735009253. Arrivals time: 0.3628094270825386 Scheduler time: 26.39364456757903 Scheduler overhead time: 0.06416777381673455 Adapter cache time: 0.02185045648366213 Engine time: 0.06148748006671667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 50.930642190854996,
    "estimated_duration": 3600.111589982742,
    "input_throughput": 5387.77910495074,
    "output_throughput": 4702.329796416437,
    "total_throughput": 10090.108901367175,
    "itl": 111.52203603885495,
    "ttft": 2112544.434284809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.246692834687457,
    "arrivals": 924451,
    "finished_requests": 78526,
    "scheduler_time": 190.91967856555846
}
#Debug simulation 
Total elapsed time: 50.930824698880315. Arrivals time: 0.42081228736788034 Scheduler time: 50.34088659007102 Scheduler overhead time: 0.06437413627281785 Adapter cache time: 0.01645581889897585 Engine time: 0.06327142240479589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 49.404734797310084,
    "estimated_duration": 3600.0187141330453,
    "input_throughput": 5393.115853475664,
    "output_throughput": 4696.212809569076,
    "total_throughput": 10089.32866304474,
    "itl": 111.7409242393447,
    "ttft": 2114145.3246855866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.164045407581147,
    "arrivals": 924451,
    "finished_requests": 78488,
    "scheduler_time": 190.1643782536208
}
#Debug simulation 
Total elapsed time: 49.404924375005066. Arrivals time: 0.4195597991347313 Scheduler time: 48.81981531344354 Scheduler overhead time: 0.06313941301777959 Adapter cache time: 0.01563240261748433 Engine time: 0.06206566095352173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 31.126928606070578,
    "estimated_duration": 3600.071688196844,
    "input_throughput": 5071.562063572355,
    "output_throughput": 4423.202752380668,
    "total_throughput": 9494.764815953024,
    "itl": 99.34571820850725,
    "ttft": 2148022.294478664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.792615746869731,
    "arrivals": 924451,
    "finished_requests": 73875,
    "scheduler_time": 201.35566998377172
}
#Debug simulation 
Total elapsed time: 31.127091957256198. Arrivals time: 0.34912424720823765 Scheduler time: 30.607051223516464 Scheduler overhead time: 0.06296514859423041 Adapter cache time: 0.01987538719549775 Engine time: 0.061910444404929876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 49.077036902774125,
    "estimated_duration": 3600.1007876994845,
    "input_throughput": 5393.717605447466,
    "output_throughput": 4699.576761241578,
    "total_throughput": 10093.294366689044,
    "itl": 112.15605848576723,
    "ttft": 2113567.3387872777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2594735024683135,
    "arrivals": 924451,
    "finished_requests": 78512,
    "scheduler_time": 189.6995329140527
}
#Debug simulation 
Total elapsed time: 49.07721832673997. Arrivals time: 0.42133775912225246 Scheduler time: 48.486878300085664 Scheduler overhead time: 0.064522092230618 Adapter cache time: 0.016939245630055666 Engine time: 0.062227590940892696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 29.444666540250182,
    "estimated_duration": 3600.0871327091495,
    "input_throughput": 5087.855467047054,
    "output_throughput": 4437.967585516988,
    "total_throughput": 9525.823052564043,
    "itl": 99.74827358749684,
    "ttft": 2144218.011407792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.094919176618598,
    "arrivals": 924451,
    "finished_requests": 74124,
    "scheduler_time": 200.93933826762066
}
#Debug simulation 
Total elapsed time: 29.44479698408395. Arrivals time: 0.3714999286457896 Scheduler time: 28.903120848350227 Scheduler overhead time: 0.06350314803421497 Adapter cache time: 0.019118420779705048 Engine time: 0.06151586305350065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 46.41248685400933,
    "estimated_duration": 3600.121856478365,
    "input_throughput": 5385.481873373504,
    "output_throughput": 4702.583877691513,
    "total_throughput": 10088.065751065018,
    "itl": 112.05755185364723,
    "ttft": 2113484.359020216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4983886754326363,
    "arrivals": 924451,
    "finished_requests": 78506,
    "scheduler_time": 189.86153263635376
}
#Debug simulation 
Total elapsed time: 46.41265109507367. Arrivals time: 0.3944763168692589 Scheduler time: 45.850542278494686 Scheduler overhead time: 0.06366189429536462 Adapter cache time: 0.017395731527358294 Engine time: 0.06163159664720297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 29.182896563783288,
    "estimated_duration": 3600.0481455598615,
    "input_throughput": 5091.022469409151,
    "output_throughput": 4436.735386358574,
    "total_throughput": 9527.757855767724,
    "itl": 99.66749637778749,
    "ttft": 2145863.5553079746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.793058684989838,
    "arrivals": 924451,
    "finished_requests": 74096,
    "scheduler_time": 201.0346040086724
}
#Debug simulation 
Total elapsed time: 29.18306003883481. Arrivals time: 0.34926976822316647 Scheduler time: 28.66457098349929 Scheduler overhead time: 0.062408520840108395 Adapter cache time: 0.020180328749120235 Engine time: 0.061051285825669765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 62.329345112200826,
    "estimated_duration": 3600.114315417121,
    "input_throughput": 5549.6512748054565,
    "output_throughput": 4824.170423040508,
    "total_throughput": 10373.821697845964,
    "itl": 119.20926994652247,
    "ttft": 2074875.347198417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.656662194668366,
    "arrivals": 807771,
    "finished_requests": 80934,
    "scheduler_time": 184.24386007889564
}
#Debug simulation 
Total elapsed time: 62.32952251192182. Arrivals time: 0.43646371085196733 Scheduler time: 61.72428352944553 Scheduler overhead time: 0.06322045996785164 Adapter cache time: 0.01869273092597723 Engine time: 0.062169997952878475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 55.42947034211829,
    "estimated_duration": 3600.0573209460103,
    "input_throughput": 5389.732237624832,
    "output_throughput": 4685.831778802665,
    "total_throughput": 10075.564016427497,
    "itl": 111.53396169299577,
    "ttft": 2088712.5510633017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.241303883176302,
    "arrivals": 807771,
    "finished_requests": 78388,
    "scheduler_time": 189.9823220173161
}
#Debug simulation 
Total elapsed time: 55.4296530848369. Arrivals time: 0.4178184913471341 Scheduler time: 54.8374143387191 Scheduler overhead time: 0.06568722147494555 Adapter cache time: 0.019307798240333796 Engine time: 0.06449595047160983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 27.736204186920077,
    "estimated_duration": 3600.03814964133,
    "input_throughput": 5081.129210206411,
    "output_throughput": 4416.548475072155,
    "total_throughput": 9497.677685278566,
    "itl": 99.01620723165293,
    "ttft": 2130382.186806359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.191940177227375,
    "arrivals": 807771,
    "finished_requests": 73953,
    "scheduler_time": 201.17479426352372
}
#Debug simulation 
Total elapsed time: 27.736327932216227. Arrivals time: 0.35313334921374917 Scheduler time: 27.207647005096078 Scheduler overhead time: 0.06282354891300201 Adapter cache time: 0.025278578978031874 Engine time: 0.061518306378275156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 54.89694213075563,
    "estimated_duration": 3600.081720214537,
    "input_throughput": 5393.294238566045,
    "output_throughput": 4688.116912800031,
    "total_throughput": 10081.411151366076,
    "itl": 111.72872252838185,
    "ttft": 2089145.0949077576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.401940453075797,
    "arrivals": 807771,
    "finished_requests": 78498,
    "scheduler_time": 189.7672072775349
}
#Debug simulation 
Total elapsed time: 54.89711486687884. Arrivals time: 0.3959699128754437 Scheduler time: 54.32426449889317 Scheduler overhead time: 0.06609596638008952 Adapter cache time: 0.020428973715752363 Engine time: 0.06496541062369943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 35.21173326205462,
    "estimated_duration": 3600.0364464453387,
    "input_throughput": 5074.512236685318,
    "output_throughput": 4418.554988715869,
    "total_throughput": 9493.067225401186,
    "itl": 99.23433339940279,
    "ttft": 2128153.6744565456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.32284712317866,
    "arrivals": 807771,
    "finished_requests": 73967,
    "scheduler_time": 200.96117807987977
}
#Debug simulation 
Total elapsed time: 35.211911560967565. Arrivals time: 0.4284606468863785 Scheduler time: 34.60398013936356 Scheduler overhead time: 0.06435155123472214 Adapter cache time: 0.025762864854186773 Engine time: 0.0629209615290165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 53.46302683791146,
    "estimated_duration": 3600.11879013097,
    "input_throughput": 5382.137681988849,
    "output_throughput": 4687.133948540105,
    "total_throughput": 10069.271630528954,
    "itl": 111.79048833934998,
    "ttft": 2095999.1290568132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.124012927608545,
    "arrivals": 807771,
    "finished_requests": 78424,
    "scheduler_time": 189.77956497190564
}
#Debug simulation 
Total elapsed time: 53.46320753917098. Arrivals time: 0.4185417895205319 Scheduler time: 52.87047804240137 Scheduler overhead time: 0.0659790295176208 Adapter cache time: 0.019907671492546797 Engine time: 0.06346651632338762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 25.741652383934706,
    "estimated_duration": 3600.0632869103238,
    "input_throughput": 5089.095257468003,
    "output_throughput": 4422.041984062641,
    "total_throughput": 9511.137241530643,
    "itl": 99.35610360432285,
    "ttft": 2130778.8280797875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.04738563060758,
    "arrivals": 807771,
    "finished_requests": 74015,
    "scheduler_time": 200.79100363113741
}
#Debug simulation 
Total elapsed time: 25.741773196030408. Arrivals time: 0.35817858995869756 Scheduler time: 25.206264252774417 Scheduler overhead time: 0.06241956213489175 Adapter cache time: 0.026878817472606897 Engine time: 0.062054810114204884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 42.258754855021834,
    "estimated_duration": 3600.094374264114,
    "input_throughput": 5578.288209209789,
    "output_throughput": 4811.24498397088,
    "total_throughput": 10389.533193180669,
    "itl": 118.96301689601978,
    "ttft": 2078356.0514961374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.818919948116065,
    "arrivals": 788657,
    "finished_requests": 81056,
    "scheduler_time": 184.18839410995625
}
#Debug simulation 
Total elapsed time: 42.25892544910312. Arrivals time: 0.4346499382518232 Scheduler time: 41.66142167383805 Scheduler overhead time: 0.059608747251331806 Adapter cache time: 0.021874884609133005 Engine time: 0.05805821716785431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 47.58019881602377,
    "estimated_duration": 3600.10635819321,
    "input_throughput": 5416.086654113667,
    "output_throughput": 4687.958443669469,
    "total_throughput": 10104.045097783135,
    "itl": 111.73002497973127,
    "ttft": 2088621.882578449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1038130675116635,
    "arrivals": 788657,
    "finished_requests": 78752,
    "scheduler_time": 189.49442890980333
}
#Debug simulation 
Total elapsed time: 47.58036731882021. Arrivals time: 0.4048817325383425 Scheduler time: 47.000967571511865 Scheduler overhead time: 0.0630234987474978 Adapter cache time: 0.02224676124751568 Engine time: 0.06456743227317929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 26.987296565901488,
    "estimated_duration": 3600.0808852070286,
    "input_throughput": 5128.445329066062,
    "output_throughput": 4427.911902063638,
    "total_throughput": 9556.3572311297,
    "itl": 99.52186657948576,
    "ttft": 2121291.976348719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.633011530586508,
    "arrivals": 788657,
    "finished_requests": 74540,
    "scheduler_time": 200.40599724028937
}
#Debug simulation 
Total elapsed time: 26.987426234874874. Arrivals time: 0.36477734753862023 Scheduler time: 26.44596988009289 Scheduler overhead time: 0.06299504591152072 Adapter cache time: 0.025678062345832586 Engine time: 0.06174091203138232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 36.82187536312267,
    "estimated_duration": 3600.1083053372918,
    "input_throughput": 5423.537667201011,
    "output_throughput": 4687.500644072691,
    "total_throughput": 10111.038311273702,
    "itl": 111.56948795461189,
    "ttft": 2090436.8509578076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.720739363892925,
    "arrivals": 788657,
    "finished_requests": 78869,
    "scheduler_time": 189.64343912682185
}
#Debug simulation 
Total elapsed time: 36.82203176012263. Arrivals time: 0.37750563863664865 Scheduler time: 36.275885917712 Scheduler overhead time: 0.06106230057775974 Adapter cache time: 0.02385068079456687 Engine time: 0.05945435864850879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 31.135360694956034,
    "estimated_duration": 3600.0089796025977,
    "input_throughput": 5134.669136864356,
    "output_throughput": 4431.016447564777,
    "total_throughput": 9565.685584429133,
    "itl": 99.57139555999815,
    "ttft": 2122436.522067937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.582261836258679,
    "arrivals": 788657,
    "finished_requests": 74709,
    "scheduler_time": 200.32592587500636
}
#Debug simulation 
Total elapsed time: 31.135514649096876. Arrivals time: 0.41300360579043627 Scheduler time: 30.54463845398277 Scheduler overhead time: 0.06386545719578862 Adapter cache time: 0.025621030014008284 Engine time: 0.062364871613681316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 52.53867749078199,
    "estimated_duration": 3600.031760441632,
    "input_throughput": 5419.4630209614015,
    "output_throughput": 4687.989752048641,
    "total_throughput": 10107.452773010044,
    "itl": 111.52349895283086,
    "ttft": 2083808.7270258153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7728972758771677,
    "arrivals": 788657,
    "finished_requests": 78747,
    "scheduler_time": 189.7617429958889
}
#Debug simulation 
Total elapsed time: 52.53885487187654. Arrivals time: 0.40976713923737407 Scheduler time: 51.953096710611135 Scheduler overhead time: 0.06607517832890153 Adapter cache time: 0.019374659284949303 Engine time: 0.06500101555138826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 27.93459935905412,
    "estimated_duration": 3600.031471721023,
    "input_throughput": 5122.590495350282,
    "output_throughput": 4428.251009811,
    "total_throughput": 9550.841505161281,
    "itl": 99.48748217637558,
    "ttft": 2123462.1782258386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.259828639477494,
    "arrivals": 788657,
    "finished_requests": 74515,
    "scheduler_time": 200.53094261181724
}
#Debug simulation 
Total elapsed time: 27.93472769483924. Arrivals time: 0.3391620204783976 Scheduler time: 27.421428207773715 Scheduler overhead time: 0.062443315982818604 Adapter cache time: 0.024883706122636795 Engine time: 0.060807519126683474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 41.63611463923007,
    "estimated_duration": 3600.1107184330367,
    "input_throughput": 5536.5883326709545,
    "output_throughput": 4828.10984423431,
    "total_throughput": 10364.698176905265,
    "itl": 119.65456471052806,
    "ttft": 2074424.0886575598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.508136723614408,
    "arrivals": 779141,
    "finished_requests": 80893,
    "scheduler_time": 183.56576913916783
}
#Debug simulation 
Total elapsed time: 41.636292906012386. Arrivals time: 0.40533722285181284 Scheduler time: 41.067953592631966 Scheduler overhead time: 0.0599916223436594 Adapter cache time: 0.02116469945758581 Engine time: 0.05836938275024295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 37.28103186376393,
    "estimated_duration": 3600.075056459332,
    "input_throughput": 5382.446670169554,
    "output_throughput": 4692.497166049247,
    "total_throughput": 10074.943836218801,
    "itl": 112.08445080070531,
    "ttft": 2092116.7872770233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.365006119832406,
    "arrivals": 779141,
    "finished_requests": 78718,
    "scheduler_time": 189.25814805190686
}
#Debug simulation 
Total elapsed time: 37.28119242982939. Arrivals time: 0.38672812981531024 Scheduler time: 36.7280726917088 Scheduler overhead time: 0.06045954301953316 Adapter cache time: 0.02171062445268035 Engine time: 0.059503096621483564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 20.895994587801397,
    "estimated_duration": 3600.0868247134267,
    "input_throughput": 5075.782304626662,
    "output_throughput": 4432.728924883721,
    "total_throughput": 9508.511229510385,
    "itl": 99.80719915049693,
    "ttft": 2124697.6269938513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.19616799887727,
    "arrivals": 779141,
    "finished_requests": 74242,
    "scheduler_time": 200.13578502051206
}
#Debug simulation 
Total elapsed time: 20.896151495166123. Arrivals time: 0.3262235247530043 Scheduler time: 20.399481744505465 Scheduler overhead time: 0.059352266136556864 Adapter cache time: 0.02757581463083625 Engine time: 0.058149658143520355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 40.7621807558462,
    "estimated_duration": 3600.095859099496,
    "input_throughput": 5389.670930832775,
    "output_throughput": 4697.050484713958,
    "total_throughput": 10086.721415546734,
    "itl": 112.10445939904093,
    "ttft": 2094998.937914108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 867,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.940219979681998,
    "arrivals": 779141,
    "finished_requests": 78841,
    "scheduler_time": 189.1613035997362
}
#Debug simulation 
Total elapsed time: 40.762331337668. Arrivals time: 0.3947902084328234 Scheduler time: 40.19969329563901 Scheduler overhead time: 0.061003272887319326 Adapter cache time: 0.022085717879235744 Engine time: 0.06023188913241029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 30.826572882011533,
    "estimated_duration": 3600.0529806946665,
    "input_throughput": 5091.656733469238,
    "output_throughput": 4434.1066883187295,
    "total_throughput": 9525.763421787968,
    "itl": 99.69182194157679,
    "ttft": 2122820.8077474907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.882554224808718,
    "arrivals": 779141,
    "finished_requests": 74350,
    "scheduler_time": 200.28173599152603
}
#Debug simulation 
Total elapsed time: 30.82667538477108. Arrivals time: 0.3481713216751814 Scheduler time: 30.301454587839544 Scheduler overhead time: 0.06382600590586662 Adapter cache time: 0.02489529037848115 Engine time: 0.061971474904567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 41.34865090902895,
    "estimated_duration": 3600.098708780991,
    "input_throughput": 5394.296537656795,
    "output_throughput": 4693.631582596684,
    "total_throughput": 10087.92812025348,
    "itl": 111.82090994609077,
    "ttft": 2088394.7268429566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.858163835774152,
    "arrivals": 779141,
    "finished_requests": 78810,
    "scheduler_time": 189.38265227850437
}
#Debug simulation 
Total elapsed time: 41.34884673496708. Arrivals time: 0.3989940732717514 Scheduler time: 40.78185299737379 Scheduler overhead time: 0.06247004633769393 Adapter cache time: 0.02080049179494381 Engine time: 0.06037095980718732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 24.24495887523517,
    "estimated_duration": 3600.0364387500163,
    "input_throughput": 5076.122786786311,
    "output_throughput": 4430.330434526891,
    "total_throughput": 9506.453221313202,
    "itl": 99.71437679114692,
    "ttft": 2125725.392489563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.494354795832141,
    "arrivals": 779141,
    "finished_requests": 74206,
    "scheduler_time": 200.3169516040794
}
#Debug simulation 
Total elapsed time: 24.245106536895037. Arrivals time: 0.35032295156270266 Scheduler time: 23.722952829673886 Scheduler overhead time: 0.06009356724098325 Adapter cache time: 0.026883354876190424 Engine time: 0.05923665454611182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 43.024505319073796,
    "estimated_duration": 3600.0242686963306,
    "input_throughput": 5555.786435640588,
    "output_throughput": 4833.557415517468,
    "total_throughput": 10389.343851158055,
    "itl": 119.86281027217247,
    "ttft": 2069843.704759564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5228877778538354,
    "arrivals": 774377,
    "finished_requests": 80900,
    "scheduler_time": 183.31376092216345
}
#Debug simulation 
Total elapsed time: 43.024649711791426. Arrivals time: 0.39632197795435786 Scheduler time: 42.46443359320983 Scheduler overhead time: 0.060787740629166365 Adapter cache time: 0.01963701518252492 Engine time: 0.059630411211401224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 33.465206081047654,
    "estimated_duration": 3600.0588964595654,
    "input_throughput": 5387.181587243743,
    "output_throughput": 4685.397790738464,
    "total_throughput": 10072.579377982207,
    "itl": 111.77078977240117,
    "ttft": 2088494.3836346702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.208741722190762,
    "arrivals": 774377,
    "finished_requests": 78415,
    "scheduler_time": 189.49943700910174
}
#Debug simulation 
Total elapsed time: 33.46537444414571. Arrivals time: 0.3784791943617165 Scheduler time: 32.92182335164398 Scheduler overhead time: 0.06002933206036687 Adapter cache time: 0.021668142173439264 Engine time: 0.05907242326065898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 19.994964291341603,
    "estimated_duration": 3600.0560941266044,
    "input_throughput": 5089.697916066866,
    "output_throughput": 4424.709388830932,
    "total_throughput": 9514.407304897799,
    "itl": 99.55643382587314,
    "ttft": 2117473.965995563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.504596468340544,
    "arrivals": 774377,
    "finished_requests": 73958,
    "scheduler_time": 200.44515064654743
}
#Debug simulation 
Total elapsed time: 19.995066770352423. Arrivals time: 0.32796106580644846 Scheduler time: 19.49607064947486 Scheduler overhead time: 0.06011523073539138 Adapter cache time: 0.026810537558048964 Engine time: 0.05874134320765734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 33.47400832688436,
    "estimated_duration": 3600.0496880844485,
    "input_throughput": 5402.721263647111,
    "output_throughput": 4697.856270144701,
    "total_throughput": 10100.577533791811,
    "itl": 112.18281726630416,
    "ttft": 2086687.4264640443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.0243253197614015,
    "arrivals": 774377,
    "finished_requests": 78591,
    "scheduler_time": 189.06436988509768
}
#Debug simulation 
Total elapsed time: 33.47418552497402. Arrivals time: 0.7242637239396572 Scheduler time: 32.58438033144921 Scheduler overhead time: 0.06015813956037164 Adapter cache time: 0.02203020453453064 Engine time: 0.05880844220519066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 27.89460063818842,
    "estimated_duration": 3600.059042787262,
    "input_throughput": 5092.223150264402,
    "output_throughput": 4428.654311084903,
    "total_throughput": 9520.877461349306,
    "itl": 99.50104337311903,
    "ttft": 2117612.1163900755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.272880537840558,
    "arrivals": 774377,
    "finished_requests": 74064,
    "scheduler_time": 200.5653897898816
}
#Debug simulation 
Total elapsed time: 27.894739665091038. Arrivals time: 0.3910246123559773 Scheduler time: 27.331246184185147 Scheduler overhead time: 0.06248723575845361 Adapter cache time: 0.02298823231831193 Engine time: 0.06122457655146718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 51.234013595152646,
    "estimated_duration": 3600.031709923041,
    "input_throughput": 5396.780241253856,
    "output_throughput": 4691.00923568282,
    "total_throughput": 10087.789476936676,
    "itl": 111.89084718540062,
    "ttft": 2079106.1867921625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.545351709686198,
    "arrivals": 774377,
    "finished_requests": 78677,
    "scheduler_time": 189.52228502580877
}
#Debug simulation 
Total elapsed time: 51.23417751584202. Arrivals time: 0.44814648339524865 Scheduler time: 50.61545755947009 Scheduler overhead time: 0.06396653363481164 Adapter cache time: 0.020057530608028173 Engine time: 0.06201687874272466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 19.554897484835237,
    "estimated_duration": 3600.0485563933953,
    "input_throughput": 5089.000526802342,
    "output_throughput": 4426.159744901721,
    "total_throughput": 9515.160271704064,
    "itl": 99.50788711853019,
    "ttft": 2118609.7724714926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.187945311833134,
    "arrivals": 774377,
    "finished_requests": 74036,
    "scheduler_time": 200.47345758201539
}
#Debug simulation 
Total elapsed time: 19.555024973116815. Arrivals time: 0.349257143214345 Scheduler time: 19.03502769768238 Scheduler overhead time: 0.05968582769855857 Adapter cache time: 0.026233605109155178 Engine time: 0.05905967717990279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 59.65323788532987,
    "estimated_duration": 3600.052416266269,
    "input_throughput": 5537.239932932577,
    "output_throughput": 4825.686404315695,
    "total_throughput": 10362.926337248273,
    "itl": 119.56802154306031,
    "ttft": 2067875.1049766482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2797548798472076,
    "arrivals": 771975,
    "finished_requests": 80838,
    "scheduler_time": 183.86980215547314
}
#Debug simulation 
Total elapsed time: 59.65341674396768. Arrivals time: 0.4171224683523178 Scheduler time: 59.068680588621646 Scheduler overhead time: 0.06373986089602113 Adapter cache time: 0.01706563215702772 Engine time: 0.06248669512569904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 48.614741581026465,
    "estimated_duration": 3600.096670307627,
    "input_throughput": 5370.145796209411,
    "output_throughput": 4682.365653964392,
    "total_throughput": 10052.511450173803,
    "itl": 111.48454090577597,
    "ttft": 2092215.4566679837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.423944479310891,
    "arrivals": 771975,
    "finished_requests": 78366,
    "scheduler_time": 189.98995370906763
}
#Debug simulation 
Total elapsed time: 48.61488929903135. Arrivals time: 0.39984810957685113 Scheduler time: 48.04452904080972 Scheduler overhead time: 0.06492396304383874 Adapter cache time: 0.018642230425029993 Engine time: 0.0619063014164567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 27.658365683164448,
    "estimated_duration": 3600.081243705687,
    "input_throughput": 5080.376458719503,
    "output_throughput": 4431.283051706648,
    "total_throughput": 9511.65951042615,
    "itl": 99.74581560772243,
    "ttft": 2125763.935741538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.183559173257104,
    "arrivals": 771975,
    "finished_requests": 74168,
    "scheduler_time": 200.37357324626657
}
#Debug simulation 
Total elapsed time: 27.65847802022472. Arrivals time: 0.33866274636238813 Scheduler time: 27.145480661652982 Scheduler overhead time: 0.062446880619972944 Adapter cache time: 0.024071906227618456 Engine time: 0.061372603289783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 43.30680190073326,
    "estimated_duration": 3600.05120188009,
    "input_throughput": 5375.969650068502,
    "output_throughput": 4685.781133110082,
    "total_throughput": 10061.750783178584,
    "itl": 111.67518074341638,
    "ttft": 2092324.8141740214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.263156266477884,
    "arrivals": 771975,
    "finished_requests": 78480,
    "scheduler_time": 189.78622404152065
}
#Debug simulation 
Total elapsed time: 43.30697736609727. Arrivals time: 0.3832156811840832 Scheduler time: 42.75821282109246 Scheduler overhead time: 0.06189770856872201 Adapter cache time: 0.01882548350840807 Engine time: 0.06031939806416631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 26.643452821765095,
    "estimated_duration": 3600.057297388763,
    "input_throughput": 5092.927274601669,
    "output_throughput": 4431.025309394508,
    "total_throughput": 9523.952583996177,
    "itl": 99.68072134337098,
    "ttft": 2122623.2680167947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.532550167799948,
    "arrivals": 771975,
    "finished_requests": 74235,
    "scheduler_time": 200.42236996207166
}
#Debug simulation 
Total elapsed time: 26.643601620104164. Arrivals time: 0.368144107516855 Scheduler time: 26.101932315621525 Scheduler overhead time: 0.06258440855890512 Adapter cache time: 0.023760894313454628 Engine time: 0.06128239585086703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 37.71435257373378,
    "estimated_duration": 3600.0513320129894,
    "input_throughput": 5396.6249945488,
    "output_throughput": 4696.7130300738145,
    "total_throughput": 10093.338024622615,
    "itl": 112.06816479432945,
    "ttft": 2092597.1806365734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.024145780228985,
    "arrivals": 771975,
    "finished_requests": 78682,
    "scheduler_time": 189.30230006749346
}
#Debug simulation 
Total elapsed time: 37.71449416689575. Arrivals time: 0.36857723677530885 Scheduler time: 37.18053387431428 Scheduler overhead time: 0.06086274702101946 Adapter cache time: 0.02073259185999632 Engine time: 0.05939479311928153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 30.0805847463198,
    "estimated_duration": 3600.0561069244554,
    "input_throughput": 5084.847140240454,
    "output_throughput": 4435.602536662101,
    "total_throughput": 9520.449676902554,
    "itl": 99.74437514853214,
    "ttft": 2120377.2986238487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.417649954203545,
    "arrivals": 771975,
    "finished_requests": 74197,
    "scheduler_time": 200.4406167962821
}
#Debug simulation 
Total elapsed time: 30.080822412390262. Arrivals time: 0.36123114405199885 Scheduler time: 29.545219941530377 Scheduler overhead time: 0.06380527233704925 Adapter cache time: 0.022202408406883478 Engine time: 0.06220530718564987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 57.57671014079824,
    "estimated_duration": 3600.092651236665,
    "input_throughput": 5554.733151973368,
    "output_throughput": 4833.248664870581,
    "total_throughput": 10387.981816843949,
    "itl": 119.7695210536711,
    "ttft": 2064792.1987351505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.167343926304055,
    "arrivals": 770785,
    "finished_requests": 81375,
    "scheduler_time": 183.47963337408117
}
#Debug simulation 
Total elapsed time: 57.57689284905791. Arrivals time: 0.41561353392899036 Scheduler time: 56.99302834505215 Scheduler overhead time: 0.06429595407098532 Adapter cache time: 0.01711287721991539 Engine time: 0.06271424097940326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 44.192496383562684,
    "estimated_duration": 3600.0954896834423,
    "input_throughput": 5398.60569134764,
    "output_throughput": 4692.937742461266,
    "total_throughput": 10091.543433808905,
    "itl": 111.89424995043352,
    "ttft": 2084945.9681704666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.592712343395694,
    "arrivals": 770785,
    "finished_requests": 79078,
    "scheduler_time": 189.39701485910265
}
#Debug simulation 
Total elapsed time: 44.19267627457157. Arrivals time: 0.39599893894046545 Scheduler time: 43.62974627921358 Scheduler overhead time: 0.062457616440951824 Adapter cache time: 0.018721662927418947 Engine time: 0.06113601289689541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 23.190419249236584,
    "estimated_duration": 3600.031025497711,
    "input_throughput": 5104.2893435785145,
    "output_throughput": 4435.990103110891,
    "total_throughput": 9540.279446689407,
    "itl": 99.7774955679571,
    "ttft": 2117206.633373725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.881957832244247,
    "arrivals": 770785,
    "finished_requests": 74635,
    "scheduler_time": 200.17398062421026
}
#Debug simulation 
Total elapsed time: 23.190523892175406. Arrivals time: 0.3421776667237282 Scheduler time: 22.675623872783035 Scheduler overhead time: 0.062043958343565464 Adapter cache time: 0.023917455226182938 Engine time: 0.060750569216907024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 47.57855209801346,
    "estimated_duration": 3600.1110268751236,
    "input_throughput": 5407.677667346366,
    "output_throughput": 4701.964154336944,
    "total_throughput": 10109.641821683312,
    "itl": 112.01124585910014,
    "ttft": 2088732.9197929434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.469944325401441,
    "arrivals": 770785,
    "finished_requests": 79140,
    "scheduler_time": 189.2919031045445
}
#Debug simulation 
Total elapsed time: 47.57873173896223. Arrivals time: 0.39764317870140076 Scheduler time: 47.01293321326375 Scheduler overhead time: 0.06318403407931328 Adapter cache time: 0.01923616323620081 Engine time: 0.061196848284453154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 36.65860616508871,
    "estimated_duration": 3600.045818853959,
    "input_throughput": 5092.416019815025,
    "output_throughput": 4437.311024303946,
    "total_throughput": 9529.72704411897,
    "itl": 99.55977366406506,
    "ttft": 2112776.544034903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.854676583157879,
    "arrivals": 770785,
    "finished_requests": 74691,
    "scheduler_time": 200.4817070517133
}
#Debug simulation 
Total elapsed time: 36.65878675086424. Arrivals time: 0.37446587439626455 Scheduler time: 36.10662793368101 Scheduler overhead time: 0.06532003218308091 Adapter cache time: 0.021724849939346313 Engine time: 0.06437279284000397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 38.30429456476122,
    "estimated_duration": 3600.0942038605835,
    "input_throughput": 5403.219443296906,
    "output_throughput": 4696.082947460202,
    "total_throughput": 10099.302390757108,
    "itl": 111.87630868889683,
    "ttft": 2087440.4577969548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.251691346419955,
    "arrivals": 770785,
    "finished_requests": 79051,
    "scheduler_time": 189.33655511982647
}
#Debug simulation 
Total elapsed time: 38.3044746266678. Arrivals time: 0.3920103348791599 Scheduler time: 37.747163406107575 Scheduler overhead time: 0.061312864534556866 Adapter cache time: 0.019043782260268927 Engine time: 0.05999480374157429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 26.62247864715755,
    "estimated_duration": 3600.015426910231,
    "input_throughput": 5088.781526617835,
    "output_throughput": 4432.824893113418,
    "total_throughput": 9521.606419731252,
    "itl": 99.61319812301342,
    "ttft": 2115319.968884279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.969558418318655,
    "arrivals": 770785,
    "finished_requests": 74524,
    "scheduler_time": 200.35453284483177
}
#Debug simulation 
Total elapsed time: 26.62260662484914. Arrivals time: 0.3563202661462128 Scheduler time: 26.094161975663155 Scheduler overhead time: 0.06227568117901683 Adapter cache time: 0.023079271893948317 Engine time: 0.06106971390545368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 56.798253499902785,
    "estimated_duration": 3600.012245111286,
    "input_throughput": 5548.440016315149,
    "output_throughput": 4819.981382997657,
    "total_throughput": 10368.421399312807,
    "itl": 119.24911909661685,
    "ttft": 2046573.1369543723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.846895820419393,
    "arrivals": 673640,
    "finished_requests": 80825,
    "scheduler_time": 183.5767639900498
}
#Debug simulation 
Total elapsed time: 56.79844262683764. Arrivals time: 0.3871995056979358 Scheduler time: 56.243577929679304 Scheduler overhead time: 0.06250016903504729 Adapter cache time: 0.019810613710433245 Engine time: 0.06099634105339646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 40.09035575808957,
    "estimated_duration": 3600.0214420301477,
    "input_throughput": 5412.1230425262665,
    "output_throughput": 4695.70953179296,
    "total_throughput": 10107.832574319225,
    "itl": 111.91295604799942,
    "ttft": 2065420.015751149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.927462151935331,
    "arrivals": 673640,
    "finished_requests": 78711,
    "scheduler_time": 188.88556042930276
}
#Debug simulation 
Total elapsed time: 40.09053093986586. Arrivals time: 0.3729317728430033 Scheduler time: 39.5505236890167 Scheduler overhead time: 0.06220806483179331 Adapter cache time: 0.019329273141920567 Engine time: 0.060845666099339724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 27.144815533887595,
    "estimated_duration": 3600.090610117384,
    "input_throughput": 5105.059841646805,
    "output_throughput": 4420.580402969661,
    "total_throughput": 9525.640244616465,
    "itl": 99.27119356445537,
    "ttft": 2107399.0485964557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.131254481291341,
    "arrivals": 673640,
    "finished_requests": 74204,
    "scheduler_time": 200.18395450689826
}
#Debug simulation 
Total elapsed time: 27.144928223919123. Arrivals time: 0.34019286278635263 Scheduler time: 26.626646233256906 Scheduler overhead time: 0.06261502671986818 Adapter cache time: 0.0277724196203053 Engine time: 0.06158115202561021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 47.551783508155495,
    "estimated_duration": 3600.1169011587676,
    "input_throughput": 5420.988133390428,
    "output_throughput": 4696.989421248316,
    "total_throughput": 10117.977554638745,
    "itl": 112.00501550617136,
    "ttft": 2059590.0209222937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.829672633777365,
    "arrivals": 673640,
    "finished_requests": 78797,
    "scheduler_time": 188.78107558686492
}
#Debug simulation 
Total elapsed time: 47.55198058998212. Arrivals time: 0.3828282677568495 Scheduler time: 46.998902494087815 Scheduler overhead time: 0.06319167651236057 Adapter cache time: 0.020617146510630846 Engine time: 0.06174591975286603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 27.213651057798415,
    "estimated_duration": 3600.1097754243888,
    "input_throughput": 5105.19710411703,
    "output_throughput": 4420.599368563407,
    "total_throughput": 9525.796472680437,
    "itl": 99.26716600821364,
    "ttft": 2107413.012406798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.03825886899134,
    "arrivals": 673640,
    "finished_requests": 74208,
    "scheduler_time": 200.1900200375184
}
#Debug simulation 
Total elapsed time: 27.21382070798427. Arrivals time: 0.32998351473361254 Scheduler time: 26.70678549213335 Scheduler overhead time: 0.06250283308327198 Adapter cache time: 0.027535472996532917 Engine time: 0.0609789970330894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 39.69427985418588,
    "estimated_duration": 3600.0877832516826,
    "input_throughput": 5418.4884298517845,
    "output_throughput": 4699.59929274791,
    "total_throughput": 10118.087722599694,
    "itl": 112.04088904195831,
    "ttft": 2064831.173692201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3602180024096535,
    "arrivals": 673640,
    "finished_requests": 78732,
    "scheduler_time": 188.80839633347873
}
#Debug simulation 
Total elapsed time: 39.69446759438142. Arrivals time: 0.37355902837589383 Scheduler time: 39.15709066297859 Scheduler overhead time: 0.06083939457312226 Adapter cache time: 0.01903340220451355 Engine time: 0.059653644915670156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 19.813763103913516,
    "estimated_duration": 3600.039832921344,
    "input_throughput": 5104.672962767608,
    "output_throughput": 4426.150192640977,
    "total_throughput": 9530.823155408585,
    "itl": 99.52932317427124,
    "ttft": 2105965.8491174798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.407815086115066,
    "arrivals": 673640,
    "finished_requests": 74242,
    "scheduler_time": 199.9192656525024
}
#Debug simulation 
Total elapsed time: 19.813895034138113. Arrivals time: 0.3252341775223613 Scheduler time: 19.315378662664443 Scheduler overhead time: 0.060590782668441534 Adapter cache time: 0.02749462192878127 Engine time: 0.059420382138341665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 50.93093794910237,
    "estimated_duration": 3600.11484254851,
    "input_throughput": 5523.445187077267,
    "output_throughput": 4831.9128030054235,
    "total_throughput": 10355.357990082692,
    "itl": 120.01197232917592,
    "ttft": 2049144.6033913598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.952694364930595,
    "arrivals": 664253,
    "finished_requests": 80972,
    "scheduler_time": 182.97773581413028
}
#Debug simulation 
Total elapsed time: 50.93111683009192. Arrivals time: 0.41974763525649905 Scheduler time: 50.34963917452842 Scheduler overhead time: 0.059712501242756844 Adapter cache time: 0.020238489843904972 Engine time: 0.05816858448088169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 38.24934915592894,
    "estimated_duration": 3600.0203537827438,
    "input_throughput": 5381.007076708616,
    "output_throughput": 4703.209519970897,
    "total_throughput": 10084.216596679515,
    "itl": 112.48958879095137,
    "ttft": 2063465.6988215093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 797,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.8251303264638485,
    "arrivals": 664253,
    "finished_requests": 78839,
    "scheduler_time": 188.48358830120242
}
#Debug simulation 
Total elapsed time: 38.249524464830756. Arrivals time: 0.36070073628798127 Scheduler time: 37.72262584650889 Scheduler overhead time: 0.06129625253379345 Adapter cache time: 0.020493640564382076 Engine time: 0.060060473158955574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 20.606530730146915,
    "estimated_duration": 3600.016130098977,
    "input_throughput": 5070.318670904998,
    "output_throughput": 4435.671236717756,
    "total_throughput": 9505.989907622754,
    "itl": 100.04614193651172,
    "ttft": 2098123.3224760094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.125660103508205,
    "arrivals": 664253,
    "finished_requests": 74295,
    "scheduler_time": 199.50481405981594
}
#Debug simulation 
Total elapsed time: 20.60670947097242. Arrivals time: 0.33902783738449216 Scheduler time: 20.095002830494195 Scheduler overhead time: 0.06023219181224704 Adapter cache time: 0.027803586330264807 Engine time: 0.05911259399726987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 38.250399553216994,
    "estimated_duration": 3600.0642139101046,
    "input_throughput": 5380.204310012248,
    "output_throughput": 4704.775524435392,
    "total_throughput": 10084.97983444764,
    "itl": 112.48961743461024,
    "ttft": 2063906.7444795955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.207438337123013,
    "arrivals": 664253,
    "finished_requests": 78849,
    "scheduler_time": 188.49976436115438
}
#Debug simulation 
Total elapsed time: 38.25053134839982. Arrivals time: 0.37240292271599174 Scheduler time: 37.71108677145094 Scheduler overhead time: 0.06137463031336665 Adapter cache time: 0.0204497161321342 Engine time: 0.0608670748770237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 22.47790688276291,
    "estimated_duration": 3600.1064002522203,
    "input_throughput": 5073.691154994839,
    "output_throughput": 4435.55362665983,
    "total_throughput": 9509.244781654668,
    "itl": 99.99401720894272,
    "ttft": 2098589.6348046563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.285707868030213,
    "arrivals": 664253,
    "finished_requests": 74403,
    "scheduler_time": 199.4801298329224
}
#Debug simulation 
Total elapsed time: 22.478074776008725. Arrivals time: 0.37009825510904193 Scheduler time: 21.933013000991195 Scheduler overhead time: 0.06168156582862139 Adapter cache time: 0.027795355767011642 Engine time: 0.05995173938572407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 45.74303936306387,
    "estimated_duration": 3600.01580155634,
    "input_throughput": 5367.100053185035,
    "output_throughput": 4700.152980629964,
    "total_throughput": 10067.253033814999,
    "itl": 112.34783688192323,
    "ttft": 2066475.722184795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.260350855030094,
    "arrivals": 664253,
    "finished_requests": 78698,
    "scheduler_time": 188.62351709161032
}
#Debug simulation 
Total elapsed time: 45.74322152463719. Arrivals time: 0.3721438101492822 Scheduler time: 45.2051816158928 Scheduler overhead time: 0.06069399882107973 Adapter cache time: 0.02092458074912429 Engine time: 0.05970809189602733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 23.094789046328515,
    "estimated_duration": 3600.081757356709,
    "input_throughput": 5067.660467076531,
    "output_throughput": 4437.463945743695,
    "total_throughput": 9505.124412820227,
    "itl": 100.04619357979986,
    "ttft": 2099719.1122024213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.055633905362258,
    "arrivals": 664253,
    "finished_requests": 74355,
    "scheduler_time": 199.47633384172053
}
#Debug simulation 
Total elapsed time: 23.094898316077888. Arrivals time: 0.33013044111430645 Scheduler time: 22.589791066013277 Scheduler overhead time: 0.06182621559128165 Adapter cache time: 0.027658980805426836 Engine time: 0.05977021669968963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 46.387468724977225,
    "estimated_duration": 3600.064949670351,
    "input_throughput": 5558.468327587352,
    "output_throughput": 4825.58432774685,
    "total_throughput": 10384.052655334202,
    "itl": 119.81385286236937,
    "ttft": 2055323.6966555505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.952694364930595,
    "arrivals": 659440,
    "finished_requests": 80772,
    "scheduler_time": 183.24250852286184
}
#Debug simulation 
Total elapsed time: 46.38763943128288. Arrivals time: 0.4170881202444434 Scheduler time: 45.81137678725645 Scheduler overhead time: 0.05889410013332963 Adapter cache time: 0.01940952055156231 Engine time: 0.05746167711913586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 44.337124112062156,
    "estimated_duration": 3600.0723707622965,
    "input_throughput": 5408.545160962163,
    "output_throughput": 4693.48148032429,
    "total_throughput": 10102.026641286453,
    "itl": 112.13592335918345,
    "ttft": 2071669.6947415404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.817358184549966,
    "arrivals": 659440,
    "finished_requests": 78577,
    "scheduler_time": 188.9183636316695
}
#Debug simulation 
Total elapsed time: 44.33728194376454. Arrivals time: 0.3693205649033189 Scheduler time: 43.8035573665984 Scheduler overhead time: 0.06035632221028209 Adapter cache time: 0.020561534445732832 Engine time: 0.05901207588613033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 21.40637095272541,
    "estimated_duration": 3600.023453262038,
    "input_throughput": 5096.328742907378,
    "output_throughput": 4431.138632040149,
    "total_throughput": 9527.467374947528,
    "itl": 99.84317725315489,
    "ttft": 2104578.0134407207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.620448121759052,
    "arrivals": 659440,
    "finished_requests": 74102,
    "scheduler_time": 199.80310869931355
}
#Debug simulation 
Total elapsed time: 21.40650743804872. Arrivals time: 0.31470805360004306 Scheduler time: 20.91937987320125 Scheduler overhead time: 0.0606324109248817 Adapter cache time: 0.026474107522517443 Engine time: 0.05953981447964907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 43.47862075595185,
    "estimated_duration": 3600.0961360973884,
    "input_throughput": 5406.3067385469085,
    "output_throughput": 4690.848900025921,
    "total_throughput": 10097.155638572829,
    "itl": 112.0385954676931,
    "ttft": 2071209.0254943396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.362597844596012,
    "arrivals": 659440,
    "finished_requests": 78550,
    "scheduler_time": 189.01788162680177
}
#Debug simulation 
Total elapsed time: 43.47876316914335. Arrivals time: 0.3653050335124135 Scheduler time: 42.950343725737184 Scheduler overhead time: 0.0600418234243989 Adapter cache time: 0.020247016102075577 Engine time: 0.058668910060077906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 21.316228322684765,
    "estimated_duration": 3600.046678430236,
    "input_throughput": 5096.299197987062,
    "output_throughput": 4431.155600170126,
    "total_throughput": 9527.454798157189,
    "itl": 99.84098412837129,
    "ttft": 2104600.98223509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.53345890758088,
    "arrivals": 659440,
    "finished_requests": 74103,
    "scheduler_time": 199.809069915955
}
#Debug simulation 
Total elapsed time: 21.31634082365781. Arrivals time: 0.3214519671164453 Scheduler time: 20.82320275856182 Scheduler overhead time: 0.06052908021956682 Adapter cache time: 0.025969662703573704 Engine time: 0.05945587391033769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 43.643482060637325,
    "estimated_duration": 3600.117075002348,
    "input_throughput": 5406.541952524504,
    "output_throughput": 4692.48850747138,
    "total_throughput": 10099.030459995884,
    "itl": 112.0532877727696,
    "ttft": 2071318.1572583516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.909235203298716,
    "arrivals": 659440,
    "finished_requests": 78559,
    "scheduler_time": 189.01336377599114
}
#Debug simulation 
Total elapsed time: 43.6436542137526. Arrivals time: 0.4098726026713848 Scheduler time: 43.07093293918297 Scheduler overhead time: 0.0601482973434031 Adapter cache time: 0.020012271124869585 Engine time: 0.058526933658868074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 21.291007709223777,
    "estimated_duration": 3600.06689370087,
    "input_throughput": 5096.710295051695,
    "output_throughput": 4431.471267357397,
    "total_throughput": 9528.181562409092,
    "itl": 99.83852477455378,
    "ttft": 2104635.360669221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.443777170106722,
    "arrivals": 659440,
    "finished_requests": 74108,
    "scheduler_time": 199.81499717724338
}
#Debug simulation 
Total elapsed time: 21.291114791296422. Arrivals time: 0.3056778865866363 Scheduler time: 20.813222634140402 Scheduler overhead time: 0.05994253419339657 Adapter cache time: 0.026568902656435966 Engine time: 0.060416423715651035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 49.46109568094835,
    "estimated_duration": 3600.0526380375363,
    "input_throughput": 5566.487775279872,
    "output_throughput": 4825.729439742392,
    "total_throughput": 10392.217215022263,
    "itl": 119.58622014820158,
    "ttft": 2047673.9651843826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.62054767715756,
    "arrivals": 657053,
    "finished_requests": 80930,
    "scheduler_time": 183.09892445682965
}
#Debug simulation 
Total elapsed time: 49.46128520183265. Arrivals time: 0.3883904297836125 Scheduler time: 48.9094741968438 Scheduler overhead time: 0.059965388383716345 Adapter cache time: 0.020939336623996496 Engine time: 0.05876443814486265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 51.2483723917976,
    "estimated_duration": 3600.079008672065,
    "input_throughput": 5392.18249189494,
    "output_throughput": 4676.201538757254,
    "total_throughput": 10068.384030652194,
    "itl": 111.19626281528059,
    "ttft": 2045896.3509791582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.230018502650791,
    "arrivals": 657053,
    "finished_requests": 78459,
    "scheduler_time": 189.68846476097778
}
#Debug simulation 
Total elapsed time: 51.248549768701196. Arrivals time: 0.376232897862792 Scheduler time: 50.70240304991603 Scheduler overhead time: 0.06373937847092748 Adapter cache time: 0.019903858192265034 Engine time: 0.061529739294201136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 24.66228649392724,
    "estimated_duration": 3600.0373630809527,
    "input_throughput": 5091.844653610003,
    "output_throughput": 4423.329925212756,
    "total_throughput": 9515.17457882276,
    "itl": 99.29469211646898,
    "ttft": 2095830.3950858454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.447424870994874,
    "arrivals": 657053,
    "finished_requests": 73985,
    "scheduler_time": 200.15820607658694
}
#Debug simulation 
Total elapsed time: 24.662405110895634. Arrivals time: 0.33655108977109194 Scheduler time: 24.15353958075866 Scheduler overhead time: 0.06188358413055539 Adapter cache time: 0.024683927185833454 Engine time: 0.059944574255496264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 39.59223562898114,
    "estimated_duration": 3600.0696252798975,
    "input_throughput": 5411.934220156982,
    "output_throughput": 4693.951995077366,
    "total_throughput": 10105.886215234348,
    "itl": 111.74127222372559,
    "ttft": 2058987.128076522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.456619299594306,
    "arrivals": 657053,
    "finished_requests": 78769,
    "scheduler_time": 188.95698899178774
}
#Debug simulation 
Total elapsed time: 39.592407448682934. Arrivals time: 0.3669294067658484 Scheduler time: 39.06046558637172 Scheduler overhead time: 0.06133660767227411 Adapter cache time: 0.018747909925878048 Engine time: 0.060319011099636555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 30.19451515097171,
    "estimated_duration": 3600.004597843746,
    "input_throughput": 5096.072658070611,
    "output_throughput": 4425.177403812708,
    "total_throughput": 9521.250061883318,
    "itl": 99.33533860533767,
    "ttft": 2097110.9701475776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.512618042891864,
    "arrivals": 657053,
    "finished_requests": 74126,
    "scheduler_time": 200.13805566777816
}
#Debug simulation 
Total elapsed time: 30.194647789001465. Arrivals time: 0.32251115422695875 Scheduler time: 29.700972225051373 Scheduler overhead time: 0.06203846354037523 Adapter cache time: 0.022987546864897013 Engine time: 0.060331014916300774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 28.30560592887923,
    "estimated_duration": 3600.107481684828,
    "input_throughput": 5417.086045129169,
    "output_throughput": 4695.325371810617,
    "total_throughput": 10112.411416939787,
    "itl": 111.8637368608658,
    "ttft": 2062419.3735882682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.024145780228985,
    "arrivals": 657053,
    "finished_requests": 78785,
    "scheduler_time": 188.80505808111175
}
#Debug simulation 
Total elapsed time: 28.305735176894814. Arrivals time: 0.36300225323066115 Scheduler time: 27.782126056496054 Scheduler overhead time: 0.059262814465910196 Adapter cache time: 0.02005922980606556 Engine time: 0.05724914651364088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 20.396013627760112,
    "estimated_duration": 3600.084386395669,
    "input_throughput": 5096.852193059492,
    "output_throughput": 4423.8163028019735,
    "total_throughput": 9520.668495861466,
    "itl": 99.3232954161889,
    "ttft": 2098067.003794859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.309324734881516,
    "arrivals": 657053,
    "finished_requests": 74078,
    "scheduler_time": 200.1495533311651
}
#Debug simulation 
Total elapsed time: 20.39617734681815. Arrivals time: 0.3216794766485691 Scheduler time: 19.903751507401466 Scheduler overhead time: 0.06081652082502842 Adapter cache time: 0.024121408816426992 Engine time: 0.05988217517733574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 46.429511866066605,
    "estimated_duration": 3600.034259443829,
    "input_throughput": 5564.821486753016,
    "output_throughput": 4824.5149207783525,
    "total_throughput": 10389.33640753137,
    "itl": 119.64363780756116,
    "ttft": 2053090.6512006028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0981673636334985,
    "arrivals": 655825,
    "finished_requests": 80829,
    "scheduler_time": 183.32846698126204
}
#Debug simulation 
Total elapsed time: 46.42968485597521. Arrivals time: 0.38005792116746306 Scheduler time: 45.89103584177792 Scheduler overhead time: 0.05846808757632971 Adapter cache time: 0.019867199938744307 Engine time: 0.05717042274773121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 42.55928472010419,
    "estimated_duration": 3600.0819572636638,
    "input_throughput": 5412.116788254835,
    "output_throughput": 4693.097601822902,
    "total_throughput": 10105.214390077737,
    "itl": 112.18529737589803,
    "ttft": 2067817.8103908473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.565325495116421,
    "arrivals": 655825,
    "finished_requests": 78611,
    "scheduler_time": 188.85568192042422
}
#Debug simulation 
Total elapsed time: 42.55943305185065. Arrivals time: 0.40551278879866004 Scheduler time: 41.9898045710288 Scheduler overhead time: 0.060755306389182806 Adapter cache time: 0.01967941876500845 Engine time: 0.05913256574422121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 26.179242813959718,
    "estimated_duration": 3600.01582885837,
    "input_throughput": 5093.569548502505,
    "output_throughput": 4430.8744067546,
    "total_throughput": 9524.443955257106,
    "itl": 99.71218372900589,
    "ttft": 2094895.0031974323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.806323517691361,
    "arrivals": 655825,
    "finished_requests": 74140,
    "scheduler_time": 199.98516955354785
}
#Debug simulation 
Total elapsed time: 26.17937545804307. Arrivals time: 0.32545209024101496 Scheduler time: 25.67990332096815 Scheduler overhead time: 0.06309198634698987 Adapter cache time: 0.023586617317050695 Engine time: 0.0612685470841825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 42.68196204677224,
    "estimated_duration": 3600.08088278658,
    "input_throughput": 5414.048082417893,
    "output_throughput": 4696.895028344954,
    "total_throughput": 10110.943110762848,
    "itl": 112.24497618992868,
    "ttft": 2068478.4966538565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.282940498241215,
    "arrivals": 655825,
    "finished_requests": 78690,
    "scheduler_time": 188.81994290711447
}
#Debug simulation 
Total elapsed time: 42.682133317925036. Arrivals time: 0.3698085453361273 Scheduler time: 42.15014141611755 Scheduler overhead time: 0.05991016561165452 Adapter cache time: 0.019609561655670404 Engine time: 0.05865866830572486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 26.164569906890392,
    "estimated_duration": 3600.0544457065907,
    "input_throughput": 5093.5821323115915,
    "output_throughput": 4430.842433236925,
    "total_throughput": 9524.424565548516,
    "itl": 99.71032733750404,
    "ttft": 2094789.6783014538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.733211154346374,
    "arrivals": 655825,
    "finished_requests": 74141,
    "scheduler_time": 199.99122850480146
}
#Debug simulation 
Total elapsed time: 26.164679397828877. Arrivals time: 0.3321100785396993 Scheduler time: 25.659120655152947 Scheduler overhead time: 0.06257124803960323 Adapter cache time: 0.023657548241317272 Engine time: 0.06142853992059827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 42.583825083915144,
    "estimated_duration": 3600.0493544863534,
    "input_throughput": 5404.559239098552,
    "output_throughput": 4689.4957089855625,
    "total_throughput": 10094.054948084115,
    "itl": 111.91161340908737,
    "ttft": 2068036.7391929931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.922003045179857,
    "arrivals": 655825,
    "finished_requests": 78551,
    "scheduler_time": 189.10740531936696
}
#Debug simulation 
Total elapsed time: 42.584066786803305. Arrivals time: 0.36746824998408556 Scheduler time: 42.05323527241126 Scheduler overhead time: 0.06025615427643061 Adapter cache time: 0.02011851780116558 Engine time: 0.0586689286865294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 26.247007130179554,
    "estimated_duration": 3600.0922510922364,
    "input_throughput": 5093.528643449807,
    "output_throughput": 4430.795903955107,
    "total_throughput": 9524.324547404913,
    "itl": 99.70834849102307,
    "ttft": 2094822.2568782694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.659684556648155,
    "arrivals": 655825,
    "finished_requests": 74141,
    "scheduler_time": 199.99717364674865
}
#Debug simulation 
Total elapsed time: 26.247124306391925. Arrivals time: 0.34120661625638604 Scheduler time: 25.73169477749616 Scheduler overhead time: 0.0628454159013927 Adapter cache time: 0.023974038660526276 Engine time: 0.06161876115947962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 50.499624042306095,
    "estimated_duration": 3600.0178133788645,
    "input_throughput": 5564.837186513021,
    "output_throughput": 4818.355324669749,
    "total_throughput": 10383.192511182771,
    "itl": 118.90264173090455,
    "ttft": 2048690.7079421398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.362663724911505,
    "arrivals": 644956,
    "finished_requests": 80986,
    "scheduler_time": 183.36821025085578
}
#Debug simulation 
Total elapsed time: 50.499887271318585. Arrivals time: 0.41858639009296894 Scheduler time: 49.917899259366095 Scheduler overhead time: 0.06016290746629238 Adapter cache time: 0.020974979735910892 Engine time: 0.05859331367537379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 35.47966736974195,
    "estimated_duration": 3600.0588424794087,
    "input_throughput": 5411.686267489511,
    "output_throughput": 4691.739146232194,
    "total_throughput": 10103.425413721705,
    "itl": 111.63207957282287,
    "ttft": 2059807.0841869763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.127129493253315,
    "arrivals": 644956,
    "finished_requests": 78838,
    "scheduler_time": 188.79715991991375
}
#Debug simulation 
Total elapsed time: 35.47983591305092. Arrivals time: 0.6614803038537502 Scheduler time: 34.65222329646349 Scheduler overhead time: 0.0611381153576076 Adapter cache time: 0.02100295852869749 Engine time: 0.059480973053723574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 24.779146121349186,
    "estimated_duration": 3600.0163473232524,
    "input_throughput": 5098.5740699893195,
    "output_throughput": 4430.241271503847,
    "total_throughput": 9528.815341493168,
    "itl": 99.51535875367723,
    "ttft": 2097427.564001468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.309700984707945,
    "arrivals": 644956,
    "finished_requests": 74338,
    "scheduler_time": 199.64933629123644
}
#Debug simulation 
Total elapsed time: 24.779305631294847. Arrivals time: 0.3436693982221186 Scheduler time: 24.262100568506867 Scheduler overhead time: 0.06078230822458863 Adapter cache time: 0.027555481996387243 Engine time: 0.05965011892840266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 36.00021270522848,
    "estimated_duration": 3600.1231382694796,
    "input_throughput": 5419.2390789660885,
    "output_throughput": 4693.490014378281,
    "total_throughput": 10112.72909334437,
    "itl": 111.71861789430022,
    "ttft": 2058501.2075036438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.854726418629279,
    "arrivals": 644956,
    "finished_requests": 78918,
    "scheduler_time": 188.73338744307682
}
#Debug simulation 
Total elapsed time: 36.00034797610715. Arrivals time: 0.3535619266331196 Scheduler time: 35.48007205501199 Scheduler overhead time: 0.061841560527682304 Adapter cache time: 0.02093840530142188 Engine time: 0.05965313781052828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 43.029350293800235,
    "estimated_duration": 3600.079475174583,
    "input_throughput": 5079.418697864502,
    "output_throughput": 4409.4126558776015,
    "total_throughput": 9488.831353742104,
    "itl": 99.06082321138108,
    "ttft": 2093494.3089637435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.74073872620699,
    "arrivals": 644956,
    "finished_requests": 74012,
    "scheduler_time": 200.53968577177923
}
#Debug simulation 
Total elapsed time: 43.0295265740715. Arrivals time: 0.3421743423677981 Scheduler time: 42.50764983147383 Scheduler overhead time: 0.06454031402245164 Adapter cache time: 0.02653542533516884 Engine time: 0.06242072815075517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 34.489459733013064,
    "estimated_duration": 3600.069267955857,
    "input_throughput": 5407.220959127027,
    "output_throughput": 4692.665263519354,
    "total_throughput": 10099.88622264638,
    "itl": 111.61574737474388,
    "ttft": 2059724.3549665685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.922003045179857,
    "arrivals": 644956,
    "finished_requests": 78795,
    "scheduler_time": 188.87296728942692
}
#Debug simulation 
Total elapsed time: 34.48964847624302. Arrivals time: 0.364846364594996 Scheduler time: 33.96167952846736 Scheduler overhead time: 0.06044742977246642 Adapter cache time: 0.019391847774386406 Engine time: 0.05913183046504855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 29.346533506177366,
    "estimated_duration": 3600.0999112366567,
    "input_throughput": 5098.906544983748,
    "output_throughput": 4425.726894486907,
    "total_throughput": 9524.633439470656,
    "itl": 99.32398665773343,
    "ttft": 2093719.8514535734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.833801442626793,
    "arrivals": 644956,
    "finished_requests": 74282,
    "scheduler_time": 199.82174391758755
}
#Debug simulation 
Total elapsed time: 29.34671587217599. Arrivals time: 0.3775810054503381 Scheduler time: 28.79088476067409 Scheduler overhead time: 0.06346088321879506 Adapter cache time: 0.027125590946525335 Engine time: 0.06169085018336773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 48.39200155530125,
    "estimated_duration": 3600.066358809005,
    "input_throughput": 5560.716110417138,
    "output_throughput": 4827.854619254838,
    "total_throughput": 10388.570729671976,
    "itl": 119.79803945479664,
    "ttft": 2048550.6270422507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.871819220371666,
    "arrivals": 640132,
    "finished_requests": 81048,
    "scheduler_time": 182.97470372120227
}
#Debug simulation 
Total elapsed time: 48.39217540016398. Arrivals time: 0.37339953426271677 Scheduler time: 47.856757811270654 Scheduler overhead time: 0.059213354252278805 Adapter cache time: 0.021433621179312468 Engine time: 0.057803033385425806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 38.69250573404133,
    "estimated_duration": 3600.0987764695265,
    "input_throughput": 5404.179498396795,
    "output_throughput": 4693.153451908632,
    "total_throughput": 10097.332950305426,
    "itl": 112.08435918720598,
    "ttft": 2061324.3480694245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.632592570777062,
    "arrivals": 640132,
    "finished_requests": 78637,
    "scheduler_time": 188.6956583564127
}
#Debug simulation 
Total elapsed time: 38.692664386704564. Arrivals time: 0.3456745781004429 Scheduler time: 38.18341073952615 Scheduler overhead time: 0.05975608993321657 Adapter cache time: 0.020923616364598274 Engine time: 0.0588512341491878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 21.733959185890853,
    "estimated_duration": 3600.0928407067463,
    "input_throughput": 5094.9236065809855,
    "output_throughput": 4422.612333762575,
    "total_throughput": 9517.53594034356,
    "itl": 99.598353927189,
    "ttft": 2096646.4796862006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.080821623722855,
    "arrivals": 640132,
    "finished_requests": 74209,
    "scheduler_time": 199.74335353358208
}
#Debug simulation 
Total elapsed time: 21.734087101649493. Arrivals time: 0.3474091337993741 Scheduler time: 21.215681452304125 Scheduler overhead time: 0.05925398413091898 Adapter cache time: 0.02816241653636098 Engine time: 0.05812731571495533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 39.89336057193577,
    "estimated_duration": 3600.030815385651,
    "input_throughput": 5406.30288963653,
    "output_throughput": 4696.024525053676,
    "total_throughput": 10102.327414690208,
    "itl": 112.20144320489388,
    "ttft": 2061315.4280176705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 930,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.370171418404197,
    "arrivals": 640132,
    "finished_requests": 78682,
    "scheduler_time": 188.60695162710002
}
#Debug simulation 
Total elapsed time: 39.89352825516835. Arrivals time: 0.38382141571491957 Scheduler time: 39.345702761318535 Scheduler overhead time: 0.06014021998271346 Adapter cache time: 0.02101664710789919 Engine time: 0.05845757247880101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 20.465673634782434,
    "estimated_duration": 3600.0611084832212,
    "input_throughput": 5096.142661792128,
    "output_throughput": 4425.375992218175,
    "total_throughput": 9521.518654010302,
    "itl": 99.7159071511605,
    "ttft": 2098383.9597846414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.2685603865793,
    "arrivals": 640132,
    "finished_requests": 74205,
    "scheduler_time": 199.62881567431953
}
#Debug simulation 
Total elapsed time: 20.465821501798928. Arrivals time: 0.3356019230559468 Scheduler time: 19.959386948030442 Scheduler overhead time: 0.058898044284433126 Adapter cache time: 0.029030869249254465 Engine time: 0.05780097935348749 
