INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.11975272465497,
    "estimated_duration": 3600.007367057997,
    "input_throughput": 6420.019084263074,
    "output_throughput": 5619.910999386037,
    "total_throughput": 12039.93008364911,
    "itl": 91.00692582367441,
    "ttft": 1922273.2091725064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4706344374595473,
    "arrivals": 541365,
    "finished_requests": 94030,
    "scheduler_time": 250.2994491341518
}
#Debug simulation 
Total elapsed time: 68.11996371671557. Arrivals time: 0.4400888388045132 Scheduler time: 67.47437058296055 Scheduler overhead time: 0.07764946669340134 Adapter cache time: 0.017537935636937618 Engine time: 0.07875748304650187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 73.12800628133118,
    "estimated_duration": 3600.017039243249,
    "input_throughput": 6634.509986936248,
    "output_throughput": 5788.468991352449,
    "total_throughput": 12422.978978288696,
    "itl": 97.26380245509576,
    "ttft": 1904425.9585134184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8550577475083956,
    "arrivals": 541365,
    "finished_requests": 96969,
    "scheduler_time": 242.3680875283926
}
#Debug simulation 
Total elapsed time: 73.12820544000715. Arrivals time: 0.46994370548054576 Scheduler time: 72.45692598586902 Scheduler overhead time: 0.07669384917244315 Adapter cache time: 0.017088803928345442 Engine time: 0.07686909893527627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 68.22196995886043,
    "estimated_duration": 3600.0814619782122,
    "input_throughput": 6434.531619534834,
    "output_throughput": 5628.602078594475,
    "total_throughput": 12063.133698129308,
    "itl": 90.97977915766073,
    "ttft": 1925673.036820232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.483775364449275,
    "arrivals": 541365,
    "finished_requests": 94272,
    "scheduler_time": 250.03110607360924
}
#Debug simulation 
Total elapsed time: 68.22213610820472. Arrivals time: 0.44968816777691245 Scheduler time: 67.56637364299968 Scheduler overhead time: 0.07739866664633155 Adapter cache time: 0.01756104128435254 Engine time: 0.07937319995835423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 74.29289845470339,
    "estimated_duration": 3600.038634399067,
    "input_throughput": 6643.449815085739,
    "output_throughput": 5797.398061391596,
    "total_throughput": 12440.847876477335,
    "itl": 97.38263750090555,
    "ttft": 1901323.2958620875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.687630715980183,
    "arrivals": 541365,
    "finished_requests": 97067,
    "scheduler_time": 241.88972838367073
}
#Debug simulation 
Total elapsed time: 74.29307072004303. Arrivals time: 0.5246976460330188 Scheduler time: 73.56619767099619 Scheduler overhead time: 0.07627016771584749 Adapter cache time: 0.017113284207880497 Engine time: 0.0779297430999577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 71.0508990152739,
    "estimated_duration": 3600.02692888167,
    "input_throughput": 6438.430450074519,
    "output_throughput": 5629.993164050079,
    "total_throughput": 12068.423614124598,
    "itl": 91.25622123241921,
    "ttft": 1918886.6244780326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0797678688541263,
    "arrivals": 541365,
    "finished_requests": 94175,
    "scheduler_time": 249.89469908753205
}
#Debug simulation 
Total elapsed time: 71.05107232322916. Arrivals time: 0.5282722706906497 Scheduler time: 70.31424400676042 Scheduler overhead time: 0.07859468553215265 Adapter cache time: 0.01753281755372882 Engine time: 0.07986867567524314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 74.29545513400808,
    "estimated_duration": 3600.0029710606864,
    "input_throughput": 6718.203344391712,
    "output_throughput": 5845.246564838258,
    "total_throughput": 12563.449909229968,
    "itl": 99.55372046017624,
    "ttft": 1902542.2395126137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8301110656745974,
    "arrivals": 533687,
    "finished_requests": 97703,
    "scheduler_time": 239.59241300706563
}
#Debug simulation 
Total elapsed time: 74.29562966711819. Arrivals time: 0.4670470738783479 Scheduler time: 73.63026167079806 Scheduler overhead time: 0.075543740298599 Adapter cache time: 0.016971589531749487 Engine time: 0.07598120532929897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.1896655401215,
    "estimated_duration": 3600.011777907275,
    "input_throughput": 6607.84838149291,
    "output_throughput": 5755.453947999188,
    "total_throughput": 12363.302329492099,
    "itl": 96.67048562971456,
    "ttft": 1905783.1435027833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9750208905059887,
    "arrivals": 533687,
    "finished_requests": 96146,
    "scheduler_time": 243.91548021811258
}
#Debug simulation 
Total elapsed time: 73.18992515373975. Arrivals time: 0.46958758728578687 Scheduler time: 72.5170771125704 Scheduler overhead time: 0.07755001448094845 Adapter cache time: 0.01726433029398322 Engine time: 0.07792001543566585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 69.85800476837903,
    "estimated_duration": 3600.0207888465893,
    "input_throughput": 6427.0998300021165,
    "output_throughput": 5600.670157924247,
    "total_throughput": 12027.769987926364,
    "itl": 90.74677991259615,
    "ttft": 1923259.7042023153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7709949306771464,
    "arrivals": 533687,
    "finished_requests": 93572,
    "scheduler_time": 251.15025558989097
}
#Debug simulation 
Total elapsed time: 69.85817554919049. Arrivals time: 0.47277605067938566 Scheduler time: 69.17699449975044 Scheduler overhead time: 0.07916770316660404 Adapter cache time: 0.01815688656643033 Engine time: 0.07944924663752317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 70.11096490407363,
    "estimated_duration": 3600.105854513774,
    "input_throughput": 6642.841062580345,
    "output_throughput": 5786.940118407647,
    "total_throughput": 12429.781180987991,
    "itl": 97.27065461826611,
    "ttft": 1902304.292378334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3138784958654974,
    "arrivals": 533687,
    "finished_requests": 96643,
    "scheduler_time": 242.33230007757132
}
#Debug simulation 
Total elapsed time: 70.11114199273288. Arrivals time: 0.48318341840058565 Scheduler time: 69.4278238103725 Scheduler overhead time: 0.07606944860890508 Adapter cache time: 0.017555103171616793 Engine time: 0.07641819305717945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 70.74102507391945,
    "estimated_duration": 3600.0420594428133,
    "input_throughput": 6429.0307218194475,
    "output_throughput": 5602.700931533492,
    "total_throughput": 12031.73165335294,
    "itl": 90.74387903606734,
    "ttft": 1921328.9607252297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1525066737272063,
    "arrivals": 533687,
    "finished_requests": 93610,
    "scheduler_time": 251.13969291034806
}
#Debug simulation 
Total elapsed time: 70.74120142078027. Arrivals time: 0.48675435315817595 Scheduler time: 70.04504222935066 Scheduler overhead time: 0.07989525562152267 Adapter cache time: 0.017706123180687428 Engine time: 0.079620320815593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 71.4589956626296,
    "estimated_duration": 3600.1078430462417,
    "input_throughput": 6654.015947402914,
    "output_throughput": 5788.524096646715,
    "total_throughput": 12442.540044049629,
    "itl": 97.10195935734157,
    "ttft": 1908471.0771173532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8089252138510226,
    "arrivals": 533687,
    "finished_requests": 96758,
    "scheduler_time": 242.40144902925485
}
#Debug simulation 
Total elapsed time: 71.45916931284592. Arrivals time: 0.4718805900774896 Scheduler time: 70.78750140499324 Scheduler overhead time: 0.07523942645639181 Adapter cache time: 0.01734827971085906 Engine time: 0.07665151683613658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.63486026972532,
    "estimated_duration": 3600.029628826104,
    "input_throughput": 6428.389315103015,
    "output_throughput": 5596.745604166041,
    "total_throughput": 12025.134919269056,
    "itl": 90.67591522741793,
    "ttft": 1923820.9888537864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8440785015002215,
    "arrivals": 533687,
    "finished_requests": 93417,
    "scheduler_time": 251.3115646240889
}
#Debug simulation 
Total elapsed time: 68.6350273899734. Arrivals time: 0.46833675913512707 Scheduler time: 67.95722633739933 Scheduler overhead time: 0.07861766498535872 Adapter cache time: 0.018387694377452135 Engine time: 0.08038290170952678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 73.20007755421102,
    "estimated_duration": 3600.097769640829,
    "input_throughput": 6721.391625543028,
    "output_throughput": 5820.823583380256,
    "total_throughput": 12542.215208923284,
    "itl": 99.19135072924456,
    "ttft": 1889463.3272825738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7507621572911956,
    "arrivals": 529924,
    "finished_requests": 97928,
    "scheduler_time": 240.7049770746612
}
#Debug simulation 
Total elapsed time: 73.2002527853474. Arrivals time: 0.47561709582805634 Scheduler time: 72.52746627759188 Scheduler overhead time: 0.07575663551688194 Adapter cache time: 0.01640877826139331 Engine time: 0.07479559909552336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 71.19005105411634,
    "estimated_duration": 3600.0853502956184,
    "input_throughput": 6661.987610385569,
    "output_throughput": 5771.133731119443,
    "total_throughput": 12433.121341505012,
    "itl": 96.81901836229244,
    "ttft": 1897328.3279577103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.784882005578842,
    "arrivals": 529924,
    "finished_requests": 97074,
    "scheduler_time": 243.04855096331403
}
#Debug simulation 
Total elapsed time: 71.19030140619725. Arrivals time: 0.45089255552738905 Scheduler time: 70.53968904167414 Scheduler overhead time: 0.07579260366037488 Adapter cache time: 0.016551082022488117 Engine time: 0.07675571134313941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 66.78759925113991,
    "estimated_duration": 3600.0314333438614,
    "input_throughput": 6468.051024313344,
    "output_throughput": 5609.201301124087,
    "total_throughput": 12077.252325437432,
    "itl": 90.84306722886885,
    "ttft": 1908836.2903211275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1752373354230294,
    "arrivals": 529924,
    "finished_requests": 94290,
    "scheduler_time": 250.6530458073304
}
#Debug simulation 
Total elapsed time: 66.787766139023. Arrivals time: 0.47399368416517973 Scheduler time: 66.10961182508618 Scheduler overhead time: 0.07790724653750658 Adapter cache time: 0.017410317435860634 Engine time: 0.07724686106666923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 71.2195214102976,
    "estimated_duration": 3600.0588777128146,
    "input_throughput": 6657.036402478472,
    "output_throughput": 5773.018638296261,
    "total_throughput": 12430.055040774734,
    "itl": 97.01386267613397,
    "ttft": 1894449.7752838656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.841458868579936,
    "arrivals": 529924,
    "finished_requests": 97027,
    "scheduler_time": 242.99445647208972
}
#Debug simulation 
Total elapsed time: 71.2196952700615. Arrivals time: 0.47543982043862343 Scheduler time: 70.54477127315477 Scheduler overhead time: 0.07608929323032498 Adapter cache time: 0.016944752540439367 Engine time: 0.07574574556201696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 67.27964089531451,
    "estimated_duration": 3600.07177262549,
    "input_throughput": 6494.992177044143,
    "output_throughput": 5630.913848480329,
    "total_throughput": 12125.906025524473,
    "itl": 91.10027335699114,
    "ttft": 1912793.3472025464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.257336310111009,
    "arrivals": 529924,
    "finished_requests": 94655,
    "scheduler_time": 249.57095066949984
}
#Debug simulation 
Total elapsed time: 67.27982571534812. Arrivals time: 0.43810155102983117 Scheduler time: 66.6354205114767 Scheduler overhead time: 0.07797617418691516 Adapter cache time: 0.017437401227653027 Engine time: 0.07878591679036617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 71.14964687824249,
    "estimated_duration": 3600.0800757258557,
    "input_throughput": 6674.9493051637055,
    "output_throughput": 5782.137497539691,
    "total_throughput": 12457.086802703396,
    "itl": 97.11486208110394,
    "ttft": 1895279.663914721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6684789531584716,
    "arrivals": 529924,
    "finished_requests": 97262,
    "scheduler_time": 242.52148650545752
}
#Debug simulation 
Total elapsed time: 71.1498148040846. Arrivals time: 0.45855931052938104 Scheduler time: 70.49005498876795 Scheduler overhead time: 0.07642325386404991 Adapter cache time: 0.017031234223395586 Engine time: 0.07706789253279567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.14685912197456,
    "estimated_duration": 3600.078413804759,
    "input_throughput": 6491.690822728687,
    "output_throughput": 5628.161020689048,
    "total_throughput": 12119.851843417735,
    "itl": 91.00348885149961,
    "ttft": 1910924.9100327643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.198883742131315,
    "arrivals": 529924,
    "finished_requests": 94621,
    "scheduler_time": 249.82718725271783
}
#Debug simulation 
Total elapsed time: 68.14701956417412. Arrivals time: 0.44910974567756057 Scheduler time: 67.49065482849255 Scheduler overhead time: 0.07840033108368516 Adapter cache time: 0.017702427227050066 Engine time: 0.07915077405050397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 73.16321468818933,
    "estimated_duration": 3600.0671002506565,
    "input_throughput": 6743.175425344094,
    "output_throughput": 5871.598059527348,
    "total_throughput": 12614.773484871443,
    "itl": 100.22807048758416,
    "ttft": 1887742.8290900667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8763979288982484,
    "arrivals": 527992,
    "finished_requests": 98203,
    "scheduler_time": 238.15527301348496
}
#Debug simulation 
Total elapsed time: 73.16337908990681. Arrivals time: 0.48068550880998373 Scheduler time: 72.48179040430114 Scheduler overhead time: 0.07597600715234876 Adapter cache time: 0.017085924744606018 Engine time: 0.07750723650678992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 74.12795811891556,
    "estimated_duration": 3600.056704566886,
    "input_throughput": 6645.102553427166,
    "output_throughput": 5788.695209595919,
    "total_throughput": 12433.797763023083,
    "itl": 97.0588180712593,
    "ttft": 1897989.4342251662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.840949073070664,
    "arrivals": 527992,
    "finished_requests": 96855,
    "scheduler_time": 242.13701437583174
}
#Debug simulation 
Total elapsed time: 74.12812146591023. Arrivals time: 0.5480071981437504 Scheduler time: 73.376524399966 Scheduler overhead time: 0.07725020265206695 Adapter cache time: 0.01648843754082918 Engine time: 0.07839761860668659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 70.37210809392855,
    "estimated_duration": 3600.0295613559424,
    "input_throughput": 6494.945555722945,
    "output_throughput": 5657.899929112864,
    "total_throughput": 12152.845484835809,
    "itl": 91.40063042835558,
    "ttft": 1915780.7494724933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0582867368031503,
    "arrivals": 527992,
    "finished_requests": 94568,
    "scheduler_time": 248.30144162115562
}
#Debug simulation 
Total elapsed time: 70.37228348478675. Arrivals time: 0.5061674048192799 Scheduler time: 69.66121445409954 Scheduler overhead time: 0.07792059425264597 Adapter cache time: 0.017487733159214258 Engine time: 0.07848639506846666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 72.27573412610218,
    "estimated_duration": 3600.008151622221,
    "input_throughput": 6668.931288164312,
    "output_throughput": 5805.850742471688,
    "total_throughput": 12474.782030635999,
    "itl": 97.60092068477051,
    "ttft": 1894617.8247472455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1143053949298296,
    "arrivals": 527992,
    "finished_requests": 97113,
    "scheduler_time": 241.30497676485695
}
#Debug simulation 
Total elapsed time: 72.27591090882197. Arrivals time: 0.4824861721135676 Scheduler time: 71.5911789801903 Scheduler overhead time: 0.07663405919447541 Adapter cache time: 0.017784947529435158 Engine time: 0.07731515495106578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 69.89973373804241,
    "estimated_duration": 3600.0269704290286,
    "input_throughput": 6482.905875901993,
    "output_throughput": 5642.099952817681,
    "total_throughput": 12125.005828719673,
    "itl": 91.4151610863272,
    "ttft": 1911697.057133325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2949722847016787,
    "arrivals": 527992,
    "finished_requests": 94342,
    "scheduler_time": 249.0233352485201
}
#Debug simulation 
Total elapsed time: 69.89990451000631. Arrivals time: 0.462429519277066 Scheduler time: 69.22965894313529 Scheduler overhead time: 0.07857841067016125 Adapter cache time: 0.017538894899189472 Engine time: 0.0797933698631823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 70.84289907291532,
    "estimated_duration": 3600.0143709841577,
    "input_throughput": 6656.734815602617,
    "output_throughput": 5793.204929428815,
    "total_throughput": 12449.939745031434,
    "itl": 97.36367526992721,
    "ttft": 1895600.987484013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.891916186078439,
    "arrivals": 527992,
    "finished_requests": 96901,
    "scheduler_time": 241.89425503263422
}
#Debug simulation 
Total elapsed time: 70.84307807590812. Arrivals time: 0.4655818403698504 Scheduler time: 70.17739412514493 Scheduler overhead time: 0.07567674433812499 Adapter cache time: 0.01719952141866088 Engine time: 0.07680561626330018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 70.38051058584824,
    "estimated_duration": 3600.0059149236745,
    "input_throughput": 6489.718781613538,
    "output_throughput": 5653.96737700403,
    "total_throughput": 12143.686158617567,
    "itl": 91.42213366349519,
    "ttft": 1915391.3574444808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1880114074982937,
    "arrivals": 527992,
    "finished_requests": 94490,
    "scheduler_time": 248.45213042135487
}
#Debug simulation 
Total elapsed time: 70.38068484794348. Arrivals time: 0.47184220096096396 Scheduler time: 69.70086058648303 Scheduler overhead time: 0.07880631973966956 Adapter cache time: 0.0175435496494174 Engine time: 0.07976048858836293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 71.00174059672281,
    "estimated_duration": 3600.0104864885548,
    "input_throughput": 6765.368070845877,
    "output_throughput": 5900.6350341828465,
    "total_throughput": 12666.003105028723,
    "itl": 100.32276528351525,
    "ttft": 1892274.911749554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8830103379301986,
    "arrivals": 526966,
    "finished_requests": 98684,
    "scheduler_time": 236.77870782965175
}
#Debug simulation 
Total elapsed time: 71.00191363599151. Arrivals time: 0.4718791074119508 Scheduler time: 70.33395214844495 Scheduler overhead time: 0.0741106397472322 Adapter cache time: 0.016894569620490074 Engine time: 0.07522864872589707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 70.64205016661435,
    "estimated_duration": 3600.092675054346,
    "input_throughput": 6680.181920493744,
    "output_throughput": 5818.954091142602,
    "total_throughput": 12499.136011636347,
    "itl": 97.4062373800181,
    "ttft": 1897496.8114548475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6291653141798483,
    "arrivals": 526966,
    "finished_requests": 97359,
    "scheduler_time": 240.6610158335849
}
#Debug simulation 
Total elapsed time: 70.64222367201. Arrivals time: 0.4638777575455606 Scheduler time: 69.97835620073602 Scheduler overhead time: 0.07612652191892266 Adapter cache time: 0.015954539645463228 Engine time: 0.07736601075157523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 69.0085648340173,
    "estimated_duration": 3600.0110048573592,
    "input_throughput": 6512.882590737803,
    "output_throughput": 5676.024871154424,
    "total_throughput": 12188.907461892228,
    "itl": 91.67555607153759,
    "ttft": 1913415.9782381828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.911839596284572,
    "arrivals": 526966,
    "finished_requests": 94927,
    "scheduler_time": 247.44996081728794
}
#Debug simulation 
Total elapsed time: 69.00873764697462. Arrivals time: 0.4520679456181824 Scheduler time: 68.34980553667992 Scheduler overhead time: 0.078579340595752 Adapter cache time: 0.016989205963909626 Engine time: 0.07959490455687046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 73.23186183907092,
    "estimated_duration": 3600.0285447337806,
    "input_throughput": 6679.828146134408,
    "output_throughput": 5824.141597619055,
    "total_throughput": 12503.969743753461,
    "itl": 97.46999462428246,
    "ttft": 1895744.675671712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8853152781166105,
    "arrivals": 526966,
    "finished_requests": 97425,
    "scheduler_time": 240.47171533042575
}
#Debug simulation 
Total elapsed time: 73.23203931003809. Arrivals time: 0.5117853456176817 Scheduler time: 72.51894681807607 Scheduler overhead time: 0.07658737851306796 Adapter cache time: 0.017064949963241816 Engine time: 0.07719938177615404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 70.1420856132172,
    "estimated_duration": 3600.04679259891,
    "input_throughput": 6504.645730755908,
    "output_throughput": 5666.4788474244615,
    "total_throughput": 12171.124578180368,
    "itl": 91.37274953952979,
    "ttft": 1915080.9262540885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.820305776335317,
    "arrivals": 526966,
    "finished_requests": 94822,
    "scheduler_time": 247.964019279059
}
#Debug simulation 
Total elapsed time: 70.14225501613691. Arrivals time: 0.4572935630567372 Scheduler time: 69.47859495412558 Scheduler overhead time: 0.07859397260472178 Adapter cache time: 0.01687563071027398 Engine time: 0.07902803272008896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 68.5583046800457,
    "estimated_duration": 3600.029455441441,
    "input_throughput": 6686.496401749109,
    "output_throughput": 5825.856776893574,
    "total_throughput": 12512.353178642683,
    "itl": 97.73853650389432,
    "ttft": 1897411.5814310887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7833895300887406,
    "arrivals": 526966,
    "finished_requests": 97478,
    "scheduler_time": 240.38101999751927
}
#Debug simulation 
Total elapsed time: 68.55847360892221. Arrivals time: 0.4902513208799064 Scheduler time: 67.87101950822398 Scheduler overhead time: 0.07479612436145544 Adapter cache time: 0.016719724982976913 Engine time: 0.07559892814606428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 67.78046923410147,
    "estimated_duration": 3600.075519884578,
    "input_throughput": 6497.682026612035,
    "output_throughput": 5659.971822105911,
    "total_throughput": 12157.653848717946,
    "itl": 91.42916735519843,
    "ttft": 1913741.9275378713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6822351502441015,
    "arrivals": 526966,
    "finished_requests": 94750,
    "scheduler_time": 248.2495470468159
}
#Debug simulation 
Total elapsed time: 67.78063193103299. Arrivals time: 0.5015147025696933 Scheduler time: 67.07515212334692 Scheduler overhead time: 0.07747599948197603 Adapter cache time: 0.016515289898961782 Engine time: 0.07845391891896725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 72.8706179461442,
    "estimated_duration": 3600.0859406356453,
    "input_throughput": 6675.936740486943,
    "output_throughput": 5846.921808839772,
    "total_throughput": 12522.858549326715,
    "itl": 99.98861520963871,
    "ttft": 1886163.319096434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1012198359845535,
    "arrivals": 518548,
    "finished_requests": 97737,
    "scheduler_time": 239.40080000045631
}
#Debug simulation 
Total elapsed time: 72.87078662822023. Arrivals time: 0.463782689999789 Scheduler time: 72.2083631856367 Scheduler overhead time: 0.0751451444812119 Adapter cache time: 0.0172465480864048 Engine time: 0.07606275845319033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 71.17696469789371,
    "estimated_duration": 3600.055006613572,
    "input_throughput": 6657.873270260503,
    "output_throughput": 5824.478781985106,
    "total_throughput": 12482.35205224561,
    "itl": 97.81807058201804,
    "ttft": 1896923.1114017772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.520449567767796,
    "arrivals": 518548,
    "finished_requests": 97365,
    "scheduler_time": 240.35554021683834
}
#Debug simulation 
Total elapsed time: 71.17713451618329. Arrivals time: 0.4623560383915901 Scheduler time: 70.5134732783772 Scheduler overhead time: 0.07659281324595213 Adapter cache time: 0.017546882387250662 Engine time: 0.07654874678701162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 70.84993626689538,
    "estimated_duration": 3600.05757209379,
    "input_throughput": 6482.209946000284,
    "output_throughput": 5666.02327643792,
    "total_throughput": 12148.233222438204,
    "itl": 91.5511288617354,
    "ttft": 1912878.792600182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.635410489719391,
    "arrivals": 518548,
    "finished_requests": 94658,
    "scheduler_time": 247.91176184452735
}
#Debug simulation 
Total elapsed time: 70.8501019179821. Arrivals time: 0.4555836799554527 Scheduler time: 70.18643242167309 Scheduler overhead time: 0.07850667089223862 Adapter cache time: 0.018099131993949413 Engine time: 0.07962704775854945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 71.5916668609716,
    "estimated_duration": 3600.088719999514,
    "input_throughput": 6663.865494960146,
    "output_throughput": 5821.39264612424,
    "total_throughput": 12485.258141084387,
    "itl": 97.6243073256437,
    "ttft": 1896414.0662703402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9810740922251675,
    "arrivals": 518548,
    "finished_requests": 97347,
    "scheduler_time": 240.55636455005754
}
#Debug simulation 
Total elapsed time: 71.5918403500691. Arrivals time: 0.4850443275645375 Scheduler time: 70.90413174405694 Scheduler overhead time: 0.07635025912895799 Adapter cache time: 0.017191702965646982 Engine time: 0.07820114167407155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 68.90529266092926,
    "estimated_duration": 3600.007142412159,
    "input_throughput": 6479.056034419834,
    "output_throughput": 5662.1840439855105,
    "total_throughput": 12141.240078405344,
    "itl": 91.5769131746437,
    "ttft": 1910947.4631331346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4845519641740528,
    "arrivals": 518548,
    "finished_requests": 94686,
    "scheduler_time": 248.09418927242288
}
#Debug simulation 
Total elapsed time: 68.90546323917806. Arrivals time: 0.46395443519577384 Scheduler time: 68.23491013096645 Scheduler overhead time: 0.07795234397053719 Adapter cache time: 0.017736472189426422 Engine time: 0.07877989951521158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 68.93309577694163,
    "estimated_duration": 3600.0243622369803,
    "input_throughput": 6628.630975478144,
    "output_throughput": 5800.303803228941,
    "total_throughput": 12428.934778707086,
    "itl": 97.76409541476593,
    "ttft": 1892224.5561436808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.389862019442938,
    "arrivals": 518548,
    "finished_requests": 96968,
    "scheduler_time": 241.47285505545454
}
#Debug simulation 
Total elapsed time: 68.93326521897689. Arrivals time: 0.5328897964209318 Scheduler time: 68.19973801635206 Scheduler overhead time: 0.07569839060306549 Adapter cache time: 0.018191687297075987 Engine time: 0.07615805370733142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 70.05537205003202,
    "estimated_duration": 3600.1007330187176,
    "input_throughput": 6485.492415769747,
    "output_throughput": 5671.490748226751,
    "total_throughput": 12156.983163996498,
    "itl": 91.59704095038802,
    "ttft": 1912426.5517679444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2667009694688276,
    "arrivals": 518548,
    "finished_requests": 94790,
    "scheduler_time": 247.68238071466132
}
#Debug simulation 
Total elapsed time: 70.05554228974506. Arrivals time: 0.4726313757710159 Scheduler time: 69.37622114876285 Scheduler overhead time: 0.0781404422596097 Adapter cache time: 0.017665155697613955 Engine time: 0.07914222357794642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 71.34739004913718,
    "estimated_duration": 3600.010620231432,
    "input_throughput": 6748.020926237793,
    "output_throughput": 5890.641511117741,
    "total_throughput": 12638.662437355535,
    "itl": 100.77950918819977,
    "ttft": 1881725.334080593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.074770199856753,
    "arrivals": 514751,
    "finished_requests": 98344,
    "scheduler_time": 237.1280433311308
}
#Debug simulation 
Total elapsed time: 71.34759218618274. Arrivals time: 0.4883959135040641 Scheduler time: 70.66133398748934 Scheduler overhead time: 0.07495919521898031 Adapter cache time: 0.01683966303244233 Engine time: 0.07559939939528704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 72.57882207306102,
    "estimated_duration": 3600.090301342326,
    "input_throughput": 6667.527753692735,
    "output_throughput": 5816.416047173171,
    "total_throughput": 12483.943800865905,
    "itl": 97.67371818069819,
    "ttft": 1894494.0259703412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.380551013317895,
    "arrivals": 514751,
    "finished_requests": 97214,
    "scheduler_time": 240.6670205627378
}
#Debug simulation 
Total elapsed time: 72.57899701409042. Arrivals time: 0.4620511597022414 Scheduler time: 71.91548492433503 Scheduler overhead time: 0.0763434749096632 Adapter cache time: 0.01770463166758418 Engine time: 0.07670288486406207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 67.319221528247,
    "estimated_duration": 3600.039882141156,
    "input_throughput": 6492.143355395082,
    "output_throughput": 5670.40440336977,
    "total_throughput": 12162.547758764853,
    "itl": 92.11493852268627,
    "ttft": 1903758.4466214082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5440919870185024,
    "arrivals": 514751,
    "finished_requests": 94616,
    "scheduler_time": 247.51677183050288
}
#Debug simulation 
Total elapsed time: 67.31939503317699. Arrivals time: 0.45653824927285314 Scheduler time: 66.65594592457637 Scheduler overhead time: 0.07789267599582672 Adapter cache time: 0.018120308872312307 Engine time: 0.07894100248813629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 69.67094657989219,
    "estimated_duration": 3600.0471747735533,
    "input_throughput": 6660.645773762196,
    "output_throughput": 5813.9235359649265,
    "total_throughput": 12474.569309727121,
    "itl": 98.02989420892399,
    "ttft": 1888395.9361129978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.838200527722942,
    "arrivals": 514751,
    "finished_requests": 97092,
    "scheduler_time": 240.69061324066533
}
#Debug simulation 
Total elapsed time: 69.67111889598891. Arrivals time: 0.45585615700110793 Scheduler time: 69.01522856485099 Scheduler overhead time: 0.07547766203060746 Adapter cache time: 0.018116415478289127 Engine time: 0.07575260335579515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 66.02598449168727,
    "estimated_duration": 3600.0619518421713,
    "input_throughput": 6508.4841076166085,
    "output_throughput": 5677.583684231022,
    "total_throughput": 12186.06779184763,
    "itl": 92.0391541661509,
    "ttft": 1905445.117763759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.039045503092964,
    "arrivals": 514751,
    "finished_requests": 94822,
    "scheduler_time": 247.08410032523653
}
#Debug simulation 
Total elapsed time: 66.0261621796526. Arrivals time: 0.45122054498642683 Scheduler time: 65.36809084704146 Scheduler overhead time: 0.07809387939050794 Adapter cache time: 0.018489064648747444 Engine time: 0.07870416343212128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 70.27555402508005,
    "estimated_duration": 3600.061349332166,
    "input_throughput": 6684.424976386606,
    "output_throughput": 5826.695426701899,
    "total_throughput": 12511.120403088506,
    "itl": 98.17085005009282,
    "ttft": 1888174.4840315857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.03236244677099,
    "arrivals": 514751,
    "finished_requests": 97440,
    "scheduler_time": 240.11759310925328
}
#Debug simulation 
Total elapsed time: 70.27572402078658. Arrivals time: 0.4540933929383755 Scheduler time: 69.62327780434862 Scheduler overhead time: 0.07515972340479493 Adapter cache time: 0.017415433190762997 Engine time: 0.07519983407109976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.57790025370196,
    "estimated_duration": 3600.067956559111,
    "input_throughput": 6515.115904205817,
    "output_throughput": 5686.827928539367,
    "total_throughput": 12201.943832745184,
    "itl": 92.14135902805765,
    "ttft": 1903899.0567492577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.53460599027577,
    "arrivals": 514751,
    "finished_requests": 94900,
    "scheduler_time": 246.72591055440085
}
#Debug simulation 
Total elapsed time: 68.57806447800249. Arrivals time: 0.45919722970575094 Scheduler time: 67.90963086672127 Scheduler overhead time: 0.07886990206316113 Adapter cache time: 0.018081038258969784 Engine time: 0.07998743513599038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 72.3583540651016,
    "estimated_duration": 3600.0273888049355,
    "input_throughput": 6801.4174214735995,
    "output_throughput": 5899.514560929577,
    "total_throughput": 12700.931982403175,
    "itl": 100.91853220687109,
    "ttft": 1875565.2942740535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1475066992082046,
    "arrivals": 512803,
    "finished_requests": 98917,
    "scheduler_time": 236.74379198373833
}
#Debug simulation 
Total elapsed time: 72.35852590901777. Arrivals time: 0.4555687247775495 Scheduler time: 71.70252217072994 Scheduler overhead time: 0.07653693901374936 Adapter cache time: 0.017599490471184254 Engine time: 0.07577687688171864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.64328694622964,
    "estimated_duration": 3600.0975537028808,
    "input_throughput": 6714.189168329108,
    "output_throughput": 5820.9092079868415,
    "total_throughput": 12535.09837631595,
    "itl": 97.83591226379606,
    "ttft": 1885310.6759892786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1956911591626747,
    "arrivals": 512803,
    "finished_requests": 97618,
    "scheduler_time": 240.5228910528586
}
#Debug simulation 
Total elapsed time: 73.64344861125574. Arrivals time: 0.45557267125695944 Scheduler time: 72.98748479504138 Scheduler overhead time: 0.07587638683617115 Adapter cache time: 0.017306406516581774 Engine time: 0.07653390243649483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 72.1782454168424,
    "estimated_duration": 3600.0780111657864,
    "input_throughput": 6539.85772724295,
    "output_throughput": 5675.483124706956,
    "total_throughput": 12215.340851949906,
    "itl": 91.84318722800526,
    "ttft": 1903723.3977374334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3426581112761293,
    "arrivals": 512803,
    "finished_requests": 95104,
    "scheduler_time": 247.47473752647574
}
#Debug simulation 
Total elapsed time: 72.17840802203864. Arrivals time: 0.4466405175626278 Scheduler time: 71.52510154759511 Scheduler overhead time: 0.07801484037190676 Adapter cache time: 0.017555691301822662 Engine time: 0.07931825146079063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 72.78589681908488,
    "estimated_duration": 3600.1073582808017,
    "input_throughput": 6715.527231261604,
    "output_throughput": 5824.461582171651,
    "total_throughput": 12539.988813433254,
    "itl": 97.88654470605844,
    "ttft": 1884075.6050289962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.068786911298517,
    "arrivals": 512803,
    "finished_requests": 97663,
    "scheduler_time": 240.3389088465613
}
#Debug simulation 
Total elapsed time: 72.78606429602951. Arrivals time: 0.4771265503950417 Scheduler time: 72.1095606861636 Scheduler overhead time: 0.07531547592952847 Adapter cache time: 0.01731528341770172 Engine time: 0.07638389291241765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 70.93218767782673,
    "estimated_duration": 3600.0442765129364,
    "input_throughput": 6533.591587596542,
    "output_throughput": 5665.853926595923,
    "total_throughput": 12199.445514192465,
    "itl": 91.72778630449103,
    "ttft": 1902034.7053288966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1759560801089033,
    "arrivals": 512803,
    "finished_requests": 94969,
    "scheduler_time": 247.90521686198284
}
#Debug simulation 
Total elapsed time: 70.93234962783754. Arrivals time: 0.4611381306312978 Scheduler time: 70.26426697336137 Scheduler overhead time: 0.07836860232055187 Adapter cache time: 0.017462688963860273 Engine time: 0.07938364567235112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 74.55318833887577,
    "estimated_duration": 3600.037734358364,
    "input_throughput": 6717.603476539741,
    "output_throughput": 5826.432539807377,
    "total_throughput": 12544.036016347118,
    "itl": 97.91136564291588,
    "ttft": 1883913.600287253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9366036326624325,
    "arrivals": 512803,
    "finished_requests": 97666,
    "scheduler_time": 240.2914573906554
}
#Debug simulation 
Total elapsed time: 74.55336438072845. Arrivals time: 0.47860031900927424 Scheduler time: 73.87417874066159 Scheduler overhead time: 0.07604401092976332 Adapter cache time: 0.01748055825009942 Engine time: 0.07611486734822392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 69.40254484023899,
    "estimated_duration": 3600.021217029942,
    "input_throughput": 6562.628266810991,
    "output_throughput": 5693.9000534311335,
    "total_throughput": 12256.528320242123,
    "itl": 92.07184724940923,
    "ttft": 1902755.1066209504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.484388874657479,
    "arrivals": 512803,
    "finished_requests": 95411,
    "scheduler_time": 246.48071978785285
}
#Debug simulation 
Total elapsed time: 69.40271249134094. Arrivals time: 0.45241031888872385 Scheduler time: 68.74349846038967 Scheduler overhead time: 0.07844326924532652 Adapter cache time: 0.01770726265385747 Engine time: 0.07893526460975409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 72.25834534363821,
    "estimated_duration": 3600.003321127532,
    "input_throughput": 6703.848259906937,
    "output_throughput": 5872.812637677849,
    "total_throughput": 12576.660897584787,
    "itl": 100.03235351921134,
    "ttft": 1877293.7595395942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.770599384387046,
    "arrivals": 511802,
    "finished_requests": 98011,
    "scheduler_time": 238.0420070891406
}
#Debug simulation 
Total elapsed time: 72.2585155875422. Arrivals time: 0.46710980078205466 Scheduler time: 71.59365998627618 Scheduler overhead time: 0.07522285543382168 Adapter cache time: 0.01686492282897234 Engine time: 0.07579021761193871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 71.68366731610149,
    "estimated_duration": 3600.051664642455,
    "input_throughput": 6662.6510490321525,
    "output_throughput": 5827.904695385459,
    "total_throughput": 12490.555744417612,
    "itl": 97.45814715837896,
    "ttft": 1887085.1458833192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1590497076138893,
    "arrivals": 511802,
    "finished_requests": 97317,
    "scheduler_time": 240.14632862569968
}
#Debug simulation 
Total elapsed time: 71.68383878888562. Arrivals time: 0.4685649503953755 Scheduler time: 71.01302038086578 Scheduler overhead time: 0.07687412621453404 Adapter cache time: 0.017077078577131033 Engine time: 0.07712271809577942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.3204444181174,
    "estimated_duration": 3600.008632142171,
    "input_throughput": 6482.313901040225,
    "output_throughput": 5661.952812560655,
    "total_throughput": 12144.26671360088,
    "itl": 91.32489979790489,
    "ttft": 1904828.3048680655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2058328225231025,
    "arrivals": 511802,
    "finished_requests": 94568,
    "scheduler_time": 247.90880038332386
}
#Debug simulation 
Total elapsed time: 68.3206217540428. Arrivals time: 0.45372785488143563 Scheduler time: 67.66075155045837 Scheduler overhead time: 0.07802154636010528 Adapter cache time: 0.017283059656620026 Engine time: 0.07884891470894217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 70.86047179391608,
    "estimated_duration": 3600.040251175654,
    "input_throughput": 6662.2796765029125,
    "output_throughput": 5833.013670650597,
    "total_throughput": 12495.29334715351,
    "itl": 97.7050640133598,
    "ttft": 1887413.0126683079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0121626598807016,
    "arrivals": 511802,
    "finished_requests": 97356,
    "scheduler_time": 239.92837667097768
}
#Debug simulation 
Total elapsed time: 70.86064877500758. Arrivals time: 0.4658336713910103 Scheduler time: 70.19414624292403 Scheduler overhead time: 0.07580224564298987 Adapter cache time: 0.017361348494887352 Engine time: 0.07707220269367099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 62.01268350798637,
    "estimated_duration": 3600.043318730456,
    "input_throughput": 6491.156892034513,
    "output_throughput": 5684.8329834034175,
    "total_throughput": 12175.98987543793,
    "itl": 91.86050512750641,
    "ttft": 1906525.6120858712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.083257717103733,
    "arrivals": 511802,
    "finished_requests": 94850,
    "scheduler_time": 246.7713472314444
}
#Debug simulation 
Total elapsed time: 62.01285639312118. Arrivals time: 0.4399317605420947 Scheduler time: 61.36772295599803 Scheduler overhead time: 0.07745721843093634 Adapter cache time: 0.018312646076083183 Engine time: 0.07802800182253122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 73.2309454777278,
    "estimated_duration": 3600.0684086295896,
    "input_throughput": 6675.138711918999,
    "output_throughput": 5838.798215504341,
    "total_throughput": 12513.93692742334,
    "itl": 97.66085735426792,
    "ttft": 1887723.9530948154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.572720139049914,
    "arrivals": 511802,
    "finished_requests": 97416,
    "scheduler_time": 239.64328879213144
}
#Debug simulation 
Total elapsed time: 73.23110432969406. Arrivals time: 0.44982786662876606 Scheduler time: 72.58175428630784 Scheduler overhead time: 0.07592477975413203 Adapter cache time: 0.016591448802500963 Engine time: 0.07656345423310995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 65.26464312104508,
    "estimated_duration": 3600.0785746931992,
    "input_throughput": 6430.894915112513,
    "output_throughput": 5632.21790283507,
    "total_throughput": 12063.112817947584,
    "itl": 91.12159245159532,
    "ttft": 1902231.5040352787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7874941189028655,
    "arrivals": 511802,
    "finished_requests": 93936,
    "scheduler_time": 249.36188817423715
}
#Debug simulation 
Total elapsed time: 65.26481147808954. Arrivals time: 0.4291548263281584 Scheduler time: 64.62872081203386 Scheduler overhead time: 0.07827729126438498 Adapter cache time: 0.01811576122418046 Engine time: 0.07870551198720932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 70.39250515913591,
    "estimated_duration": 3600.003894995982,
    "input_throughput": 6767.669899986925,
    "output_throughput": 5898.6286180181205,
    "total_throughput": 12666.298518005045,
    "itl": 101.3016709631682,
    "ttft": 1870986.7596679844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3987782424223103,
    "arrivals": 507065,
    "finished_requests": 99058,
    "scheduler_time": 236.64448484955741
}
#Debug simulation 
Total elapsed time: 70.39266935689375. Arrivals time: 0.4561582482419908 Scheduler time: 69.74047991586849 Scheduler overhead time: 0.07464344799518585 Adapter cache time: 0.017422583419829607 Engine time: 0.0742310993373394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 70.1623341110535,
    "estimated_duration": 3600.096578678122,
    "input_throughput": 6665.6822881155085,
    "output_throughput": 5808.976382427706,
    "total_throughput": 12474.658670543215,
    "itl": 98.49069921159186,
    "ttft": 1875853.8678447567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8565875972807455,
    "arrivals": 507065,
    "finished_requests": 97518,
    "scheduler_time": 240.74141949057082
}
#Debug simulation 
Total elapsed time: 70.16250070277601. Arrivals time: 0.4669876932166517 Scheduler time: 69.49408607324585 Scheduler overhead time: 0.0763395419344306 Adapter cache time: 0.01787003967911005 Engine time: 0.07634405000135303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.48542897123843,
    "estimated_duration": 3600.0200075589373,
    "input_throughput": 6498.851381624432,
    "output_throughput": 5661.537146239409,
    "total_throughput": 12160.38852786384,
    "itl": 92.14521413488393,
    "ttft": 1896419.5806915467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.498117242367035,
    "arrivals": 507065,
    "finished_requests": 95015,
    "scheduler_time": 247.78265497570177
}
#Debug simulation 
Total elapsed time: 68.48559179715812. Arrivals time: 0.4567205752246082 Scheduler time: 67.82312778569758 Scheduler overhead time: 0.07773327501490712 Adapter cache time: 0.01801524916663766 Engine time: 0.07824493106454611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 74.65722096618265,
    "estimated_duration": 3600.0482717490386,
    "input_throughput": 6659.8484770738,
    "output_throughput": 5802.659970959479,
    "total_throughput": 12462.508448033279,
    "itl": 97.85231097373068,
    "ttft": 1883094.63615972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1706557932263206,
    "arrivals": 507065,
    "finished_requests": 97397,
    "scheduler_time": 241.1217444909596
}
#Debug simulation 
Total elapsed time: 74.65739132277668. Arrivals time: 0.47452147817239165 Scheduler time: 73.98165330057964 Scheduler overhead time: 0.07622937252745032 Adapter cache time: 0.01767300022765994 Engine time: 0.07666471181437373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 64.87412424013019,
    "estimated_duration": 3600.071548499762,
    "input_throughput": 6514.618857998386,
    "output_throughput": 5685.811163539255,
    "total_throughput": 12200.430021537642,
    "itl": 92.37840928755533,
    "ttft": 1899129.825018835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.245337176788633,
    "arrivals": 507065,
    "finished_requests": 95339,
    "scheduler_time": 246.4654920080351
}
#Debug simulation 
Total elapsed time: 64.87429737485945. Arrivals time: 0.45839761896058917 Scheduler time: 64.21050050668418 Scheduler overhead time: 0.07761191669851542 Adapter cache time: 0.0182544500567019 Engine time: 0.07796222204342484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 69.28446910483763,
    "estimated_duration": 3600.06328662709,
    "input_throughput": 6700.132214230863,
    "output_throughput": 5841.8006367059925,
    "total_throughput": 12541.932850936855,
    "itl": 98.67691615614062,
    "ttft": 1879749.9709648998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.172808707463541,
    "arrivals": 507065,
    "finished_requests": 98074,
    "scheduler_time": 239.31956570456987
}
#Debug simulation 
Total elapsed time: 69.28464453388005. Arrivals time: 0.4666782272979617 Scheduler time: 68.61879049846902 Scheduler overhead time: 0.07550306152552366 Adapter cache time: 0.01796314585953951 Engine time: 0.07542388932779431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.9877893095836,
    "estimated_duration": 3600.006448415229,
    "input_throughput": 6520.740819876553,
    "output_throughput": 5684.917872580282,
    "total_throughput": 12205.658692456835,
    "itl": 92.2234127300738,
    "ttft": 1899559.3646992713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3996925558150086,
    "arrivals": 507065,
    "finished_requests": 95444,
    "scheduler_time": 246.70444675503248
}
#Debug simulation 
Total elapsed time: 68.98795980866998. Arrivals time: 0.4558708416298032 Scheduler time: 68.32629985688254 Scheduler overhead time: 0.07743247458711267 Adapter cache time: 0.017870706040412188 Engine time: 0.07890947535634041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 73.00080977007747,
    "estimated_duration": 3600.0801112966064,
    "input_throughput": 6784.095421477635,
    "output_throughput": 5885.69680255492,
    "total_throughput": 12669.792224032555,
    "itl": 100.1907812340488,
    "ttft": 1875399.4160562756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9226847921218995,
    "arrivals": 505172,
    "finished_requests": 98339,
    "scheduler_time": 237.33903409859275
}
#Debug simulation 
Total elapsed time: 73.0009890650399. Arrivals time: 0.5209114849567413 Scheduler time: 72.28419659798965 Scheduler overhead time: 0.07423776527866721 Adapter cache time: 0.016796079464256763 Engine time: 0.07454434083774686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.89800522476435,
    "estimated_duration": 3600.0730327337624,
    "input_throughput": 6679.468661150999,
    "output_throughput": 5795.400762788624,
    "total_throughput": 12474.869423939623,
    "itl": 97.24049023074244,
    "ttft": 1880239.4241898537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2950574522651777,
    "arrivals": 505172,
    "finished_requests": 96868,
    "scheduler_time": 241.63195709308968
}
#Debug simulation 
Total elapsed time: 73.89817003766075. Arrivals time: 0.46483049960806966 Scheduler time: 73.23231922416016 Scheduler overhead time: 0.075921222101897 Adapter cache time: 0.017258433159440756 Engine time: 0.07711428916081786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 70.47158026928082,
    "estimated_duration": 3600.0425965861464,
    "input_throughput": 6530.27189797515,
    "output_throughput": 5672.557602336506,
    "total_throughput": 12202.829500311656,
    "itl": 91.38282506378084,
    "ttft": 1896458.892397066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5287127294671055,
    "arrivals": 505172,
    "finished_requests": 94715,
    "scheduler_time": 247.35776960219943
}
#Debug simulation 
Total elapsed time: 70.4717585821636. Arrivals time: 0.44660095777362585 Scheduler time: 69.81460887007415 Scheduler overhead time: 0.08017043303698301 Adapter cache time: 0.01807736372575164 Engine time: 0.07989281881600618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 72.68260510172695,
    "estimated_duration": 3600.0509362224084,
    "input_throughput": 6679.172996710759,
    "output_throughput": 5795.769662607621,
    "total_throughput": 12474.942659318382,
    "itl": 97.12023556704668,
    "ttft": 1879027.1145883214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.313595165060828,
    "arrivals": 505172,
    "finished_requests": 96842,
    "scheduler_time": 241.58986909808598
}
#Debug simulation 
Total elapsed time: 72.68277390487492. Arrivals time: 0.4459244809113443 Scheduler time: 72.0352593078278 Scheduler overhead time: 0.07645817892625928 Adapter cache time: 0.017863187473267317 Engine time: 0.07677483186125755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 66.34432151494548,
    "estimated_duration": 3600.0543350277544,
    "input_throughput": 6540.198510592336,
    "output_throughput": 5676.494602085624,
    "total_throughput": 12216.69311267796,
    "itl": 91.33753709057554,
    "ttft": 1900687.0159453705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.79577922623142,
    "arrivals": 505172,
    "finished_requests": 94778,
    "scheduler_time": 247.1710942215881
}
#Debug simulation 
Total elapsed time: 66.3444954031147. Arrivals time: 0.501096498221159 Scheduler time: 65.63615680020303 Scheduler overhead time: 0.07814816106110811 Adapter cache time: 0.018155731726437807 Engine time: 0.07908565225079656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 74.08979241689667,
    "estimated_duration": 3600.0974874709595,
    "input_throughput": 6667.038902010737,
    "output_throughput": 5793.527001029092,
    "total_throughput": 12460.56590303983,
    "itl": 97.07609464964797,
    "ttft": 1877657.4846099901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.789773451029311,
    "arrivals": 505172,
    "finished_requests": 96768,
    "scheduler_time": 241.74507225872216
}
#Debug simulation 
Total elapsed time: 74.08996363310143. Arrivals time: 0.5167058147490025 Scheduler time: 73.37066735280678 Scheduler overhead time: 0.0769232027232647 Adapter cache time: 0.01727026328444481 Engine time: 0.07725664926692843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 63.13111488800496,
    "estimated_duration": 3600.0786172855533,
    "input_throughput": 6522.717833785966,
    "output_throughput": 5660.433053366191,
    "total_throughput": 12183.150887152156,
    "itl": 91.66884758570463,
    "ttft": 1897463.0616637073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9789322871715167,
    "arrivals": 505172,
    "finished_requests": 94561,
    "scheduler_time": 247.89835279228728
}
#Debug simulation 
Total elapsed time: 63.13128686742857. Arrivals time: 0.48203983157873154 Scheduler time: 62.44375785533339 Scheduler overhead time: 0.07755227107554674 Adapter cache time: 0.017817947082221508 Engine time: 0.07856875751167536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 74.6003753002733,
    "estimated_duration": 3600.074316509692,
    "input_throughput": 6803.232613193768,
    "output_throughput": 5913.955415409737,
    "total_throughput": 12717.188028603505,
    "itl": 100.34271904398878,
    "ttft": 1869372.0319467098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8036614295467968,
    "arrivals": 504244,
    "finished_requests": 99089,
    "scheduler_time": 236.05965023056248
}
#Debug simulation 
Total elapsed time: 74.60055254818872. Arrivals time: 0.46855066111311316 Scheduler time: 73.931321461685 Scheduler overhead time: 0.07597295427694917 Adapter cache time: 0.017019035760313272 Engine time: 0.07706487365067005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.78836496919394,
    "estimated_duration": 3600.0534708274013,
    "input_throughput": 6746.0461898134845,
    "output_throughput": 5855.247754182762,
    "total_throughput": 12601.293943996247,
    "itl": 97.99243633986077,
    "ttft": 1873802.2338258026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2276107638655276,
    "arrivals": 504244,
    "finished_requests": 98194,
    "scheduler_time": 238.80035816561693
}
#Debug simulation 
Total elapsed time: 73.7885312801227. Arrivals time: 0.46309758722782135 Scheduler time: 73.12275067577139 Scheduler overhead time: 0.07666322262957692 Adapter cache time: 0.01756404945626855 Engine time: 0.07745616976171732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 74.84906777506694,
    "estimated_duration": 3600.081833614149,
    "input_throughput": 6099.269965193077,
    "output_throughput": 5305.157738824611,
    "total_throughput": 11404.427704017688,
    "itl": 82.54245765204728,
    "ttft": 1919723.5090309656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.129559424240149,
    "arrivals": 504244,
    "finished_requests": 88925,
    "scheduler_time": 265.45558543797426
}
#Debug simulation 
Total elapsed time: 74.84923193091527. Arrivals time: 0.43950582575052977 Scheduler time: 74.18728940188885 Scheduler overhead time: 0.08517105598002672 Adapter cache time: 0.01716896053403616 Engine time: 0.08551544090732932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 72.88666862808168,
    "estimated_duration": 3600.0199944256174,
    "input_throughput": 6703.731934091801,
    "output_throughput": 5834.275096394598,
    "total_throughput": 12538.0070304864,
    "itl": 97.73218851934935,
    "ttft": 1879172.0519272324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.189250372122038,
    "arrivals": 504244,
    "finished_requests": 97732,
    "scheduler_time": 239.8218111096757
}
#Debug simulation 
Total elapsed time: 72.88683898281306. Arrivals time: 0.45664367405697703 Scheduler time: 72.22999770753086 Scheduler overhead time: 0.07562194485217333 Adapter cache time: 0.017382889986038208 Engine time: 0.07663322100415826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 65.99696027720347,
    "estimated_duration": 3600.0587568126984,
    "input_throughput": 6522.622708744222,
    "output_throughput": 5683.766955547103,
    "total_throughput": 12206.389664291326,
    "itl": 91.69229192673883,
    "ttft": 1890908.2989266263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8325904426444652,
    "arrivals": 504244,
    "finished_requests": 95132,
    "scheduler_time": 246.8154363183144
}
#Debug simulation 
Total elapsed time: 65.99711963906884. Arrivals time: 0.4512067213654518 Scheduler time: 65.3382831402123 Scheduler overhead time: 0.07855487801134586 Adapter cache time: 0.01789459027349949 Engine time: 0.07917807810008526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 72.76624965993688,
    "estimated_duration": 3600.0334067418444,
    "input_throughput": 6675.348888428601,
    "output_throughput": 5808.978872484007,
    "total_throughput": 12484.327760912609,
    "itl": 97.52945199266733,
    "ttft": 1879757.3958290415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.483345245881927,
    "arrivals": 504244,
    "finished_requests": 97335,
    "scheduler_time": 241.05968436903612
}
#Debug simulation 
Total elapsed time: 72.76641159597784. Arrivals time: 0.4662306713871658 Scheduler time: 72.1010250817053 Scheduler overhead time: 0.07613622210919857 Adapter cache time: 0.016633640974760056 Engine time: 0.07633396470919251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 64.80224286299199,
    "estimated_duration": 3600.007634375735,
    "input_throughput": 6522.358112740969,
    "output_throughput": 5678.764901715286,
    "total_throughput": 12201.123014456254,
    "itl": 91.62339904716059,
    "ttft": 1897242.3155812921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.498985607940732,
    "arrivals": 504244,
    "finished_requests": 95091,
    "scheduler_time": 247.16870960905808
}
#Debug simulation 
Total elapsed time: 64.80240414803848. Arrivals time: 0.48995899595320225 Scheduler time: 64.10756975784898 Scheduler overhead time: 0.0772243388928473 Adapter cache time: 0.017632502131164074 Engine time: 0.07799056125804782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 69.99340462731197,
    "estimated_duration": 3600.0811034752332,
    "input_throughput": 6736.757951532868,
    "output_throughput": 5907.876902958867,
    "total_throughput": 12644.634854491735,
    "itl": 100.95650923329774,
    "ttft": 1873377.286408545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2334680166235565,
    "arrivals": 501368,
    "finished_requests": 98525,
    "scheduler_time": 236.1007850767071
}
#Debug simulation 
Total elapsed time: 69.99357856111601. Arrivals time: 0.4376026908867061 Scheduler time: 69.36282606609166 Scheduler overhead time: 0.0732344794087112 Adapter cache time: 0.016652286052703857 Engine time: 0.07380216754972935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 69.25361959496513,
    "estimated_duration": 3600.0489998313706,
    "input_throughput": 6645.69926718238,
    "output_throughput": 5829.172325427507,
    "total_throughput": 12474.871592609887,
    "itl": 98.05275105358837,
    "ttft": 1875399.441289787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.690322322021243,
    "arrivals": 501368,
    "finished_requests": 97149,
    "scheduler_time": 239.88035918691446
}
#Debug simulation 
Total elapsed time: 69.25377947930247. Arrivals time: 0.3956252229399979 Scheduler time: 68.66783761326224 Scheduler overhead time: 0.07227918179705739 Adapter cache time: 0.01616296684369445 Engine time: 0.0723636937327683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 68.75815038895234,
    "estimated_duration": 3600.0797254039776,
    "input_throughput": 6461.546069619244,
    "output_throughput": 5674.9768222723005,
    "total_throughput": 12136.522891891545,
    "itl": 91.89537834859759,
    "ttft": 1894219.9741549667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7837294646352846,
    "arrivals": 501368,
    "finished_requests": 94551,
    "scheduler_time": 247.11909561126274
}
#Debug simulation 
Total elapsed time: 68.75830442178994. Arrivals time: 0.3636330356821418 Scheduler time: 68.2007655496709 Scheduler overhead time: 0.07418423239141703 Adapter cache time: 0.016379342414438725 Engine time: 0.07292843330651522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 70.06445052055642,
    "estimated_duration": 3600.0531444585295,
    "input_throughput": 6681.752472745225,
    "output_throughput": 5859.017951573181,
    "total_throughput": 12540.770424318405,
    "itl": 98.37932724110078,
    "ttft": 1877815.47442493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3049919860996257,
    "arrivals": 501368,
    "finished_requests": 97674,
    "scheduler_time": 238.39488685938304
}
#Debug simulation 
Total elapsed time: 70.06460299482569. Arrivals time: 0.38848280906677246 Scheduler time: 69.48774734232575 Scheduler overhead time: 0.0716720256023109 Adapter cache time: 0.015999278984963894 Engine time: 0.07151053426787257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 63.94711248995736,
    "estimated_duration": 3600.000953299915,
    "input_throughput": 6443.672182568848,
    "output_throughput": 5658.630723785503,
    "total_throughput": 12102.30290635435,
    "itl": 92.14051650116136,
    "ttft": 1890757.6001328495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.233488905062001,
    "arrivals": 501368,
    "finished_requests": 94203,
    "scheduler_time": 247.85698592178645
}
#Debug simulation 
Total elapsed time: 63.94727026624605. Arrivals time: 0.38001745473593473 Scheduler time: 63.37341089453548 Scheduler overhead time: 0.07310687098652124 Adapter cache time: 0.01680144341662526 Engine time: 0.07355049159377813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 69.53209048090503,
    "estimated_duration": 3600.043389414013,
    "input_throughput": 6662.819973373801,
    "output_throughput": 5843.341516898807,
    "total_throughput": 12506.161490272607,
    "itl": 98.15752733241723,
    "ttft": 1875957.1604636903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1153534189984065,
    "arrivals": 501368,
    "finished_requests": 97402,
    "scheduler_time": 239.17681600724515
}
#Debug simulation 
Total elapsed time: 69.53225267492235. Arrivals time: 0.3928469722159207 Scheduler time: 68.95280200615525 Scheduler overhead time: 0.07130192080512643 Adapter cache time: 0.015846368856728077 Engine time: 0.07076609646901488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 69.33887096401304,
    "estimated_duration": 3600.0660273367644,
    "input_throughput": 6466.402233522798,
    "output_throughput": 5675.823955683406,
    "total_throughput": 12142.226189206205,
    "itl": 91.62554182297221,
    "ttft": 1895173.64301922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5083562533557697,
    "arrivals": 501368,
    "finished_requests": 94605,
    "scheduler_time": 247.1480562841126
}
#Debug simulation 
Total elapsed time: 69.33903179503977. Arrivals time: 0.3786514741368592 Scheduler time: 68.76554235257208 Scheduler overhead time: 0.07433711225166917 Adapter cache time: 0.016507795080542564 Engine time: 0.07330080959945917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 67.33383082598448,
    "estimated_duration": 3600.0722603158483,
    "input_throughput": 6771.018256689488,
    "output_throughput": 5920.464218162674,
    "total_throughput": 12691.482474852162,
    "itl": 101.07039265592641,
    "ttft": 1875021.369754682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.982196473409451,
    "arrivals": 500381,
    "finished_requests": 98787,
    "scheduler_time": 235.63172484589512
}
#Debug simulation 
Total elapsed time: 67.33398283785209. Arrivals time: 0.3927592961117625 Scheduler time: 66.7583664408885 Scheduler overhead time: 0.07001089304685593 Adapter cache time: 0.015611488837748766 Engine time: 0.06881978828459978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 66.62934699608013,
    "estimated_duration": 3600.0682274698456,
    "input_throughput": 6715.840776437761,
    "output_throughput": 5868.71044242646,
    "total_throughput": 12584.55121886422,
    "itl": 98.49811473556397,
    "ttft": 1878951.8366869472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.438289632587699,
    "arrivals": 500381,
    "finished_requests": 97875,
    "scheduler_time": 238.05478648638555
}
#Debug simulation 
Total elapsed time: 66.62949314713478. Arrivals time: 0.38435691269114614 Scheduler time: 66.05866946885362 Scheduler overhead time: 0.0713131008669734 Adapter cache time: 0.015928788110613823 Engine time: 0.0699418862350285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 63.09502575872466,
    "estimated_duration": 3600.0379921500034,
    "input_throughput": 6499.002524700336,
    "output_throughput": 5669.637943962435,
    "total_throughput": 12168.640468662772,
    "itl": 92.16751626819541,
    "ttft": 1895525.8437562275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8882504598936403,
    "arrivals": 500381,
    "finished_requests": 94710,
    "scheduler_time": 247.39616332829425
}
#Debug simulation 
Total elapsed time: 63.09516960568726. Arrivals time: 0.3794298698194325 Scheduler time: 62.523725809995085 Scheduler overhead time: 0.07334485650062561 Adapter cache time: 0.01648888224735856 Engine time: 0.07155947852879763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 62.26019310299307,
    "estimated_duration": 3600.0440195626056,
    "input_throughput": 6708.172141443459,
    "output_throughput": 5863.881354029895,
    "total_throughput": 12572.053495473354,
    "itl": 98.54660680279463,
    "ttft": 1882834.9511424683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9533944354578803,
    "arrivals": 500381,
    "finished_requests": 97749,
    "scheduler_time": 238.16506149589645
}
#Debug simulation 
Total elapsed time: 62.260340528097004. Arrivals time: 0.4034844390116632 Scheduler time: 61.67225921433419 Scheduler overhead time: 0.07008633250370622 Adapter cache time: 0.01659228978678584 Engine time: 0.06892925780266523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 63.50704916007817,
    "estimated_duration": 3600.0387048678726,
    "input_throughput": 6513.109697486033,
    "output_throughput": 5673.040951583203,
    "total_throughput": 12186.150649069237,
    "itl": 92.16397880978855,
    "ttft": 1896973.2274347972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7108835700201177,
    "arrivals": 500381,
    "finished_requests": 94839,
    "scheduler_time": 247.2672328881898
}
#Debug simulation 
Total elapsed time: 63.50720549421385. Arrivals time: 0.40045063430443406 Scheduler time: 62.91208305209875 Scheduler overhead time: 0.07469777949154377 Adapter cache time: 0.016419729683548212 Engine time: 0.0726675670593977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 67.13751384057105,
    "estimated_duration": 3600.0754831407107,
    "input_throughput": 6703.369724611067,
    "output_throughput": 5848.999860866801,
    "total_throughput": 12552.369585477869,
    "itl": 98.45595647921202,
    "ttft": 1878764.600958406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0259785258304195,
    "arrivals": 500381,
    "finished_requests": 97672,
    "scheduler_time": 239.06999877722228
}
#Debug simulation 
Total elapsed time: 67.13765171263367. Arrivals time: 0.3956715166568756 Scheduler time: 66.5548243704252 Scheduler overhead time: 0.07121691899374127 Adapter cache time: 0.016190460417419672 Engine time: 0.0704110749065876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 63.83407937781885,
    "estimated_duration": 3600.0661897225104,
    "input_throughput": 6516.909902094987,
    "output_throughput": 5686.254341223064,
    "total_throughput": 12203.164243318051,
    "itl": 92.28555878087579,
    "ttft": 1895257.5303120546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7751200950518573,
    "arrivals": 500381,
    "finished_requests": 94916,
    "scheduler_time": 246.5985255903108
}
#Debug simulation 
Total elapsed time: 63.83420797996223. Arrivals time: 0.3860218417830765 Scheduler time: 63.2539937030524 Scheduler overhead time: 0.07449872279539704 Adapter cache time: 0.016359209083020687 Engine time: 0.07253155438229442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 72.9637281736359,
    "estimated_duration": 3600.090315651174,
    "input_throughput": 6781.98318910334,
    "output_throughput": 5899.143948603587,
    "total_throughput": 12681.127137706928,
    "itl": 100.10130617039357,
    "ttft": 1873834.8930476499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5722271134285415,
    "arrivals": 498436,
    "finished_requests": 98808,
    "scheduler_time": 236.69139432485287
}
#Debug simulation 
Total elapsed time: 72.96385524887592. Arrivals time: 0.6294238185510039 Scheduler time: 72.15153150446713 Scheduler overhead time: 0.0702193658798933 Adapter cache time: 0.015098482370376587 Engine time: 0.06846430152654648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 74.69888052716851,
    "estimated_duration": 3600.0486354104,
    "input_throughput": 6716.51648318455,
    "output_throughput": 5841.389694893023,
    "total_throughput": 12557.906178077574,
    "itl": 97.94495118465358,
    "ttft": 1869653.4527398928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4307913437951396,
    "arrivals": 498436,
    "finished_requests": 97824,
    "scheduler_time": 239.1489560577455
}
#Debug simulation 
Total elapsed time: 74.69900043820962. Arrivals time: 0.40458864718675613 Scheduler time: 74.10638915328309 Scheduler overhead time: 0.07245367020368576 Adapter cache time: 0.015466321725398302 Engine time: 0.07052243314683437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 71.5642661540769,
    "estimated_duration": 3600.026033645498,
    "input_throughput": 6548.315145412471,
    "output_throughput": 5691.5618966375705,
    "total_throughput": 12239.87704205004,
    "itl": 91.78644907570718,
    "ttft": 1890118.4318053282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3668863313971347,
    "arrivals": 498436,
    "finished_requests": 95340,
    "scheduler_time": 246.4526703834472
}
#Debug simulation 
Total elapsed time: 71.56439684610814. Arrivals time: 0.39577056327834725 Scheduler time: 70.97187041677535 Scheduler overhead time: 0.07608925458043814 Adapter cache time: 0.01591163594275713 Engine time: 0.07384992856532335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 67.57604670384899,
    "estimated_duration": 3600.060772915157,
    "input_throughput": 6645.288096241759,
    "output_throughput": 5784.132911494809,
    "total_throughput": 12429.421007736568,
    "itl": 96.6569143914065,
    "ttft": 1877431.7163251915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9152894779201564,
    "arrivals": 498436,
    "finished_requests": 96797,
    "scheduler_time": 242.1622898906686
}
#Debug simulation 
Total elapsed time: 67.57617954770103. Arrivals time: 0.3911185539327562 Scheduler time: 66.99576730420813 Scheduler overhead time: 0.07295086001977324 Adapter cache time: 0.01577148074284196 Engine time: 0.0705206673592329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 70.61080797296017,
    "estimated_duration": 3600.021972147435,
    "input_throughput": 6534.506228573814,
    "output_throughput": 5695.268295201482,
    "total_throughput": 12229.774523775297,
    "itl": 91.97109794263794,
    "ttft": 1889667.0433040468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3228252347884952,
    "arrivals": 498436,
    "finished_requests": 95218,
    "scheduler_time": 246.22002840548745
}
#Debug simulation 
Total elapsed time: 70.61093625891954. Arrivals time: 0.3950920104980469 Scheduler time: 70.0194956897758 Scheduler overhead time: 0.07593866204842925 Adapter cache time: 0.015933243092149496 Engine time: 0.07357477443292737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 74.7460866109468,
    "estimated_duration": 3600.10482960205,
    "input_throughput": 6712.073715550963,
    "output_throughput": 5846.5228087057185,
    "total_throughput": 12558.596524256682,
    "itl": 97.99154135959171,
    "ttft": 1866753.627161835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7578538463264586,
    "arrivals": 498436,
    "finished_requests": 97747,
    "scheduler_time": 239.02842687070645
}
#Debug simulation 
Total elapsed time: 74.74621346220374. Arrivals time: 0.4001988470554352 Scheduler time: 74.15608989354223 Scheduler overhead time: 0.07390350289642811 Adapter cache time: 0.015797153115272522 Engine time: 0.07103760866448283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 71.69085111794993,
    "estimated_duration": 3600.0234527870793,
    "input_throughput": 6540.8437774954355,
    "output_throughput": 5692.2912499737,
    "total_throughput": 12233.135027469136,
    "itl": 91.80993449516859,
    "ttft": 1889913.7457535116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.304544061236109,
    "arrivals": 498436,
    "finished_requests": 95314,
    "scheduler_time": 246.4131215673421
}
#Debug simulation 
Total elapsed time: 71.69097911380231. Arrivals time: 0.39990313118323684 Scheduler time: 71.09511055937037 Scheduler overhead time: 0.07572015328332782 Adapter cache time: 0.015881944447755814 Engine time: 0.07297299336642027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 89.83837939985096,
    "estimated_duration": 3600.0946246402946,
    "input_throughput": 6547.779838524459,
    "output_throughput": 5709.892139863929,
    "total_throughput": 12257.671978388387,
    "itl": 95.03945550890944,
    "ttft": 1841063.9138110788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8367234747065475,
    "arrivals": 401058,
    "finished_requests": 95811,
    "scheduler_time": 241.8088976992041
}
#Debug simulation 
Total elapsed time: 89.83850819384679. Arrivals time: 0.4588917647488415 Scheduler time: 89.17597352946177 Scheduler overhead time: 0.07974510826170444 Adapter cache time: 0.01688953721895814 Engine time: 0.07576960930600762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 83.3924371022731,
    "estimated_duration": 3600.003135899949,
    "input_throughput": 6565.987613811049,
    "output_throughput": 5729.401675880438,
    "total_throughput": 12295.389289691488,
    "itl": 95.63086458801972,
    "ttft": 1842186.7842697361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3203192829061345,
    "arrivals": 401058,
    "finished_requests": 96091,
    "scheduler_time": 240.80193239893003
}
#Debug simulation 
Total elapsed time: 83.39256397727877. Arrivals time: 0.4497551401145756 Scheduler time: 82.73968196334317 Scheduler overhead time: 0.07870529452338815 Adapter cache time: 0.01711214752867818 Engine time: 0.0759085533209145 
