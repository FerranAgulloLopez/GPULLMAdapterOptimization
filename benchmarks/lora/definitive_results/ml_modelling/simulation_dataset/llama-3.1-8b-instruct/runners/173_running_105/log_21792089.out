INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.294451765017584,
    "estimated_duration": 3600.0330668223405,
    "input_throughput": 5123.82626981862,
    "output_throughput": 4465.155097641573,
    "total_throughput": 9588.981367460194,
    "itl": 98.23416555326521,
    "ttft": 1992010.0151146345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.247918838299844,
    "arrivals": 381208,
    "finished_requests": 74404,
    "scheduler_time": 170.2623157280251
}
#Debug simulation 
Total elapsed time: 8.294563847011887. Arrivals time: 0.2630327849765308 Scheduler time: 7.878840602817945 Scheduler overhead time: 0.05524094891734421 Adapter cache time: 0.016335973632521927 Engine time: 0.05573883675970137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.674325525993481,
    "estimated_duration": 3600.050952954437,
    "input_throughput": 5624.850665900085,
    "output_throughput": 4871.252720911683,
    "total_throughput": 10496.103386811768,
    "itl": 118.6996583855899,
    "ttft": 1912284.5922808363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7075277664186426,
    "arrivals": 377644,
    "finished_requests": 81666,
    "scheduler_time": 157.9884060559669
}
#Debug simulation 
Total elapsed time: 12.674439306021668. Arrivals time: 0.27580837946152315 Scheduler time: 12.267232969519682 Scheduler overhead time: 0.04949560627574101 Adapter cache time: 0.00910147262038663 Engine time: 0.05083199328510091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.17616499698488,
    "estimated_duration": 3600.0949737437277,
    "input_throughput": 5474.094473542869,
    "output_throughput": 4737.0553067009105,
    "total_throughput": 10211.149780243779,
    "itl": 110.93385036705311,
    "ttft": 1933619.2700545334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.83549103921745,
    "arrivals": 377644,
    "finished_requests": 79475,
    "scheduler_time": 162.11985751832864
}
#Debug simulation 
Total elapsed time: 12.176282397995237. Arrivals time: 0.29633042425848544 Scheduler time: 11.741796655813232 Scheduler overhead time: 0.052053348859772086 Adapter cache time: 0.009421192458830774 Engine time: 0.05340697057545185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.441564549983013,
    "estimated_duration": 3600.070274883575,
    "input_throughput": 5155.153256168086,
    "output_throughput": 4463.6078667991205,
    "total_throughput": 9618.761122967207,
    "itl": 98.26164662594417,
    "ttft": 1979188.437577558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.060500821461932,
    "arrivals": 377644,
    "finished_requests": 74782,
    "scheduler_time": 170.205664782593
}
#Debug simulation 
Total elapsed time: 8.44167466997169. Arrivals time: 0.26576051098527387 Scheduler time: 8.02133289235644 Scheduler overhead time: 0.05569061066489667 Adapter cache time: 0.017444591445382684 Engine time: 0.05608920432860032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 12.104589975031558,
    "estimated_duration": 3600.118302601135,
    "input_throughput": 5475.030080472275,
    "output_throughput": 4737.148217512196,
    "total_throughput": 10212.17829798447,
    "itl": 110.93184517302124,
    "ttft": 1933998.2477090887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8485232565365727,
    "arrivals": 377644,
    "finished_requests": 79484,
    "scheduler_time": 162.11883037128484
}
#Debug simulation 
Total elapsed time: 12.104716497007757. Arrivals time: 0.2819318872061558 Scheduler time: 11.685004820639733 Scheduler overhead time: 0.05184964748332277 Adapter cache time: 0.009551074530463666 Engine time: 0.05304140888620168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.44933236495126,
    "estimated_duration": 3600.022779022144,
    "input_throughput": 5158.0226403577935,
    "output_throughput": 4465.406745111353,
    "total_throughput": 9623.429385469148,
    "itl": 98.38861838583829,
    "ttft": 1978413.9469211472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.717126204911646,
    "arrivals": 377644,
    "finished_requests": 74809,
    "scheduler_time": 170.09690203736565
}
#Debug simulation 
Total elapsed time: 8.449434591981117. Arrivals time: 0.2556516417535022 Scheduler time: 8.038754892186262 Scheduler overhead time: 0.055458542075939476 Adapter cache time: 0.01820060214959085 Engine time: 0.05610847007483244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.090700261003803,
    "estimated_duration": 3600.072332238963,
    "input_throughput": 5475.095548355681,
    "output_throughput": 4737.163430656313,
    "total_throughput": 10212.258979011993,
    "itl": 110.92897317642291,
    "ttft": 1933951.1889248963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7916061966307452,
    "arrivals": 377644,
    "finished_requests": 79483,
    "scheduler_time": 162.11881601146726
}
#Debug simulation 
Total elapsed time: 12.090802367019933. Arrivals time: 0.283661637455225 Scheduler time: 11.670409571030177 Scheduler overhead time: 0.05190219107316807 Adapter cache time: 0.009453417093027383 Engine time: 0.05209080601343885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.183505780005362,
    "estimated_duration": 3600.051681736211,
    "input_throughput": 5163.435040197864,
    "output_throughput": 4468.52834963794,
    "total_throughput": 9631.963389835804,
    "itl": 98.47349976881954,
    "ttft": 1979319.3460697958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3794275438785855,
    "arrivals": 377644,
    "finished_requests": 74883,
    "scheduler_time": 170.03855816371893
}
#Debug simulation 
Total elapsed time: 8.183679263980594. Arrivals time: 0.2521158144227229 Scheduler time: 7.777906627277844 Scheduler overhead time: 0.05497889657272026 Adapter cache time: 0.01789221348008141 Engine time: 0.05545360705582425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.352096069022082,
    "estimated_duration": 3600.083121708665,
    "input_throughput": 5645.80075316517,
    "output_throughput": 4873.538584207121,
    "total_throughput": 10519.339337372292,
    "itl": 118.89647534469914,
    "ttft": 1914598.5112914154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.340792797310286,
    "arrivals": 376253,
    "finished_requests": 82008,
    "scheduler_time": 157.9156379747084
}
#Debug simulation 
Total elapsed time: 12.352222608984448. Arrivals time: 0.2910377379739657 Scheduler time: 11.927656586631201 Scheduler overhead time: 0.0493659385247156 Adapter cache time: 0.012131361523643136 Engine time: 0.04980055574560538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.726719388971105,
    "estimated_duration": 3600.071374664166,
    "input_throughput": 5489.639771890247,
    "output_throughput": 4741.610435874315,
    "total_throughput": 10231.250207764562,
    "itl": 110.96571819244645,
    "ttft": 1934007.5812621196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7113252493599465,
    "arrivals": 376253,
    "finished_requests": 79754,
    "scheduler_time": 162.18890070000026
}
#Debug simulation 
Total elapsed time: 9.726818105962593. Arrivals time: 0.27518833946669474 Scheduler time: 9.31339539878536 Scheduler overhead time: 0.0509753679507412 Adapter cache time: 0.012576076842378825 Engine time: 0.05157245590817183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.258683250984177,
    "estimated_duration": 3600.0335474558706,
    "input_throughput": 5189.433863249022,
    "output_throughput": 4473.27803691735,
    "total_throughput": 9662.711900166372,
    "itl": 98.55525408911004,
    "ttft": 1974348.205064203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.561656106691841,
    "arrivals": 376253,
    "finished_requests": 75308,
    "scheduler_time": 170.0292287526968
}
#Debug simulation 
Total elapsed time: 8.258779148978647. Arrivals time: 0.26093474647495896 Scheduler time: 7.844366313191131 Scheduler overhead time: 0.055282444693148136 Adapter cache time: 0.016542785975616425 Engine time: 0.05621516128303483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 9.87974895897787,
    "estimated_duration": 3600.0997314989854,
    "input_throughput": 5486.142183004567,
    "output_throughput": 4738.378176233812,
    "total_throughput": 10224.520359238379,
    "itl": 111.00461104469905,
    "ttft": 1934068.0716801435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8120323750190392,
    "arrivals": 376253,
    "finished_requests": 79708,
    "scheduler_time": 162.09594996798444
}
#Debug simulation 
Total elapsed time: 9.879846391966566. Arrivals time: 0.28996462863869965 Scheduler time: 9.45029496884672 Scheduler overhead time: 0.050740116159431636 Adapter cache time: 0.013274821103550494 Engine time: 0.05237184831639752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.081990153994411,
    "estimated_duration": 3600.1041425534095,
    "input_throughput": 5189.090998559315,
    "output_throughput": 4474.918047391179,
    "total_throughput": 9664.009045950495,
    "itl": 98.62130695708944,
    "ttft": 1973793.1033998518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.19362058596689,
    "arrivals": 376253,
    "finished_requests": 75282,
    "scheduler_time": 170.0043309258219
}
#Debug simulation 
Total elapsed time: 8.082085755013395. Arrivals time: 0.2643331909785047 Scheduler time: 7.664271971676499 Scheduler overhead time: 0.05507440282963216 Adapter cache time: 0.016159940336365253 Engine time: 0.05695652327267453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.577618454990443,
    "estimated_duration": 3600.010046226933,
    "input_throughput": 5486.998021214638,
    "output_throughput": 4739.403440799308,
    "total_throughput": 10226.401462013946,
    "itl": 110.98842543134586,
    "ttft": 1934094.8853475903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.432273878357363,
    "arrivals": 376253,
    "finished_requests": 79710,
    "scheduler_time": 162.13248409951512
}
#Debug simulation 
Total elapsed time: 9.577729123993777. Arrivals time: 0.28383344429312274 Scheduler time: 9.156438398989849 Scheduler overhead time: 0.05042981985025108 Adapter cache time: 0.012734377989545465 Engine time: 0.051253506273496896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.155204597045667,
    "estimated_duration": 3600.079686660572,
    "input_throughput": 5189.385132007891,
    "output_throughput": 4474.275405537348,
    "total_throughput": 9663.66053754524,
    "itl": 98.60365191330615,
    "ttft": 1973865.2615964788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.588146154098248,
    "arrivals": 376253,
    "finished_requests": 75317,
    "scheduler_time": 170.0101622853268
}
#Debug simulation 
Total elapsed time: 8.155329652014188. Arrivals time: 0.2734054073225707 Scheduler time: 7.728748240682762 Scheduler overhead time: 0.05499064613832161 Adapter cache time: 0.016969656862784177 Engine time: 0.05597411945927888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.41888768604258,
    "estimated_duration": 3600.08559435193,
    "input_throughput": 5609.162468714894,
    "output_throughput": 4868.686185544777,
    "total_throughput": 10477.848654259671,
    "itl": 118.43536871759225,
    "ttft": 1921663.2064850626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7868766748020417,
    "arrivals": 375490,
    "finished_requests": 81547,
    "scheduler_time": 158.08157077305472
}
#Debug simulation 
Total elapsed time: 10.419067039038055. Arrivals time: 0.2854968916508369 Scheduler time: 10.004117896896787 Scheduler overhead time: 0.048928999342024326 Adapter cache time: 0.00895369373029098 Engine time: 0.04940702865133062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.620251846965402,
    "estimated_duration": 3600.043712329634,
    "input_throughput": 5449.736605365857,
    "output_throughput": 4732.036986566501,
    "total_throughput": 10181.773591932359,
    "itl": 110.69026344699668,
    "ttft": 1946214.038531337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.664692397876646,
    "arrivals": 375490,
    "finished_requests": 79212,
    "scheduler_time": 162.2025929126502
}
#Debug simulation 
Total elapsed time: 10.620375743950717. Arrivals time: 0.2899572800961323 Scheduler time: 10.190829104278237 Scheduler overhead time: 0.051303869870025665 Adapter cache time: 0.012359362270217389 Engine time: 0.052525993960443884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.9272352759726346,
    "estimated_duration": 3600.100992090523,
    "input_throughput": 5135.706203970597,
    "output_throughput": 4468.470477729171,
    "total_throughput": 9604.176681699768,
    "itl": 98.32408567972058,
    "ttft": 1986942.1834260903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3083481779182655,
    "arrivals": 375490,
    "finished_requests": 74698,
    "scheduler_time": 170.1394427722245
}
#Debug simulation 
Total elapsed time: 7.927342302980833. Arrivals time: 0.24670465115923434 Scheduler time: 7.5273819147842005 Scheduler overhead time: 0.05551232764264569 Adapter cache time: 0.0160930113052018 Engine time: 0.05633057374507189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 9.912576953007374,
    "estimated_duration": 3600.0675283749197,
    "input_throughput": 5450.885530710621,
    "output_throughput": 4732.804833716879,
    "total_throughput": 10183.6903644275,
    "itl": 110.6556220516125,
    "ttft": 1945631.9643545165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5422361437370964,
    "arrivals": 375490,
    "finished_requests": 79221,
    "scheduler_time": 162.24694389481806
}
#Debug simulation 
Total elapsed time: 9.912674978026189. Arrivals time: 0.3082558675087057 Scheduler time: 9.465253380127251 Scheduler overhead time: 0.05108647735323757 Adapter cache time: 0.012776374525856227 Engine time: 0.05199322721455246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.681035696004983,
    "estimated_duration": 3600.060249312941,
    "input_throughput": 5137.794569835316,
    "output_throughput": 4469.576308638408,
    "total_throughput": 9607.370878473723,
    "itl": 98.32170706085859,
    "ttft": 1987019.7732474965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.119796601757441,
    "arrivals": 375490,
    "finished_requests": 74715,
    "scheduler_time": 170.14127514334072
}
#Debug simulation 
Total elapsed time: 7.681150853983127. Arrivals time: 0.26538242830429226 Scheduler time: 7.263809757947456 Scheduler overhead time: 0.054863977478817105 Adapter cache time: 0.016073486942332238 Engine time: 0.05558902624761686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.808028288010973,
    "estimated_duration": 3600.1196028056384,
    "input_throughput": 5452.573293593371,
    "output_throughput": 4734.484372884931,
    "total_throughput": 10187.057666478302,
    "itl": 110.74809265019253,
    "ttft": 1946081.0145235457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2662919339025303,
    "arrivals": 375490,
    "finished_requests": 79251,
    "scheduler_time": 162.19693754963782
}
#Debug simulation 
Total elapsed time: 9.80812080897158. Arrivals time: 0.301037585362792 Scheduler time: 9.368394569901284 Scheduler overhead time: 0.050805539707653224 Adapter cache time: 0.012533327681012452 Engine time: 0.052169884264003485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.025735003000591,
    "estimated_duration": 3600.0706136191247,
    "input_throughput": 5140.135565673588,
    "output_throughput": 4469.424832704765,
    "total_throughput": 9609.560398378353,
    "itl": 98.31740998891345,
    "ttft": 1987098.3481981712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.744365290477903,
    "arrivals": 375490,
    "finished_requests": 74728,
    "scheduler_time": 170.15798489392202
}
#Debug simulation 
Total elapsed time: 8.025829986028839. Arrivals time: 0.25778577890014276 Scheduler time: 7.616611201898195 Scheduler overhead time: 0.05494394473498687 Adapter cache time: 0.015278682054486126 Engine time: 0.05580841074697673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.495441105973441,
    "estimated_duration": 3600.033557712965,
    "input_throughput": 5606.810235630962,
    "output_throughput": 4866.459359098242,
    "total_throughput": 10473.269594729205,
    "itl": 118.39959308922984,
    "ttft": 1918008.0123113382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7273649935144924,
    "arrivals": 373265,
    "finished_requests": 81423,
    "scheduler_time": 158.02587800750837
}
#Debug simulation 
Total elapsed time: 9.495543306984473. Arrivals time: 0.2742012407979928 Scheduler time: 9.093040279403795 Scheduler overhead time: 0.04854787542717531 Adapter cache time: 0.0088499472476542 Engine time: 0.04895769682480022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.946415423008148,
    "estimated_duration": 3600.1174205964885,
    "input_throughput": 5439.818959225839,
    "output_throughput": 4727.712185893085,
    "total_throughput": 10167.531145118923,
    "itl": 110.66737048949834,
    "ttft": 1941489.577367311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0402483208850066,
    "arrivals": 373265,
    "finished_requests": 79007,
    "scheduler_time": 162.12707413554827
}
#Debug simulation 
Total elapsed time: 8.946576564980205. Arrivals time: 0.3012208915897645 Scheduler time: 8.505734985112213 Scheduler overhead time: 0.051031585899181664 Adapter cache time: 0.013126433070283383 Engine time: 0.05234362272312865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.2269971880014054,
    "estimated_duration": 3600.0025564354696,
    "input_throughput": 5131.570522630861,
    "output_throughput": 4467.546549723761,
    "total_throughput": 9599.117072354622,
    "itl": 98.3713895635189,
    "ttft": 1981790.5048669002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.473755216780153,
    "arrivals": 373265,
    "finished_requests": 74568,
    "scheduler_time": 170.0357554800635
}
#Debug simulation 
Total elapsed time: 7.227097854018211. Arrivals time: 0.249194020871073 Scheduler time: 6.825254459341522 Scheduler overhead time: 0.05500584340188652 Adapter cache time: 0.016300310206133872 Engine time: 0.05579819076228887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.993160140002146,
    "estimated_duration": 3600.0342839136742,
    "input_throughput": 5445.8239710669695,
    "output_throughput": 4731.992713547306,
    "total_throughput": 10177.816684614276,
    "itl": 110.71769454904705,
    "ttft": 1941403.2369537347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.922504435908045,
    "arrivals": 373265,
    "finished_requests": 79081,
    "scheduler_time": 162.13428656869357
}
#Debug simulation 
Total elapsed time: 8.993259185052011. Arrivals time: 0.28460902970982715 Scheduler time: 8.569186403648928 Scheduler overhead time: 0.050999243336264044 Adapter cache time: 0.013466553704347461 Engine time: 0.05173721245955676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.526217415987048,
    "estimated_duration": 3600.0400345352055,
    "input_throughput": 5128.931573780095,
    "output_throughput": 4467.5119847872675,
    "total_throughput": 9596.443558567364,
    "itl": 98.36955518931686,
    "ttft": 1981083.2873569562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.045100059667637,
    "arrivals": 373265,
    "finished_requests": 74545,
    "scheduler_time": 170.05692368467794
}
#Debug simulation 
Total elapsed time: 7.526313619979192. Arrivals time: 0.2806565252249129 Scheduler time: 7.093517798290122 Scheduler overhead time: 0.05507073918124661 Adapter cache time: 0.01607968664029613 Engine time: 0.05566210101824254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.658896512992214,
    "estimated_duration": 3600.0720936213884,
    "input_throughput": 5433.021753829635,
    "output_throughput": 4723.35346565099,
    "total_throughput": 10156.375219480624,
    "itl": 110.38240303241449,
    "ttft": 1940403.979220397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.547184455287632,
    "arrivals": 373265,
    "finished_requests": 78945,
    "scheduler_time": 162.30875540302077
}
#Debug simulation 
Total elapsed time: 8.658997214981355. Arrivals time: 0.3007576691452414 Scheduler time: 8.220028230745811 Scheduler overhead time: 0.05079285998363048 Adapter cache time: 0.013060076569672674 Engine time: 0.05115417292108759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.211005310993642,
    "estimated_duration": 3600.074323344051,
    "input_throughput": 5127.635249167002,
    "output_throughput": 4466.763893102882,
    "total_throughput": 9594.399142269884,
    "itl": 98.37432131529744,
    "ttft": 1981054.3716831454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.338621914014257,
    "arrivals": 373265,
    "finished_requests": 74535,
    "scheduler_time": 170.04601662909562
}
#Debug simulation 
Total elapsed time: 7.211103348992765. Arrivals time: 0.28288927348330617 Scheduler time: 6.776182338187937 Scheduler overhead time: 0.05481437628623098 Adapter cache time: 0.016402077744714916 Engine time: 0.05549921025522053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.611579912016168,
    "estimated_duration": 3600.0687847254876,
    "input_throughput": 5579.218954154389,
    "output_throughput": 4872.545512026259,
    "total_throughput": 10451.764466180648,
    "itl": 118.38217347436593,
    "ttft": 1922203.9171409633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0498467999044796,
    "arrivals": 372565,
    "finished_requests": 81299,
    "scheduler_time": 158.19280737013713
}
#Debug simulation 
Total elapsed time: 8.611679819994606. Arrivals time: 0.3071858364273794 Scheduler time: 8.175193879811559 Scheduler overhead time: 0.047725451353471726 Adapter cache time: 0.011007049528416246 Engine time: 0.04859050450613722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.312359675997868,
    "estimated_duration": 3600.0022214768237,
    "input_throughput": 5412.071660335621,
    "output_throughput": 4730.204303322435,
    "total_throughput": 10142.275963658058,
    "itl": 110.7606887360847,
    "ttft": 1942317.521995092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9821416081115628,
    "arrivals": 372565,
    "finished_requests": 78927,
    "scheduler_time": 162.13181384568952
}
#Debug simulation 
Total elapsed time: 8.312460429035127. Arrivals time: 0.26343208097387105 Scheduler time: 7.912445172725711 Scheduler overhead time: 0.05051410401938483 Adapter cache time: 0.011542493244633079 Engine time: 0.05138212913880125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.607686898962129,
    "estimated_duration": 3600.0792950099994,
    "input_throughput": 5116.480357955237,
    "output_throughput": 4469.867933827081,
    "total_throughput": 9586.348291782318,
    "itl": 98.3587173757575,
    "ttft": 1982942.9107638407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.715235306257413,
    "arrivals": 372565,
    "finished_requests": 74497,
    "scheduler_time": 170.09625818649923
}
#Debug simulation 
Total elapsed time: 6.607831342960708. Arrivals time: 0.28894633799791336 Scheduler time: 6.169086740643252 Scheduler overhead time: 0.054311803192831576 Adapter cache time: 0.014931125333532691 Engine time: 0.05526296212337911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.300179223995656,
    "estimated_duration": 3600.038395774719,
    "input_throughput": 5413.338375188686,
    "output_throughput": 4730.7145445972465,
    "total_throughput": 10144.052919785932,
    "itl": 110.74386191856865,
    "ttft": 1942539.1407475935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.823893894837236,
    "arrivals": 372565,
    "finished_requests": 78923,
    "scheduler_time": 162.14423628113107
}
#Debug simulation 
Total elapsed time: 8.300293058971874. Arrivals time: 0.2651886601233855 Scheduler time: 7.8993783938349225 Scheduler overhead time: 0.050308274279814214 Adapter cache time: 0.011352781555615366 Engine time: 0.05106111097848043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.6656686079804786,
    "estimated_duration": 3600.06613163814,
    "input_throughput": 5118.405142078692,
    "output_throughput": 4470.2628817201985,
    "total_throughput": 9588.66802379889,
    "itl": 98.35454112099536,
    "ttft": 1983192.3160071252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.419527287567061,
    "arrivals": 372565,
    "finished_requests": 74509,
    "scheduler_time": 170.10778649574524
}
#Debug simulation 
Total elapsed time: 6.665764848003164. Arrivals time: 0.2787760218488984 Scheduler time: 6.2371307101566344 Scheduler overhead time: 0.054559291631449014 Adapter cache time: 0.014632989768870175 Engine time: 0.055389451037626714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.88033939700108,
    "estimated_duration": 3600.1221203333075,
    "input_throughput": 5412.8944376464215,
    "output_throughput": 4730.280926810161,
    "total_throughput": 10143.175364456582,
    "itl": 110.76571298187062,
    "ttft": 1941996.734451365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1896848826156843,
    "arrivals": 372565,
    "finished_requests": 78910,
    "scheduler_time": 162.13064452169954
}
#Debug simulation 
Total elapsed time: 7.880450654018205. Arrivals time: 0.2631495540845208 Scheduler time: 7.48069944785675 Scheduler overhead time: 0.050161878229118884 Adapter cache time: 0.012302235991228372 Engine time: 0.05110803205752745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.639185995969456,
    "estimated_duration": 3600.0471237603974,
    "input_throughput": 5117.686065385574,
    "output_throughput": 4470.083986898124,
    "total_throughput": 9587.770052283697,
    "itl": 98.35173442391516,
    "ttft": 1982795.9651151241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4184338466450837,
    "arrivals": 372565,
    "finished_requests": 74499,
    "scheduler_time": 170.11118912529525
}
#Debug simulation 
Total elapsed time: 6.639298530993983. Arrivals time: 0.2796080054831691 Scheduler time: 6.210177796019707 Scheduler overhead time: 0.05453727050917223 Adapter cache time: 0.01451081020059064 Engine time: 0.05519159330287948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.410700427019037,
    "estimated_duration": 3600.0798827013514,
    "input_throughput": 5605.65366812282,
    "output_throughput": 4875.189599079229,
    "total_throughput": 10480.843267202048,
    "itl": 118.86175429236413,
    "ttft": 1913692.4312633623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 65,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42980658707674557,
    "arrivals": 371093,
    "finished_requests": 81714,
    "scheduler_time": 157.81349450143895
}
#Debug simulation 
Total elapsed time: 7.410800003039185. Arrivals time: 0.2651553124305792 Scheduler time: 7.019973462272901 Scheduler overhead time: 0.04763979103881866 Adapter cache time: 0.007970947306603193 Engine time: 0.04840808844892308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.028389510989655,
    "estimated_duration": 3600.075406859069,
    "input_throughput": 5453.243274459148,
    "output_throughput": 4741.734011314352,
    "total_throughput": 10194.9772857735,
    "itl": 111.11521432960821,
    "ttft": 1936115.7094337412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.786733170095833,
    "arrivals": 371093,
    "finished_requests": 79477,
    "scheduler_time": 161.88509867874333
}
#Debug simulation 
Total elapsed time: 7.028485569986515. Arrivals time: 0.2628395142965019 Scheduler time: 6.631502417090815 Scheduler overhead time: 0.0499320047092624 Adapter cache time: 0.01092831400455907 Engine time: 0.0503624239936471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.377118991978932,
    "estimated_duration": 3600.0144546388506,
    "input_throughput": 5148.639882852756,
    "output_throughput": 4479.598124729698,
    "total_throughput": 9628.238007582453,
    "itl": 98.715581771609,
    "ttft": 1975703.7606615701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9267508952366383,
    "arrivals": 371093,
    "finished_requests": 75037,
    "scheduler_time": 169.80434373739968
}
#Debug simulation 
Total elapsed time: 6.377216166001745. Arrivals time: 0.24237584881484509 Scheduler time: 5.985107036191039 Scheduler overhead time: 0.055819922243244946 Adapter cache time: 0.013576990109868348 Engine time: 0.05526427843142301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.464658130018506,
    "estimated_duration": 3600.0595401190276,
    "input_throughput": 5452.752595128183,
    "output_throughput": 4740.990200244213,
    "total_throughput": 10193.742795372396,
    "itl": 111.05484659087648,
    "ttft": 1935568.7972472587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.221094691809264,
    "arrivals": 371093,
    "finished_requests": 79444,
    "scheduler_time": 161.96379833991875
}
#Debug simulation 
Total elapsed time: 8.46481852803845. Arrivals time: 0.2821476408280432 Scheduler time: 8.046312394435517 Scheduler overhead time: 0.05043211724841967 Adapter cache time: 0.011810754367616028 Engine time: 0.05109369457932189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.349833564949222,
    "estimated_duration": 3600.106197972712,
    "input_throughput": 5150.8988847168885,
    "output_throughput": 4480.693933163321,
    "total_throughput": 9631.59281788021,
    "itl": 98.72223073611593,
    "ttft": 1975855.3647032573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.979548954865915,
    "arrivals": 371093,
    "finished_requests": 75071,
    "scheduler_time": 169.80441426053255
}
#Debug simulation 
Total elapsed time: 6.34992859698832. Arrivals time: 0.2580495757283643 Scheduler time: 5.9439101936877705 Scheduler overhead time: 0.05425348650896922 Adapter cache time: 0.013829961826559156 Engine time: 0.054764592729043216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.524555492971558,
    "estimated_duration": 3600.1118084777604,
    "input_throughput": 5450.131563635076,
    "output_throughput": 4739.302251619333,
    "total_throughput": 10189.43381525441,
    "itl": 111.07344603488919,
    "ttft": 1935043.2295470983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8194174680625954,
    "arrivals": 371093,
    "finished_requests": 79416,
    "scheduler_time": 161.92214398499667
}
#Debug simulation 
Total elapsed time: 7.524621728982311. Arrivals time: 0.5243242655415088 Scheduler time: 6.865875612245873 Scheduler overhead time: 0.04987422627164051 Adapter cache time: 0.011349845910444856 Engine time: 0.05032412911532447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.427805147948675,
    "estimated_duration": 3600.0432993201375,
    "input_throughput": 5148.995014449023,
    "output_throughput": 4480.1461146442,
    "total_throughput": 9629.141129093223,
    "itl": 98.71511336371525,
    "ttft": 1975262.3570974164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7811676922626973,
    "arrivals": 371093,
    "finished_requests": 75052,
    "scheduler_time": 169.81501875692203
}
#Debug simulation 
Total elapsed time: 6.427904829964973. Arrivals time: 0.2432508923811838 Scheduler time: 6.03611778432969 Scheduler overhead time: 0.05422167421784252 Adapter cache time: 0.013514924969058484 Engine time: 0.05566770368022844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 36.52522910601692,
    "estimated_duration": 3600.094282589295,
    "input_throughput": 5636.90820491634,
    "output_throughput": 4865.318134780142,
    "total_throughput": 10502.22633969648,
    "itl": 118.18164668597345,
    "ttft": 1831763.6169705077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.874871692722721,
    "arrivals": 299534,
    "finished_requests": 81686,
    "scheduler_time": 156.57410259337274
}
#Debug simulation 
Total elapsed time: 36.52537912002299. Arrivals time: 0.3763756899861619 Scheduler time: 35.99098437244538 Scheduler overhead time: 0.05780917825177312 Adapter cache time: 0.017217124870512635 Engine time: 0.05883419583551586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 31.78720839897869,
    "estimated_duration": 3600.0717725320633,
    "input_throughput": 5474.4233574372365,
    "output_throughput": 4726.470213684734,
    "total_throughput": 10200.893571121971,
    "itl": 110.58306061004896,
    "ttft": 1859391.689952227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.552463412852965,
    "arrivals": 299534,
    "finished_requests": 79348,
    "scheduler_time": 160.5050528969729
}
#Debug simulation 
Total elapsed time: 31.787357927008998. Arrivals time: 0.34670490986900404 Scheduler time: 31.278426191827748 Scheduler overhead time: 0.05922030290821567 Adapter cache time: 0.01783302938565612 Engine time: 0.06025388109264895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 20.554523483966477,
    "estimated_duration": 3600.106270203581,
    "input_throughput": 5167.266631534197,
    "output_throughput": 4466.917305496823,
    "total_throughput": 9634.18393703102,
    "itl": 98.23654091759205,
    "ttft": 1909396.7079353214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.185230659986873,
    "arrivals": 299534,
    "finished_requests": 74964,
    "scheduler_time": 168.31755071436436
}
#Debug simulation 
Total elapsed time: 20.55462097900454. Arrivals time: 0.3057467277976684 Scheduler time: 20.081371754058637 Scheduler overhead time: 0.05990482511697337 Adapter cache time: 0.02059743134304881 Engine time: 0.060534763033501804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 31.657644774008077,
    "estimated_duration": 3600.074784975898,
    "input_throughput": 5477.267050754339,
    "output_throughput": 4728.695379063902,
    "total_throughput": 10205.96242981824,
    "itl": 110.69933400573154,
    "ttft": 1860156.0281415256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3217259227950064,
    "arrivals": 299534,
    "finished_requests": 79364,
    "scheduler_time": 160.43996712497923
}
#Debug simulation 
Total elapsed time: 31.657762977993116. Arrivals time: 0.35355690855067223 Scheduler time: 31.14293869532412 Scheduler overhead time: 0.058844462502747774 Adapter cache time: 0.017759547161404043 Engine time: 0.05973617365816608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 16.789845563995186,
    "estimated_duration": 3600.0225301808186,
    "input_throughput": 5166.1479460424,
    "output_throughput": 4465.032056116782,
    "total_throughput": 9631.180002159183,
    "itl": 98.29151041492996,
    "ttft": 1907368.7226025236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.519349530506898,
    "arrivals": 299534,
    "finished_requests": 74933,
    "scheduler_time": 168.24932285114252
}
#Debug simulation 
Total elapsed time: 16.79001098702429. Arrivals time: 0.3076042215107009 Scheduler time: 16.31450226670131 Scheduler overhead time: 0.05902937089558691 Adapter cache time: 0.022711687139235437 Engine time: 0.059994144074153155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.162215786986053,
    "estimated_duration": 3600.0926155677503,
    "input_throughput": 5465.482725337323,
    "output_throughput": 4726.641455393905,
    "total_throughput": 10192.124180731227,
    "itl": 110.43000352236957,
    "ttft": 1859536.5308576345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4240572118153585,
    "arrivals": 299534,
    "finished_requests": 79279,
    "scheduler_time": 160.65561910387424
}
#Debug simulation 
Total elapsed time: 27.162342816009186. Arrivals time: 0.3507116858381778 Scheduler time: 26.650946567417122 Scheduler overhead time: 0.058163333393167704 Adapter cache time: 0.01822184369666502 Engine time: 0.059702864615246654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 19.79527602903545,
    "estimated_duration": 3600.072172912588,
    "input_throughput": 5162.358727093011,
    "output_throughput": 4465.956021929557,
    "total_throughput": 9628.31474902257,
    "itl": 98.19829381654841,
    "ttft": 1905936.0529573206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.090937841367003,
    "arrivals": 299534,
    "finished_requests": 74891,
    "scheduler_time": 168.35488138749872
}
#Debug simulation 
Total elapsed time: 19.795403495023493. Arrivals time: 0.31332940061111003 Scheduler time: 19.313452485541347 Scheduler overhead time: 0.06051092263078317 Adapter cache time: 0.020735304744448513 Engine time: 0.061020338791422546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 59.79448630101979,
    "estimated_duration": 3600.028034347985,
    "input_throughput": 5607.979106656176,
    "output_throughput": 4849.9925093395195,
    "total_throughput": 10457.971615995695,
    "itl": 117.92142117522448,
    "ttft": 1804131.933004468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.074770199856753,
    "arrivals": 287913,
    "finished_requests": 81247,
    "scheduler_time": 156.53170221941923
}
#Debug simulation 
Total elapsed time: 59.79465026198886. Arrivals time: 0.3776468979776837 Scheduler time: 59.251777336758096 Scheduler overhead time: 0.061021030822303146 Adapter cache time: 0.016735943558160216 Engine time: 0.06244633410824463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 30.63963688595686,
    "estimated_duration": 3600.0014252445817,
    "input_throughput": 5443.03395620704,
    "output_throughput": 4733.127570593216,
    "total_throughput": 10176.161526800255,
    "itl": 111.0006893150881,
    "ttft": 1850887.1924297952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0764268288901135,
    "arrivals": 287913,
    "finished_requests": 79055,
    "scheduler_time": 160.033972257767
}
#Debug simulation 
Total elapsed time: 30.639764794963412. Arrivals time: 0.34308341704308987 Scheduler time: 30.1355696687242 Scheduler overhead time: 0.05952658277237788 Adapter cache time: 0.016840412514284253 Engine time: 0.05995714757591486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.90308364701923,
    "estimated_duration": 3600.079921771778,
    "input_throughput": 5140.96114591016,
    "output_throughput": 4465.391977211527,
    "total_throughput": 9606.353123121688,
    "itl": 98.36557838546453,
    "ttft": 1900718.9218891803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.651169317197076,
    "arrivals": 287913,
    "finished_requests": 74577,
    "scheduler_time": 167.91199579391403
}
#Debug simulation 
Total elapsed time: 16.90325493196724. Arrivals time: 0.3065852326108143 Scheduler time: 16.428039747290313 Scheduler overhead time: 0.05925801151897758 Adapter cache time: 0.023346374684479088 Engine time: 0.05977096583228558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 37.09911781799747,
    "estimated_duration": 3600.0557238281226,
    "input_throughput": 5432.475356021384,
    "output_throughput": 4719.721944173777,
    "total_throughput": 10152.197300195161,
    "itl": 110.44201520104784,
    "ttft": 1856699.686445036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5012314611626736,
    "arrivals": 287913,
    "finished_requests": 78909,
    "scheduler_time": 160.54427524472268
}
#Debug simulation 
Total elapsed time: 37.09929013898363. Arrivals time: 0.3577982861897908 Scheduler time: 36.58237862668466 Scheduler overhead time: 0.05863829632289708 Adapter cache time: 0.01630332798231393 Engine time: 0.05916881520533934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 20.291297460964415,
    "estimated_duration": 3600.0026014207688,
    "input_throughput": 5138.409342454227,
    "output_throughput": 4471.881212987593,
    "total_throughput": 9610.290555441821,
    "itl": 98.58416133229859,
    "ttft": 1899077.639746294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.73286782783459,
    "arrivals": 287913,
    "finished_requests": 74686,
    "scheduler_time": 167.78735097957878
}
#Debug simulation 
Total elapsed time: 20.291399882989936. Arrivals time: 0.30107211583526805 Scheduler time: 19.821387214469723 Scheduler overhead time: 0.06086737982695922 Adapter cache time: 0.020460977277252823 Engine time: 0.06116908189142123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 29.48272264696425,
    "estimated_duration": 3600.083526586956,
    "input_throughput": 5440.727098509695,
    "output_throughput": 4726.328118317623,
    "total_throughput": 10167.055216827319,
    "itl": 110.65507838333495,
    "ttft": 1852913.6954543428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5494600429572003,
    "arrivals": 287913,
    "finished_requests": 79056,
    "scheduler_time": 160.23502550021183
}
#Debug simulation 
Total elapsed time: 29.482842152996454. Arrivals time: 0.3517788898316212 Scheduler time: 28.9712279465748 Scheduler overhead time: 0.058944130898453295 Adapter cache time: 0.016637122549582273 Engine time: 0.05944215157069266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 20.70221577398479,
    "estimated_duration": 3600.0992596853994,
    "input_throughput": 5129.554400567767,
    "output_throughput": 4464.412739943316,
    "total_throughput": 9593.967140511084,
    "itl": 98.25179015758668,
    "ttft": 1900761.6023313878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.620361807551264,
    "arrivals": 287913,
    "finished_requests": 74567,
    "scheduler_time": 168.05573079423084
}
#Debug simulation 
Total elapsed time: 20.702312660985626. Arrivals time: 0.3096348283579573 Scheduler time: 20.224446158856153 Scheduler overhead time: 0.06010736629832536 Adapter cache time: 0.01963748410344124 Engine time: 0.06200322572840378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 57.174286674999166,
    "estimated_duration": 3600.077339522841,
    "input_throughput": 5605.399022531739,
    "output_throughput": 4865.054927492587,
    "total_throughput": 10470.453950024326,
    "itl": 118.22999048602945,
    "ttft": 1808265.5651578547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.684638066971694,
    "arrivals": 282093,
    "finished_requests": 81423,
    "scheduler_time": 156.04652400913432
}
#Debug simulation 
Total elapsed time: 57.17445430299267. Arrivals time: 0.3683556935284287 Scheduler time: 56.6462085909443 Scheduler overhead time: 0.059689333429560065 Adapter cache time: 0.015017337864264846 Engine time: 0.06045361841097474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 30.659018923994154,
    "estimated_duration": 3600.012811351859,
    "input_throughput": 5444.008959690471,
    "output_throughput": 4726.273458346595,
    "total_throughput": 10170.282418037066,
    "itl": 110.39085704001216,
    "ttft": 1840386.2656126926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.17885289474391,
    "arrivals": 282093,
    "finished_requests": 79074,
    "scheduler_time": 160.15933376265565
}
#Debug simulation 
Total elapsed time: 30.659157140995376. Arrivals time: 0.34371017705416307 Scheduler time: 30.15354969672626 Scheduler overhead time: 0.059501386946067214 Adapter cache time: 0.01731280330568552 Engine time: 0.06019590672804043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.191802390036173,
    "estimated_duration": 3600.0861133172634,
    "input_throughput": 5123.195229073288,
    "output_throughput": 4468.455335135569,
    "total_throughput": 9591.650564208856,
    "itl": 98.41388007392128,
    "ttft": 1889763.554688215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.104031190187697,
    "arrivals": 282093,
    "finished_requests": 74567,
    "scheduler_time": 167.66586831252152
}
#Debug simulation 
Total elapsed time: 18.19187460799003. Arrivals time: 0.3074084197287448 Scheduler time: 17.713429056107998 Scheduler overhead time: 0.06118681776570156 Adapter cache time: 0.022321039403323084 Engine time: 0.06108650710666552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 37.69809618301224,
    "estimated_duration": 3600.0976410940275,
    "input_throughput": 5439.83551347476,
    "output_throughput": 4730.40364394806,
    "total_throughput": 10170.239157422819,
    "itl": 110.68932113263703,
    "ttft": 1843975.2535890935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1268746687052715,
    "arrivals": 282093,
    "finished_requests": 79144,
    "scheduler_time": 159.9925211684689
}
#Debug simulation 
Total elapsed time: 37.69833840196952. Arrivals time: 0.34871109772939235 Scheduler time: 37.18627841462148 Scheduler overhead time: 0.059830132813658565 Adapter cache time: 0.017621666193008423 Engine time: 0.060714595136232674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 18.90646220202325,
    "estimated_duration": 3600.0875511057147,
    "input_throughput": 5115.745308567133,
    "output_throughput": 4461.235948294409,
    "total_throughput": 9576.981256861542,
    "itl": 98.0294747589478,
    "ttft": 1889226.895222404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.036138990167549,
    "arrivals": 282093,
    "finished_requests": 74424,
    "scheduler_time": 167.96089558989053
}
#Debug simulation 
Total elapsed time: 18.906527173006907. Arrivals time: 0.30387739290017635 Scheduler time: 18.433662672061473 Scheduler overhead time: 0.059827491524629295 Adapter cache time: 0.022226356901228428 Engine time: 0.06053345266263932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 33.5706038850476,
    "estimated_duration": 3600.029663990652,
    "input_throughput": 5444.425971277467,
    "output_throughput": 4730.818518067696,
    "total_throughput": 10175.244489345163,
    "itl": 110.60453387570294,
    "ttft": 1834096.6319882928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4217816241457903,
    "arrivals": 282093,
    "finished_requests": 79076,
    "scheduler_time": 160.04459726339826
}
#Debug simulation 
Total elapsed time: 33.570717438007705. Arrivals time: 0.3469241171842441 Scheduler time: 33.06158968160162 Scheduler overhead time: 0.05990044178906828 Adapter cache time: 0.016745316912420094 Engine time: 0.060383123403880745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 19.696674350998364,
    "estimated_duration": 3600.0096774114645,
    "input_throughput": 5130.4375974012155,
    "output_throughput": 4469.860206478776,
    "total_throughput": 9600.297803879992,
    "itl": 98.36419643983642,
    "ttft": 1889330.2294137436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 881,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.5120774285681815,
    "arrivals": 282093,
    "finished_requests": 74630,
    "scheduler_time": 167.7149409186395
}
#Debug simulation 
Total elapsed time: 19.696811455010902. Arrivals time: 0.32185286679305136 Scheduler time: 19.20582527091028 Scheduler overhead time: 0.0602608218905516 Adapter cache time: 0.02149346988881007 Engine time: 0.061184388934634626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 38.14621476200409,
    "estimated_duration": 3600.0738363031087,
    "input_throughput": 5629.244821492524,
    "output_throughput": 4871.229535116537,
    "total_throughput": 10500.474356609062,
    "itl": 118.45440573413384,
    "ttft": 1817766.921232412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.035095745665052,
    "arrivals": 279137,
    "finished_requests": 81691,
    "scheduler_time": 155.88835621583996
}
#Debug simulation 
Total elapsed time: 38.146366751985624. Arrivals time: 0.3430501132970676 Scheduler time: 37.648628081486095 Scheduler overhead time: 0.05669545166892931 Adapter cache time: 0.01580805703997612 Engine time: 0.057438988937065005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 33.209180897974875,
    "estimated_duration": 3600.0160756160626,
    "input_throughput": 5470.213350819553,
    "output_throughput": 4735.38024329036,
    "total_throughput": 10205.593594109914,
    "itl": 110.727127070697,
    "ttft": 1839674.5211465105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7619431510241763,
    "arrivals": 279137,
    "finished_requests": 79364,
    "scheduler_time": 159.88923538807452
}
#Debug simulation 
Total elapsed time: 33.20935734396335. Arrivals time: 0.3409405066049658 Scheduler time: 32.70907370513305 Scheduler overhead time: 0.05858333793003112 Adapter cache time: 0.016482091799844056 Engine time: 0.059534470608923584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.47248309996212,
    "estimated_duration": 3600.019483087013,
    "input_throughput": 5158.628748329786,
    "output_throughput": 4465.1927789612655,
    "total_throughput": 9623.821527291051,
    "itl": 98.12777233651157,
    "ttft": 1888288.155481066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.758468841514573,
    "arrivals": 279137,
    "finished_requests": 74780,
    "scheduler_time": 167.77922265315814
}
#Debug simulation 
Total elapsed time: 17.47259334794944. Arrivals time: 0.3023003335110843 Scheduler time: 17.00298160762759 Scheduler overhead time: 0.0594391874037683 Adapter cache time: 0.021348434733226895 Engine time: 0.06028061138931662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 29.780115956964437,
    "estimated_duration": 3600.1133233351484,
    "input_throughput": 5473.208266051481,
    "output_throughput": 4734.149030678543,
    "total_throughput": 10207.357296730022,
    "itl": 110.80223295637242,
    "ttft": 1840163.1800808397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.992812328953291,
    "arrivals": 279137,
    "finished_requests": 79408,
    "scheduler_time": 159.83538371763171
}
#Debug simulation 
Total elapsed time: 29.780266120971646. Arrivals time: 0.3366715963347815 Scheduler time: 29.28472916194005 Scheduler overhead time: 0.05806040158495307 Adapter cache time: 0.016870698251295835 Engine time: 0.05909146019257605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 18.720792150008492,
    "estimated_duration": 3600.016053231112,
    "input_throughput": 5159.188382876817,
    "output_throughput": 4470.560898070195,
    "total_throughput": 9629.749280947011,
    "itl": 98.38896893120345,
    "ttft": 1889108.0401701115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 930,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9330196566926565,
    "arrivals": 279137,
    "finished_requests": 74854,
    "scheduler_time": 167.59090869961443
}
#Debug simulation 
Total elapsed time: 18.720981160993688. Arrivals time: 0.30021721875527874 Scheduler time: 18.25509776256513 Scheduler overhead time: 0.058656510431319475 Adapter cache time: 0.02142552036093548 Engine time: 0.059558413398917764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 33.29065171099501,
    "estimated_duration": 3600.0009264552564,
    "input_throughput": 5473.005535973682,
    "output_throughput": 4733.21378191367,
    "total_throughput": 10206.219317887351,
    "itl": 110.62170696990229,
    "ttft": 1840311.5409497118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.045130288652131,
    "arrivals": 279137,
    "finished_requests": 79370,
    "scheduler_time": 160.0749944833137
}
#Debug simulation 
Total elapsed time: 33.29082058701897. Arrivals time: 0.34761728189187124 Scheduler time: 32.78692496102303 Scheduler overhead time: 0.05791644146665931 Adapter cache time: 0.015532183460891247 Engine time: 0.05824019864667207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.35435957001755,
    "estimated_duration": 3600.0103826211257,
    "input_throughput": 5156.308739999985,
    "output_throughput": 4462.456018891629,
    "total_throughput": 9618.764758891613,
    "itl": 98.14089970515873,
    "ttft": 1888609.811338268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 975,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.21271539142358,
    "arrivals": 279137,
    "finished_requests": 74795,
    "scheduler_time": 167.75541346647015
}
#Debug simulation 
Total elapsed time: 17.354504632006865. Arrivals time: 0.30605684709735215 Scheduler time: 16.880993300059345 Scheduler overhead time: 0.059190956642851233 Adapter cache time: 0.022259925899561495 Engine time: 0.0598240778199397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 42.215661589987576,
    "estimated_duration": 3600.0514200952493,
    "input_throughput": 5629.639312058432,
    "output_throughput": 4872.157353668002,
    "total_throughput": 10501.796665726433,
    "itl": 118.32967409662314,
    "ttft": 1782186.198839211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4053906514542605,
    "arrivals": 277607,
    "finished_requests": 81743,
    "scheduler_time": 155.73971354577588
}
#Debug simulation 
Total elapsed time: 42.21582360198954. Arrivals time: 0.3568368328269571 Scheduler time: 41.70147863263264 Scheduler overhead time: 0.05793752451427281 Adapter cache time: 0.01633690227754414 Engine time: 0.05934479529969394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 33.60014945798321,
    "estimated_duration": 3600.0774600783852,
    "input_throughput": 5473.02390531647,
    "output_throughput": 4727.737719184913,
    "total_throughput": 10200.761624501383,
    "itl": 110.39469849452522,
    "ttft": 1832365.6012186909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.838361111888669,
    "arrivals": 277607,
    "finished_requests": 79388,
    "scheduler_time": 159.88838214285343
}
#Debug simulation 
Total elapsed time: 33.60027008398902. Arrivals time: 0.32465366733958945 Scheduler time: 33.11616005055839 Scheduler overhead time: 0.057933867326937616 Adapter cache time: 0.017876492347568274 Engine time: 0.05894391023321077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.905836539983284,
    "estimated_duration": 3600.08945593087,
    "input_throughput": 5169.660984212326,
    "output_throughput": 4485.584927173568,
    "total_throughput": 9655.245911385895,
    "itl": 97.96190932367674,
    "ttft": 1885207.7812506428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.055887777670298,
    "arrivals": 277607,
    "finished_requests": 75198,
    "scheduler_time": 168.0560625149723
}
#Debug simulation 
Total elapsed time: 12.905950420012232. Arrivals time: 0.2988846304942854 Scheduler time: 12.443234280974139 Scheduler overhead time: 0.05689276964403689 Adapter cache time: 0.022938349458854645 Engine time: 0.05826994660310447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 28.9167904080241,
    "estimated_duration": 3600.048133404018,
    "input_throughput": 5470.172972765071,
    "output_throughput": 4729.928981227047,
    "total_throughput": 10200.101953992118,
    "itl": 110.40947005515478,
    "ttft": 1836870.633145161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.641961052659894,
    "arrivals": 277607,
    "finished_requests": 79418,
    "scheduler_time": 159.8402345092336
}
#Debug simulation 
Total elapsed time: 28.916967538010795. Arrivals time: 0.33792444388382137 Scheduler time: 28.41998946783133 Scheduler overhead time: 0.05829197011189535 Adapter cache time: 0.016589396633207798 Engine time: 0.059395482880063355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 16.537458601000253,
    "estimated_duration": 3600.062578304673,
    "input_throughput": 5173.003411726785,
    "output_throughput": 4487.475883713038,
    "total_throughput": 9660.479295439824,
    "itl": 98.01692903540852,
    "ttft": 1885109.658072956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.733133414606586,
    "arrivals": 277607,
    "finished_requests": 75245,
    "scheduler_time": 167.99846182570278
}
#Debug simulation 
Total elapsed time: 16.53758924495196. Arrivals time: 0.2949503172421828 Scheduler time: 16.076339229824953 Scheduler overhead time: 0.059095761098433286 Adapter cache time: 0.02120923704933375 Engine time: 0.059833967476151884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.219838760967832,
    "estimated_duration": 3600.1148126584153,
    "input_throughput": 5475.06094269394,
    "output_throughput": 4737.422801081714,
    "total_throughput": 10212.483743775654,
    "itl": 110.78245609546502,
    "ttft": 1839177.481164708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3985215280530765,
    "arrivals": 277607,
    "finished_requests": 79537,
    "scheduler_time": 159.65343384502162
}
#Debug simulation 
Total elapsed time: 24.22000858199317. Arrivals time: 0.32204405806260183 Scheduler time: 23.740777024650015 Scheduler overhead time: 0.05701764055993408 Adapter cache time: 0.017880263039842248 Engine time: 0.0579159096814692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.625873555021826,
    "estimated_duration": 3600.06079644625,
    "input_throughput": 5166.469138065762,
    "output_throughput": 4484.165105193668,
    "total_throughput": 9650.63424325943,
    "itl": 98.3017390373831,
    "ttft": 1884747.6842565304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 952,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.001695614531655,
    "arrivals": 277607,
    "finished_requests": 75154,
    "scheduler_time": 167.6402009288707
}
#Debug simulation 
Total elapsed time: 14.62599250196945. Arrivals time: 0.30170991126215085 Scheduler time: 14.159836903621908 Scheduler overhead time: 0.058295929338783026 Adapter cache time: 0.02142009325325489 Engine time: 0.058788379887118936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 28.546653899014927,
    "estimated_duration": 3600.049396113964,
    "input_throughput": 5583.280891005782,
    "output_throughput": 4868.395144499616,
    "total_throughput": 10451.676035505398,
    "itl": 118.1366784534237,
    "ttft": 1815010.6113231804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.028483336633102,
    "arrivals": 276925,
    "finished_requests": 81382,
    "scheduler_time": 155.91827011832473
}
#Debug simulation 
Total elapsed time: 28.54682087904075. Arrivals time: 0.33984086505370215 Scheduler time: 28.057677593722474 Scheduler overhead time: 0.054950275633018464 Adapter cache time: 0.015053995186462998 Engine time: 0.05581113899825141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 27.347648657974787,
    "estimated_duration": 3600.1130018584267,
    "input_throughput": 5381.109979047769,
    "output_throughput": 4685.596255254255,
    "total_throughput": 10066.706234302024,
    "itl": 107.0335553046491,
    "ttft": 1833239.1154262049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.657845533392397,
    "arrivals": 276925,
    "finished_requests": 78343,
    "scheduler_time": 162.39314210149166
}
#Debug simulation 
Total elapsed time: 27.347747533000074. Arrivals time: 0.33364728721790016 Scheduler time: 26.85105545708211 Scheduler overhead time: 0.06000845570815727 Adapter cache time: 0.01655403128825128 Engine time: 0.06106066273059696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.217146393028088,
    "estimated_duration": 3600.0313484695203,
    "input_throughput": 5141.947168840528,
    "output_throughput": 4489.856458297685,
    "total_throughput": 9631.803627138213,
    "itl": 97.70223257208062,
    "ttft": 1883682.1678698743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.12310376858807,
    "arrivals": 276925,
    "finished_requests": 74884,
    "scheduler_time": 168.50289935634387
}
#Debug simulation 
Total elapsed time: 14.217251879046671. Arrivals time: 0.27975650515872985 Scheduler time: 13.775092576863244 Scheduler overhead time: 0.05750917742261663 Adapter cache time: 0.02029925980605185 Engine time: 0.058604595775250345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 25.159628307039384,
    "estimated_duration": 3600.0234329702184,
    "input_throughput": 5468.086907356208,
    "output_throughput": 4768.588404947201,
    "total_throughput": 10236.675312303409,
    "itl": 110.08503933568566,
    "ttft": 1831393.676397848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.83264764382969,
    "arrivals": 276925,
    "finished_requests": 79741,
    "scheduler_time": 160.75931281009468
}
#Debug simulation 
Total elapsed time: 25.159784653049428. Arrivals time: 0.33592921047238633 Scheduler time: 24.66590846562758 Scheduler overhead time: 0.057760402793064713 Adapter cache time: 0.016765826498158276 Engine time: 0.05875943775754422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 15.073904063028749,
    "estimated_duration": 3600.0097471139798,
    "input_throughput": 5162.228800879858,
    "output_throughput": 4506.063355246354,
    "total_throughput": 9668.292156126212,
    "itl": 97.74718533884386,
    "ttft": 1880056.5849737842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.455277954693912,
    "arrivals": 276925,
    "finished_requests": 75183,
    "scheduler_time": 168.65943992769317
}
#Debug simulation 
Total elapsed time: 15.07402398798149. Arrivals time: 0.2900351533899084 Scheduler time: 14.621848333044909 Scheduler overhead time: 0.05776608799351379 Adapter cache time: 0.019119130447506905 Engine time: 0.05929777480196208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 33.05438414000673,
    "estimated_duration": 3600.0727845962356,
    "input_throughput": 5465.651995757313,
    "output_throughput": 4753.150012193199,
    "total_throughput": 10218.802007950511,
    "itl": 110.17715183405612,
    "ttft": 1817034.3484680224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.236647916869246,
    "arrivals": 276925,
    "finished_requests": 79569,
    "scheduler_time": 160.41172831295333
}
#Debug simulation 
Total elapsed time: 33.054492498980835. Arrivals time: 0.33624127082293853 Scheduler time: 32.558287054125685 Scheduler overhead time: 0.0591647510882467 Adapter cache time: 0.01596009818604216 Engine time: 0.0599411113653332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.867114106949884,
    "estimated_duration": 3600.05168421424,
    "input_throughput": 5118.639290875076,
    "output_throughput": 4464.763400614409,
    "total_throughput": 9583.402691489484,
    "itl": 97.5747760979536,
    "ttft": 1886298.4428360283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.175975861866058,
    "arrivals": 276925,
    "finished_requests": 74537,
    "scheduler_time": 168.24631025721519
}
#Debug simulation 
Total elapsed time: 16.86732508899877. Arrivals time: 0.2953097253921442 Scheduler time: 16.407844030181877 Scheduler overhead time: 0.05906082520959899 Adapter cache time: 0.01868784544058144 Engine time: 0.06009465589886531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 40.770490072027314,
    "estimated_duration": 3600.0741161037677,
    "input_throughput": 5561.801605815292,
    "output_throughput": 4879.268713226039,
    "total_throughput": 10441.07031904133,
    "itl": 118.35967878807682,
    "ttft": 1698847.845747404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6978628850355943,
    "arrivals": 218234,
    "finished_requests": 81482,
    "scheduler_time": 153.3310870541608
}
#Debug simulation 
Total elapsed time: 40.77064111398067. Arrivals time: 0.35497758886776865 Scheduler time: 40.249878939881455 Scheduler overhead time: 0.061324265610892326 Adapter cache time: 0.016430216492153704 Engine time: 0.0631729660090059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 26.98582596797496,
    "estimated_duration": 3600.049734075162,
    "input_throughput": 5406.341977939366,
    "output_throughput": 4744.681396571889,
    "total_throughput": 10151.023374511255,
    "itl": 110.63222968786576,
    "ttft": 1737178.63845147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6586765704397157,
    "arrivals": 218234,
    "finished_requests": 79269,
    "scheduler_time": 157.2570956443199
}
#Debug simulation 
Total elapsed time: 26.98596744297538. Arrivals time: 0.3327576505835168 Scheduler time: 26.493047703814227 Scheduler overhead time: 0.05912158323917538 Adapter cache time: 0.016683760564774275 Engine time: 0.059348613664042205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.989771073975135,
    "estimated_duration": 3600.0368302993215,
    "input_throughput": 5099.957268624242,
    "output_throughput": 4475.757265700059,
    "total_throughput": 9575.714534324301,
    "itl": 98.56471482611113,
    "ttft": 1791391.9370826548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.254543124353484,
    "arrivals": 218234,
    "finished_requests": 74786,
    "scheduler_time": 164.38261770043883
}
#Debug simulation 
Total elapsed time: 12.98992611002177. Arrivals time: 0.2842869072337635 Scheduler time: 12.53802730969619 Scheduler overhead time: 0.05751079908804968 Adapter cache time: 0.02562498179031536 Engine time: 0.05865665792953223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 23.4873800080386,
    "estimated_duration": 3600.0499160332824,
    "input_throughput": 5409.749712987022,
    "output_throughput": 4739.627615719496,
    "total_throughput": 10149.377328706518,
    "itl": 110.73283019798984,
    "ttft": 1722824.0016567602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6021940210275325,
    "arrivals": 218234,
    "finished_requests": 79199,
    "scheduler_time": 157.08936359080684
}
#Debug simulation 
Total elapsed time: 23.487505424011033. Arrivals time: 0.3212894441676326 Scheduler time: 23.010309501667507 Scheduler overhead time: 0.05805190315004438 Adapter cache time: 0.014299517089966685 Engine time: 0.05907648702850565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.774278221011627,
    "estimated_duration": 3600.0704499804447,
    "input_throughput": 5099.973251940037,
    "output_throughput": 4474.2549413408,
    "total_throughput": 9574.228193280836,
    "itl": 98.5634529789383,
    "ttft": 1793129.6403731557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.817609143205882,
    "arrivals": 218234,
    "finished_requests": 74778,
    "scheduler_time": 164.3662301852788
}
#Debug simulation 
Total elapsed time: 13.77434527297737. Arrivals time: 0.28918346925638616 Scheduler time: 13.31798222893849 Scheduler overhead time: 0.057742970646359026 Adapter cache time: 0.02479575393954292 Engine time: 0.0586690028430894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.14362211403204,
    "estimated_duration": 3600.0714172257467,
    "input_throughput": 5404.4555635491615,
    "output_throughput": 4745.787241400343,
    "total_throughput": 10150.242804949505,
    "itl": 110.86612467692751,
    "ttft": 1736721.1700442694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3579424147400854,
    "arrivals": 218234,
    "finished_requests": 79307,
    "scheduler_time": 157.08350474736898
}
#Debug simulation 
Total elapsed time: 25.143738776037935. Arrivals time: 0.34961153886979446 Scheduler time: 24.635839780559763 Scheduler overhead time: 0.05809231207240373 Adapter cache time: 0.016720078827347606 Engine time: 0.058771761192474514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.571437462989707,
    "estimated_duration": 3600.0442233097033,
    "input_throughput": 5092.076614310792,
    "output_throughput": 4471.903121567581,
    "total_throughput": 9563.979735878373,
    "itl": 98.50155190296455,
    "ttft": 1793161.200755695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.344885468427092,
    "arrivals": 218234,
    "finished_requests": 74688,
    "scheduler_time": 164.40791487570948
}
#Debug simulation 
Total elapsed time: 13.57155045302352. Arrivals time: 0.30933531193295494 Scheduler time: 13.096617226488888 Scheduler overhead time: 0.05756545247277245 Adapter cache time: 0.02413085085572675 Engine time: 0.058105159318074584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 36.077949538012035,
    "estimated_duration": 3600.0710979009564,
    "input_throughput": 5572.576055983194,
    "output_throughput": 4865.568907851026,
    "total_throughput": 10438.14496383422,
    "itl": 118.0867503489639,
    "ttft": 1694522.3900996828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.074770199856753,
    "arrivals": 212464,
    "finished_requests": 80966,
    "scheduler_time": 153.0710074670358
}
#Debug simulation 
Total elapsed time: 36.07815980701707. Arrivals time: 0.33814775914652273 Scheduler time: 35.58070843323367 Scheduler overhead time: 0.05925991205731407 Adapter cache time: 0.015910385351162404 Engine time: 0.059542605304159224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 21.81553822098067,
    "estimated_duration": 3600.096529427885,
    "input_throughput": 5421.37741042784,
    "output_throughput": 4729.059585162169,
    "total_throughput": 10150.43699559001,
    "itl": 110.57321693165737,
    "ttft": 1727092.2899440962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.383421695646836,
    "arrivals": 212464,
    "finished_requests": 78694,
    "scheduler_time": 156.7700966226288
}
#Debug simulation 
Total elapsed time: 21.81567774200812. Arrivals time: 0.318871600611601 Scheduler time: 21.340502700186335 Scheduler overhead time: 0.05706858111079782 Adapter cache time: 0.016995467769447714 Engine time: 0.05773241206770763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.968922019994352,
    "estimated_duration": 3600.1005342150484,
    "input_throughput": 5112.251401060629,
    "output_throughput": 4465.281412899496,
    "total_throughput": 9577.532813960124,
    "itl": 97.99599325283502,
    "ttft": 1782180.0925781915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.723081088364148,
    "arrivals": 212464,
    "finished_requests": 74233,
    "scheduler_time": 164.58130548784746
}
#Debug simulation 
Total elapsed time: 12.96906970301643. Arrivals time: 0.2755289772176184 Scheduler time: 12.53047782293288 Scheduler overhead time: 0.05709081148961559 Adapter cache time: 0.02214339264901355 Engine time: 0.05792944831773639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 21.016089340962935,
    "estimated_duration": 3600.1161894977513,
    "input_throughput": 5416.772396648834,
    "output_throughput": 4728.9226524589185,
    "total_throughput": 10145.695049107751,
    "itl": 110.25369149137958,
    "ttft": 1724332.8619750894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.498181166094723,
    "arrivals": 212464,
    "finished_requests": 78703,
    "scheduler_time": 157.06003696853924
}
#Debug simulation 
Total elapsed time: 21.01621154200984. Arrivals time: 0.3053105234866962 Scheduler time: 20.55695965664927 Scheduler overhead time: 0.05625178338959813 Adapter cache time: 0.016081265464890748 Engine time: 0.05710924416780472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 15.405170509009622,
    "estimated_duration": 3600.022999318717,
    "input_throughput": 5116.531200907829,
    "output_throughput": 4468.40311938125,
    "total_throughput": 9584.93432028908,
    "itl": 97.90232165710121,
    "ttft": 1783150.674374776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.57534598085566,
    "arrivals": 212464,
    "finished_requests": 74309,
    "scheduler_time": 164.69414457894467
}
#Debug simulation 
Total elapsed time: 15.40526702196803. Arrivals time: 0.2903219287400134 Scheduler time: 14.948029876104556 Scheduler overhead time: 0.05958373722387478 Adapter cache time: 0.021485148405190557 Engine time: 0.05961583455791697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 22.1578155499883,
    "estimated_duration": 3600.0741588877136,
    "input_throughput": 5422.865512868151,
    "output_throughput": 4734.611912901884,
    "total_throughput": 10157.477425770036,
    "itl": 110.56150916153409,
    "ttft": 1726649.323615758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.479236912610925,
    "arrivals": 212464,
    "finished_requests": 78735,
    "scheduler_time": 156.88349345245123
}
#Debug simulation 
Total elapsed time: 22.157929095963482. Arrivals time: 0.3125382648431696 Scheduler time: 21.690744690829888 Scheduler overhead time: 0.05628505360800773 Adapter cache time: 0.016516841656994075 Engine time: 0.05759138386929408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.724377873004414,
    "estimated_duration": 3600.0878067489025,
    "input_throughput": 5121.337031123684,
    "output_throughput": 4476.536369415294,
    "total_throughput": 9597.873400538978,
    "itl": 98.01475009356544,
    "ttft": 1782161.5379710065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3925822367333165,
    "arrivals": 212464,
    "finished_requests": 74417,
    "scheduler_time": 164.69926813190355
}
#Debug simulation 
Total elapsed time: 16.724515449022874. Arrivals time: 0.2982378207379952 Scheduler time: 16.260933635465335 Scheduler overhead time: 0.05907028395449743 Adapter cache time: 0.01961644203402102 Engine time: 0.06040580978151411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 39.60796215198934,
    "estimated_duration": 3600.061873479683,
    "input_throughput": 5582.900712918379,
    "output_throughput": 4876.484798588025,
    "total_throughput": 10459.385511506405,
    "itl": 118.5479344425107,
    "ttft": 1668800.083427125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4415051689650846,
    "arrivals": 209539,
    "finished_requests": 81303,
    "scheduler_time": 152.45706649130463
}
#Debug simulation 
Total elapsed time: 39.6080993549549. Arrivals time: 0.3258412176510319 Scheduler time: 39.11895488301525 Scheduler overhead time: 0.062154441548045725 Adapter cache time: 0.012846117548178881 Engine time: 0.06301962770521641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 26.53851029300131,
    "estimated_duration": 3600.013046463882,
    "input_throughput": 5429.819211127716,
    "output_throughput": 4754.397492201344,
    "total_throughput": 10184.216703329059,
    "itl": 110.50526185413447,
    "ttft": 1717378.3426662015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.350850666635674,
    "arrivals": 209539,
    "finished_requests": 79178,
    "scheduler_time": 156.84212323893476
}
#Debug simulation 
Total elapsed time: 26.538688709959388. Arrivals time: 0.2996669764397666 Scheduler time: 26.07748342328705 Scheduler overhead time: 0.06002160778734833 Adapter cache time: 0.01566017494769767 Engine time: 0.06082572054583579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.51430119300494,
    "estimated_duration": 3600.0180853954384,
    "input_throughput": 5119.657891378479,
    "output_throughput": 4484.499971123521,
    "total_throughput": 9604.157862502001,
    "itl": 98.46623574130987,
    "ttft": 1770011.0158608602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.224503984525829,
    "arrivals": 209539,
    "finished_requests": 74627,
    "scheduler_time": 163.974839656499
}
#Debug simulation 
Total elapsed time: 15.5144111700356. Arrivals time: 0.28160067461431026 Scheduler time: 15.069507476058789 Scheduler overhead time: 0.05876830796478316 Adapter cache time: 0.018868022481910884 Engine time: 0.059566506650298834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 29.299300618004054,
    "estimated_duration": 3600.0348926919514,
    "input_throughput": 5415.726119649115,
    "output_throughput": 4740.446553627415,
    "total_throughput": 10156.17267327653,
    "itl": 110.85008903511027,
    "ttft": 1717774.5981949246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.649657909558151,
    "arrivals": 209539,
    "finished_requests": 78951,
    "scheduler_time": 156.32376763273408
}
#Debug simulation 
Total elapsed time: 29.299447271972895. Arrivals time: 0.310822258121334 Scheduler time: 28.825385565811303 Scheduler overhead time: 0.06153749173972756 Adapter cache time: 0.0149471519398503 Engine time: 0.06161710200831294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.10421702201711,
    "estimated_duration": 3600.067070565885,
    "input_throughput": 4924.338256068488,
    "output_throughput": 4316.379304999289,
    "total_throughput": 9240.717561067777,
    "itl": 92.21235688655995,
    "ttft": 1782896.9664472141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.082458009240245,
    "arrivals": 209539,
    "finished_requests": 71779,
    "scheduler_time": 169.66177139617963
}
#Debug simulation 
Total elapsed time: 14.104322355997283. Arrivals time: 0.2565362566965632 Scheduler time: 13.677501216239762 Scheduler overhead time: 0.06089892180170864 Adapter cache time: 0.020409417687915266 Engine time: 0.061775224981829524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.702229145972524,
    "estimated_duration": 3600.0381084078726,
    "input_throughput": 5413.471583671356,
    "output_throughput": 4739.4614962967225,
    "total_throughput": 10152.93307996808,
    "itl": 110.7265360371112,
    "ttft": 1717995.9991936788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6557111112773306,
    "arrivals": 209539,
    "finished_requests": 78907,
    "scheduler_time": 156.4009946362694
}
#Debug simulation 
Total elapsed time: 27.702315101982094. Arrivals time: 0.3022409116383642 Scheduler time: 27.23974636278581 Scheduler overhead time: 0.05958539166022092 Adapter cache time: 0.014990514901001006 Engine time: 0.060690595011692494 
