INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249198701 . Total output tokens: 219930190
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.373895090073347,
    "estimated_duration": 3600.097682617964,
    "input_throughput": 6717.7299429312225,
    "output_throughput": 5850.222648593337,
    "total_throughput": 12567.95259152456,
    "itl": 93.99857879497392,
    "ttft": 1795069.2406312616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 373254,
    "finished_requests": 97787,
    "scheduler_time": 44.49308714374126
}
#Debug simulation 
Total elapsed time: 7.374032792169601. Arrivals time: 0.31075202859938145 Scheduler time: 6.900398830883205 Scheduler overhead time: 0.05643216613680124 Adapter cache time: 0.021186295431107283 Engine time: 0.05857614753767848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249198701 . Total output tokens: 219930190
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.892388813197613,
    "estimated_duration": 3600.0305229132323,
    "input_throughput": 6504.600405735057,
    "output_throughput": 5672.941068142223,
    "total_throughput": 12177.54147387728,
    "itl": 85.22818414929311,
    "ttft": 1818860.81474018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.701702552586794,
    "arrivals": 373254,
    "finished_requests": 94775,
    "scheduler_time": 37.587984625334194
}
#Debug simulation 
Total elapsed time: 6.892533041071147. Arrivals time: 0.2841565618291497 Scheduler time: 6.433097263798118 Scheduler overhead time: 0.06116606621071696 Adapter cache time: 0.021643918938934803 Engine time: 0.06365088326856494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249198701 . Total output tokens: 219930190
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.316970807034522,
    "estimated_duration": 3600.0311074173437,
    "input_throughput": 5881.973618608845,
    "output_throughput": 5137.365886059815,
    "total_throughput": 11019.33950466866,
    "itl": 67.19956139493664,
    "ttft": 1892697.0594291904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 373254,
    "finished_requests": 85748,
    "scheduler_time": 17.376286305744966
}
#Debug simulation 
Total elapsed time: 6.317105157766491. Arrivals time: 0.2692437549121678 Scheduler time: 5.838202903978527 Scheduler overhead time: 0.07412103610113263 Adapter cache time: 0.02345547406002879 Engine time: 0.07723406096920371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249198701 . Total output tokens: 219930190
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.895647221244872,
    "estimated_duration": 3600.0063671459716,
    "input_throughput": 6504.644051106065,
    "output_throughput": 5672.979133142712,
    "total_throughput": 12177.623184248778,
    "itl": 85.22942047669963,
    "ttft": 1818788.7213694218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407823,
    "arrivals": 373254,
    "finished_requests": 94775,
    "scheduler_time": 37.58924670236351
}
#Debug simulation 
Total elapsed time: 6.895779102109373. Arrivals time: 0.29126265179365873 Scheduler time: 6.429140263237059 Scheduler overhead time: 0.06123538641259074 Adapter cache time: 0.021955270320177078 Engine time: 0.06340625323355198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249198701 . Total output tokens: 219930190
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.313069365918636,
    "estimated_duration": 3600.0428664497185,
    "input_throughput": 5881.954405971447,
    "output_throughput": 5137.349105578577,
    "total_throughput": 11019.303511550024,
    "itl": 67.20056991024302,
    "ttft": 1892799.3466006296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 373254,
    "finished_requests": 85748,
    "scheduler_time": 17.377030870065
}
#Debug simulation 
Total elapsed time: 6.313204243779182. Arrivals time: 0.27056003315374255 Scheduler time: 5.833130210172385 Scheduler overhead time: 0.07397533161565661 Adapter cache time: 0.023969025816768408 Engine time: 0.07680098852142692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249198701 . Total output tokens: 219930190
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.904636241961271,
    "estimated_duration": 3600.072572972999,
    "input_throughput": 6504.524429812273,
    "output_throughput": 5672.874806280516,
    "total_throughput": 12177.39923609279,
    "itl": 85.22695317284384,
    "ttft": 1818796.0285962154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 373254,
    "finished_requests": 94775,
    "scheduler_time": 37.589703536596936
}
#Debug simulation 
Total elapsed time: 6.9047659751959145. Arrivals time: 0.28917673928663135 Scheduler time: 6.440287584904581 Scheduler overhead time: 0.061138116754591465 Adapter cache time: 0.022153111174702644 Engine time: 0.06338756904006004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249198701 . Total output tokens: 219930190
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.323165794834495,
    "estimated_duration": 3600.0196095390006,
    "input_throughput": 5881.962127065075,
    "output_throughput": 5137.379516210004,
    "total_throughput": 11019.34164327508,
    "itl": 67.2011067170732,
    "ttft": 1892645.3621315556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 373254,
    "finished_requests": 85746,
    "scheduler_time": 17.37630185643012
}
#Debug simulation 
Total elapsed time: 6.323257730808109. Arrivals time: 0.2698711291886866 Scheduler time: 5.843694989103824 Scheduler overhead time: 0.07374411495402455 Adapter cache time: 0.023984636645764112 Engine time: 0.07714628335088491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 248713290 . Total output tokens: 219483241
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.1120735090225935,
    "estimated_duration": 3600.017889042264,
    "input_throughput": 6777.597709796701,
    "output_throughput": 5897.071251956428,
    "total_throughput": 12674.668961753128,
    "itl": 93.14284908672457,
    "ttft": 1784141.568686886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 372568,
    "finished_requests": 98665,
    "scheduler_time": 44.851962740885796
}
#Debug simulation 
Total elapsed time: 7.112172190099955. Arrivals time: 0.2951223277486861 Scheduler time: 6.655991893261671 Scheduler overhead time: 0.056942364666610956 Adapter cache time: 0.018799516838043928 Engine time: 0.058686450589448214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 248713290 . Total output tokens: 219483241
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.951506151352078,
    "estimated_duration": 3600.044147070879,
    "input_throughput": 6562.988128693863,
    "output_throughput": 5716.110180688528,
    "total_throughput": 12279.09830938239,
    "itl": 84.53680634997549,
    "ttft": 1809036.8965646396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 372568,
    "finished_requests": 95574,
    "scheduler_time": 37.85106509134583
}
#Debug simulation 
Total elapsed time: 6.951627387199551. Arrivals time: 0.29335760371759534 Scheduler time: 6.4839204186573625 Scheduler overhead time: 0.06145491497591138 Adapter cache time: 0.019903731998056173 Engine time: 0.06394892511889338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 248713290 . Total output tokens: 219483241
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.358198123984039,
    "estimated_duration": 3600.065882939282,
    "input_throughput": 5922.007177989074,
    "output_throughput": 5164.7590918028745,
    "total_throughput": 11086.766269791948,
    "itl": 66.8430501814326,
    "ttft": 1884806.9868269982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 372568,
    "finished_requests": 86379,
    "scheduler_time": 17.495512671792106
}
#Debug simulation 
Total elapsed time: 6.358293652068824. Arrivals time: 0.27269453136250377 Scheduler time: 5.876597453840077 Scheduler overhead time: 0.07472104066982865 Adapter cache time: 0.02169619919732213 Engine time: 0.07741114776581526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 248713290 . Total output tokens: 219483241
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.930972241330892,
    "estimated_duration": 3600.080612674591,
    "input_throughput": 6563.077481325189,
    "output_throughput": 5716.175612165409,
    "total_throughput": 12279.253093490599,
    "itl": 84.53509354454935,
    "ttft": 1809005.378011771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 372568,
    "finished_requests": 95578,
    "scheduler_time": 37.85229848534163
}
#Debug simulation 
Total elapsed time: 6.93109858315438. Arrivals time: 0.29325364669784904 Scheduler time: 6.462999093346298 Scheduler overhead time: 0.06171187153086066 Adapter cache time: 0.019817774649709463 Engine time: 0.06405743351206183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 248713290 . Total output tokens: 219483241
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.345164480153471,
    "estimated_duration": 3600.00479295249,
    "input_throughput": 5922.086282144947,
    "output_throughput": 5164.824234789673,
    "total_throughput": 11086.91051693462,
    "itl": 66.84267283214642,
    "ttft": 1884841.234569486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 372568,
    "finished_requests": 86379,
    "scheduler_time": 17.496034695628406
}
#Debug simulation 
Total elapsed time: 6.345260822214186. Arrivals time: 0.2701469575986266 Scheduler time: 5.866388014983386 Scheduler overhead time: 0.07426286954432726 Adapter cache time: 0.021855206694453955 Engine time: 0.07734371861442924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 248713290 . Total output tokens: 219483241
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.1977251139469445,
    "estimated_duration": 3600.0364926480756,
    "input_throughput": 6563.146803720395,
    "output_throughput": 5716.162056141595,
    "total_throughput": 12279.30885986199,
    "itl": 84.53338405937117,
    "ttft": 1808977.8131663383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 372568,
    "finished_requests": 95576,
    "scheduler_time": 37.850614601002235
}
#Debug simulation 
Total elapsed time: 7.197836013045162. Arrivals time: 0.5621960065327585 Scheduler time: 6.46142589347437 Scheduler overhead time: 0.0616196277551353 Adapter cache time: 0.01980259222909808 Engine time: 0.06376647856086493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 248713290 . Total output tokens: 219483241
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.327208765782416,
    "estimated_duration": 3600.016135174399,
    "input_throughput": 5921.86623601542,
    "output_throughput": 5164.729073943241,
    "total_throughput": 11086.595309958662,
    "itl": 66.84385503823583,
    "ttft": 1884868.6079724072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 372568,
    "finished_requests": 86376,
    "scheduler_time": 17.49732359043402
}
#Debug simulation 
Total elapsed time: 6.327338108792901. Arrivals time: 0.2710786825045943 Scheduler time: 5.848538572434336 Scheduler overhead time: 0.07420318387448788 Adapter cache time: 0.021525156684219837 Engine time: 0.0769477435387671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248477466 . Total output tokens: 219284988
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.124551710672677,
    "estimated_duration": 3600.1040782274545,
    "input_throughput": 6769.265962999279,
    "output_throughput": 5918.4958370678005,
    "total_throughput": 12687.76180006708,
    "itl": 93.14310653285492,
    "ttft": 1783377.0355461445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6281788580352434,
    "arrivals": 372217,
    "finished_requests": 98721,
    "scheduler_time": 45.022081092536126
}
#Debug simulation 
Total elapsed time: 7.124678419902921. Arrivals time: 0.2986964685842395 Scheduler time: 6.664035641122609 Scheduler overhead time: 0.05714705539867282 Adapter cache time: 0.018785302992910147 Engine time: 0.059156559873372316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248477466 . Total output tokens: 219284988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.913195796310902,
    "estimated_duration": 3600.026690566819,
    "input_throughput": 6563.44578275327,
    "output_throughput": 5734.596094549933,
    "total_throughput": 12298.041877303203,
    "itl": 84.49963602232492,
    "ttft": 1808506.387111567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.693930410672911,
    "arrivals": 372217,
    "finished_requests": 95700,
    "scheduler_time": 37.98457214868168
}
#Debug simulation 
Total elapsed time: 6.913292064331472. Arrivals time: 0.2904144977219403 Scheduler time: 6.448821811005473 Scheduler overhead time: 0.06175055168569088 Adapter cache time: 0.01926870411261916 Engine time: 0.06397039396688342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248477466 . Total output tokens: 219284988
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.3616836606524885,
    "estimated_duration": 3600.0339487185624,
    "input_throughput": 5914.798111162103,
    "output_throughput": 5177.890893677584,
    "total_throughput": 11092.689004839687,
    "itl": 66.85827455928879,
    "ttft": 1883810.6464403355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7044690924976023,
    "arrivals": 372217,
    "finished_requests": 86299,
    "scheduler_time": 17.51042069564891
}
#Debug simulation 
Total elapsed time: 6.361793522723019. Arrivals time: 0.28231974644586444 Scheduler time: 5.871634998824447 Scheduler overhead time: 0.07434118585661054 Adapter cache time: 0.020946321543306112 Engine time: 0.0772216240875423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248477466 . Total output tokens: 219284988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.983652629889548,
    "estimated_duration": 3600.0430593945352,
    "input_throughput": 6563.568993525874,
    "output_throughput": 5734.623908490726,
    "total_throughput": 12298.1929020166,
    "itl": 84.49784624590713,
    "ttft": 1808475.9744982382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6495073395268992,
    "arrivals": 372217,
    "finished_requests": 95701,
    "scheduler_time": 37.98511647357135
}
#Debug simulation 
Total elapsed time: 6.983765068929642. Arrivals time: 0.30302127124741673 Scheduler time: 6.502832800615579 Scheduler overhead time: 0.06209180224686861 Adapter cache time: 0.02205687202513218 Engine time: 0.06444529816508293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248477466 . Total output tokens: 219284988
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.376450889278203,
    "estimated_duration": 3600.0095324131375,
    "input_throughput": 5914.569894410065,
    "output_throughput": 5177.69156780691,
    "total_throughput": 11092.261462216975,
    "itl": 66.86085769030207,
    "ttft": 1883902.9940049292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6978413428459318,
    "arrivals": 372217,
    "finished_requests": 86294,
    "scheduler_time": 17.513198191992775
}
#Debug simulation 
Total elapsed time: 6.376555824186653. Arrivals time: 0.27885988634079695 Scheduler time: 5.889768488705158 Scheduler overhead time: 0.0742471688427031 Adapter cache time: 0.021139841061085463 Engine time: 0.07730072923004627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248477466 . Total output tokens: 219284988
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.971391749102622,
    "estimated_duration": 3600.08004499827,
    "input_throughput": 6563.75266789696,
    "output_throughput": 5734.878875452871,
    "total_throughput": 12298.631543349831,
    "itl": 84.49596137062795,
    "ttft": 1808528.9735946232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6064724893542007,
    "arrivals": 372217,
    "finished_requests": 95705,
    "scheduler_time": 37.98344805390117
}
#Debug simulation 
Total elapsed time: 6.971502494066954. Arrivals time: 0.29880485590547323 Scheduler time: 6.49841837072745 Scheduler overhead time: 0.061969546135514975 Adapter cache time: 0.019340157508850098 Engine time: 0.06372033478692174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248477466 . Total output tokens: 219284988
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.363077403046191,
    "estimated_duration": 3600.015524126962,
    "input_throughput": 5914.578105927377,
    "output_throughput": 5177.898504901726,
    "total_throughput": 11092.476610829102,
    "itl": 66.85861131928068,
    "ttft": 1883871.6615672712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6916278275474907,
    "arrivals": 372217,
    "finished_requests": 86296,
    "scheduler_time": 17.51001656610985
}
#Debug simulation 
Total elapsed time: 6.363169998861849. Arrivals time: 0.2744399020448327 Scheduler time: 5.88158070622012 Scheduler overhead time: 0.07408734504133463 Adapter cache time: 0.020736445672810078 Engine time: 0.07720823073759675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 247761835 . Total output tokens: 218644987
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.259321484249085,
    "estimated_duration": 3600.032734197947,
    "input_throughput": 6829.441789916828,
    "output_throughput": 5991.373576997599,
    "total_throughput": 12820.815366914427,
    "itl": 92.3103715644865,
    "ttft": 1774328.2195740396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 371082,
    "finished_requests": 100008,
    "scheduler_time": 45.81691645094152
}
#Debug simulation 
Total elapsed time: 7.259417672175914. Arrivals time: 0.299555822275579 Scheduler time: 6.799615270458162 Scheduler overhead time: 0.05721404263749719 Adapter cache time: 0.01640377612784505 Engine time: 0.05959620280191302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 247761835 . Total output tokens: 218644987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.0943643460050225,
    "estimated_duration": 3600.0380427880214,
    "input_throughput": 6590.081748588054,
    "output_throughput": 5795.10459390677,
    "total_throughput": 12385.186342494824,
    "itl": 83.85713210133754,
    "ttft": 1799053.0265670419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867941,
    "arrivals": 371082,
    "finished_requests": 96606,
    "scheduler_time": 38.65998274041779
}
#Debug simulation 
Total elapsed time: 7.094461173284799. Arrivals time: 0.3258346072398126 Scheduler time: 6.594373567029834 Scheduler overhead time: 0.0626279660500586 Adapter cache time: 0.017558983992785215 Engine time: 0.06446161027997732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 247761835 . Total output tokens: 218644987
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.727831104770303,
    "estimated_duration": 3600.0704921800457,
    "input_throughput": 5948.0010312334425,
    "output_throughput": 5222.639123550719,
    "total_throughput": 11170.640154784161,
    "itl": 66.45715546040148,
    "ttft": 1877933.7721112808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 371082,
    "finished_requests": 87032,
    "scheduler_time": 17.969772617535405
}
#Debug simulation 
Total elapsed time: 6.727900423575193. Arrivals time: 0.5885426057502627 Scheduler time: 5.93246740475297 Scheduler overhead time: 0.07481068279594183 Adapter cache time: 0.018825232982635498 Engine time: 0.0779968579299748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 247761835 . Total output tokens: 218644987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.057703322265297,
    "estimated_duration": 3600.0308927313686,
    "input_throughput": 6589.845394910127,
    "output_throughput": 5795.010826746458,
    "total_throughput": 12384.856221656584,
    "itl": 83.85524957335825,
    "ttft": 1799051.3569173054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 371082,
    "finished_requests": 96604,
    "scheduler_time": 38.66042817522477
}
#Debug simulation 
Total elapsed time: 7.05779778631404. Arrivals time: 0.32646658830344677 Scheduler time: 6.557734780013561 Scheduler overhead time: 0.06241344893351197 Adapter cache time: 0.017420997377485037 Engine time: 0.06446907762438059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 247761835 . Total output tokens: 218644987
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.451135625131428,
    "estimated_duration": 3600.008419846764,
    "input_throughput": 5948.076921695494,
    "output_throughput": 5222.71945152848,
    "total_throughput": 11170.796373223973,
    "itl": 66.4569065950299,
    "ttft": 1877825.3185435557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 371082,
    "finished_requests": 87030,
    "scheduler_time": 17.968109253254873
}
#Debug simulation 
Total elapsed time: 6.4512323858216405. Arrivals time: 0.3082870850339532 Scheduler time: 5.935501587111503 Scheduler overhead time: 0.07490828912705183 Adapter cache time: 0.018923519179224968 Engine time: 0.0783851994201541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 247761835 . Total output tokens: 218644987
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.051255628000945,
    "estimated_duration": 3600.018903051293,
    "input_throughput": 6590.116785190106,
    "output_throughput": 5795.135403960614,
    "total_throughput": 12385.25218915072,
    "itl": 83.8540134670727,
    "ttft": 1798980.2038993076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 371082,
    "finished_requests": 96606,
    "scheduler_time": 38.66006890136833
}
#Debug simulation 
Total elapsed time: 7.0513506778515875. Arrivals time: 0.29519440652802587 Scheduler time: 6.58273023320362 Scheduler overhead time: 0.06221263948827982 Adapter cache time: 0.017360841389745474 Engine time: 0.06456296797841787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 247761835 . Total output tokens: 218644987
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.448026293888688,
    "estimated_duration": 3600.024776634217,
    "input_throughput": 5947.995174638676,
    "output_throughput": 5222.644055682941,
    "total_throughput": 11170.639230321618,
    "itl": 66.45770461644051,
    "ttft": 1877860.4497176667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 371082,
    "finished_requests": 87029,
    "scheduler_time": 17.96941704915844
}
#Debug simulation 
Total elapsed time: 6.448150639887899. Arrivals time: 0.3086627027951181 Scheduler time: 5.932622247375548 Scheduler overhead time: 0.07487231818959117 Adapter cache time: 0.018624076154083014 Engine time: 0.07792131556198001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247533445 . Total output tokens: 218431649
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.249753541778773,
    "estimated_duration": 3600.048746326083,
    "input_throughput": 6861.420147493361,
    "output_throughput": 6012.1319251824225,
    "total_throughput": 12873.552072675784,
    "itl": 91.79512459759714,
    "ttft": 1772426.1266890923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6281788580352434,
    "arrivals": 370740,
    "finished_requests": 100343,
    "scheduler_time": 45.92306545802738
}
#Debug simulation 
Total elapsed time: 7.24985835980624. Arrivals time: 0.30147562827914953 Scheduler time: 6.788332668598741 Scheduler overhead time: 0.057580705266445875 Adapter cache time: 0.015469569712877274 Engine time: 0.05963974725455046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247533445 . Total output tokens: 218431649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.085556897800416,
    "estimated_duration": 3600.0495090185377,
    "input_throughput": 6634.426260018696,
    "output_throughput": 5817.555271818946,
    "total_throughput": 12451.981531837642,
    "itl": 83.40718534554638,
    "ttft": 1798188.3633979468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6861582687590274,
    "arrivals": 370740,
    "finished_requests": 97059,
    "scheduler_time": 38.75286702479211
}
#Debug simulation 
Total elapsed time: 7.085680030751973. Arrivals time: 0.297195116057992 Scheduler time: 6.6156757757999 Scheduler overhead time: 0.06272030202671885 Adapter cache time: 0.015915386844426394 Engine time: 0.06469900999218225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247533445 . Total output tokens: 218431649
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.425392512232065,
    "estimated_duration": 3600.0387380233387,
    "input_throughput": 5954.755645704672,
    "output_throughput": 5234.180343944355,
    "total_throughput": 11188.935989649028,
    "itl": 66.25001951227867,
    "ttft": 1875116.817808492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7044690924976023,
    "arrivals": 370740,
    "finished_requests": 87132,
    "scheduler_time": 17.988356532261587
}
#Debug simulation 
Total elapsed time: 6.42548751598224. Arrivals time: 0.2730690189637244 Scheduler time: 5.946610040962696 Scheduler overhead time: 0.07463833829388022 Adapter cache time: 0.0176875414326787 Engine time: 0.07798846997320652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247533445 . Total output tokens: 218431649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.052678287029266,
    "estimated_duration": 3600.0170268460365,
    "input_throughput": 6634.456954478584,
    "output_throughput": 5817.482207396149,
    "total_throughput": 12451.939161874732,
    "itl": 83.40760766744279,
    "ttft": 1798155.7661554932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6431234185863287,
    "arrivals": 370740,
    "finished_requests": 97058,
    "scheduler_time": 38.75399655081246
}
#Debug simulation 
Total elapsed time: 7.052803459111601. Arrivals time: 0.2974386033602059 Scheduler time: 6.582040258683264 Scheduler overhead time: 0.06294598756358027 Adapter cache time: 0.01580012682825327 Engine time: 0.06505994964390993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247533445 . Total output tokens: 218431649
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.415071372874081,
    "estimated_duration": 3600.0094369680714,
    "input_throughput": 5954.5146687319975,
    "output_throughput": 5234.069890624877,
    "total_throughput": 11188.584559356874,
    "itl": 66.25026479198013,
    "ttft": 1875093.853526052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6980484600225465,
    "arrivals": 370740,
    "finished_requests": 87126,
    "scheduler_time": 17.987936036196796
}
#Debug simulation 
Total elapsed time: 6.415190890897065. Arrivals time: 0.2746616215445101 Scheduler time: 5.934185998514295 Scheduler overhead time: 0.07489744434133172 Adapter cache time: 0.017790642101317644 Engine time: 0.0781543361954391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247533445 . Total output tokens: 218431649
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.055298782885075,
    "estimated_duration": 3600.0337388772473,
    "input_throughput": 6634.704486811041,
    "output_throughput": 5817.670477313862,
    "total_throughput": 12452.374964124901,
    "itl": 83.40666450431847,
    "ttft": 1798189.240235699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6000885684136302,
    "arrivals": 370740,
    "finished_requests": 97060,
    "scheduler_time": 38.754702884583395
}
#Debug simulation 
Total elapsed time: 7.055424560792744. Arrivals time: 0.2958935908973217 Scheduler time: 6.5865777507424355 Scheduler overhead time: 0.06249870825558901 Adapter cache time: 0.015900398138910532 Engine time: 0.06492998637259007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247533445 . Total output tokens: 218431649
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.440599829889834,
    "estimated_duration": 3600.061666758959,
    "input_throughput": 5954.8527176480075,
    "output_throughput": 5234.148674170932,
    "total_throughput": 11189.00139181894,
    "itl": 66.25005307171587,
    "ttft": 1875122.9210986125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6916278275474907,
    "arrivals": 370740,
    "finished_requests": 87129,
    "scheduler_time": 17.986734917800526
}
#Debug simulation 
Total elapsed time: 6.440727647859603. Arrivals time: 0.2792744725011289 Scheduler time: 5.955163604579866 Scheduler overhead time: 0.07491698116064072 Adapter cache time: 0.017867144662886858 Engine time: 0.07795576844364405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247072596 . Total output tokens: 218002503
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.350796798244119,
    "estimated_duration": 3600.0857704780083,
    "input_throughput": 6966.919290000626,
    "output_throughput": 6062.099458564363,
    "total_throughput": 13029.018748564988,
    "itl": 91.00805119743542,
    "ttft": 1762374.5781522833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6215664490032935,
    "arrivals": 369999,
    "finished_requests": 101606,
    "scheduler_time": 46.276151840558065
}
#Debug simulation 
Total elapsed time: 7.3508973070420325. Arrivals time: 0.3038015076890588 Scheduler time: 6.887207286898047 Scheduler overhead time: 0.058667806908488274 Adapter cache time: 0.013481004163622856 Engine time: 0.06029469007626176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247072596 . Total output tokens: 218002503
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.141771678812802,
    "estimated_duration": 3600.08300453182,
    "input_throughput": 6718.154267430649,
    "output_throughput": 5857.828270474147,
    "total_throughput": 12575.982537904796,
    "itl": 82.82220211339683,
    "ttft": 1788484.1727429319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6861582687590272,
    "arrivals": 369999,
    "finished_requests": 98045,
    "scheduler_time": 38.9667534187235
}
#Debug simulation 
Total elapsed time: 7.141892796847969. Arrivals time: 0.31423587584868073 Scheduler time: 6.656597084831446 Scheduler overhead time: 0.06255927449092269 Adapter cache time: 0.01410112576559186 Engine time: 0.06469548447057605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247072596 . Total output tokens: 218002503
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.493155846837908,
    "estimated_duration": 3600.00729118758,
    "input_throughput": 6040.086933498103,
    "output_throughput": 5259.627958629431,
    "total_throughput": 11299.714892127533,
    "itl": 65.86402194193083,
    "ttft": 1869810.2017452482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6963930191239344,
    "arrivals": 369999,
    "finished_requests": 88081,
    "scheduler_time": 18.021120744725778
}
#Debug simulation 
Total elapsed time: 6.493256154935807. Arrivals time: 0.277301165740937 Scheduler time: 6.0102990181185305 Scheduler overhead time: 0.07547474652528763 Adapter cache time: 0.016031089704483747 Engine time: 0.07861461490392685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247072596 . Total output tokens: 218002503
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.131493889726698,
    "estimated_duration": 3600.0245031060404,
    "input_throughput": 6717.960385862303,
    "output_throughput": 5857.445687329777,
    "total_throughput": 12575.40607319208,
    "itl": 82.82522550035625,
    "ttft": 1788503.6506640017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6417351976130159,
    "arrivals": 369999,
    "finished_requests": 98038,
    "scheduler_time": 38.968179343017006
}
#Debug simulation 
Total elapsed time: 7.131593347992748. Arrivals time: 0.29757182486355305 Scheduler time: 6.661730945575982 Scheduler overhead time: 0.06309299729764462 Adapter cache time: 0.014018977526575327 Engine time: 0.06544026779010892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247072596 . Total output tokens: 218002503
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.489837211091071,
    "estimated_duration": 3600.036006650901,
    "input_throughput": 6039.949311570466,
    "output_throughput": 5259.437118134375,
    "total_throughput": 11299.386429704842,
    "itl": 65.86347375776846,
    "ttft": 1869841.0059609578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6899723866488786,
    "arrivals": 369999,
    "finished_requests": 88079,
    "scheduler_time": 18.020013025592636
}
#Debug simulation 
Total elapsed time: 6.4899365762248635. Arrivals time: 0.27544070268049836 Scheduler time: 6.009405713528395 Scheduler overhead time: 0.07539904769510031 Adapter cache time: 0.015882389154285192 Engine time: 0.07820589281618595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247072596 . Total output tokens: 218002503
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.102454661857337,
    "estimated_duration": 3600.0408525120615,
    "input_throughput": 6718.164318364209,
    "output_throughput": 5857.896302839064,
    "total_throughput": 12576.060621203274,
    "itl": 82.82236326905007,
    "ttft": 1788458.8029838298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6000885684136302,
    "arrivals": 369999,
    "finished_requests": 98044,
    "scheduler_time": 38.9668979899433
}
#Debug simulation 
Total elapsed time: 7.102586111985147. Arrivals time: 0.29678164375945926 Scheduler time: 6.634021163452417 Scheduler overhead time: 0.06274716928601265 Adapter cache time: 0.01419107522815466 Engine time: 0.06514393398538232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247072596 . Total output tokens: 218002503
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.507766069844365,
    "estimated_duration": 3600.075177956754,
    "input_throughput": 6040.266918076347,
    "output_throughput": 5259.711829336543,
    "total_throughput": 11299.97874741289,
    "itl": 65.86263539896213,
    "ttft": 1869893.0698015722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6837588713504374,
    "arrivals": 369999,
    "finished_requests": 88085,
    "scheduler_time": 18.01999217792671
}
#Debug simulation 
Total elapsed time: 6.507894848007709. Arrivals time: 0.30918690422549844 Scheduler time: 5.993250580504537 Scheduler overhead time: 0.07523041730746627 Adapter cache time: 0.016002819873392582 Engine time: 0.07876059971749783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215651961 . Total output tokens: 190166512
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.211780129931867,
    "estimated_duration": 3600.0370572903366,
    "input_throughput": 4854.2891981099465,
    "output_throughput": 4221.211270374551,
    "total_throughput": 9075.500468484497,
    "itl": 129.92022677923745,
    "ttft": 1984621.0814355144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 322758,
    "finished_requests": 70623,
    "scheduler_time": 32.229877170090134
}
#Debug simulation 
Total elapsed time: 5.211917788721621. Arrivals time: 0.2368156909942627 Scheduler time: 4.852532581426203 Scheduler overhead time: 0.04113112296909094 Adapter cache time: 0.019257578998804092 Engine time: 0.04259927896782756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215651961 . Total output tokens: 190166512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.364388580434024,
    "estimated_duration": 3600.037576500196,
    "input_throughput": 4695.584876764989,
    "output_throughput": 4089.8325884458163,
    "total_throughput": 8785.417465210805,
    "itl": 117.99456467583225,
    "ttft": 2008447.065749178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 322758,
    "finished_requests": 68392,
    "scheduler_time": 27.23691149434231
}
#Debug simulation 
Total elapsed time: 5.364456357434392. Arrivals time: 0.4966879799030721 Scheduler time: 4.730955976527184 Scheduler overhead time: 0.04472925188019872 Adapter cache time: 0.024783459026366472 Engine time: 0.04621423687785864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215651961 . Total output tokens: 190166512
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.733844114933163,
    "estimated_duration": 3600.025609473708,
    "input_throughput": 4271.021005944401,
    "output_throughput": 3723.2679580742,
    "total_throughput": 7994.288964018601,
    "itl": 92.36860141519313,
    "ttft": 2079412.731417074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 322758,
    "finished_requests": 62175,
    "scheduler_time": 12.544411099422499
}
#Debug simulation 
Total elapsed time: 4.733995953109115. Arrivals time: 0.21710372203961015 Scheduler time: 4.335695223417133 Scheduler overhead time: 0.05439701769500971 Adapter cache time: 0.04412781959399581 Engine time: 0.05670410953462124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215651961 . Total output tokens: 190166512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.095385174266994,
    "estimated_duration": 3600.027469328311,
    "input_throughput": 4695.6863924024565,
    "output_throughput": 4089.7810156840446,
    "total_throughput": 8785.4674080865,
    "itl": 117.99177130708955,
    "ttft": 2008504.7974803196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407823,
    "arrivals": 322758,
    "finished_requests": 68392,
    "scheduler_time": 27.23679586011389
}
#Debug simulation 
Total elapsed time: 5.095508347265422. Arrivals time: 0.2320291162468493 Scheduler time: 4.726997051388025 Scheduler overhead time: 0.04461395833641291 Adapter cache time: 0.024489224422723055 Engine time: 0.04611756233498454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215651961 . Total output tokens: 190166512
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.734420960769057,
    "estimated_duration": 3600.02574302176,
    "input_throughput": 4271.127791184537,
    "output_throughput": 3723.321152906262,
    "total_throughput": 7994.448944090798,
    "itl": 92.39674790746834,
    "ttft": 2079340.0430639535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 322758,
    "finished_requests": 62176,
    "scheduler_time": 12.563577103238547
}
#Debug simulation 
Total elapsed time: 4.734524576924741. Arrivals time: 0.2185367145575583 Scheduler time: 4.333815403282642 Scheduler overhead time: 0.054680321365594864 Adapter cache time: 0.04445335129275918 Engine time: 0.05706058256328106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215651961 . Total output tokens: 190166512
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.070626270957291,
    "estimated_duration": 3600.119725603453,
    "input_throughput": 4695.643558678149,
    "output_throughput": 4089.752597750628,
    "total_throughput": 8785.396156428777,
    "itl": 117.990864207339,
    "ttft": 2008485.2247996135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 322758,
    "finished_requests": 68394,
    "scheduler_time": 27.23806127874636
}
#Debug simulation 
Total elapsed time: 5.070808531250805. Arrivals time: 0.23062689788639545 Scheduler time: 4.703975654672831 Scheduler overhead time: 0.04457150353118777 Adapter cache time: 0.024304748978465796 Engine time: 0.04615209763869643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215651961 . Total output tokens: 190166512
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.740353765897453,
    "estimated_duration": 3600.030055273323,
    "input_throughput": 4269.411856016594,
    "output_throughput": 3722.303368098578,
    "total_throughput": 7991.7152241151725,
    "itl": 92.37919493637541,
    "ttft": 2079718.3995005372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 322758,
    "finished_requests": 62158,
    "scheduler_time": 12.535214615449625
}
#Debug simulation 
Total elapsed time: 4.740449378732592. Arrivals time: 0.2313362737186253 Scheduler time: 4.328461727593094 Scheduler overhead time: 0.05450988234952092 Adapter cache time: 0.04346142569556832 Engine time: 0.05678298370912671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192578431 . Total output tokens: 169779390
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.554574762005359,
    "estimated_duration": 3600.0167258141623,
    "input_throughput": 5219.534916396938,
    "output_throughput": 4512.829033127846,
    "total_throughput": 9732.363949524783,
    "itl": 121.62463944779893,
    "ttft": 1892749.9529999162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 287932,
    "finished_requests": 75825,
    "scheduler_time": 34.7909890896284
}
#Debug simulation 
Total elapsed time: 5.554670792073011. Arrivals time: 0.2517225183546543 Scheduler time: 5.165203345473856 Scheduler overhead time: 0.04389202082529664 Adapter cache time: 0.02767052687704563 Engine time: 0.045395777095109224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192578431 . Total output tokens: 169779390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.445236831903458,
    "estimated_duration": 3600.056769203953,
    "input_throughput": 5072.512788190826,
    "output_throughput": 4386.228054812492,
    "total_throughput": 9458.740843003317,
    "itl": 109.93212893643418,
    "ttft": 1915883.7528013573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 287932,
    "finished_requests": 73670,
    "scheduler_time": 29.531086911255432
}
#Debug simulation 
Total elapsed time: 5.445379612036049. Arrivals time: 0.24396090535447001 Scheduler time: 5.049832817167044 Scheduler overhead time: 0.048238823655992746 Adapter cache time: 0.0305422218516469 Engine time: 0.049929722212255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192578431 . Total output tokens: 169779390
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.059192484244704,
    "estimated_duration": 3600.003249173805,
    "input_throughput": 4639.584423662173,
    "output_throughput": 4006.9586057486276,
    "total_throughput": 8646.543029410801,
    "itl": 85.7667751002885,
    "ttft": 1986038.5719931277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 287932,
    "finished_requests": 67247,
    "scheduler_time": 13.971540318870916
}
#Debug simulation 
Total elapsed time: 5.059324542060494. Arrivals time: 0.22465756721794605 Scheduler time: 4.647446831688285 Scheduler overhead time: 0.058400196488946676 Adapter cache time: 0.04028878081589937 Engine time: 0.06071058148518205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192578431 . Total output tokens: 169779390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.449602414853871,
    "estimated_duration": 3600.0892090250554,
    "input_throughput": 5071.539603582343,
    "output_throughput": 4384.78217718247,
    "total_throughput": 9456.321780764813,
    "itl": 109.8307618471445,
    "ttft": 1916059.6599988926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 287932,
    "finished_requests": 73652,
    "scheduler_time": 29.47857063252601
}
#Debug simulation 
Total elapsed time: 5.4497255007736385. Arrivals time: 0.2426383369602263 Scheduler time: 5.055763601791114 Scheduler overhead time: 0.0480110552161932 Adapter cache time: 0.03061706479638815 Engine time: 0.049843203742057085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192578431 . Total output tokens: 169779390
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.054264692123979,
    "estimated_duration": 3600.062420659086,
    "input_throughput": 4642.323117536476,
    "output_throughput": 4009.0390980936654,
    "total_throughput": 8651.36221563014,
    "itl": 85.86934956746003,
    "ttft": 1985956.3676720855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 287932,
    "finished_requests": 67284,
    "scheduler_time": 14.061594239130255
}
#Debug simulation 
Total elapsed time: 5.05440645897761. Arrivals time: 0.22903242986649275 Scheduler time: 4.6378347696736455 Scheduler overhead time: 0.05826276820152998 Adapter cache time: 0.040537113789469004 Engine time: 0.06086239404976368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192578431 . Total output tokens: 169779390
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.471669194754213,
    "estimated_duration": 3600.10826986479,
    "input_throughput": 5071.248871269553,
    "output_throughput": 4384.643409791908,
    "total_throughput": 9455.89228106146,
    "itl": 109.81122292619294,
    "ttft": 1916024.935922648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 287932,
    "finished_requests": 73648,
    "scheduler_time": 29.4710251834982
}
#Debug simulation 
Total elapsed time: 5.471783927176148. Arrivals time: 0.26462131552398205 Scheduler time: 5.055818634107709 Scheduler overhead time: 0.04785260930657387 Adapter cache time: 0.030984974466264248 Engine time: 0.04977124556899071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192578431 . Total output tokens: 169779390
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.042844993062317,
    "estimated_duration": 3600.0051715270065,
    "input_throughput": 4638.62528089558,
    "output_throughput": 4005.9323008924775,
    "total_throughput": 8644.557581788058,
    "itl": 85.73370607993883,
    "ttft": 1986049.3934472515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 287932,
    "finished_requests": 67231,
    "scheduler_time": 13.943258260153378
}
#Debug simulation 
Total elapsed time: 5.0429561347700655. Arrivals time: 0.23353890422731638 Scheduler time: 4.622142781037837 Scheduler overhead time: 0.05815680557861924 Adapter cache time: 0.040930915623903275 Engine time: 0.060511338990181684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188763411 . Total output tokens: 166351228
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.768046001903713,
    "estimated_duration": 3600.1246189074673,
    "input_throughput": 5327.848624812563,
    "output_throughput": 4672.9149073471,
    "total_throughput": 10000.763532159663,
    "itl": 116.99436350408409,
    "ttft": 1867762.935178109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 282072,
    "finished_requests": 77489,
    "scheduler_time": 35.90279300376199
}
#Debug simulation 
Total elapsed time: 5.7681940058246255. Arrivals time: 0.2752875331789255 Scheduler time: 5.354068119078875 Scheduler overhead time: 0.04544804943725467 Adapter cache time: 0.024473770055919886 Engine time: 0.04726194916293025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188763411 . Total output tokens: 166351228
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.642170494887978,
    "estimated_duration": 3600.0713888334712,
    "input_throughput": 5173.818235319885,
    "output_throughput": 4535.834775568487,
    "total_throughput": 9709.653010888373,
    "itl": 106.04652976911414,
    "ttft": 1892704.0951059184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 282072,
    "finished_requests": 75204,
    "scheduler_time": 30.436785273325974
}
#Debug simulation 
Total elapsed time: 5.642273202072829. Arrivals time: 0.25225086556747556 Scheduler time: 5.237125634681433 Scheduler overhead time: 0.051915536634624004 Adapter cache time: 0.026238930877298117 Engine time: 0.051177908666431904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188763411 . Total output tokens: 166351228
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.2049327827990055,
    "estimated_duration": 3600.031526525808,
    "input_throughput": 4700.926887807542,
    "output_throughput": 4124.826377376322,
    "total_throughput": 8825.753265183863,
    "itl": 83.40321797881938,
    "ttft": 1970483.067063095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 282072,
    "finished_requests": 68367,
    "scheduler_time": 14.417176080862
}
#Debug simulation 
Total elapsed time: 5.205029767006636. Arrivals time: 0.25945301819592714 Scheduler time: 4.760516650509089 Scheduler overhead time: 0.05988170439377427 Adapter cache time: 0.034059653989970684 Engine time: 0.06243093451485038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188763411 . Total output tokens: 166351228
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.868842524942011,
    "estimated_duration": 3600.038150527895,
    "input_throughput": 5173.866559516527,
    "output_throughput": 4536.082207241449,
    "total_throughput": 9709.948766757976,
    "itl": 106.04388045458285,
    "ttft": 1892688.8958231723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407829,
    "arrivals": 282072,
    "finished_requests": 75206,
    "scheduler_time": 30.435324483035227
}
#Debug simulation 
Total elapsed time: 5.868960433173925. Arrivals time: 0.5059089190326631 Scheduler time: 5.2131610587239265 Scheduler overhead time: 0.04926212225109339 Adapter cache time: 0.026025496888905764 Engine time: 0.05116356071084738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188763411 . Total output tokens: 166351228
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.468112553004175,
    "estimated_duration": 3600.0695094424555,
    "input_throughput": 4699.698146278373,
    "output_throughput": 4123.530937684326,
    "total_throughput": 8823.229083962698,
    "itl": 83.35777360119776,
    "ttft": 1970822.2192816583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 282072,
    "finished_requests": 68350,
    "scheduler_time": 14.372193591610356
}
#Debug simulation 
Total elapsed time: 5.468179594259709. Arrivals time: 0.23554069874808192 Scheduler time: 5.047196188941598 Scheduler overhead time: 0.0598318250849843 Adapter cache time: 0.03409726871177554 Engine time: 0.06290043611079454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188763411 . Total output tokens: 166351228
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.88401668285951,
    "estimated_duration": 3600.040701518055,
    "input_throughput": 5173.253177983993,
    "output_throughput": 4535.1984473718085,
    "total_throughput": 9708.451625355801,
    "itl": 106.01511948445403,
    "ttft": 1892611.1461629046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 282072,
    "finished_requests": 75192,
    "scheduler_time": 30.41737771467787
}
#Debug simulation 
Total elapsed time: 5.884085596073419. Arrivals time: 0.5083451415412128 Scheduler time: 5.225421663373709 Scheduler overhead time: 0.049516132567077875 Adapter cache time: 0.026036846451461315 Engine time: 0.051429636776447296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188763411 . Total output tokens: 166351228
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.461375036276877,
    "estimated_duration": 3600.002486847951,
    "input_throughput": 4700.5764751058405,
    "output_throughput": 4124.578261889167,
    "total_throughput": 8825.154736995008,
    "itl": 83.40449058116562,
    "ttft": 1970596.4183220083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 282072,
    "finished_requests": 68363,
    "scheduler_time": 14.419058945599163
}
#Debug simulation 
Total elapsed time: 5.461486486252397. Arrivals time: 0.23544334899634123 Scheduler time: 5.040863125119358 Scheduler overhead time: 0.05984177440404892 Adapter cache time: 0.03405736247077584 Engine time: 0.06295282952487469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186844445 . Total output tokens: 164688198
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.907345688901842,
    "estimated_duration": 3600.1086776302686,
    "input_throughput": 5492.875290925006,
    "output_throughput": 4809.35481408769,
    "total_throughput": 10302.230105012695,
    "itl": 113.93925431073627,
    "ttft": 1834003.5833547735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 279133,
    "finished_requests": 79927,
    "scheduler_time": 37.11072540171983
}
#Debug simulation 
Total elapsed time: 5.907441288698465. Arrivals time: 0.2808567900210619 Scheduler time: 5.49136378755793 Scheduler overhead time: 0.04668226791545749 Adapter cache time: 0.017872827127575874 Engine time: 0.048600473906844854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186844445 . Total output tokens: 164688198
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.743895382154733,
    "estimated_duration": 3600.113694663824,
    "input_throughput": 5316.1279401725,
    "output_throughput": 4655.080761710479,
    "total_throughput": 9971.208701882979,
    "itl": 103.42122223615819,
    "ttft": 1861205.3560933126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867946,
    "arrivals": 279133,
    "finished_requests": 77333,
    "scheduler_time": 31.364025959744428
}
#Debug simulation 
Total elapsed time: 5.743998236954212. Arrivals time: 0.25591419404372573 Scheduler time: 5.342011631466448 Scheduler overhead time: 0.050415373872965574 Adapter cache time: 0.019299335312098265 Engine time: 0.05224291421473026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186844445 . Total output tokens: 164688198
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.275123291183263,
    "estimated_duration": 3600.0230741661867,
    "input_throughput": 4802.9667154299495,
    "output_throughput": 4204.495551325255,
    "total_throughput": 9007.462266755205,
    "itl": 81.91038365383588,
    "ttft": 1943885.5773059812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 279133,
    "finished_requests": 69874,
    "scheduler_time": 14.855203403437287
}
#Debug simulation 
Total elapsed time: 5.275273736100644. Arrivals time: 0.23441837076097727 Scheduler time: 4.861563114449382 Scheduler overhead time: 0.06071631284430623 Adapter cache time: 0.025851044338196516 Engine time: 0.06362233497202396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186844445 . Total output tokens: 164688198
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.0191216161474586,
    "estimated_duration": 3600.092918329394,
    "input_throughput": 5316.196396642248,
    "output_throughput": 4655.160402853418,
    "total_throughput": 9971.356799495667,
    "itl": 103.42335766935226,
    "ttft": 1861202.386873965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407829,
    "arrivals": 279133,
    "finished_requests": 77334,
    "scheduler_time": 31.366204809371386
}
#Debug simulation 
Total elapsed time: 6.019215689972043. Arrivals time: 0.28206599596887827 Scheduler time: 5.591075333766639 Scheduler overhead time: 0.050417809281498194 Adapter cache time: 0.019198867958039045 Engine time: 0.052511750254780054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186844445 . Total output tokens: 164688198
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.277912102174014,
    "estimated_duration": 3600.0700359379875,
    "input_throughput": 4802.904062252483,
    "output_throughput": 4204.440705014309,
    "total_throughput": 9007.344767266792,
    "itl": 81.90702367000753,
    "ttft": 1943829.807245732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 279133,
    "finished_requests": 69874,
    "scheduler_time": 14.85250206761307
}
#Debug simulation 
Total elapsed time: 5.2780344150960445. Arrivals time: 0.2604669416323304 Scheduler time: 4.839029748458415 Scheduler overhead time: 0.0606248308904469 Adapter cache time: 0.02564016543328762 Engine time: 0.06338178692385554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186844445 . Total output tokens: 164688198
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.745989214163274,
    "estimated_duration": 3600.045956701643,
    "input_throughput": 5316.112135839076,
    "output_throughput": 4655.05196365716,
    "total_throughput": 9971.164099496236,
    "itl": 103.42030004907775,
    "ttft": 1861202.0769409384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 279133,
    "finished_requests": 77331,
    "scheduler_time": 31.365224856481042
}
#Debug simulation 
Total elapsed time: 5.746138880960643. Arrivals time: 0.2518232283182442 Scheduler time: 5.348050430417061 Scheduler overhead time: 0.050453780218958855 Adapter cache time: 0.019307986833155155 Engine time: 0.05245298147201538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186844445 . Total output tokens: 164688198
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.280520344618708,
    "estimated_duration": 3600.0077830672094,
    "input_throughput": 4802.820449812679,
    "output_throughput": 4204.512854442742,
    "total_throughput": 9007.33330425542,
    "itl": 81.9060452872204,
    "ttft": 1943803.5034192181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 279133,
    "finished_requests": 69873,
    "scheduler_time": 14.852894560407465
}
#Debug simulation 
Total elapsed time: 5.280653594993055. Arrivals time: 0.237853960134089 Scheduler time: 4.863988914526999 Scheduler overhead time: 0.06089467741549015 Adapter cache time: 0.025454317685216665 Engine time: 0.06332966685295105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185884460 . Total output tokens: 163843506
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.9724723431281745,
    "estimated_duration": 3600.070828993862,
    "input_throughput": 5605.7577638382645,
    "output_throughput": 4875.265469403331,
    "total_throughput": 10481.023233241596,
    "itl": 112.43637716468895,
    "ttft": 1820410.9591348772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 277639,
    "finished_requests": 81454,
    "scheduler_time": 37.663315081074934
}
#Debug simulation 
Total elapsed time: 5.972604620270431. Arrivals time: 0.2844917206093669 Scheduler time: 5.554753336124122 Scheduler overhead time: 0.04712642589583993 Adapter cache time: 0.014937019906938076 Engine time: 0.04873086232692003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185884460 . Total output tokens: 163843506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.80185759998858,
    "estimated_duration": 3600.073991107299,
    "input_throughput": 5422.792433773103,
    "output_throughput": 4714.1547762411465,
    "total_throughput": 10136.947210014248,
    "itl": 102.16252256303663,
    "ttft": 1848314.030640011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 277639,
    "finished_requests": 78725,
    "scheduler_time": 31.796211300724785
}
#Debug simulation 
Total elapsed time: 5.802003878168762. Arrivals time: 0.2772066779434681 Scheduler time: 5.380527643952519 Scheduler overhead time: 0.051030654925853014 Adapter cache time: 0.016047086101025343 Engine time: 0.052851539105176926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185884460 . Total output tokens: 163843506
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.347982434090227,
    "estimated_duration": 3600.015494511507,
    "input_throughput": 4881.498989877147,
    "output_throughput": 4247.6597734963225,
    "total_throughput": 9129.15876337347,
    "itl": 81.07064314912319,
    "ttft": 1933313.381478651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 277639,
    "finished_requests": 70868,
    "scheduler_time": 14.999463600203926
}
#Debug simulation 
Total elapsed time: 5.3480951972305775. Arrivals time: 0.24562809383496642 Scheduler time: 4.92557536624372 Scheduler overhead time: 0.06101443199440837 Adapter cache time: 0.02255016891285777 Engine time: 0.06398558709770441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185884460 . Total output tokens: 163843506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.817348894197494,
    "estimated_duration": 3600.0305093503366,
    "input_throughput": 5422.9320971846655,
    "output_throughput": 4714.449490335793,
    "total_throughput": 10137.381587520458,
    "itl": 102.16325705456151,
    "ttft": 1848230.689441226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 277639,
    "finished_requests": 78728,
    "scheduler_time": 31.796559435612334
}
#Debug simulation 
Total elapsed time: 5.8174616023898125. Arrivals time: 0.258886544033885 Scheduler time: 5.414236584212631 Scheduler overhead time: 0.051173987332731485 Adapter cache time: 0.01610760297626257 Engine time: 0.05263938149437308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185884460 . Total output tokens: 163843506
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.604613230098039,
    "estimated_duration": 3600.0704096062086,
    "input_throughput": 4881.424528005901,
    "output_throughput": 4247.594980141698,
    "total_throughput": 9129.0195081476,
    "itl": 81.06870411488053,
    "ttft": 1933280.5880845487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 277639,
    "finished_requests": 70868,
    "scheduler_time": 14.999025258330748
}
#Debug simulation 
Total elapsed time: 5.604757523164153. Arrivals time: 0.27558123134076595 Scheduler time: 5.1519470158964396 Scheduler overhead time: 0.061506940983235836 Adapter cache time: 0.022383310832083225 Engine time: 0.06395131908357143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185884460 . Total output tokens: 163843506
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.836079782806337,
    "estimated_duration": 3600.1064880989775,
    "input_throughput": 5422.756539156924,
    "output_throughput": 4714.181665487836,
    "total_throughput": 10136.938204644759,
    "itl": 102.15989405896433,
    "ttft": 1848314.355875553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 277639,
    "finished_requests": 78726,
    "scheduler_time": 31.796986056915742
}
#Debug simulation 
Total elapsed time: 5.836190128698945. Arrivals time: 0.2968424600549042 Scheduler time: 5.395081389695406 Scheduler overhead time: 0.05092094372957945 Adapter cache time: 0.01622412819415331 Engine time: 0.052972201723605394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185884460 . Total output tokens: 163843506
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.321160846855491,
    "estimated_duration": 3600.08051419153,
    "input_throughput": 4881.8824831052025,
    "output_throughput": 4247.924994931487,
    "total_throughput": 9129.80747803669,
    "itl": 81.06642055872335,
    "ttft": 1933279.294512547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 277639,
    "finished_requests": 70874,
    "scheduler_time": 14.995270590181683
}
#Debug simulation 
Total elapsed time: 5.3212588909082115. Arrivals time: 0.2633534995839 Scheduler time: 4.881133958231658 Scheduler overhead time: 0.06121225608512759 Adapter cache time: 0.02256850153207779 Engine time: 0.06362495850771666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185392347 . Total output tokens: 163412615
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.0580670409835875,
    "estimated_duration": 3600.066231521385,
    "input_throughput": 5623.280433772694,
    "output_throughput": 4933.415625660414,
    "total_throughput": 10556.696059433107,
    "itl": 111.68562066507927,
    "ttft": 1809935.210975335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 276898,
    "finished_requests": 82328,
    "scheduler_time": 38.2131940080007
}
#Debug simulation 
Total elapsed time: 6.058223428204656. Arrivals time: 0.29110359214246273 Scheduler time: 5.635381978005171 Scheduler overhead time: 0.04750526184216142 Adapter cache time: 0.012223572935909033 Engine time: 0.04936459893360734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185392347 . Total output tokens: 163412615
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.881155761890113,
    "estimated_duration": 3600.1015480309998,
    "input_throughput": 5428.082441365548,
    "output_throughput": 4762.628990112131,
    "total_throughput": 10190.711431477679,
    "itl": 101.65805948546861,
    "ttft": 1839394.4097129535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 276898,
    "finished_requests": 79469,
    "scheduler_time": 32.28114609927977
}
#Debug simulation 
Total elapsed time: 5.881248302292079. Arrivals time: 0.2606514263898134 Scheduler time: 5.4778597466647625 Scheduler overhead time: 0.05136379553005099 Adapter cache time: 0.013480059802532196 Engine time: 0.053493636660277843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185392347 . Total output tokens: 163412615
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.353160109836608,
    "estimated_duration": 3600.0884542743815,
    "input_throughput": 4868.384547382625,
    "output_throughput": 4282.130896449652,
    "total_throughput": 9150.515443832277,
    "itl": 80.91901455462681,
    "ttft": 1927363.7947514954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 276898,
    "finished_requests": 71457,
    "scheduler_time": 15.418568562806518
}
#Debug simulation 
Total elapsed time: 5.353257688693702. Arrivals time: 0.24053588137030602 Scheduler time: 4.937864162959158 Scheduler overhead time: 0.06141743762418628 Adapter cache time: 0.01990775065496564 Engine time: 0.06415872881188989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185392347 . Total output tokens: 163412615
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.866035788785666,
    "estimated_duration": 3600.110639914815,
    "input_throughput": 5428.358446356642,
    "output_throughput": 4762.622795505447,
    "total_throughput": 10190.98124186209,
    "itl": 101.65669625247027,
    "ttft": 1839413.5236930023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 276898,
    "finished_requests": 79472,
    "scheduler_time": 32.28136731967205
}
#Debug simulation 
Total elapsed time: 5.866198044735938. Arrivals time: 0.28719684248790145 Scheduler time: 5.436927569098771 Scheduler overhead time: 0.05107373418286443 Adapter cache time: 0.01343016279861331 Engine time: 0.053084464743733406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185392347 . Total output tokens: 163412615
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.3436628729105,
    "estimated_duration": 3600.01646808883,
    "input_throughput": 4867.818287871119,
    "output_throughput": 4281.705969023821,
    "total_throughput": 9149.52425689494,
    "itl": 80.90477544352993,
    "ttft": 1927393.7589170025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 276898,
    "finished_requests": 71449,
    "scheduler_time": 15.404846439841569
}
#Debug simulation 
Total elapsed time: 5.343783102929592. Arrivals time: 0.2651729458011687 Scheduler time: 4.904030749574304 Scheduler overhead time: 0.061535206623375416 Adapter cache time: 0.019966352730989456 Engine time: 0.06377003015950322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185392347 . Total output tokens: 163412615
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.867196127772331,
    "estimated_duration": 3600.012892122584,
    "input_throughput": 5427.955006149633,
    "output_throughput": 4762.487944839336,
    "total_throughput": 10190.442950988969,
    "itl": 101.65860722983385,
    "ttft": 1839451.7819206384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 276898,
    "finished_requests": 79465,
    "scheduler_time": 32.282988141553965
}
#Debug simulation 
Total elapsed time: 5.867295499891043. Arrivals time: 0.25764645589515567 Scheduler time: 5.466913084499538 Scheduler overhead time: 0.05142180249094963 Adapter cache time: 0.013441793620586395 Engine time: 0.053486103657633066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185392347 . Total output tokens: 163412615
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.354364892933518,
    "estimated_duration": 3600.0678834419814,
    "input_throughput": 4868.463197766938,
    "output_throughput": 4282.080643785293,
    "total_throughput": 9150.543841552231,
    "itl": 80.91674018931741,
    "ttft": 1927453.1805486009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 276898,
    "finished_requests": 71457,
    "scheduler_time": 15.418850955852404
}
#Debug simulation 
Total elapsed time: 5.354548799805343. Arrivals time: 0.2621867498382926 Scheduler time: 4.918419956229627 Scheduler overhead time: 0.06130930548533797 Adapter cache time: 0.019527900498360395 Engine time: 0.06379500171169639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185149554 . Total output tokens: 163203095
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.317279269918799,
    "estimated_duration": 3600.0217971356,
    "input_throughput": 5693.225528886429,
    "output_throughput": 4955.104720252917,
    "total_throughput": 10648.330249139346,
    "itl": 111.30335789756339,
    "ttft": 1803690.853008929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6149540399713436,
    "arrivals": 276581,
    "finished_requests": 82873,
    "scheduler_time": 38.454952896867866
}
#Debug simulation 
Total elapsed time: 6.317343925591558. Arrivals time: 0.5212021735496819 Scheduler time: 5.666353372391313 Scheduler overhead time: 0.04761909553781152 Adapter cache time: 0.010294526349753141 Engine time: 0.04923529643565416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185149554 . Total output tokens: 163203095
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.869811824988574,
    "estimated_duration": 3600.0543736216914,
    "input_throughput": 5497.85557268916,
    "output_throughput": 4784.348293793287,
    "total_throughput": 10282.203866482447,
    "itl": 101.35769701672461,
    "ttft": 1834815.7417545686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6783861268451443,
    "arrivals": 276581,
    "finished_requests": 80026,
    "scheduler_time": 32.49346781068954
}
#Debug simulation 
Total elapsed time: 5.869942520745099. Arrivals time: 0.2584236725233495 Scheduler time: 5.4707084856927395 Scheduler overhead time: 0.05127735109999776 Adapter cache time: 0.011863912921398878 Engine time: 0.05318105826154351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185149554 . Total output tokens: 163203095
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.372306292876601,
    "estimated_duration": 3600.0063884978517,
    "input_throughput": 4929.387085728109,
    "output_throughput": 4295.63404370865,
    "total_throughput": 9225.021129436758,
    "itl": 80.66101796016376,
    "ttft": 1923758.0599190125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6883169457502665,
    "arrivals": 276581,
    "finished_requests": 71786,
    "scheduler_time": 15.477497284330529
}
#Debug simulation 
Total elapsed time: 5.372493722010404. Arrivals time: 0.26917451713234186 Scheduler time: 4.928960788529366 Scheduler overhead time: 0.061689354944974184 Adapter cache time: 0.018356619402766228 Engine time: 0.06416778126731515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185149554 . Total output tokens: 163203095
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.884225940797478,
    "estimated_duration": 3600.1035362487582,
    "input_throughput": 5497.978266654032,
    "output_throughput": 4784.472120473432,
    "total_throughput": 10282.450387127465,
    "itl": 101.35574452614065,
    "ttft": 1834806.3605285764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6367394976457584,
    "arrivals": 276581,
    "finished_requests": 80030,
    "scheduler_time": 32.49276918785607
}
#Debug simulation 
Total elapsed time: 5.884319541975856. Arrivals time: 0.2599119869992137 Scheduler time: 5.4831570675596595 Scheduler overhead time: 0.05133909313008189 Adapter cache time: 0.012002867180854082 Engine time: 0.05340318847447634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185149554 . Total output tokens: 163203095
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.383522717747837,
    "estimated_duration": 3600.0805529749973,
    "input_throughput": 4931.017997730699,
    "output_throughput": 4296.681358203884,
    "total_throughput": 9227.699355934583,
    "itl": 80.679585856811,
    "ttft": 1923574.1375821922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6821034304518254,
    "arrivals": 276581,
    "finished_requests": 71805,
    "scheduler_time": 15.503679998697594
}
#Debug simulation 
Total elapsed time: 5.383621447719634. Arrivals time: 0.2691143536940217 Scheduler time: 4.939882825594395 Scheduler overhead time: 0.06166264694184065 Adapter cache time: 0.018777205608785152 Engine time: 0.06469521624967456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185149554 . Total output tokens: 163203095
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.142615392804146,
    "estimated_duration": 3600.087936062106,
    "input_throughput": 5497.835983875964,
    "output_throughput": 4784.421465782457,
    "total_throughput": 10282.25744965842,
    "itl": 101.35379597073936,
    "ttft": 1834859.6555573277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5937046474730597,
    "arrivals": 276581,
    "finished_requests": 80030,
    "scheduler_time": 32.49316593603738
}
#Debug simulation 
Total elapsed time: 6.142724310979247. Arrivals time: 0.28987469989806414 Scheduler time: 5.711796352639794 Scheduler overhead time: 0.05139231123030186 Adapter cache time: 0.011911613401025534 Engine time: 0.053377298172563314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185149554 . Total output tokens: 163203095
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.37144101690501,
    "estimated_duration": 3600.0408506665276,
    "input_throughput": 4928.371853534691,
    "output_throughput": 4294.778209846539,
    "total_throughput": 9223.15006338123,
    "itl": 80.62210240491866,
    "ttft": 1923916.1100244152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6758899151533844,
    "arrivals": 276581,
    "finished_requests": 71771,
    "scheduler_time": 15.43848016454195
}
#Debug simulation 
Total elapsed time: 5.37156827095896. Arrivals time: 0.24229161068797112 Scheduler time: 4.955032333731651 Scheduler overhead time: 0.061903745867311954 Adapter cache time: 0.01847067568451166 Engine time: 0.06449992628768086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161845506 . Total output tokens: 142589050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.5604860577732325,
    "estimated_duration": 3600.030635958915,
    "input_throughput": 5116.701179153582,
    "output_throughput": 4484.657113396924,
    "total_throughput": 9601.358292550507,
    "itl": 122.50369211171596,
    "ttft": 1831281.7247254143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 241359,
    "finished_requests": 74794,
    "scheduler_time": 35.069330532031074
}
#Debug simulation 
Total elapsed time: 5.560581281781197. Arrivals time: 0.2549080024473369 Scheduler time: 5.1627020430751145 Scheduler overhead time: 0.0439500599168241 Adapter cache time: 0.03305691061541438 Engine time: 0.04531528102234006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161845506 . Total output tokens: 142589050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.434025476220995,
    "estimated_duration": 3600.06986311568,
    "input_throughput": 4985.398806807347,
    "output_throughput": 4371.785992613742,
    "total_throughput": 9357.184799421088,
    "itl": 110.49263395367804,
    "ttft": 1854787.2222563548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 241359,
    "finished_requests": 72905,
    "scheduler_time": 29.96293890572938
}
#Debug simulation 
Total elapsed time: 5.4341977261938155. Arrivals time: 0.24245522869750857 Scheduler time: 5.0343929645605385 Scheduler overhead time: 0.047608448658138514 Adapter cache time: 0.037779579404741526 Engine time: 0.049329263623803854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161845506 . Total output tokens: 142589050
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.101220249664038,
    "estimated_duration": 3600.0392043899324,
    "input_throughput": 4589.9000154916785,
    "output_throughput": 4033.228022154426,
    "total_throughput": 8623.128037646104,
    "itl": 85.64902658333732,
    "ttft": 1924459.5703496416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 241359,
    "finished_requests": 67113,
    "scheduler_time": 14.851515053995193
}
#Debug simulation 
Total elapsed time: 5.1013186275959015. Arrivals time: 0.234407817479223 Scheduler time: 4.665140280965716 Scheduler overhead time: 0.05854583904147148 Adapter cache time: 0.054013924673199654 Engine time: 0.06145887356251478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161845506 . Total output tokens: 142589050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.442699984647334,
    "estimated_duration": 3600.074624178311,
    "input_throughput": 4985.032776673664,
    "output_throughput": 4371.728823146882,
    "total_throughput": 9356.761599820546,
    "itl": 110.4972981956579,
    "ttft": 1854667.1891197814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407829,
    "arrivals": 241359,
    "finished_requests": 72902,
    "scheduler_time": 29.963965687570617
}
#Debug simulation 
Total elapsed time: 5.442830386571586. Arrivals time: 0.24243971006944776 Scheduler time: 5.041566396597773 Scheduler overhead time: 0.04784075962379575 Adapter cache time: 0.03867990896105766 Engine time: 0.04971332801505923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161845506 . Total output tokens: 142589050
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.108096179086715,
    "estimated_duration": 3600.0632861055683,
    "input_throughput": 4590.089030872507,
    "output_throughput": 4033.304096636431,
    "total_throughput": 8623.393127508938,
    "itl": 85.64820044960226,
    "ttft": 1924593.1851465288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 241359,
    "finished_requests": 67115,
    "scheduler_time": 14.851927876257445
}
#Debug simulation 
Total elapsed time: 5.108239847701043. Arrivals time: 0.23728381097316742 Scheduler time: 4.668848247267306 Scheduler overhead time: 0.05865743150934577 Adapter cache time: 0.05443952139467001 Engine time: 0.06105066975578666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161845506 . Total output tokens: 142589050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.445239690132439,
    "estimated_duration": 3600.049641310697,
    "input_throughput": 4985.274590120878,
    "output_throughput": 4371.746661323805,
    "total_throughput": 9357.021251444683,
    "itl": 110.49167641624521,
    "ttft": 1854707.506074321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 241359,
    "finished_requests": 72903,
    "scheduler_time": 29.963687693052393
}
#Debug simulation 
Total elapsed time: 5.4453323520720005. Arrivals time: 0.243933183606714 Scheduler time: 5.04280810803175 Scheduler overhead time: 0.047743847128003836 Adapter cache time: 0.03874892368912697 Engine time: 0.04947388498112559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161845506 . Total output tokens: 142589050
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.098882019054145,
    "estimated_duration": 3600.092571293646,
    "input_throughput": 4589.938084303828,
    "output_throughput": 4033.2049002791227,
    "total_throughput": 8623.142984582952,
    "itl": 85.64595532528976,
    "ttft": 1924599.6968017693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 241359,
    "finished_requests": 67114,
    "scheduler_time": 14.850350640039427
}
#Debug simulation 
Total elapsed time: 5.0989776449278. Arrivals time: 0.23291910253465176 Scheduler time: 4.664079376030713 Scheduler overhead time: 0.058675280306488276 Adapter cache time: 0.05411918926984072 Engine time: 0.06129108555614948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157976578 . Total output tokens: 139181202
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.759460962377489,
    "estimated_duration": 3600.019426869572,
    "input_throughput": 5342.526447620977,
    "output_throughput": 4674.125887879448,
    "total_throughput": 10016.652335500425,
    "itl": 117.80882906751593,
    "ttft": 1783935.736082708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 235577,
    "finished_requests": 78014,
    "scheduler_time": 36.77356086118882
}
#Debug simulation 
Total elapsed time: 5.759617158211768. Arrivals time: 0.2712093396112323 Scheduler time: 5.345919055864215 Scheduler overhead time: 0.04516386706382036 Adapter cache time: 0.028867801185697317 Engine time: 0.04693367751315236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157976578 . Total output tokens: 139181202
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.639838104136288,
    "estimated_duration": 3600.0164981525895,
    "input_throughput": 5198.341454713741,
    "output_throughput": 4548.468599630832,
    "total_throughput": 9746.810054344573,
    "itl": 106.42152696693643,
    "ttft": 1809209.7748163615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 235577,
    "finished_requests": 75846,
    "scheduler_time": 31.397694051135772
}
#Debug simulation 
Total elapsed time: 5.639940022025257. Arrivals time: 0.26776320300996304 Scheduler time: 5.215959103778005 Scheduler overhead time: 0.049137008376419544 Adapter cache time: 0.032606182619929314 Engine time: 0.05113893933594227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157976578 . Total output tokens: 139181202
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.276432276703417,
    "estimated_duration": 3600.0782293908223,
    "input_throughput": 4779.635581116705,
    "output_throughput": 4175.340379351569,
    "total_throughput": 8954.975960468273,
    "itl": 82.84623555315879,
    "ttft": 1886742.8481472258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 235577,
    "finished_requests": 69691,
    "scheduler_time": 15.630291629795781
}
#Debug simulation 
Total elapsed time: 5.276555948890746. Arrivals time: 0.24623944982886314 Scheduler time: 4.8322342853061855 Scheduler overhead time: 0.0605001007206738 Adapter cache time: 0.04554728604853153 Engine time: 0.06323871295899153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157976578 . Total output tokens: 139181202
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.636132047045976,
    "estimated_duration": 3600.0624830923057,
    "input_throughput": 5198.499494910058,
    "output_throughput": 4548.432999955839,
    "total_throughput": 9746.932494865896,
    "itl": 106.4207126281154,
    "ttft": 1809232.2704113782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407826,
    "arrivals": 235577,
    "finished_requests": 75848,
    "scheduler_time": 31.39922678163729
}
#Debug simulation 
Total elapsed time: 5.636303722858429. Arrivals time: 0.244927900377661 Scheduler time: 5.234734659548849 Scheduler overhead time: 0.049339073710143566 Adapter cache time: 0.03268546285107732 Engine time: 0.05115438997745514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157976578 . Total output tokens: 139181202
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.266008413862437,
    "estimated_duration": 3600.0917485653067,
    "input_throughput": 4779.735129488701,
    "output_throughput": 4175.376643106494,
    "total_throughput": 8955.111772595195,
    "itl": 82.84702883393683,
    "ttft": 1886763.3280666422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 235577,
    "finished_requests": 69692,
    "scheduler_time": 15.631069754667937
}
#Debug simulation 
Total elapsed time: 5.266108619980514. Arrivals time: 0.23647549794986844 Scheduler time: 4.832665276713669 Scheduler overhead time: 0.060266425367444754 Adapter cache time: 0.04505063546821475 Engine time: 0.06294793728739023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157976578 . Total output tokens: 139181202
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.6412105252966285,
    "estimated_duration": 3600.005382551399,
    "input_throughput": 5198.220838974764,
    "output_throughput": 4548.428199403175,
    "total_throughput": 9746.64903837794,
    "itl": 106.42093584551255,
    "ttft": 1809261.4181223926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 235577,
    "finished_requests": 75844,
    "scheduler_time": 31.399426002048653
}
#Debug simulation 
Total elapsed time: 5.641343127004802. Arrivals time: 0.2488268632441759 Scheduler time: 5.235707985237241 Scheduler overhead time: 0.04948550369590521 Adapter cache time: 0.03250488359481096 Engine time: 0.0513636521063745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157976578 . Total output tokens: 139181202
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.255833414848894,
    "estimated_duration": 3600.0025572425184,
    "input_throughput": 4779.735771404572,
    "output_throughput": 4175.308422978826,
    "total_throughput": 8955.044194383398,
    "itl": 82.84764859552669,
    "ttft": 1886782.9267238372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 235577,
    "finished_requests": 69690,
    "scheduler_time": 15.630301250730305
}
#Debug simulation 
Total elapsed time: 5.255973076913506. Arrivals time: 0.24576135259121656 Scheduler time: 4.812511540949345 Scheduler overhead time: 0.06025127600878477 Adapter cache time: 0.0454332591034472 Engine time: 0.06309334142133594 
