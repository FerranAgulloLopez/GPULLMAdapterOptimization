INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.276542840991169,
    "estimated_duration": 3600.082470757847,
    "input_throughput": 5684.749215117794,
    "output_throughput": 4947.991648716364,
    "total_throughput": 10632.740863834157,
    "itl": 116.62204189646674,
    "ttft": 1730676.4334308938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.529500186885786,
    "arrivals": 232682,
    "finished_requests": 82785,
    "scheduler_time": 98.46645443770332
}
#Debug simulation 
Total elapsed time: 6.276651030872017. Arrivals time: 0.2531157531775534 Scheduler time: 5.890854959376156 Scheduler overhead time: 0.04702829197049141 Adapter cache time: 0.01607188070192933 Engine time: 0.047527799382805824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.2593139060772955,
    "estimated_duration": 3600.0289358715486,
    "input_throughput": 5526.414746770212,
    "output_throughput": 4816.499064000492,
    "total_throughput": 10342.913810770704,
    "itl": 108.96683492562104,
    "ttft": 1756318.341424459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.000301066855913,
    "arrivals": 232682,
    "finished_requests": 80533,
    "scheduler_time": 98.4044779140259
}
#Debug simulation 
Total elapsed time: 6.259386189747602. Arrivals time: 0.2499788817949593 Scheduler time: 5.868051676079631 Scheduler overhead time: 0.04950835416093469 Adapter cache time: 0.018172928132116795 Engine time: 0.050357019528746605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.682600066997111,
    "estimated_duration": 3600.0732789600984,
    "input_throughput": 5226.030567198498,
    "output_throughput": 4561.242154699486,
    "total_throughput": 9787.272721897984,
    "itl": 96.61816842081436,
    "ttft": 1807762.4789559392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.410015283725233,
    "arrivals": 232682,
    "finished_requests": 76166,
    "scheduler_time": 98.31052411709796
}
#Debug simulation 
Total elapsed time: 5.6826959499157965. Arrivals time: 0.2561976248398423 Scheduler time: 5.268564699683338 Scheduler overhead time: 0.054387901443988085 Adapter cache time: 0.02247583493590355 Engine time: 0.055059623904526234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.051804444286972,
    "estimated_duration": 3600.0692577753653,
    "input_throughput": 5526.986170342602,
    "output_throughput": 4816.841221192426,
    "total_throughput": 10343.827391535027,
    "itl": 108.95746676353275,
    "ttft": 1756099.42230222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.647116800341749,
    "arrivals": 232682,
    "finished_requests": 80541,
    "scheduler_time": 98.41482492292076
}
#Debug simulation 
Total elapsed time: 6.051919793244451. Arrivals time: 0.2502118614502251 Scheduler time: 5.659861932974309 Scheduler overhead time: 0.049713803455233574 Adapter cache time: 0.01842490630224347 Engine time: 0.05013428255915642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.651224839966744,
    "estimated_duration": 3600.0458123360054,
    "input_throughput": 5225.880719499043,
    "output_throughput": 4561.326120831978,
    "total_throughput": 9787.20684033102,
    "itl": 96.62076155490973,
    "ttft": 1807687.133220281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.407722029639418,
    "arrivals": 232682,
    "finished_requests": 76167,
    "scheduler_time": 98.30912311380273
}
#Debug simulation 
Total elapsed time: 5.651318939868361. Arrivals time: 0.2401422611437738 Scheduler time: 5.253455707803369 Scheduler overhead time: 0.054364573676139116 Adapter cache time: 0.022410567849874496 Engine time: 0.05518773663789034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.117328309919685,
    "estimated_duration": 3600.0678905020477,
    "input_throughput": 5527.504926365411,
    "output_throughput": 4817.012491834322,
    "total_throughput": 10344.517418199732,
    "itl": 108.94444937329098,
    "ttft": 1756124.970489853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.228431250327241,
    "arrivals": 232682,
    "finished_requests": 80545,
    "scheduler_time": 98.42498770075699
}
#Debug simulation 
Total elapsed time: 6.117476581130177. Arrivals time: 0.2542304270900786 Scheduler time: 5.721141865476966 Scheduler overhead time: 0.049710785038769245 Adapter cache time: 0.018285082653164864 Engine time: 0.05050439154729247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.704373048152775,
    "estimated_duration": 3600.0406497505023,
    "input_throughput": 5226.759314871643,
    "output_throughput": 4561.5296041554675,
    "total_throughput": 9788.28891902711,
    "itl": 96.61668306623362,
    "ttft": 1807671.1347921134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.25063694043086,
    "arrivals": 232682,
    "finished_requests": 76173,
    "scheduler_time": 98.31504564182879
}
#Debug simulation 
Total elapsed time: 5.704465163871646. Arrivals time: 0.26228931872174144 Scheduler time: 5.284564634785056 Scheduler overhead time: 0.05434714816510677 Adapter cache time: 0.022534532006829977 Engine time: 0.054881521966308355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.1381482682190835,
    "estimated_duration": 3600.0629924311384,
    "input_throughput": 5667.9433229084825,
    "output_throughput": 4944.906252314838,
    "total_throughput": 10612.84957522332,
    "itl": 116.58386742847227,
    "ttft": 1726011.330047429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.874871692722721,
    "arrivals": 231202,
    "finished_requests": 82369,
    "scheduler_time": 98.42987915618545
}
#Debug simulation 
Total elapsed time: 6.13826623512432. Arrivals time: 0.2563309110701084 Scheduler time: 5.7490987768396735 Scheduler overhead time: 0.04732452658936381 Adapter cache time: 0.015214013401418924 Engine time: 0.04812416434288025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.8911706930957735,
    "estimated_duration": 3600.0091654111,
    "input_throughput": 5511.458468115939,
    "output_throughput": 4814.644964388778,
    "total_throughput": 10326.103432504717,
    "itl": 108.89624143654954,
    "ttft": 1751746.3985788815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.037386506581687,
    "arrivals": 231202,
    "finished_requests": 80133,
    "scheduler_time": 98.37609119474675
}
#Debug simulation 
Total elapsed time: 5.891314567066729. Arrivals time: 0.2567467777989805 Scheduler time: 5.495052118320018 Scheduler overhead time: 0.04947776719927788 Adapter cache time: 0.01661556586623192 Engine time: 0.05009694956243038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.639137921854854,
    "estimated_duration": 3600.0594607878106,
    "input_throughput": 5219.954338167421,
    "output_throughput": 4558.319988528441,
    "total_throughput": 9778.274326695862,
    "itl": 96.43077774052567,
    "ttft": 1801451.135279932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0069552817009635,
    "arrivals": 231202,
    "finished_requests": 75882,
    "scheduler_time": 98.35412228006376
}
#Debug simulation 
Total elapsed time: 5.639225695282221. Arrivals time: 0.24812388233840466 Scheduler time: 5.234104686416686 Scheduler overhead time: 0.054272104520350695 Adapter cache time: 0.021064124535769224 Engine time: 0.0556715177372098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.899230074137449,
    "estimated_duration": 3600.072984717919,
    "input_throughput": 5512.359633885292,
    "output_throughput": 4814.620723962382,
    "total_throughput": 10326.980357847675,
    "itl": 108.88351781759125,
    "ttft": 1751745.4788783365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.603175628106103,
    "arrivals": 231202,
    "finished_requests": 80141,
    "scheduler_time": 98.3879492808192
}
#Debug simulation 
Total elapsed time: 5.899337626993656. Arrivals time: 0.28299220837652683 Scheduler time: 5.476728357840329 Scheduler overhead time: 0.049299223348498344 Adapter cache time: 0.016600335482507944 Engine time: 0.05015486013144255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.657292468007654,
    "estimated_duration": 3600.0851186676327,
    "input_throughput": 5219.873525366753,
    "output_throughput": 4558.104172290534,
    "total_throughput": 9777.977697657287,
    "itl": 96.42812184480073,
    "ttft": 1801596.998438802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.920331425922948,
    "arrivals": 231202,
    "finished_requests": 75881,
    "scheduler_time": 98.3559698317565
}
#Debug simulation 
Total elapsed time: 5.657460106071085. Arrivals time: 0.2706326334737241 Scheduler time: 5.22921442752704 Scheduler overhead time: 0.054598457645624876 Adapter cache time: 0.021191783249378204 Engine time: 0.05579825909808278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.917260955087841,
    "estimated_duration": 3600.014204553632,
    "input_throughput": 5513.39435685949,
    "output_throughput": 4815.780164997879,
    "total_throughput": 10329.174521857369,
    "itl": 108.86774529630921,
    "ttft": 1751623.2061411212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.277227030182237,
    "arrivals": 231202,
    "finished_requests": 80155,
    "scheduler_time": 98.39523777765687
}
#Debug simulation 
Total elapsed time: 5.917355476878583. Arrivals time: 0.2643348667770624 Scheduler time: 5.513571482151747 Scheduler overhead time: 0.04956982750445604 Adapter cache time: 0.016385553404688835 Engine time: 0.05007369723170996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.612712491303682,
    "estimated_duration": 3600.073987016226,
    "input_throughput": 5219.950219849551,
    "output_throughput": 4558.236874903992,
    "total_throughput": 9778.187094753544,
    "itl": 96.42862316120825,
    "ttft": 1801672.405917832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.861976251099286,
    "arrivals": 231202,
    "finished_requests": 75883,
    "scheduler_time": 98.3548357818033
}
#Debug simulation 
Total elapsed time: 5.612833641003817. Arrivals time: 0.24673978192731738 Scheduler time: 5.210044137667865 Scheduler overhead time: 0.05430815787985921 Adapter cache time: 0.020870119333267212 Engine time: 0.05506150331348181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.007024290971458,
    "estimated_duration": 3600.0351610745797,
    "input_throughput": 5704.574561396778,
    "output_throughput": 4945.7978056762495,
    "total_throughput": 10650.372367073027,
    "itl": 116.3939862137614,
    "ttft": 1723081.2022034249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.253305243719407,
    "arrivals": 230450,
    "finished_requests": 82580,
    "scheduler_time": 98.48415826093783
}
#Debug simulation 
Total elapsed time: 6.007162315770984. Arrivals time: 0.26450341288000345 Scheduler time: 5.61168522387743 Scheduler overhead time: 0.04701027646660805 Adapter cache time: 0.014074282255023718 Engine time: 0.047459978610277176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.140365982893854,
    "estimated_duration": 3600.1213288839026,
    "input_throughput": 5547.618864887446,
    "output_throughput": 4815.084664208832,
    "total_throughput": 10362.703529096278,
    "itl": 108.70043840872812,
    "ttft": 1747348.6185767679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1166757594328445,
    "arrivals": 230450,
    "finished_requests": 80319,
    "scheduler_time": 98.47111213096998
}
#Debug simulation 
Total elapsed time: 6.140458999201655. Arrivals time: 0.26648671831935644 Scheduler time: 5.734686537180096 Scheduler overhead time: 0.04945315793156624 Adapter cache time: 0.015914585441350937 Engine time: 0.05040571512654424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.601220286916941,
    "estimated_duration": 3600.1034340378656,
    "input_throughput": 5261.949926464461,
    "output_throughput": 4569.189830623901,
    "total_throughput": 9831.139757088362,
    "itl": 96.21123070830694,
    "ttft": 1795221.8303275458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5243965191440925,
    "arrivals": 230450,
    "finished_requests": 76196,
    "scheduler_time": 98.60764060269224
}
#Debug simulation 
Total elapsed time: 5.601328251883388. Arrivals time: 0.25396420108154416 Scheduler time: 5.191628164611757 Scheduler overhead time: 0.05376326059922576 Adapter cache time: 0.020848095882683992 Engine time: 0.055349298287183046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.13905683811754,
    "estimated_duration": 3600.040618313879,
    "input_throughput": 5547.908514808493,
    "output_throughput": 4815.35705786544,
    "total_throughput": 10363.265572673932,
    "itl": 108.69343417075584,
    "ttft": 1747294.6415694247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.807111960067408,
    "arrivals": 230450,
    "finished_requests": 80320,
    "scheduler_time": 98.4746668782044
}
#Debug simulation 
Total elapsed time: 6.139162375126034. Arrivals time: 0.25684083299711347 Scheduler time: 5.743247208651155 Scheduler overhead time: 0.04956901725381613 Adapter cache time: 0.01572750275954604 Engine time: 0.05036382796242833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.631952858995646,
    "estimated_duration": 3600.0022299567863,
    "input_throughput": 5262.310351465367,
    "output_throughput": 4569.655224962867,
    "total_throughput": 9831.965576428232,
    "itl": 96.20582877902949,
    "ttft": 1795188.4125488256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.445801716051092,
    "arrivals": 230450,
    "finished_requests": 76201,
    "scheduler_time": 98.60809295055928
}
#Debug simulation 
Total elapsed time: 5.63204528670758. Arrivals time: 0.2490015965886414 Scheduler time: 5.226455352734774 Scheduler overhead time: 0.05425122985616326 Adapter cache time: 0.020983124151825905 Engine time: 0.0555291255004704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.15013444237411,
    "estimated_duration": 3600.010817248971,
    "input_throughput": 5548.3794393883945,
    "output_throughput": 4815.965806805231,
    "total_throughput": 10364.345246193625,
    "itl": 108.68832506445818,
    "ttft": 1747180.4561816975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.568611805778912,
    "arrivals": 230450,
    "finished_requests": 80326,
    "scheduler_time": 98.47905434950832
}
#Debug simulation 
Total elapsed time: 6.150204378180206. Arrivals time: 0.49332535546272993 Scheduler time: 5.518041955772787 Scheduler overhead time: 0.04936751304194331 Adapter cache time: 0.015612023416906595 Engine time: 0.05042251152917743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.605057423003018,
    "estimated_duration": 3600.090302369959,
    "input_throughput": 5262.599937431529,
    "output_throughput": 4569.737317191713,
    "total_throughput": 9832.337254623242,
    "itl": 96.20308298585462,
    "ttft": 1795305.6220914817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.434090078361359,
    "arrivals": 230450,
    "finished_requests": 76205,
    "scheduler_time": 98.61115824137076
}
#Debug simulation 
Total elapsed time: 5.605214179027826. Arrivals time: 0.2508664601482451 Scheduler time: 5.19867440732196 Scheduler overhead time: 0.05373316444456577 Adapter cache time: 0.020763727836310863 Engine time: 0.05545636545866728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.963859015144408,
    "estimated_duration": 3600.0719989044533,
    "input_throughput": 5629.439079598217,
    "output_throughput": 4957.309744202606,
    "total_throughput": 10586.748823800823,
    "itl": 116.71594394942464,
    "ttft": 1725458.9612556312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.367242433438087,
    "arrivals": 230128,
    "finished_requests": 82309,
    "scheduler_time": 98.66551006126956
}
#Debug simulation 
Total elapsed time: 5.963950404897332. Arrivals time: 0.26948375161737204 Scheduler time: 5.565316764172167 Scheduler overhead time: 0.04637875035405159 Adapter cache time: 0.013486600946635008 Engine time: 0.04725352907553315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.836265292018652,
    "estimated_duration": 3600.1081498218905,
    "input_throughput": 5488.317622062971,
    "output_throughput": 4833.760063808344,
    "total_throughput": 10322.077685871314,
    "itl": 108.9570655225609,
    "ttft": 1749391.8362372813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.086881172368307,
    "arrivals": 230128,
    "finished_requests": 80219,
    "scheduler_time": 98.73955020116755
}
#Debug simulation 
Total elapsed time: 5.836359739303589. Arrivals time: 0.25403483491390944 Scheduler time: 5.444750961381942 Scheduler overhead time: 0.04867970058694482 Adapter cache time: 0.015589385759085417 Engine time: 0.05001940578222275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.598924390040338,
    "estimated_duration": 3600.013323486986,
    "input_throughput": 5211.825155643157,
    "output_throughput": 4594.09077519204,
    "total_throughput": 9805.915930835197,
    "itl": 96.24836221450146,
    "ttft": 1795919.1923958554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.457268916899365,
    "arrivals": 230128,
    "finished_requests": 76212,
    "scheduler_time": 99.03507044047161
}
#Debug simulation 
Total elapsed time: 5.599082856904715. Arrivals time: 0.24778649164363742 Scheduler time: 5.197610245551914 Scheduler overhead time: 0.0535775669850409 Adapter cache time: 0.01937738060951233 Engine time: 0.055078134406358004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.801549558062106,
    "estimated_duration": 3600.024303131318,
    "input_throughput": 5482.086046706364,
    "output_throughput": 4829.69628423805,
    "total_throughput": 10311.782330944414,
    "itl": 108.7108032857317,
    "ttft": 1750069.0024679983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.798990680016574,
    "arrivals": 230128,
    "finished_requests": 80139,
    "scheduler_time": 98.74172829313106
}
#Debug simulation 
Total elapsed time: 5.801646592095494. Arrivals time: 0.254869953263551 Scheduler time: 5.4097823849879205 Scheduler overhead time: 0.04836478549987078 Adapter cache time: 0.015500679612159729 Engine time: 0.049851404037326574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.58481059782207,
    "estimated_duration": 3600.0425843909284,
    "input_throughput": 5211.412798655581,
    "output_throughput": 4593.9359361211655,
    "total_throughput": 9805.348734776748,
    "itl": 96.24902164936259,
    "ttft": 1795999.0026554735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.431068773432661,
    "arrivals": 230128,
    "finished_requests": 76209,
    "scheduler_time": 99.03594114628712
}
#Debug simulation 
Total elapsed time: 5.584902679082006. Arrivals time: 0.24759132461622357 Scheduler time: 5.183859644457698 Scheduler overhead time: 0.05342648318037391 Adapter cache time: 0.019605517387390137 Engine time: 0.05498634837567806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.786760499700904,
    "estimated_duration": 3600.0229048028586,
    "input_throughput": 5480.438464343721,
    "output_throughput": 4828.700666545325,
    "total_throughput": 10309.139130889045,
    "itl": 108.6309045695312,
    "ttft": 1750259.5180271838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.623791506574478,
    "arrivals": 230128,
    "finished_requests": 80117,
    "scheduler_time": 98.74776843283077
}
#Debug simulation 
Total elapsed time: 5.786939466837794. Arrivals time: 0.25645391177386045 Scheduler time: 5.393206973094493 Scheduler overhead time: 0.04857461526989937 Adapter cache time: 0.015314709860831499 Engine time: 0.05018163565546274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.593065326102078,
    "estimated_duration": 3600.0624409202064,
    "input_throughput": 5211.591828725132,
    "output_throughput": 4593.799766365373,
    "total_throughput": 9805.391595090505,
    "itl": 96.24592267946586,
    "ttft": 1795996.8440737512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.389180731289114,
    "arrivals": 230128,
    "finished_requests": 76210,
    "scheduler_time": 99.03702999664145
}
#Debug simulation 
Total elapsed time: 5.5931565458886325. Arrivals time: 0.2478009150363505 Scheduler time: 5.1916420087218285 Scheduler overhead time: 0.0535596190020442 Adapter cache time: 0.019355677999556065 Engine time: 0.05528732156381011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.1505391439422965,
    "estimated_duration": 3600.024324434019,
    "input_throughput": 5678.045523543418,
    "output_throughput": 4936.84358724275,
    "total_throughput": 10614.889110786167,
    "itl": 116.90045016554492,
    "ttft": 1649693.860418262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.667849469040894,
    "arrivals": 200953,
    "finished_requests": 82649,
    "scheduler_time": 97.41047031818354
}
#Debug simulation 
Total elapsed time: 6.150661118328571. Arrivals time: 0.2632365976460278 Scheduler time: 5.7383963274769485 Scheduler overhead time: 0.04789536027237773 Adapter cache time: 0.030853902455419302 Engine time: 0.04785923333838582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.9468851909041405,
    "estimated_duration": 3600.028655963729,
    "input_throughput": 5526.646007953459,
    "output_throughput": 4806.923403604806,
    "total_throughput": 10333.569411558265,
    "itl": 109.11692325411181,
    "ttft": 1677197.9160787107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.172126265060626,
    "arrivals": 200953,
    "finished_requests": 80443,
    "scheduler_time": 97.35627656068792
}
#Debug simulation 
Total elapsed time: 5.947027768008411. Arrivals time: 0.2611914183944464 Scheduler time: 5.524746868759394 Scheduler overhead time: 0.05081263883039355 Adapter cache time: 0.035802618600428104 Engine time: 0.05078002903610468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.653515917249024,
    "estimated_duration": 3600.088300882684,
    "input_throughput": 5283.444018674872,
    "output_throughput": 4592.288749124976,
    "total_throughput": 9875.732767799847,
    "itl": 95.86724491536793,
    "ttft": 1724875.1382541056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.0625374077124,
    "arrivals": 200953,
    "finished_requests": 76872,
    "scheduler_time": 98.12789373400503
}
#Debug simulation 
Total elapsed time: 5.653628715313971. Arrivals time: 0.2451850576326251 Scheduler time: 5.227689457125962 Scheduler overhead time: 0.05439836159348488 Adapter cache time: 0.044625929556787014 Engine time: 0.05577500956133008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.892579786945134,
    "estimated_duration": 3600.078806388725,
    "input_throughput": 5528.242594212543,
    "output_throughput": 4808.246133190595,
    "total_throughput": 10336.488727403139,
    "itl": 109.0802109995302,
    "ttft": 1676834.0357886765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.9207914618639,
    "arrivals": 200953,
    "finished_requests": 80465,
    "scheduler_time": 97.38828579020756
}
#Debug simulation 
Total elapsed time: 5.892703117802739. Arrivals time: 0.25325811421498656 Scheduler time: 5.480652015656233 Scheduler overhead time: 0.049325010273605585 Adapter cache time: 0.03599199280142784 Engine time: 0.05012646410614252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.606017709709704,
    "estimated_duration": 3600.0500573535037,
    "input_throughput": 5283.814307288714,
    "output_throughput": 4592.782804846548,
    "total_throughput": 9876.597112135263,
    "itl": 95.86405137051861,
    "ttft": 1724682.497698429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.864944628193346,
    "arrivals": 200953,
    "finished_requests": 76878,
    "scheduler_time": 98.13224063214784
}
#Debug simulation 
Total elapsed time: 5.6061808918602765. Arrivals time: 0.24419678235426545 Scheduler time: 5.181998766027391 Scheduler overhead time: 0.05411730566993356 Adapter cache time: 0.04432161618024111 Engine time: 0.05562770552933216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.888198385946453,
    "estimated_duration": 3600.0284041343484,
    "input_throughput": 5530.711084705364,
    "output_throughput": 4809.897883059535,
    "total_throughput": 10340.608967764898,
    "itl": 109.04216729924987,
    "ttft": 1676533.462041715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.806588248853641,
    "arrivals": 200953,
    "finished_requests": 80500,
    "scheduler_time": 97.41532982290435
}
#Debug simulation 
Total elapsed time: 5.888293793890625. Arrivals time: 0.25340674724429846 Scheduler time: 5.475599657744169 Scheduler overhead time: 0.0496042906306684 Adapter cache time: 0.036012849770486355 Engine time: 0.050286551006138325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.652899087872356,
    "estimated_duration": 3600.10303549162,
    "input_throughput": 5283.874048177719,
    "output_throughput": 4592.8582701639425,
    "total_throughput": 9876.732318341661,
    "itl": 95.85588053802098,
    "ttft": 1724645.7877533445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.689924627896684,
    "arrivals": 200953,
    "finished_requests": 76880,
    "scheduler_time": 98.13857950308916
}
#Debug simulation 
Total elapsed time: 5.652992768678814. Arrivals time: 0.25023134145885706 Scheduler time: 5.22304189670831 Scheduler overhead time: 0.054239073768258095 Adapter cache time: 0.04386876244097948 Engine time: 0.055634383112192154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.009357359725982,
    "estimated_duration": 3600.0126496033517,
    "input_throughput": 5725.049050111207,
    "output_throughput": 5000.326874402336,
    "total_throughput": 10725.375924513544,
    "itl": 115.49259817462774,
    "ttft": 1633555.814165147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.95218305741475,
    "arrivals": 198151,
    "finished_requests": 83306,
    "scheduler_time": 98.53845278426374
}
#Debug simulation 
Total elapsed time: 6.00951628992334. Arrivals time: 0.26084602158516645 Scheduler time: 5.5993261225521564 Scheduler overhead time: 0.046452156733721495 Adapter cache time: 0.03339417790994048 Engine time: 0.04737879289314151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.188917941879481,
    "estimated_duration": 3600.0009190749815,
    "input_throughput": 5623.1405088645115,
    "output_throughput": 4909.795690980449,
    "total_throughput": 10532.93619984496,
    "itl": 106.96970884385019,
    "ttft": 1653366.229801983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.584012485420956,
    "arrivals": 198151,
    "finished_requests": 81814,
    "scheduler_time": 99.28268551465193
}
#Debug simulation 
Total elapsed time: 6.188982511870563. Arrivals time: 0.26058432180434465 Scheduler time: 5.7679825481027365 Scheduler overhead time: 0.04958257731050253 Adapter cache time: 0.03608740447089076 Engine time: 0.05094405263662338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.7773370440118015,
    "estimated_duration": 3600.083914662492,
    "input_throughput": 5417.120673374171,
    "output_throughput": 4731.167773792519,
    "total_throughput": 10148.28844716669,
    "itl": 93.1938841892838,
    "ttft": 1691453.0330094777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.798375597567881,
    "arrivals": 198151,
    "finished_requests": 78854,
    "scheduler_time": 100.83385196103701
}
#Debug simulation 
Total elapsed time: 5.777433392126113. Arrivals time: 0.2537388503551483 Scheduler time: 5.344311058986932 Scheduler overhead time: 0.05528040835633874 Adapter cache time: 0.04055409086868167 Engine time: 0.05718730203807354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.964714962989092,
    "estimated_duration": 3600.0468729304985,
    "input_throughput": 5624.698987187583,
    "output_throughput": 4911.33188652273,
    "total_throughput": 10536.030873710313,
    "itl": 106.93994817774659,
    "ttft": 1653061.8655964339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.584767237757621,
    "arrivals": 198151,
    "finished_requests": 81835,
    "scheduler_time": 99.30909728837328
}
#Debug simulation 
Total elapsed time: 5.964878893923014. Arrivals time: 0.2569061820395291 Scheduler time: 5.548478590790182 Scheduler overhead time: 0.04920579586178064 Adapter cache time: 0.03606320405378938 Engine time: 0.050627728924155235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.748545648995787,
    "estimated_duration": 3600.1026052388142,
    "input_throughput": 5416.994496662782,
    "output_throughput": 4731.097934601824,
    "total_throughput": 10148.092431264606,
    "itl": 93.1912914002648,
    "ttft": 1691360.0959476365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.696464967587616,
    "arrivals": 198151,
    "finished_requests": 78854,
    "scheduler_time": 100.83622294147958
}
#Debug simulation 
Total elapsed time: 5.7486399109475315. Arrivals time: 0.25251674884930253 Scheduler time: 5.31744231749326 Scheduler overhead time: 0.054962489288300276 Adapter cache time: 0.0403300067409873 Engine time: 0.05691126687452197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.921993799041957,
    "estimated_duration": 3600.052736519629,
    "input_throughput": 5625.891197244013,
    "output_throughput": 4912.7577550706155,
    "total_throughput": 10538.648952314628,
    "itl": 106.91628682557823,
    "ttft": 1652636.2456165042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.63605512905937,
    "arrivals": 198151,
    "finished_requests": 81854,
    "scheduler_time": 99.334646616317
}
#Debug simulation 
Total elapsed time: 5.922114534303546. Arrivals time: 0.2568587982095778 Scheduler time: 5.505683426279575 Scheduler overhead time: 0.04921985138207674 Adapter cache time: 0.03629125840961933 Engine time: 0.050518880132585764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.7556721502915025,
    "estimated_duration": 3600.0319424086038,
    "input_throughput": 5417.5349863566225,
    "output_throughput": 4732.040235343687,
    "total_throughput": 10149.57522170031,
    "itl": 93.18241637570553,
    "ttft": 1691143.0998180206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.447375824302098,
    "arrivals": 198151,
    "finished_requests": 78862,
    "scheduler_time": 100.84191460842347
}
#Debug simulation 
Total elapsed time: 5.75585618801415. Arrivals time: 0.25263538863509893 Scheduler time: 5.324584157206118 Scheduler overhead time: 0.055106776766479015 Adapter cache time: 0.04025626415386796 Engine time: 0.056744611356407404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.133280842099339,
    "estimated_duration": 3600.1237949208435,
    "input_throughput": 5853.429548653434,
    "output_throughput": 5121.137785875881,
    "total_throughput": 10974.567334529314,
    "itl": 112.91741645529792,
    "ttft": 1606656.2183772787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.44099386144922,
    "arrivals": 196793,
    "finished_requests": 85495,
    "scheduler_time": 100.80243137759139
}
#Debug simulation 
Total elapsed time: 6.133408261928707. Arrivals time: 0.26512754103168845 Scheduler time: 5.719124252907932 Scheduler overhead time: 0.046872845850884914 Adapter cache time: 0.03146005840972066 Engine time: 0.048290446400642395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.039091825950891,
    "estimated_duration": 3600.044575440188,
    "input_throughput": 5742.955834782135,
    "output_throughput": 5030.772708636674,
    "total_throughput": 10773.728543418809,
    "itl": 104.54187716418886,
    "ttft": 1625460.1044204435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.410438621449162,
    "arrivals": 196793,
    "finished_requests": 83935,
    "scheduler_time": 101.60147997328309
}
#Debug simulation 
Total elapsed time: 6.039217844139785. Arrivals time: 0.2621497241780162 Scheduler time: 5.618189681787044 Scheduler overhead time: 0.05019002966582775 Adapter cache time: 0.03318035043776035 Engine time: 0.05141726695001125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.9196942606940866,
    "estimated_duration": 3600.0014843499193,
    "input_throughput": 5527.297165432472,
    "output_throughput": 4844.971335657552,
    "total_throughput": 10372.268501090024,
    "itl": 91.07343308532353,
    "ttft": 1665631.0457291275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.294655880289948,
    "arrivals": 196793,
    "finished_requests": 80811,
    "scheduler_time": 103.14303227022836
}
#Debug simulation 
Total elapsed time: 5.919845648575574. Arrivals time: 0.25634998828172684 Scheduler time: 5.484874435700476 Scheduler overhead time: 0.056283390149474144 Adapter cache time: 0.03663920983672142 Engine time: 0.0583802186883986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.083121757954359,
    "estimated_duration": 3600.0636910091625,
    "input_throughput": 5744.350593476032,
    "output_throughput": 5031.69820168437,
    "total_throughput": 10776.048795160403,
    "itl": 104.5215937820493,
    "ttft": 1625248.6684989566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.685230089454096,
    "arrivals": 196793,
    "finished_requests": 83952,
    "scheduler_time": 101.62079010098002
}
#Debug simulation 
Total elapsed time: 6.083231118042022. Arrivals time: 0.2640975401736796 Scheduler time: 5.660105854272842 Scheduler overhead time: 0.05002592597156763 Adapter cache time: 0.033200128469616175 Engine time: 0.051678068935871124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.85182990739122,
    "estimated_duration": 3600.084815605908,
    "input_throughput": 5527.397552896516,
    "output_throughput": 4844.933631671791,
    "total_throughput": 10372.331184568307,
    "itl": 91.06890084468712,
    "ttft": 1665613.5402614325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.181985632725862,
    "arrivals": 196793,
    "finished_requests": 80813,
    "scheduler_time": 103.1483010693411
}
#Debug simulation 
Total elapsed time: 5.8519243113696575. Arrivals time: 0.25790730444714427 Scheduler time: 5.416983159258962 Scheduler overhead time: 0.055978864431381226 Adapter cache time: 0.03618082497268915 Engine time: 0.05798637308180332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.060013003181666,
    "estimated_duration": 3600.0331001981913,
    "input_throughput": 5744.932733774422,
    "output_throughput": 5032.204009180544,
    "total_throughput": 10777.136742954965,
    "itl": 104.49873943293524,
    "ttft": 1624998.453221061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.971684509171395,
    "arrivals": 196793,
    "finished_requests": 83962,
    "scheduler_time": 101.63907902430914
}
#Debug simulation 
Total elapsed time: 6.060164102818817. Arrivals time: 0.26333830831572413 Scheduler time: 5.637806017883122 Scheduler overhead time: 0.049895007628947496 Adapter cache time: 0.03326027002185583 Engine time: 0.05168428970500827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.849249619990587,
    "estimated_duration": 3600.0672547548784,
    "input_throughput": 5527.795619294613,
    "output_throughput": 4845.249481648274,
    "total_throughput": 10373.045100942887,
    "itl": 91.06643336298536,
    "ttft": 1665472.2225771346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.075475534964227,
    "arrivals": 196793,
    "finished_requests": 80816,
    "scheduler_time": 103.14869147169975
}
#Debug simulation 
Total elapsed time: 5.849341894034296. Arrivals time: 0.25931647373363376 Scheduler time: 5.4131979094818234 Scheduler overhead time: 0.05588984489440918 Adapter cache time: 0.03640070743858814 Engine time: 0.05774003965780139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.156032556202263,
    "estimated_duration": 3600.036612905724,
    "input_throughput": 5917.278986450647,
    "output_throughput": 5172.327673904028,
    "total_throughput": 11089.606660354675,
    "itl": 111.64593692880038,
    "ttft": 1587038.6135803375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1958272629372235,
    "arrivals": 196113,
    "finished_requests": 86264,
    "scheduler_time": 101.60521399728661
}
#Debug simulation 
Total elapsed time: 6.1561252092942595. Arrivals time: 0.283354917075485 Scheduler time: 5.727772875223309 Scheduler overhead time: 0.04709350410848856 Adapter cache time: 0.027003866154700518 Engine time: 0.048400045838207006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.1317940121516585,
    "estimated_duration": 3600.010440548717,
    "input_throughput": 5803.130114482592,
    "output_throughput": 5075.616946603889,
    "total_throughput": 10878.74706108648,
    "itl": 103.43302166928164,
    "ttft": 1608016.1169998012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.776636832780214,
    "arrivals": 196113,
    "finished_requests": 84598,
    "scheduler_time": 102.32664222684197
}
#Debug simulation 
Total elapsed time: 6.13193614827469. Arrivals time: 0.2809835718944669 Scheduler time: 5.69474180880934 Scheduler overhead time: 0.050511157140135765 Adapter cache time: 0.02896995423361659 Engine time: 0.05231202859431505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.9796946360729635,
    "estimated_duration": 3600.0528961933715,
    "input_throughput": 5579.911901083635,
    "output_throughput": 4880.670786415083,
    "total_throughput": 10460.582687498718,
    "itl": 90.34900455738781,
    "ttft": 1649579.4393461084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.714812764450925,
    "arrivals": 196113,
    "finished_requests": 81380,
    "scheduler_time": 103.71082131767852
}
#Debug simulation 
Total elapsed time: 5.979809925891459. Arrivals time: 0.26635650359094143 Scheduler time: 5.53833909984678 Scheduler overhead time: 0.056764570996165276 Adapter cache time: 0.032219573855400085 Engine time: 0.05887020891532302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.10553979780525,
    "estimated_duration": 3600.115326061073,
    "input_throughput": 5803.334090093972,
    "output_throughput": 5075.889616012262,
    "total_throughput": 10879.223706106233,
    "itl": 103.42015743258945,
    "ttft": 1607776.1051849483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.405972355222319,
    "arrivals": 196113,
    "finished_requests": 84602,
    "scheduler_time": 102.33877400719972
}
#Debug simulation 
Total elapsed time: 6.105669926851988. Arrivals time: 0.2824628436937928 Scheduler time: 5.667697720229626 Scheduler overhead time: 0.05043024895712733 Adapter cache time: 0.028816139791160822 Engine time: 0.052072932943701744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.933773644268513,
    "estimated_duration": 3600.0506768526807,
    "input_throughput": 5579.971173506355,
    "output_throughput": 4880.6743507735955,
    "total_throughput": 10460.645524279951,
    "itl": 90.34514731907872,
    "ttft": 1649524.7561581724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.639787470563333,
    "arrivals": 196113,
    "finished_requests": 81381,
    "scheduler_time": 103.71342124805066
}
#Debug simulation 
Total elapsed time: 5.933920112904161. Arrivals time: 0.2600128441117704 Scheduler time: 5.499299423769116 Scheduler overhead time: 0.05662076734006405 Adapter cache time: 0.0320603484287858 Engine time: 0.05869330232962966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.1298986710608006,
    "estimated_duration": 3600.000517479224,
    "input_throughput": 5803.66027686844,
    "output_throughput": 5076.568992494726,
    "total_throughput": 10880.229269363166,
    "itl": 103.40876953216286,
    "ttft": 1607486.6357819568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.9753500003739894,
    "arrivals": 196113,
    "finished_requests": 84611,
    "scheduler_time": 102.34753924304555
}
#Debug simulation 
Total elapsed time: 6.130005380138755. Arrivals time: 0.2725080559030175 Scheduler time: 5.702315756119788 Scheduler overhead time: 0.05019284226000309 Adapter cache time: 0.028671898879110813 Engine time: 0.05206120852380991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.880358051043004,
    "estimated_duration": 3600.0785683503404,
    "input_throughput": 5579.95960882738,
    "output_throughput": 4880.79042343002,
    "total_throughput": 10460.7500322574,
    "itl": 90.3436702361171,
    "ttft": 1649593.0332906283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.582778736762723,
    "arrivals": 196113,
    "finished_requests": 81382,
    "scheduler_time": 103.71600766494333
}
#Debug simulation 
Total elapsed time: 5.8804846489802. Arrivals time: 0.257735351100564 Scheduler time: 5.4491779981181026 Scheduler overhead time: 0.05633278330788016 Adapter cache time: 0.03224398707970977 Engine time: 0.058170410338789225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.227780538145453,
    "estimated_duration": 3600.0557167893376,
    "input_throughput": 6006.305652203689,
    "output_throughput": 5215.782053713911,
    "total_throughput": 11222.0877059176,
    "itl": 110.9782371845294,
    "ttft": 1578790.9984850357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.046794327553425,
    "arrivals": 195753,
    "finished_requests": 87438,
    "scheduler_time": 102.54524791192742
}
#Debug simulation 
Total elapsed time: 6.227954764384776. Arrivals time: 0.2606307999230921 Scheduler time: 5.820041473023593 Scheduler overhead time: 0.048838595394045115 Adapter cache time: 0.02553364308550954 Engine time: 0.050005854573100805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.169228077866137,
    "estimated_duration": 3600.0773884732434,
    "input_throughput": 5885.451259420191,
    "output_throughput": 5118.675798193041,
    "total_throughput": 11004.127057613232,
    "itl": 102.88670017347471,
    "ttft": 1599614.4752619446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.327061819667001,
    "arrivals": 195753,
    "finished_requests": 85776,
    "scheduler_time": 103.22364489196627
}
#Debug simulation 
Total elapsed time: 6.16931709786877. Arrivals time: 0.2637661714106798 Scheduler time: 5.750035533215851 Scheduler overhead time: 0.0510307434014976 Adapter cache time: 0.0275956722907722 Engine time: 0.05255876109004021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.98598547000438,
    "estimated_duration": 3600.0289927313315,
    "input_throughput": 5641.667897955103,
    "output_throughput": 4914.957917207112,
    "total_throughput": 10556.625815162215,
    "itl": 89.97503256133793,
    "ttft": 1643697.6542983588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0812822062569065,
    "arrivals": 195753,
    "finished_requests": 82294,
    "scheduler_time": 104.47828751285974
}
#Debug simulation 
Total elapsed time: 5.986072308849543. Arrivals time: 0.276969313621521 Scheduler time: 5.535747427958995 Scheduler overhead time: 0.05678276903927326 Adapter cache time: 0.03037652838975191 Engine time: 0.05874781031161547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.163261340931058,
    "estimated_duration": 3600.0079262518043,
    "input_throughput": 5885.835652051262,
    "output_throughput": 5118.783729786452,
    "total_throughput": 11004.619381837714,
    "itl": 102.87999545844315,
    "ttft": 1599723.5437091766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.053865618729025,
    "arrivals": 195753,
    "finished_requests": 85777,
    "scheduler_time": 103.22733068072387
}
#Debug simulation 
Total elapsed time: 6.16343076294288. Arrivals time: 0.2739840727299452 Scheduler time: 5.73353857640177 Scheduler overhead time: 0.05077471490949392 Adapter cache time: 0.027475968468934298 Engine time: 0.05308192037045956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.978020558133721,
    "estimated_duration": 3600.0398336819517,
    "input_throughput": 5641.669242094926,
    "output_throughput": 4914.988671640127,
    "total_throughput": 10556.657913735053,
    "itl": 89.97459337437023,
    "ttft": 1643753.4808855234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.046072286232408,
    "arrivals": 195753,
    "finished_requests": 82295,
    "scheduler_time": 104.47948791371974
}
#Debug simulation 
Total elapsed time: 5.978146641049534. Arrivals time: 0.2796874069608748 Scheduler time: 5.52506858156994 Scheduler overhead time: 0.056710594333708286 Adapter cache time: 0.03043181961402297 Engine time: 0.05895392410457134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.184771182946861,
    "estimated_duration": 3600.0342572489335,
    "input_throughput": 5886.224542816822,
    "output_throughput": 5119.299063027121,
    "total_throughput": 11005.523605843942,
    "itl": 102.87181333474098,
    "ttft": 1599604.6143028692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.80481688058002,
    "arrivals": 195753,
    "finished_requests": 85786,
    "scheduler_time": 103.23474161024241
}
#Debug simulation 
Total elapsed time: 6.1848877356387675. Arrivals time: 0.2670620405115187 Scheduler time: 5.763042658567429 Scheduler overhead time: 0.05082574486732483 Adapter cache time: 0.027203527744859457 Engine time: 0.05232584290206432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.986545309890062,
    "estimated_duration": 3600.065017521801,
    "input_throughput": 5641.62977644806,
    "output_throughput": 4914.954289403427,
    "total_throughput": 10556.584065851486,
    "itl": 89.97250421743962,
    "ttft": 1643684.041561596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9968332602084025,
    "arrivals": 195753,
    "finished_requests": 82295,
    "scheduler_time": 104.48183952238499
}
#Debug simulation 
Total elapsed time: 5.986700192093849. Arrivals time: 0.274421208538115 Scheduler time: 5.538798224180937 Scheduler overhead time: 0.05680444976314902 Adapter cache time: 0.03032973874360323 Engine time: 0.05892999982461333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.271841769106686,
    "estimated_duration": 3600.1067726860424,
    "input_throughput": 5972.269534650004,
    "output_throughput": 5203.887601928577,
    "total_throughput": 11176.157136578582,
    "itl": 110.78177121852306,
    "ttft": 1573127.895703912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.64953847812057,
    "arrivals": 192543,
    "finished_requests": 86682,
    "scheduler_time": 102.22030591411237
}
#Debug simulation 
Total elapsed time: 6.271934656891972. Arrivals time: 0.2675427459180355 Scheduler time: 5.8497093678452075 Scheduler overhead time: 0.04807047126814723 Adapter cache time: 0.03394988412037492 Engine time: 0.049604812636971474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.189580772072077,
    "estimated_duration": 3600.0221368358193,
    "input_throughput": 5870.728066849068,
    "output_throughput": 5117.8696407111165,
    "total_throughput": 10988.597707560184,
    "itl": 102.34080637317145,
    "ttft": 1591518.426298815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.833656391435998,
    "arrivals": 192543,
    "finished_requests": 85196,
    "scheduler_time": 103.17982503743013
}
#Debug simulation 
Total elapsed time: 6.189690410159528. Arrivals time: 0.27365436125546694 Scheduler time: 5.751612077001482 Scheduler overhead time: 0.05117972940206528 Adapter cache time: 0.035718115977942944 Engine time: 0.05297322338446975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.960091508924961,
    "estimated_duration": 3600.091794492625,
    "input_throughput": 5657.423522132839,
    "output_throughput": 4939.823486502611,
    "total_throughput": 10597.24700863545,
    "itl": 89.07254860814159,
    "ttft": 1631274.8120061744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.616800217702743,
    "arrivals": 192543,
    "finished_requests": 82164,
    "scheduler_time": 104.89333020277729
}
#Debug simulation 
Total elapsed time: 5.9602701580151916. Arrivals time: 0.2607370656915009 Scheduler time: 5.518993168137968 Scheduler overhead time: 0.057277509942650795 Adapter cache time: 0.0369389308616519 Engine time: 0.058831260073930025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.179755860939622,
    "estimated_duration": 3600.0221412420633,
    "input_throughput": 5871.601109849591,
    "output_throughput": 5118.91601690038,
    "total_throughput": 10990.517126749972,
    "itl": 102.32130466876664,
    "ttft": 1591063.6109075488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.926590911937142,
    "arrivals": 192543,
    "finished_requests": 85209,
    "scheduler_time": 103.20395253699574
}
#Debug simulation 
Total elapsed time: 6.179848483297974. Arrivals time: 0.27086821012198925 Scheduler time: 5.745230166241527 Scheduler overhead time: 0.051109562162309885 Adapter cache time: 0.03530971286818385 Engine time: 0.052804389502853155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.985689903143793,
    "estimated_duration": 3600.03430842211,
    "input_throughput": 5658.054689186501,
    "output_throughput": 4940.357084484381,
    "total_throughput": 10598.411773670881,
    "itl": 89.06591184594505,
    "ttft": 1631167.7911613714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.46032935620262,
    "arrivals": 192543,
    "finished_requests": 82168,
    "scheduler_time": 104.8958441448092
}
#Debug simulation 
Total elapsed time: 5.985787527170032. Arrivals time: 0.2602674439549446 Scheduler time: 5.5424988134764135 Scheduler overhead time: 0.05740996589884162 Adapter cache time: 0.037152267061173916 Engine time: 0.06088831648230553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.198804732877761,
    "estimated_duration": 3600.035444008125,
    "input_throughput": 5873.3721733747125,
    "output_throughput": 5120.492919224269,
    "total_throughput": 10993.86509259898,
    "itl": 102.295526710063,
    "ttft": 1591033.678535062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.02092313109481,
    "arrivals": 192543,
    "finished_requests": 85233,
    "scheduler_time": 103.22943623948018
}
#Debug simulation 
Total elapsed time: 6.198953398969024. Arrivals time: 0.26247934019193053 Scheduler time: 5.772281078156084 Scheduler overhead time: 0.051568294409662485 Adapter cache time: 0.03520640358328819 Engine time: 0.05270668398588896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.036962535697967,
    "estimated_duration": 3600.0140441108433,
    "input_throughput": 5658.361814816522,
    "output_throughput": 4940.564337268561,
    "total_throughput": 10598.926152085083,
    "itl": 89.06166472461378,
    "ttft": 1631113.611665753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.353089679404865,
    "arrivals": 192543,
    "finished_requests": 82172,
    "scheduler_time": 104.90004219882942
}
#Debug simulation 
Total elapsed time: 6.037072579842061. Arrivals time: 0.26779863331466913 Scheduler time: 5.587702430319041 Scheduler overhead time: 0.0575175154954195 Adapter cache time: 0.03680830402299762 Engine time: 0.059639949817210436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.366025011986494,
    "estimated_duration": 3600.0515143664925,
    "input_throughput": 6150.065050915282,
    "output_throughput": 5328.103757252872,
    "total_throughput": 11478.168808168153,
    "itl": 108.33177941720973,
    "ttft": 1541457.8985044581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.768054376365832,
    "arrivals": 191076,
    "finished_requests": 89112,
    "scheduler_time": 104.51952131465549
}
#Debug simulation 
Total elapsed time: 6.366117998026311. Arrivals time: 0.26824756618589163 Scheduler time: 5.945682003162801 Scheduler overhead time: 0.04868054296821356 Adapter cache time: 0.02974810777232051 Engine time: 0.05033024260774255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.254724129103124,
    "estimated_duration": 3600.001590924706,
    "input_throughput": 6039.632330944364,
    "output_throughput": 5230.584077370712,
    "total_throughput": 11270.216408315076,
    "itl": 100.2799498108172,
    "ttft": 1562374.6412737868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.594562288597173,
    "arrivals": 191076,
    "finished_requests": 87455,
    "scheduler_time": 105.26685723889298
}
#Debug simulation 
Total elapsed time: 6.254895560443401. Arrivals time: 0.26606994308531284 Scheduler time: 5.827073006425053 Scheduler overhead time: 0.05199182825163007 Adapter cache time: 0.030866912100464106 Engine time: 0.05385354580357671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.072410712018609,
    "estimated_duration": 3600.083551602225,
    "input_throughput": 5797.241008673678,
    "output_throughput": 5029.415217861193,
    "total_throughput": 10826.656226534871,
    "itl": 87.50191079703035,
    "ttft": 1603629.9420448493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.473837953237771,
    "arrivals": 191076,
    "finished_requests": 84004,
    "scheduler_time": 106.71029973465711
}
#Debug simulation 
Total elapsed time: 6.072498383931816. Arrivals time: 0.2614851947873831 Scheduler time: 5.631513114087284 Scheduler overhead time: 0.05864841351285577 Adapter cache time: 0.032717280089855194 Engine time: 0.06032251054421067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.288038718979806,
    "estimated_duration": 3600.11416033541,
    "input_throughput": 6040.979822143694,
    "output_throughput": 5232.004642387544,
    "total_throughput": 11272.984464531239,
    "itl": 100.26288240145534,
    "ttft": 1562047.4229980237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.992348239300792,
    "arrivals": 191076,
    "finished_requests": 87476,
    "scheduler_time": 105.28728950927783
}
#Debug simulation 
Total elapsed time: 6.288130779750645. Arrivals time: 0.2681183065287769 Scheduler time: 5.857913629151881 Scheduler overhead time: 0.052193481009453535 Adapter cache time: 0.03078802116215229 Engine time: 0.053965041879564524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.1222989009693265,
    "estimated_duration": 3600.081295780595,
    "input_throughput": 5797.4090819731255,
    "output_throughput": 5029.419480393723,
    "total_throughput": 10826.828562366847,
    "itl": 87.50085139671594,
    "ttft": 1603690.0683881978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.38327587807547,
    "arrivals": 191076,
    "finished_requests": 84006,
    "scheduler_time": 106.7126978172443
}
#Debug simulation 
Total elapsed time: 6.122448849957436. Arrivals time: 0.258399382699281 Scheduler time: 5.6842235256917775 Scheduler overhead time: 0.058535147458314896 Adapter cache time: 0.03254285827279091 Engine time: 0.06052632816135883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.309968272224069,
    "estimated_duration": 3600.0235524140653,
    "input_throughput": 6042.197969903208,
    "output_throughput": 5232.74048786926,
    "total_throughput": 11274.938457772467,
    "itl": 100.24649389355811,
    "ttft": 1562024.5626995598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.362936432147405,
    "arrivals": 191076,
    "finished_requests": 87491,
    "scheduler_time": 105.30044429227208
}
#Debug simulation 
Total elapsed time: 6.31010190024972. Arrivals time: 0.26520620845258236 Scheduler time: 5.882673105224967 Scheduler overhead time: 0.05221865279600024 Adapter cache time: 0.030946034938097 Engine time: 0.053977783769369125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.093548694625497,
    "estimated_duration": 3600.0402028776034,
    "input_throughput": 5797.4755346668535,
    "output_throughput": 5029.477444592746,
    "total_throughput": 10826.952979259599,
    "itl": 87.49645969142229,
    "ttft": 1603654.0980383826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.313008293192796,
    "arrivals": 191076,
    "finished_requests": 84007,
    "scheduler_time": 106.71307215003041
}
#Debug simulation 
Total elapsed time: 6.093669021036476. Arrivals time: 0.26169178634881973 Scheduler time: 5.653075485955924 Scheduler overhead time: 0.058027900755405426 Adapter cache time: 0.03241125261411071 Engine time: 0.060457488521933556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.531139576341957,
    "estimated_duration": 3600.110390023157,
    "input_throughput": 6233.4235811740355,
    "output_throughput": 5434.192255386413,
    "total_throughput": 11667.61583656045,
    "itl": 106.3145718820115,
    "ttft": 1514799.3775563424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.329601679751754,
    "arrivals": 190312,
    "finished_requests": 90720,
    "scheduler_time": 106.47449460424866
}
#Debug simulation 
Total elapsed time: 6.531300719361752. Arrivals time: 0.2770615555346012 Scheduler time: 6.102864325512201 Scheduler overhead time: 0.04973113443702459 Adapter cache time: 0.02602608222514391 Engine time: 0.0516371657140553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.452834014780819,
    "estimated_duration": 3600.0109872422,
    "input_throughput": 6115.059947876468,
    "output_throughput": 5331.4992837572445,
    "total_throughput": 11446.559231633713,
    "itl": 98.4899348993022,
    "ttft": 1536778.308406592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.858154821335345,
    "arrivals": 190312,
    "finished_requests": 88981,
    "scheduler_time": 107.18981810718145
}
#Debug simulation 
Total elapsed time: 6.452925606165081. Arrivals time: 0.2719192882068455 Scheduler time: 6.020007924176753 Scheduler overhead time: 0.05312950303778052 Adapter cache time: 0.027536981273442507 Engine time: 0.05491185002028942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.219911098014563,
    "estimated_duration": 3600.0672995384775,
    "input_throughput": 5868.895007242955,
    "output_throughput": 5114.551609176995,
    "total_throughput": 10983.446616419951,
    "itl": 86.09454370165639,
    "ttft": 1581631.2745659507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.785617493288614,
    "arrivals": 190312,
    "finished_requests": 85337,
    "scheduler_time": 108.42896423175546
}
#Debug simulation 
Total elapsed time: 6.220004049129784. Arrivals time: 0.2723769210278988 Scheduler time: 5.769060337450355 Scheduler overhead time: 0.059348808135837317 Adapter cache time: 0.029313613194972277 Engine time: 0.061462747398763895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.533430120907724,
    "estimated_duration": 3600.1069678552235,
    "input_throughput": 6115.208852562444,
    "output_throughput": 5331.688244651042,
    "total_throughput": 11446.897097213485,
    "itl": 98.47913111090959,
    "ttft": 1536763.4431196877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.481115900520226,
    "arrivals": 190312,
    "finished_requests": 88987,
    "scheduler_time": 107.202225266089
}
#Debug simulation 
Total elapsed time: 6.5335907018743455. Arrivals time: 0.28847832372412086 Scheduler time: 6.083435831591487 Scheduler overhead time: 0.053459529764950275 Adapter cache time: 0.02742982329800725 Engine time: 0.055183371528983116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.236396772786975,
    "estimated_duration": 3600.047317034755,
    "input_throughput": 5869.015915436098,
    "output_throughput": 5114.793050877624,
    "total_throughput": 10983.808966313722,
    "itl": 86.09500871903789,
    "ttft": 1581570.191361054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.724312305524967,
    "arrivals": 190312,
    "finished_requests": 85338,
    "scheduler_time": 108.43015160415342
}
#Debug simulation 
Total elapsed time: 6.236520690843463. Arrivals time: 0.27327394392341375 Scheduler time: 5.784589359536767 Scheduler overhead time: 0.05924660386517644 Adapter cache time: 0.029262266121804714 Engine time: 0.061752923764288425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.4714904190041125,
    "estimated_duration": 3600.084856294304,
    "input_throughput": 6115.5555712823925,
    "output_throughput": 5332.262367770893,
    "total_throughput": 11447.817939053286,
    "itl": 98.47256632188902,
    "ttft": 1536546.994415833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.119904594337543,
    "arrivals": 190312,
    "finished_requests": 88992,
    "scheduler_time": 107.21012449827012
}
#Debug simulation 
Total elapsed time: 6.471590694971383. Arrivals time: 0.30110087245702744 Scheduler time: 6.009823629166931 Scheduler overhead time: 0.052707315888255835 Adapter cache time: 0.02760039595887065 Engine time: 0.05493953777477145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.516109559684992,
    "estimated_duration": 3600.081136616956,
    "input_throughput": 5869.147443675557,
    "output_throughput": 5114.746113001056,
    "total_throughput": 10983.893556676612,
    "itl": 86.09267898298683,
    "ttft": 1581643.0950577534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.680971450116509,
    "arrivals": 190312,
    "finished_requests": 85340,
    "scheduler_time": 108.43148217583207
}
#Debug simulation 
Total elapsed time: 6.5162321999669075. Arrivals time: 0.29213150311261415 Scheduler time: 6.045158244669437 Scheduler overhead time: 0.05939593492075801 Adapter cache time: 0.029769339598715305 Engine time: 0.06135925790295005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.592532836832106,
    "estimated_duration": 3600.1014201090716,
    "input_throughput": 6276.445400617469,
    "output_throughput": 5471.778347678656,
    "total_throughput": 11748.223748296125,
    "itl": 105.38034517224607,
    "ttft": 1504046.5579473583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.524414014029363,
    "arrivals": 189952,
    "finished_requests": 91460,
    "scheduler_time": 107.09216779083823
}
#Debug simulation 
Total elapsed time: 6.592659325804561. Arrivals time: 0.30340770864859223 Scheduler time: 6.138280211482197 Scheduler overhead time: 0.050016055814921856 Adapter cache time: 0.024873097892850637 Engine time: 0.05201325658708811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.4508982240222394,
    "estimated_duration": 3600.076966569441,
    "input_throughput": 6148.184665366116,
    "output_throughput": 5364.113928486898,
    "total_throughput": 11512.298593853015,
    "itl": 97.7247406328402,
    "ttft": 1526884.3831814455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8307685827137945,
    "arrivals": 189952,
    "finished_requests": 89652,
    "scheduler_time": 107.74158219130383
}
#Debug simulation 
Total elapsed time: 6.450995098799467. Arrivals time: 0.3125055255368352 Scheduler time: 5.978300301823765 Scheduler overhead time: 0.053432025015354156 Adapter cache time: 0.0256179659627378 Engine time: 0.05544842779636383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.249929883982986,
    "estimated_duration": 3600.0537310015243,
    "input_throughput": 5890.609581013229,
    "output_throughput": 5144.325163960215,
    "total_throughput": 11034.934744973443,
    "itl": 85.58878169293958,
    "ttft": 1573916.764675242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8065538089583035,
    "arrivals": 189952,
    "finished_requests": 85994,
    "scheduler_time": 108.8890960100382
}
#Debug simulation 
Total elapsed time: 6.250079227145761. Arrivals time: 0.2835393794812262 Scheduler time: 5.7889546803198755 Scheduler overhead time: 0.05978229083120823 Adapter cache time: 0.027380422223359346 Engine time: 0.061796425841748714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.434798569884151,
    "estimated_duration": 3600.035106329132,
    "input_throughput": 6148.6922616627035,
    "output_throughput": 5364.460742632098,
    "total_throughput": 11513.153004294802,
    "itl": 97.72035254397042,
    "ttft": 1526769.8469912894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5953282011765935,
    "arrivals": 189952,
    "finished_requests": 89657,
    "scheduler_time": 107.74664873789497
}
#Debug simulation 
Total elapsed time: 6.434901186265051. Arrivals time: 0.3133694208227098 Scheduler time: 5.961527165025473 Scheduler overhead time: 0.05323657672852278 Adapter cache time: 0.025917474180459976 Engine time: 0.05528139416128397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.3247946430929005,
    "estimated_duration": 3600.013170714827,
    "input_throughput": 5890.605115699962,
    "output_throughput": 5144.271457296568,
    "total_throughput": 11034.876572996529,
    "itl": 85.58894431687668,
    "ttft": 1573996.6397490825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7802484310139306,
    "arrivals": 189952,
    "finished_requests": 85991,
    "scheduler_time": 108.88934753593249
}
#Debug simulation 
Total elapsed time: 6.324926504865289. Arrivals time: 0.29438913706690073 Scheduler time: 5.852325604762882 Scheduler overhead time: 0.059832018334418535 Adapter cache time: 0.027630949392914772 Engine time: 0.06207461655139923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.478282989002764,
    "estimated_duration": 3600.0306882713558,
    "input_throughput": 6148.962583046582,
    "output_throughput": 5364.659268855729,
    "total_throughput": 11513.621851902311,
    "itl": 97.71618527597629,
    "ttft": 1526669.7976258856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.351558493799515,
    "arrivals": 189952,
    "finished_requests": 89660,
    "scheduler_time": 107.75221865440307
}
#Debug simulation 
Total elapsed time: 6.4784534480422735. Arrivals time: 0.30047772731631994 Scheduler time: 6.017726645804942 Scheduler overhead time: 0.053189383354038 Adapter cache time: 0.025930454023182392 Engine time: 0.055518364533782005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.278171804733574,
    "estimated_duration": 3600.0278146816595,
    "input_throughput": 5890.663375853733,
    "output_throughput": 5144.449974656011,
    "total_throughput": 11035.113350509744,
    "itl": 85.59386170613264,
    "ttft": 1573904.8949883024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7458669796958897,
    "arrivals": 189952,
    "finished_requests": 85994,
    "scheduler_time": 108.8890051375902
}
#Debug simulation 
Total elapsed time: 6.278271896764636. Arrivals time: 0.2907626572996378 Scheduler time: 5.81084024393931 Scheduler overhead time: 0.05945056490600109 Adapter cache time: 0.026993855368345976 Engine time: 0.06167202163487673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.630969634279609,
    "estimated_duration": 3600.0817902720482,
    "input_throughput": 6407.343039352696,
    "output_throughput": 5563.343047960725,
    "total_throughput": 11970.686087313421,
    "itl": 103.79938994232057,
    "ttft": 1477222.2119736576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.625633850013983,
    "arrivals": 188134,
    "finished_requests": 93306,
    "scheduler_time": 108.56408666391398
}
#Debug simulation 
Total elapsed time: 6.631103402003646. Arrivals time: 0.3049383847974241 Scheduler time: 6.174219216220081 Scheduler overhead time: 0.050536464899778366 Adapter cache time: 0.024918355513364077 Engine time: 0.052293282467871904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.615271649789065,
    "estimated_duration": 3600.0895826600863,
    "input_throughput": 6282.5528311681255,
    "output_throughput": 5451.3424039573365,
    "total_throughput": 11733.895235125463,
    "itl": 96.2179002057859,
    "ttft": 1501485.0206086268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.258245256003004,
    "arrivals": 188134,
    "finished_requests": 91437,
    "scheduler_time": 109.21735650839413
}
#Debug simulation 
Total elapsed time: 6.615426058880985. Arrivals time: 0.29386510234326124 Scheduler time: 6.158657173626125 Scheduler overhead time: 0.054478765930980444 Adapter cache time: 0.026034221053123474 Engine time: 0.05618155375123024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.370779152959585,
    "estimated_duration": 3600.0806497775156,
    "input_throughput": 6019.047934756446,
    "output_throughput": 5225.2132188101195,
    "total_throughput": 11244.261153566566,
    "itl": 84.28663876226327,
    "ttft": 1550291.488024306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 954,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.198767305677785,
    "arrivals": 188134,
    "finished_requests": 87594,
    "scheduler_time": 110.32624606541322
}
#Debug simulation 
Total elapsed time: 6.370875022839755. Arrivals time: 0.29495781660079956 Scheduler time: 5.896367260720581 Scheduler overhead time: 0.06051278207451105 Adapter cache time: 0.02747969562187791 Engine time: 0.06258870009332895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.617952988948673,
    "estimated_duration": 3600.0746912785903,
    "input_throughput": 6283.0660304901985,
    "output_throughput": 5451.662446767058,
    "total_throughput": 11734.728477257257,
    "itl": 96.20646222174982,
    "ttft": 1501194.9526934053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.7940222669904955,
    "arrivals": 188134,
    "finished_requests": 91444,
    "scheduler_time": 109.22949369428682
}
#Debug simulation 
Total elapsed time: 6.618069547694176. Arrivals time: 0.30291989585384727 Scheduler time: 6.152468001935631 Scheduler overhead time: 0.05452523333951831 Adapter cache time: 0.02576135192066431 Engine time: 0.056344115640968084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.318975147791207,
    "estimated_duration": 3600.0573586660284,
    "input_throughput": 6019.268261889453,
    "output_throughput": 5225.406743788812,
    "total_throughput": 11244.675005678264,
    "itl": 84.28279601962548,
    "ttft": 1550291.763751032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.109349043904832,
    "arrivals": 188134,
    "finished_requests": 87596,
    "scheduler_time": 110.3272327820576
}
#Debug simulation 
Total elapsed time: 6.319153300952166. Arrivals time: 0.2864990998059511 Scheduler time: 5.85361198335886 Scheduler overhead time: 0.06067551067098975 Adapter cache time: 0.026966877281665802 Engine time: 0.062481723725795746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.562488987110555,
    "estimated_duration": 3600.032687213433,
    "input_throughput": 6284.284051184985,
    "output_throughput": 5452.74382361079,
    "total_throughput": 11737.027874795775,
    "itl": 96.1931696165887,
    "ttft": 1500954.7690412898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.313697810224226,
    "arrivals": 188134,
    "finished_requests": 91461,
    "scheduler_time": 109.24111889526976
}
#Debug simulation 
Total elapsed time: 6.562582405284047. Arrivals time: 0.2966229342855513 Scheduler time: 6.103877999819815 Scheduler overhead time: 0.05428234860301018 Adapter cache time: 0.02572624199092388 Engine time: 0.05615903390571475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.356122272089124,
    "estimated_duration": 3600.0828713371134,
    "input_throughput": 6019.044498259524,
    "output_throughput": 5225.369157408615,
    "total_throughput": 11244.413655668139,
    "itl": 84.28280841173543,
    "ttft": 1550209.67588952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 952,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.049749669507174,
    "arrivals": 188134,
    "finished_requests": 87595,
    "scheduler_time": 110.32932917800358
}
#Debug simulation 
Total elapsed time: 6.356217793188989. Arrivals time: 0.2870854237116873 Scheduler time: 5.889786629471928 Scheduler overhead time: 0.060698795132339 Adapter cache time: 0.027118783444166183 Engine time: 0.06269893096759915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.736092895735055,
    "estimated_duration": 3600.0063449882746,
    "input_throughput": 6461.589444802983,
    "output_throughput": 5642.198944531626,
    "total_throughput": 12103.788389334608,
    "itl": 102.44910049014081,
    "ttft": 1470810.4851032041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.906407501706944,
    "arrivals": 187468,
    "finished_requests": 94126,
    "scheduler_time": 110.17382882239619
}
#Debug simulation 
Total elapsed time: 6.736246989108622. Arrivals time: 0.3032001913525164 Scheduler time: 6.2808390823192894 Scheduler overhead time: 0.05141271883621812 Adapter cache time: 0.023092446383088827 Engine time: 0.05312489625066519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.659641406964511,
    "estimated_duration": 3600.0911591765007,
    "input_throughput": 6324.787899317655,
    "output_throughput": 5529.849695404332,
    "total_throughput": 11854.637594721986,
    "itl": 95.05690279967963,
    "ttft": 1494816.494053414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.271929507288158,
    "arrivals": 187468,
    "finished_requests": 92162,
    "scheduler_time": 110.78502286056259
}
#Debug simulation 
Total elapsed time: 6.659737796057016. Arrivals time: 0.3192570568062365 Scheduler time: 6.178517068270594 Scheduler overhead time: 0.05483607668429613 Adapter cache time: 0.02389802597463131 Engine time: 0.0568387545645237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.425582691095769,
    "estimated_duration": 3600.060755092586,
    "input_throughput": 6044.789374517191,
    "output_throughput": 5284.066101687434,
    "total_throughput": 11328.855476204624,
    "itl": 83.42574496880266,
    "ttft": 1545746.5240273962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.263175544999568,
    "arrivals": 187468,
    "finished_requests": 88028,
    "scheduler_time": 111.63020420377818
}
#Debug simulation 
Total elapsed time: 6.425700617954135. Arrivals time: 0.29350300040096045 Scheduler time: 5.953064538538456 Scheduler overhead time: 0.06100179813802242 Adapter cache time: 0.025526999961584806 Engine time: 0.06319862557575107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.674499738961458,
    "estimated_duration": 3600.0910737156546,
    "input_throughput": 6325.02276574309,
    "output_throughput": 5530.235094705967,
    "total_throughput": 11855.257860449057,
    "itl": 95.04417839953364,
    "ttft": 1494725.7168708276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.915713901072732,
    "arrivals": 187468,
    "finished_requests": 92168,
    "scheduler_time": 110.79501478314953
}
#Debug simulation 
Total elapsed time: 6.674649904947728. Arrivals time: 0.30154979787766933 Scheduler time: 6.211294380016625 Scheduler overhead time: 0.05470110196620226 Adapter cache time: 0.0236779754050076 Engine time: 0.05711750593036413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.47766940202564,
    "estimated_duration": 3600.03580462501,
    "input_throughput": 6045.080155047748,
    "output_throughput": 5284.024113193912,
    "total_throughput": 11329.104268241661,
    "itl": 83.42399893895315,
    "ttft": 1545722.6397881128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.212431836728967,
    "arrivals": 187468,
    "finished_requests": 88029,
    "scheduler_time": 111.63197599023222
}
#Debug simulation 
Total elapsed time: 6.477785721886903. Arrivals time: 0.3130569849163294 Scheduler time: 5.984905763994902 Scheduler overhead time: 0.06143173296004534 Adapter cache time: 0.025319722946733236 Engine time: 0.06371435709297657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.712891643866897,
    "estimated_duration": 3600.038955095144,
    "input_throughput": 6325.639884471237,
    "output_throughput": 5530.954039210879,
    "total_throughput": 11856.593923682116,
    "itl": 95.03622197813363,
    "ttft": 1494577.0999031882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.596423077210762,
    "arrivals": 187468,
    "finished_requests": 92176,
    "scheduler_time": 110.80208895923042
}
#Debug simulation 
Total elapsed time: 6.713006985839456. Arrivals time: 0.30750034796074033 Scheduler time: 6.2429493754170835 Scheduler overhead time: 0.05521082179620862 Adapter cache time: 0.02397923171520233 Engine time: 0.05716885533183813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.433481729123741,
    "estimated_duration": 3600.008487520958,
    "input_throughput": 6045.606302163835,
    "output_throughput": 5284.576707512344,
    "total_throughput": 11330.183009676179,
    "itl": 83.42048142545349,
    "ttft": 1545582.1898037023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.15987743936482,
    "arrivals": 187468,
    "finished_requests": 88034,
    "scheduler_time": 111.63324874613346
}
#Debug simulation 
Total elapsed time: 6.433656495064497. Arrivals time: 0.3151132194325328 Scheduler time: 5.9389236606657505 Scheduler overhead time: 0.06128215882927179 Adapter cache time: 0.02532077394425869 Engine time: 0.06360629200935364 
