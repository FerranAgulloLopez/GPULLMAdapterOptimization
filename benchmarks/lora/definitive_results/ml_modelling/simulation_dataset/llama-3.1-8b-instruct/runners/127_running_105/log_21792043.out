INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 75.55298877414316,
    "estimated_duration": 3600.017523094693,
    "input_throughput": 6766.244009573751,
    "output_throughput": 5863.443959532297,
    "total_throughput": 12629.68796910605,
    "itl": 96.70231495305406,
    "ttft": 1902839.8195534123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.111179814846253,
    "arrivals": 540089,
    "finished_requests": 98217,
    "scheduler_time": 224.76539534587658
}
#Debug simulation 
Total elapsed time: 75.55320749990642. Arrivals time: 0.5208720387890935 Scheduler time: 74.83092189067975 Scheduler overhead time: 0.07778480229899287 Adapter cache time: 0.015196834225207567 Engine time: 0.07805723883211613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 70.97064060391858,
    "estimated_duration": 3600.0146842521235,
    "input_throughput": 6586.442023062426,
    "output_throughput": 5718.727229102095,
    "total_throughput": 12305.169252164522,
    "itl": 90.88939973377735,
    "ttft": 1916467.025697272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2671049541933543,
    "arrivals": 540089,
    "finished_requests": 95724,
    "scheduler_time": 231.18416479851214
}
#Debug simulation 
Total elapsed time: 70.97084101708606. Arrivals time: 0.45622033486142755 Scheduler time: 70.30879252543673 Scheduler overhead time: 0.08080370863899589 Adapter cache time: 0.015350704081356525 Engine time: 0.0782487764954567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 78.33483165781945,
    "estimated_duration": 3600.0980366938834,
    "input_throughput": 6737.581797154399,
    "output_throughput": 5846.86855342707,
    "total_throughput": 12584.45035058147,
    "itl": 96.57875839647103,
    "ttft": 1902722.110125261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.838569230884307,
    "arrivals": 540089,
    "finished_requests": 97998,
    "scheduler_time": 225.33889608013686
}
#Debug simulation 
Total elapsed time: 78.33500877395272. Arrivals time: 0.528697048779577 Scheduler time: 77.60540238954127 Scheduler overhead time: 0.07796675572171807 Adapter cache time: 0.014945025090128183 Engine time: 0.07729233661666512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 71.10990750417113,
    "estimated_duration": 3600.0528822845354,
    "input_throughput": 6603.053837618932,
    "output_throughput": 5725.723391851784,
    "total_throughput": 12328.777229470716,
    "itl": 90.99243718941877,
    "ttft": 1913430.3734693006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3128143678791915,
    "arrivals": 540089,
    "finished_requests": 95899,
    "scheduler_time": 231.14926155796533
}
#Debug simulation 
Total elapsed time: 71.11007997114211. Arrivals time: 0.5001853494904935 Scheduler time: 70.40446122549474 Scheduler overhead time: 0.0799302700906992 Adapter cache time: 0.014929287601262331 Engine time: 0.07922201789915562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 73.88038055505604,
    "estimated_duration": 3600.0930013273874,
    "input_throughput": 6767.8815494534165,
    "output_throughput": 5909.17151089048,
    "total_throughput": 12677.053060343897,
    "itl": 99.60403820249117,
    "ttft": 1864079.8714032143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3077307521505355,
    "arrivals": 483089,
    "finished_requests": 98789,
    "scheduler_time": 222.20026004587834
}
#Debug simulation 
Total elapsed time: 73.88054770603776. Arrivals time: 0.4679876076988876 Scheduler time: 73.21592607814819 Scheduler overhead time: 0.07688532723113894 Adapter cache time: 0.01536580454558134 Engine time: 0.07492210250347853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 72.91611410584301,
    "estimated_duration": 3600.102959393441,
    "input_throughput": 6705.026570703132,
    "output_throughput": 5859.193261393265,
    "total_throughput": 12564.219832096398,
    "itl": 97.21920725157398,
    "ttft": 1868855.2430135228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.562549662827518,
    "arrivals": 483089,
    "finished_requests": 97944,
    "scheduler_time": 224.28973179744244
}
#Debug simulation 
Total elapsed time: 72.91627785004675. Arrivals time: 0.47669025231152773 Scheduler time: 72.24246348021552 Scheduler overhead time: 0.07686996692791581 Adapter cache time: 0.014973738230764866 Engine time: 0.07552873576059937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 70.54753742692992,
    "estimated_duration": 3600.095711122066,
    "input_throughput": 6528.3928222771365,
    "output_throughput": 5704.770552780351,
    "total_throughput": 12233.163375057487,
    "itl": 91.15018757434608,
    "ttft": 1884057.2190845448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3170179182291135,
    "arrivals": 483089,
    "finished_requests": 95317,
    "scheduler_time": 230.93160782725144
}
#Debug simulation 
Total elapsed time: 70.54771886300296. Arrivals time: 0.4515044162981212 Scheduler time: 69.89264541072771 Scheduler overhead time: 0.07952815154567361 Adapter cache time: 0.015613949857652187 Engine time: 0.07703721849247813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 75.43740398436785,
    "estimated_duration": 3600.0281898192175,
    "input_throughput": 6704.845553226659,
    "output_throughput": 5853.479997626965,
    "total_throughput": 12558.325550853624,
    "itl": 96.88834317639149,
    "ttft": 1870777.3070730479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1805719081452093,
    "arrivals": 483089,
    "finished_requests": 97876,
    "scheduler_time": 224.87443653591936
}
#Debug simulation 
Total elapsed time: 75.43765698606148. Arrivals time: 0.4601805047132075 Scheduler time: 74.7792390822433 Scheduler overhead time: 0.07747528282925487 Adapter cache time: 0.015148185659199953 Engine time: 0.07594629656523466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 71.46242452412844,
    "estimated_duration": 3600.0203556191846,
    "input_throughput": 6515.339548952578,
    "output_throughput": 5703.01247545829,
    "total_throughput": 12218.35202441087,
    "itl": 91.1741035109044,
    "ttft": 1879885.7350438624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.368574771313008,
    "arrivals": 483089,
    "finished_requests": 95141,
    "scheduler_time": 230.9762188329938
}
#Debug simulation 
Total elapsed time: 71.46258697099984. Arrivals time: 0.4617204265668988 Scheduler time: 70.7968340003863 Scheduler overhead time: 0.07930264994502068 Adapter cache time: 0.015768221579492092 Engine time: 0.07778418669477105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 73.66747030988336,
    "estimated_duration": 3600.100497506758,
    "input_throughput": 6698.977991503896,
    "output_throughput": 5856.404012777263,
    "total_throughput": 12555.38200428116,
    "itl": 97.1956505152732,
    "ttft": 1868554.4323395898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2024527244968253,
    "arrivals": 483089,
    "finished_requests": 97847,
    "scheduler_time": 224.36666979168857
}
#Debug simulation 
Total elapsed time: 73.66764192096889. Arrivals time: 0.453994148876518 Scheduler time: 73.01432125037536 Scheduler overhead time: 0.0775790298357606 Adapter cache time: 0.015236556995660067 Engine time: 0.0764735322445631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 70.10188114782795,
    "estimated_duration": 3600.0140420542903,
    "input_throughput": 6508.875167228203,
    "output_throughput": 5697.392776917031,
    "total_throughput": 12206.267944145235,
    "itl": 91.11466828619,
    "ttft": 1883262.2444550171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5747126318141955,
    "arrivals": 483089,
    "finished_requests": 95100,
    "scheduler_time": 230.96030029290705
}
#Debug simulation 
Total elapsed time: 70.10204514069483. Arrivals time: 0.4546170369721949 Scheduler time: 69.44371050177142 Scheduler overhead time: 0.07959595881402493 Adapter cache time: 0.015430936589837074 Engine time: 0.07776623079553246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 78.63354215305299,
    "estimated_duration": 3600.0486094030407,
    "input_throughput": 6769.46970558853,
    "output_throughput": 5915.685956121416,
    "total_throughput": 12685.155661709947,
    "itl": 99.63008374727096,
    "ttft": 1848151.121516009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8118000747542806,
    "arrivals": 473564,
    "finished_requests": 99076,
    "scheduler_time": 222.2059329594361
}
#Debug simulation 
Total elapsed time: 78.63370350236073. Arrivals time: 0.47874542558565736 Scheduler time: 77.95836692862213 Scheduler overhead time: 0.07721248222514987 Adapter cache time: 0.014437426812946796 Engine time: 0.07514244830235839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 77.62978491093963,
    "estimated_duration": 3600.098556034852,
    "input_throughput": 6724.246468036317,
    "output_throughput": 5876.284682411678,
    "total_throughput": 12600.531150447994,
    "itl": 97.45534588618833,
    "ttft": 1852123.308707503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.784787765196526,
    "arrivals": 473564,
    "finished_requests": 98417,
    "scheduler_time": 223.2959582889377
}
#Debug simulation 
Total elapsed time: 77.6299595311284. Arrivals time: 0.46574688935652375 Scheduler time: 76.96468489337713 Scheduler overhead time: 0.07813679100945592 Adapter cache time: 0.014460969250649214 Engine time: 0.07685758359730244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 69.34914714191109,
    "estimated_duration": 3600.0053231216116,
    "input_throughput": 6516.450920038688,
    "output_throughput": 5701.74462469999,
    "total_throughput": 12218.195544738679,
    "itl": 91.02724527064392,
    "ttft": 1877762.0393936473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8380478935921603,
    "arrivals": 473564,
    "finished_requests": 95497,
    "scheduler_time": 230.83191059862682
}
#Debug simulation 
Total elapsed time: 69.34931870922446. Arrivals time: 0.4389155223034322 Scheduler time: 68.71010144799948 Scheduler overhead time: 0.0785166509449482 Adapter cache time: 0.01430146163329482 Engine time: 0.0764321330934763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 76.51290585799143,
    "estimated_duration": 3600.050399488229,
    "input_throughput": 6724.025864593775,
    "output_throughput": 5876.314954648226,
    "total_throughput": 12600.340819242001,
    "itl": 97.45550668011725,
    "ttft": 1853156.7427293835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.648194403569212,
    "arrivals": 473564,
    "finished_requests": 98423,
    "scheduler_time": 223.24636605096302
}
#Debug simulation 
Total elapsed time: 76.5130852512084. Arrivals time: 0.46612929087132215 Scheduler time: 75.84820640925318 Scheduler overhead time: 0.07825237885117531 Adapter cache time: 0.014010683633387089 Engine time: 0.07644828734919429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 69.25282725784928,
    "estimated_duration": 3600.011944656689,
    "input_throughput": 6516.66060020177,
    "output_throughput": 5701.951358930155,
    "total_throughput": 12218.611959131926,
    "itl": 91.02859937874788,
    "ttft": 1877888.9153187617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8220998709928282,
    "arrivals": 473564,
    "finished_requests": 95501,
    "scheduler_time": 230.8249422692743
}
#Debug simulation 
Total elapsed time: 69.25300225801766. Arrivals time: 0.45910249650478363 Scheduler time: 68.5907540190965 Scheduler overhead time: 0.0793251283466816 Adapter cache time: 0.01455181185156107 Engine time: 0.0780844148248434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 72.323577682022,
    "estimated_duration": 3600.1025734780837,
    "input_throughput": 6690.043549712382,
    "output_throughput": 5850.096370907809,
    "total_throughput": 12540.13992062019,
    "itl": 97.08675586521755,
    "ttft": 1860233.560835653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.570444551380346,
    "arrivals": 473564,
    "finished_requests": 98049,
    "scheduler_time": 224.52129574257023
}
#Debug simulation 
Total elapsed time: 72.3237541820854. Arrivals time: 0.4572137244977057 Scheduler time: 71.66907052369788 Scheduler overhead time: 0.07723442651331425 Adapter cache time: 0.014367382973432541 Engine time: 0.07574565010145307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 69.89822845812887,
    "estimated_duration": 3600.0436083154377,
    "input_throughput": 6516.603283863448,
    "output_throughput": 5701.901208248199,
    "total_throughput": 12218.504492111648,
    "itl": 91.0272123655869,
    "ttft": 1877830.2916053608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8051162625104227,
    "arrivals": 473564,
    "finished_requests": 95501,
    "scheduler_time": 230.83753915883935
}
#Debug simulation 
Total elapsed time: 69.89840088691562. Arrivals time: 0.7242714106105268 Scheduler time: 68.97097528539598 Scheduler overhead time: 0.07960612932220101 Adapter cache time: 0.014522120356559753 Engine time: 0.07776294136419892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 74.83201267803088,
    "estimated_duration": 3600.0102057429076,
    "input_throughput": 6755.832514363953,
    "output_throughput": 5911.00463161289,
    "total_throughput": 12666.837145976844,
    "itl": 99.74627570784367,
    "ttft": 1854175.817160713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.115970890223981,
    "arrivals": 468761,
    "finished_requests": 98438,
    "scheduler_time": 222.29890567877942
}
#Debug simulation 
Total elapsed time: 74.83217372139916. Arrivals time: 0.4652616227976978 Scheduler time: 74.16894692648202 Scheduler overhead time: 0.07737975614145398 Adapter cache time: 0.014858780894428492 Engine time: 0.07603580038994551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.4288180009462,
    "estimated_duration": 3600.052130055648,
    "input_throughput": 6686.037626801792,
    "output_throughput": 5850.250007261547,
    "total_throughput": 12536.287634063337,
    "itl": 96.75063680375818,
    "ttft": 1856014.8867810643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0215595016069736,
    "arrivals": 468761,
    "finished_requests": 97454,
    "scheduler_time": 224.55002397471716
}
#Debug simulation 
Total elapsed time: 76.42898374516517. Arrivals time: 0.4751831288449466 Scheduler time: 75.75269296532497 Scheduler overhead time: 0.07885050075128675 Adapter cache time: 0.014663657639175653 Engine time: 0.07737676193937659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 66.38887411309406,
    "estimated_duration": 3600.0151649323225,
    "input_throughput": 6486.665730598111,
    "output_throughput": 5685.039940765013,
    "total_throughput": 12171.705671363123,
    "itl": 91.04900325096817,
    "ttft": 1878793.674949602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8338573916070213,
    "arrivals": 468761,
    "finished_requests": 94562,
    "scheduler_time": 231.37736009896204
}
#Debug simulation 
Total elapsed time: 66.38903910620138. Arrivals time: 0.4353658934123814 Scheduler time: 65.74945944454521 Scheduler overhead time: 0.07951421430334449 Adapter cache time: 0.014458784367889166 Engine time: 0.07910911133512855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 76.86922416463494,
    "estimated_duration": 3600.101297181167,
    "input_throughput": 6682.152254670132,
    "output_throughput": 5852.612263020915,
    "total_throughput": 12534.764517691046,
    "itl": 96.67740070375251,
    "ttft": 1857423.1168726592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8663620834005976,
    "arrivals": 468761,
    "finished_requests": 97399,
    "scheduler_time": 224.75463993338073
}
#Debug simulation 
Total elapsed time: 76.86939056403935. Arrivals time: 0.5069553898647428 Scheduler time: 76.1597695783712 Scheduler overhead time: 0.0795498052611947 Adapter cache time: 0.0143791395239532 Engine time: 0.07855501770973206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 73.5129805598408,
    "estimated_duration": 3600.013587369213,
    "input_throughput": 6519.575115590498,
    "output_throughput": 5705.417077331016,
    "total_throughput": 12224.992192921514,
    "itl": 90.8314574562704,
    "ttft": 1871970.0179947254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.832197461165493,
    "arrivals": 468761,
    "finished_requests": 95047,
    "scheduler_time": 230.69642206208556
}
#Debug simulation 
Total elapsed time: 73.51316162012517. Arrivals time: 0.4542894526384771 Scheduler time: 72.8515384378843 Scheduler overhead time: 0.08112323563545942 Adapter cache time: 0.014998263213783503 Engine time: 0.07920376397669315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 80.35414062766358,
    "estimated_duration": 3600.087378983042,
    "input_throughput": 6662.6099521994365,
    "output_throughput": 5837.858026084038,
    "total_throughput": 12500.467978283474,
    "itl": 96.72333498982235,
    "ttft": 1853992.010847648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5512927885586345,
    "arrivals": 468761,
    "finished_requests": 97194,
    "scheduler_time": 224.8962654811356
}
#Debug simulation 
Total elapsed time: 80.35431170789525. Arrivals time: 0.45681420993059874 Scheduler time: 79.69572952250019 Scheduler overhead time: 0.07907261094078422 Adapter cache time: 0.014226770494133234 Engine time: 0.07805923791602254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 74.50029069324955,
    "estimated_duration": 3600.035729072502,
    "input_throughput": 6509.300952420648,
    "output_throughput": 5710.1636058751465,
    "total_throughput": 12219.464558295795,
    "itl": 91.07952552424649,
    "ttft": 1864451.6795683783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.747450349591678,
    "arrivals": 468761,
    "finished_requests": 94898,
    "scheduler_time": 230.56779756656655
}
#Debug simulation 
Total elapsed time: 74.50045985495672. Arrivals time: 0.44970925338566303 Scheduler time: 73.8439742620103 Scheduler overhead time: 0.08055396378040314 Adapter cache time: 0.015076430048793554 Engine time: 0.07957578357309103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 76.50581168010831,
    "estimated_duration": 3600.0903123747553,
    "input_throughput": 6816.366777146987,
    "output_throughput": 5938.426579609246,
    "total_throughput": 12754.793356756232,
    "itl": 99.96814815085965,
    "ttft": 1847746.6751054404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3540176153741865,
    "arrivals": 466310,
    "finished_requests": 99230,
    "scheduler_time": 220.6142341480653
}
#Debug simulation 
Total elapsed time: 76.50598578201607. Arrivals time: 0.5023035719059408 Scheduler time: 75.80683448119089 Scheduler overhead time: 0.07640608260408044 Adapter cache time: 0.015088436659425497 Engine time: 0.07576942397281528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 73.34323530318215,
    "estimated_duration": 3600.094698618409,
    "input_throughput": 6745.17645586353,
    "output_throughput": 5877.624276972623,
    "total_throughput": 12622.800732836153,
    "itl": 97.27863083667829,
    "ttft": 1856232.341143591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.602515262565578,
    "arrivals": 466310,
    "finished_requests": 98311,
    "scheduler_time": 223.2862718245208
}
#Debug simulation 
Total elapsed time: 73.34340217709541. Arrivals time: 0.48667813232168555 Scheduler time: 72.65699724433944 Scheduler overhead time: 0.07787765190005302 Adapter cache time: 0.014951541554182768 Engine time: 0.07717573316767812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 75.17729958426207,
    "estimated_duration": 3600.013525231198,
    "input_throughput": 6538.764878248131,
    "output_throughput": 5705.474120039842,
    "total_throughput": 12244.238998287974,
    "itl": 91.00097795711186,
    "ttft": 1868823.1787528365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.747368474621342,
    "arrivals": 466310,
    "finished_requests": 95231,
    "scheduler_time": 230.0815940399609
}
#Debug simulation 
Total elapsed time: 75.17746227001771. Arrivals time: 0.49190757889300585 Scheduler time: 74.48014495382085 Scheduler overhead time: 0.07981615886092186 Adapter cache time: 0.015451288316398859 Engine time: 0.0784559203311801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 76.659662717022,
    "estimated_duration": 3600.05076528204,
    "input_throughput": 6726.167095619539,
    "output_throughput": 5870.381385675909,
    "total_throughput": 12596.54848129545,
    "itl": 97.31234694621729,
    "ttft": 1850904.852756496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4961604761797904,
    "arrivals": 466310,
    "finished_requests": 97964,
    "scheduler_time": 223.2913055289723
}
#Debug simulation 
Total elapsed time: 76.65982823772356. Arrivals time: 0.5118008893914521 Scheduler time: 75.94794892566279 Scheduler overhead time: 0.07788699679076672 Adapter cache time: 0.015695969108492136 Engine time: 0.07655819784849882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 74.68455069838092,
    "estimated_duration": 3600.0389420781003,
    "input_throughput": 6543.913101784697,
    "output_throughput": 5710.3390632028395,
    "total_throughput": 12254.252164987536,
    "itl": 91.09652527890437,
    "ttft": 1870385.0355104436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4238108576228963,
    "arrivals": 466310,
    "finished_requests": 95305,
    "scheduler_time": 229.91031052013705
}
#Debug simulation 
Total elapsed time: 74.68471767520532. Arrivals time: 0.5040959310717881 Scheduler time: 73.97335361037403 Scheduler overhead time: 0.08129207883030176 Adapter cache time: 0.015280373860150576 Engine time: 0.07924287859350443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 76.49141883710399,
    "estimated_duration": 3600.0023125734065,
    "input_throughput": 6743.559834728572,
    "output_throughput": 5868.701785610089,
    "total_throughput": 12612.261620338662,
    "itl": 97.15255306007619,
    "ttft": 1855491.3901441232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3620507480110877,
    "arrivals": 466310,
    "finished_requests": 98083,
    "scheduler_time": 223.40885185621536
}
#Debug simulation 
Total elapsed time: 76.49158024135977. Arrivals time: 0.4985447842627764 Scheduler time: 75.79349140869454 Scheduler overhead time: 0.07811204716563225 Adapter cache time: 0.015380290802568197 Engine time: 0.07572799175977707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.90835542883724,
    "estimated_duration": 3600.0759142087973,
    "input_throughput": 6535.248856042723,
    "output_throughput": 5699.643143361207,
    "total_throughput": 12234.89199940393,
    "itl": 91.02169629778933,
    "ttft": 1867532.4602569118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6162801222317063,
    "arrivals": 466310,
    "finished_requests": 95112,
    "scheduler_time": 230.40754967596646
}
#Debug simulation 
Total elapsed time: 76.90859336405993. Arrivals time: 0.4612085926346481 Scheduler time: 76.23990415781736 Scheduler overhead time: 0.08096929080784321 Adapter cache time: 0.015715486835688353 Engine time: 0.07914701523259282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 80.11325252475217,
    "estimated_duration": 3600.0601286418414,
    "input_throughput": 6857.778514192192,
    "output_throughput": 5953.0933468284165,
    "total_throughput": 12810.871861020609,
    "itl": 100.19411387651567,
    "ttft": 1836313.3059276247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.692776712179182,
    "arrivals": 465116,
    "finished_requests": 99637,
    "scheduler_time": 220.08780466780476
}
#Debug simulation 
Total elapsed time: 80.1134273018688. Arrivals time: 0.4577628877013922 Scheduler time: 79.45701955305412 Scheduler overhead time: 0.0783092025667429 Adapter cache time: 0.013596480246633291 Engine time: 0.07676078518852592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 78.74160479195416,
    "estimated_duration": 3600.017642991869,
    "input_throughput": 6755.313837792469,
    "output_throughput": 5867.604577194487,
    "total_throughput": 12622.918414986956,
    "itl": 96.87009455272026,
    "ttft": 1848598.828635601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.156736209210942,
    "arrivals": 465116,
    "finished_requests": 98132,
    "scheduler_time": 224.22821259243884
}
#Debug simulation 
Total elapsed time: 78.74177286401391. Arrivals time: 0.47030931059271097 Scheduler time: 78.069916381035 Scheduler overhead time: 0.07872078055515885 Adapter cache time: 0.014933624304831028 Engine time: 0.07732317736372352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 77.5608471040614,
    "estimated_duration": 3600.0112905606507,
    "input_throughput": 6543.376978223713,
    "output_throughput": 5682.061068429135,
    "total_throughput": 12225.438046652847,
    "itl": 90.70600765353159,
    "ttft": 1868019.9692525053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0416585343284592,
    "arrivals": 465116,
    "finished_requests": 95081,
    "scheduler_time": 231.1675706576356
}
#Debug simulation 
Total elapsed time: 77.5610176869668. Arrivals time: 0.4631056347861886 Scheduler time: 76.88927314057946 Scheduler overhead time: 0.0814876826480031 Adapter cache time: 0.015241642016917467 Engine time: 0.08006821619346738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 77.3840374648571,
    "estimated_duration": 3600.086423743631,
    "input_throughput": 6779.5283577164655,
    "output_throughput": 5888.543080572902,
    "total_throughput": 12668.071438289368,
    "itl": 97.25839679542888,
    "ttft": 1846693.506683803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.004872416877186,
    "arrivals": 465116,
    "finished_requests": 98418,
    "scheduler_time": 223.53077462289198
}
#Debug simulation 
Total elapsed time: 77.3842048086226. Arrivals time: 0.46270646108314395 Scheduler time: 76.72202252130955 Scheduler overhead time: 0.07840932719409466 Adapter cache time: 0.014544785488396883 Engine time: 0.07679374376311898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 77.67144990898669,
    "estimated_duration": 3600.0841699198468,
    "input_throughput": 6606.045824903448,
    "output_throughput": 5733.349006798235,
    "total_throughput": 12339.394831701682,
    "itl": 91.16311678159035,
    "ttft": 1862910.533419261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0591004048241364,
    "arrivals": 465116,
    "finished_requests": 95915,
    "scheduler_time": 229.8969580086779
}
#Debug simulation 
Total elapsed time: 77.67161122523248. Arrivals time: 0.46692732675001025 Scheduler time: 76.99589519947767 Scheduler overhead time: 0.0813549030572176 Adapter cache time: 0.015071969013661146 Engine time: 0.08026493806391954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 77.95348647003993,
    "estimated_duration": 3600.0875076503826,
    "input_throughput": 6778.287735546291,
    "output_throughput": 5883.327267737324,
    "total_throughput": 12661.615003283616,
    "itl": 97.25570389745462,
    "ttft": 1847099.1218613018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9087923612305824,
    "arrivals": 465116,
    "finished_requests": 98394,
    "scheduler_time": 223.47170545450822
}
#Debug simulation 
Total elapsed time: 77.95364442002028. Arrivals time: 0.46353413769975305 Scheduler time: 77.2922098650597 Scheduler overhead time: 0.07743915636092424 Adapter cache time: 0.01428175251930952 Engine time: 0.07639427343383431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 75.2002801252529,
    "estimated_duration": 3600.0007124690455,
    "input_throughput": 6572.645643664842,
    "output_throughput": 5710.286647665978,
    "total_throughput": 12282.93229133082,
    "itl": 91.02843900646995,
    "ttft": 1869650.191462548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4990264482796323,
    "arrivals": 465116,
    "finished_requests": 95434,
    "scheduler_time": 229.97575630608316
}
#Debug simulation 
Total elapsed time: 75.20045056613162. Arrivals time: 0.4528996078297496 Scheduler time: 74.54006747808307 Scheduler overhead time: 0.08098644576966763 Adapter cache time: 0.01567764300853014 Engine time: 0.07939767744392157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 76.52537147514522,
    "estimated_duration": 3600.0429689641987,
    "input_throughput": 6833.172329350782,
    "output_throughput": 5950.75980611526,
    "total_throughput": 12783.932135466042,
    "itl": 100.23036760939104,
    "ttft": 1839343.5588840407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8911489831376798,
    "arrivals": 464531,
    "finished_requests": 99687,
    "scheduler_time": 221.2690771723454
}
#Debug simulation 
Total elapsed time: 76.52554055396467. Arrivals time: 0.46022452507168055 Scheduler time: 75.86949485214427 Scheduler overhead time: 0.07668597158044577 Adapter cache time: 0.014169917441904545 Engine time: 0.07524332776665688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.5553981596604,
    "estimated_duration": 3600.072326899647,
    "input_throughput": 6763.951606764144,
    "output_throughput": 5886.797007284336,
    "total_throughput": 12650.748614048482,
    "itl": 97.06424200510112,
    "ttft": 1849130.6873320646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.104276620713065,
    "arrivals": 464531,
    "finished_requests": 98643,
    "scheduler_time": 224.08354018430106
}
#Debug simulation 
Total elapsed time: 76.55556467361748. Arrivals time: 0.48123776260763407 Scheduler time: 75.87414931459352 Scheduler overhead time: 0.07828081585466862 Adapter cache time: 0.014683605637401342 Engine time: 0.07683581532910466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 75.40856448607519,
    "estimated_duration": 3600.058804822518,
    "input_throughput": 6583.263853427085,
    "output_throughput": 5731.921093165953,
    "total_throughput": 12315.184946593039,
    "itl": 91.27427828380017,
    "ttft": 1860323.7412961605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9180357381329003,
    "arrivals": 464531,
    "finished_requests": 95999,
    "scheduler_time": 230.18193683226272
}
#Debug simulation 
Total elapsed time: 75.40873047616333. Arrivals time: 0.49609154975041747 Scheduler time: 74.70815574936569 Scheduler overhead time: 0.0796424257569015 Adapter cache time: 0.014888236299157143 Engine time: 0.07863595243543386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 76.61534127919003,
    "estimated_duration": 3600.044662873452,
    "input_throughput": 6745.21159429671,
    "output_throughput": 5873.6201853458215,
    "total_throughput": 12618.83177964253,
    "itl": 97.4788098303667,
    "ttft": 1842437.9598087799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.769215048318727,
    "arrivals": 464531,
    "finished_requests": 98389,
    "scheduler_time": 224.24216924798537
}
#Debug simulation 
Total elapsed time: 76.61551257036626. Arrivals time: 0.5201777219772339 Scheduler time: 75.89598442893475 Scheduler overhead time: 0.07791666546836495 Adapter cache time: 0.014463885687291622 Engine time: 0.07658567884936929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 71.29745279019699,
    "estimated_duration": 3600.00101427799,
    "input_throughput": 6588.535088164965,
    "output_throughput": 5731.901996182768,
    "total_throughput": 12320.437084347732,
    "itl": 91.43661973279565,
    "ttft": 1863269.234557967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7589470287831555,
    "arrivals": 464531,
    "finished_requests": 96070,
    "scheduler_time": 229.98223360454654
}
#Debug simulation 
Total elapsed time: 71.29762653214857. Arrivals time: 0.45045600831508636 Scheduler time: 70.64273135270923 Scheduler overhead time: 0.08061714516952634 Adapter cache time: 0.014544229954481125 Engine time: 0.07803763635456562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 74.86537039000541,
    "estimated_duration": 3600.098600006541,
    "input_throughput": 6768.211015097123,
    "output_throughput": 5888.001234177722,
    "total_throughput": 12656.212249274844,
    "itl": 97.68648855084328,
    "ttft": 1844067.1059545164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.813033547122025,
    "arrivals": 464531,
    "finished_requests": 98698,
    "scheduler_time": 223.5961249162657
}
#Debug simulation 
Total elapsed time: 74.86552953300998. Arrivals time: 0.48764269705861807 Scheduler time: 74.17941212654114 Scheduler overhead time: 0.07694893330335617 Adapter cache time: 0.014212635345757008 Engine time: 0.07698789099231362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 71.81084260297939,
    "estimated_duration": 3600.064228968159,
    "input_throughput": 6597.840063205739,
    "output_throughput": 5737.268194773277,
    "total_throughput": 12335.108257979016,
    "itl": 91.42563492146064,
    "ttft": 1864807.6109066494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7886573299020578,
    "arrivals": 464531,
    "finished_requests": 96215,
    "scheduler_time": 229.76169350219644
}
#Debug simulation 
Total elapsed time: 71.81100526731461. Arrivals time: 0.4642036999575794 Scheduler time: 71.14297387795523 Scheduler overhead time: 0.07959985360503197 Adapter cache time: 0.014651547186076641 Engine time: 0.07801667088642716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 76.20029925694689,
    "estimated_duration": 3600.0404909003155,
    "input_throughput": 6840.135287989975,
    "output_throughput": 5947.458939453598,
    "total_throughput": 12787.594227443573,
    "itl": 99.69231017046113,
    "ttft": 1799677.309082433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7192263483069816,
    "arrivals": 406769,
    "finished_requests": 99784,
    "scheduler_time": 219.81757247729556
}
#Debug simulation 
Total elapsed time: 76.20046845404431. Arrivals time: 0.46250704815611243 Scheduler time: 75.54044230328873 Scheduler overhead time: 0.0774689894169569 Adapter cache time: 0.014554237015545368 Engine time: 0.07568187732249498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 77.27465577796102,
    "estimated_duration": 3600.080106698767,
    "input_throughput": 6765.707783745728,
    "output_throughput": 5880.346373573447,
    "total_throughput": 12646.054157319175,
    "itl": 97.03825686150837,
    "ttft": 1808687.4347851756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1589554672315736,
    "arrivals": 406769,
    "finished_requests": 98669,
    "scheduler_time": 222.52978620921235
}
#Debug simulation 
Total elapsed time: 77.27490366436541. Arrivals time: 0.46017139172181487 Scheduler time: 76.61332870321348 Scheduler overhead time: 0.07879899861291051 Adapter cache time: 0.014765155501663685 Engine time: 0.07755505153909326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 71.07194500975311,
    "estimated_duration": 3600.0441057337052,
    "input_throughput": 6581.1907588202575,
    "output_throughput": 5729.385917008458,
    "total_throughput": 12310.576675828715,
    "itl": 91.3430991067963,
    "ttft": 1826954.119127477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8979980199970352,
    "arrivals": 406769,
    "finished_requests": 96046,
    "scheduler_time": 228.68381338687647
}
#Debug simulation 
Total elapsed time: 71.07212335290387. Arrivals time: 0.4505996610969305 Scheduler time: 70.41740268515423 Scheduler overhead time: 0.07975641870871186 Adapter cache time: 0.014620455913245678 Engine time: 0.07865365920588374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 71.93744772905484,
    "estimated_duration": 3600.080317237076,
    "input_throughput": 6757.152856708903,
    "output_throughput": 5877.391651150379,
    "total_throughput": 12634.544507859282,
    "itl": 97.11025822355948,
    "ttft": 1806883.2532662456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9940405022120076,
    "arrivals": 406769,
    "finished_requests": 98557,
    "scheduler_time": 222.19894764447932
}
#Debug simulation 
Total elapsed time: 71.9376185880974. Arrivals time: 0.4448610655963421 Scheduler time: 71.29574431059882 Scheduler overhead time: 0.07685951655730605 Adapter cache time: 0.014627994503825903 Engine time: 0.07556395279243588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 69.7408092720434,
    "estimated_duration": 3600.0927357609457,
    "input_throughput": 6598.429469339476,
    "output_throughput": 5741.127942258774,
    "total_throughput": 12339.55741159825,
    "itl": 91.20388450702234,
    "ttft": 1825957.3236304244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8194092029612556,
    "arrivals": 406769,
    "finished_requests": 96306,
    "scheduler_time": 228.58843831917147
}
#Debug simulation 
Total elapsed time: 69.74098220374435. Arrivals time: 0.4474278367124498 Scheduler time: 69.08988627279177 Scheduler overhead time: 0.0796463587321341 Adapter cache time: 0.014665030408650637 Engine time: 0.07778247259557247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 74.60033908672631,
    "estimated_duration": 3600.052673299222,
    "input_throughput": 6790.4420347263485,
    "output_throughput": 5901.404487098784,
    "total_throughput": 12691.846521825131,
    "itl": 97.20683366404744,
    "ttft": 1803788.255551629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.595980235142628,
    "arrivals": 406769,
    "finished_requests": 99009,
    "scheduler_time": 221.9852477182538
}
#Debug simulation 
Total elapsed time: 74.60051504755393. Arrivals time: 0.4662704160436988 Scheduler time: 73.93469294905663 Scheduler overhead time: 0.07786282338202 Adapter cache time: 0.014265985693782568 Engine time: 0.07706337422132492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.98742342274636,
    "estimated_duration": 3600.05482263289,
    "input_throughput": 6558.9662278339865,
    "output_throughput": 5713.229662696552,
    "total_throughput": 12272.195890530538,
    "itl": 91.13172524867478,
    "ttft": 1817263.27639991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.990967832803732,
    "arrivals": 406769,
    "finished_requests": 95706,
    "scheduler_time": 228.91502432282587
}
#Debug simulation 
Total elapsed time: 76.98759212484583. Arrivals time: 0.45744756422936916 Scheduler time: 76.32318775262684 Scheduler overhead time: 0.08072314085438848 Adapter cache time: 0.015290830750018358 Engine time: 0.07960098376497626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 76.42950019519776,
    "estimated_duration": 3600.001293195101,
    "input_throughput": 6779.704231255473,
    "output_throughput": 5923.840094255281,
    "total_throughput": 12703.544325510753,
    "itl": 99.35162810016956,
    "ttft": 1797749.9343168377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7192263483069816,
    "arrivals": 397242,
    "finished_requests": 98691,
    "scheduler_time": 220.21091798020942
}
#Debug simulation 
Total elapsed time: 76.42968180915341. Arrivals time: 0.4537635985761881 Scheduler time: 75.77995786862448 Scheduler overhead time: 0.07692013680934906 Adapter cache time: 0.014279300346970558 Engine time: 0.07523114560171962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 73.2156876269728,
    "estimated_duration": 3600.046464916815,
    "input_throughput": 6713.238352760662,
    "output_throughput": 5861.419902669946,
    "total_throughput": 12574.658255430608,
    "itl": 96.75463978168852,
    "ttft": 1806257.2700509254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.028774459594863,
    "arrivals": 397242,
    "finished_requests": 97700,
    "scheduler_time": 222.7961972019285
}
#Debug simulation 
Total elapsed time: 73.21586201526225. Arrivals time: 0.4586119679734111 Scheduler time: 72.55916376318783 Scheduler overhead time: 0.07741229562088847 Adapter cache time: 0.014723372180014849 Engine time: 0.07585848588496447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 69.35507987719029,
    "estimated_duration": 3600.0466795557127,
    "input_throughput": 6506.582021011681,
    "output_throughput": 5700.793024865108,
    "total_throughput": 12207.375045876788,
    "itl": 90.7333774069732,
    "ttft": 1822828.7836500248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4188941898942113,
    "arrivals": 397242,
    "finished_requests": 94927,
    "scheduler_time": 229.441523584829
}
#Debug simulation 
Total elapsed time: 69.35525334207341. Arrivals time: 0.4539769235998392 Scheduler time: 68.69926866143942 Scheduler overhead time: 0.0786743825301528 Adapter cache time: 0.015055095311254263 Engine time: 0.07728379452601075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 75.85816084919497,
    "estimated_duration": 3600.070368862828,
    "input_throughput": 6691.661976487857,
    "output_throughput": 5842.5255189231075,
    "total_throughput": 12534.187495410964,
    "itl": 96.47589701381119,
    "ttft": 1802851.6281263013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8799609623290576,
    "arrivals": 397242,
    "finished_requests": 97392,
    "scheduler_time": 223.3041720893185
}
#Debug simulation 
Total elapsed time: 75.85832626605406. Arrivals time: 0.48314882488921285 Scheduler time: 75.17456908617169 Scheduler overhead time: 0.07866063341498375 Adapter cache time: 0.015040200669318438 Engine time: 0.07648250134661794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 63.32467211969197,
    "estimated_duration": 3600.0996998284613,
    "input_throughput": 6542.386312557475,
    "output_throughput": 5720.870175062471,
    "total_throughput": 12263.256487619947,
    "itl": 91.14908818375773,
    "ttft": 1822933.7382021889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.436957770669844,
    "arrivals": 397242,
    "finished_requests": 95266,
    "scheduler_time": 228.32244391061795
}
#Debug simulation 
Total elapsed time: 63.324853238649666. Arrivals time: 0.43196392245590687 Scheduler time: 62.6907346220687 Scheduler overhead time: 0.07819890091195703 Adapter cache time: 0.01525508239865303 Engine time: 0.07727702287957072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 69.91722676996142,
    "estimated_duration": 3600.0032789082316,
    "input_throughput": 6725.698318625672,
    "output_throughput": 5878.367979269679,
    "total_throughput": 12604.066297895351,
    "itl": 96.9481808559917,
    "ttft": 1798906.6971294598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9662476496957169,
    "arrivals": 397242,
    "finished_requests": 97926,
    "scheduler_time": 222.2968705155178
}
#Debug simulation 
Total elapsed time: 69.91740242391825. Arrivals time: 0.455540029797703 Scheduler time: 69.26394292665645 Scheduler overhead time: 0.07735588541254401 Adapter cache time: 0.014589286409318447 Engine time: 0.0758498813956976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 68.66072476701811,
    "estimated_duration": 3600.093841932324,
    "input_throughput": 6551.138396809423,
    "output_throughput": 5720.472827715567,
    "total_throughput": 12271.61122452499,
    "itl": 91.11700751392233,
    "ttft": 1823287.0598377062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0385420800931806,
    "arrivals": 397242,
    "finished_requests": 95356,
    "scheduler_time": 228.35439467277956
}
#Debug simulation 
Total elapsed time: 68.66089802188799. Arrivals time: 0.4484328394755721 Scheduler time: 68.00959978811443 Scheduler overhead time: 0.0798015845939517 Adapter cache time: 0.014818751718848944 Engine time: 0.07716670539230108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 79.74153379909694,
    "estimated_duration": 3600.0182867078156,
    "input_throughput": 6785.378032715138,
    "output_throughput": 5921.853530220768,
    "total_throughput": 12707.231562935907,
    "itl": 99.49350914458827,
    "ttft": 1784607.3045941524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6398774399235825,
    "arrivals": 392500,
    "finished_requests": 99155,
    "scheduler_time": 220.00663095618785
}
#Debug simulation 
Total elapsed time: 79.74170003505424. Arrivals time: 0.4537710342556238 Scheduler time: 79.09019662532955 Scheduler overhead time: 0.0775044965557754 Adapter cache time: 0.01460811123251915 Engine time: 0.07562647201120853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.39798805722967,
    "estimated_duration": 3600.066673333405,
    "input_throughput": 6715.870064043365,
    "output_throughput": 5862.770585983901,
    "total_throughput": 12578.640650027266,
    "itl": 96.93195992726073,
    "ttft": 1790286.955859013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8341970586264524,
    "arrivals": 392500,
    "finished_requests": 98157,
    "scheduler_time": 222.37994455971057
}
#Debug simulation 
Total elapsed time: 76.39814935391769. Arrivals time: 0.4560726787894964 Scheduler time: 75.74347130488604 Scheduler overhead time: 0.0775595186278224 Adapter cache time: 0.014124161098152399 Engine time: 0.07688515307381749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 73.4051459361799,
    "estimated_duration": 3600.0657332461615,
    "input_throughput": 6556.505561001666,
    "output_throughput": 5708.510489187444,
    "total_throughput": 12265.016050189111,
    "itl": 90.76445216934871,
    "ttft": 1820150.0167425512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8916307530179663,
    "arrivals": 392500,
    "finished_requests": 95724,
    "scheduler_time": 229.08361398088883
}
#Debug simulation 
Total elapsed time: 73.40530959423631. Arrivals time: 0.44022894324734807 Scheduler time: 72.75927115231752 Scheduler overhead time: 0.08054376626387239 Adapter cache time: 0.015008557587862015 Engine time: 0.07881577499210835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 73.86847789119929,
    "estimated_duration": 3600.0188969503497,
    "input_throughput": 6728.23773800709,
    "output_throughput": 5862.377838593626,
    "total_throughput": 12590.615576600716,
    "itl": 96.28874618672346,
    "ttft": 1799095.6405542395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6837214872660093,
    "arrivals": 392500,
    "finished_requests": 98196,
    "scheduler_time": 223.13061280237187
}
#Debug simulation 
Total elapsed time: 73.86865065526217. Arrivals time: 0.4585227738134563 Scheduler time: 73.20794254075736 Scheduler overhead time: 0.07882163999602199 Adapter cache time: 0.014765641186386347 Engine time: 0.07780210394412279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 76.04566252604127,
    "estimated_duration": 3600.059816370011,
    "input_throughput": 6535.862791225816,
    "output_throughput": 5692.715134012549,
    "total_throughput": 12228.577925238365,
    "itl": 90.73388806719885,
    "ttft": 1809427.1333565933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.935007794764828,
    "arrivals": 392500,
    "finished_requests": 95431,
    "scheduler_time": 229.31029125066814
}
#Debug simulation 
Total elapsed time: 76.04582306882367. Arrivals time: 0.45038113882765174 Scheduler time: 75.3887146259658 Scheduler overhead time: 0.08077333029359579 Adapter cache time: 0.01470007561147213 Engine time: 0.0791856124997139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 75.19786011381075,
    "estimated_duration": 3600.0508538401846,
    "input_throughput": 6726.490814475311,
    "output_throughput": 5868.804319100856,
    "total_throughput": 12595.295133576166,
    "itl": 97.0976123283339,
    "ttft": 1793804.3547356424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5895963142020575,
    "arrivals": 392500,
    "finished_requests": 98256,
    "scheduler_time": 222.19925739708722
}
#Debug simulation 
Total elapsed time: 75.19802339188755. Arrivals time: 0.4448106409981847 Scheduler time: 74.55704016704112 Scheduler overhead time: 0.07649311563000083 Adapter cache time: 0.014249107800424099 Engine time: 0.07539670169353485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 68.42069765087217,
    "estimated_duration": 3600.0632126961746,
    "input_throughput": 6549.887212213799,
    "output_throughput": 5703.552073082135,
    "total_throughput": 12253.439285295935,
    "itl": 90.66012717803827,
    "ttft": 1817698.5504484905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9231506054662213,
    "arrivals": 392500,
    "finished_requests": 95581,
    "scheduler_time": 229.4922861848171
}
#Debug simulation 
Total elapsed time: 68.42086195712909. Arrivals time: 0.4344035894609988 Scheduler time: 67.78137905569747 Scheduler overhead time: 0.08000589953735471 Adapter cache time: 0.01480735931545496 Engine time: 0.07856399333104491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 76.03485746867955,
    "estimated_duration": 3600.013436427108,
    "input_throughput": 6786.487170516615,
    "output_throughput": 5934.055352082724,
    "total_throughput": 12720.542522599339,
    "itl": 99.59291192372895,
    "ttft": 1787552.8038649526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6266526218596826,
    "arrivals": 390109,
    "finished_requests": 98942,
    "scheduler_time": 220.10054271972217
}
#Debug simulation 
Total elapsed time: 76.03503729961812. Arrivals time: 0.46884004259482026 Scheduler time: 75.36864119768143 Scheduler overhead time: 0.07723935460671782 Adapter cache time: 0.014372592326253653 Engine time: 0.07607519580051303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 68.32854800205678,
    "estimated_duration": 3600.074699121838,
    "input_throughput": 6724.18519701964,
    "output_throughput": 5884.5803963922235,
    "total_throughput": 12608.765593411865,
    "itl": 97.612989161064,
    "ttft": 1799046.9348948712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8292013586591949,
    "arrivals": 390109,
    "finished_requests": 98107,
    "scheduler_time": 221.7812415848563
}
#Debug simulation 
Total elapsed time: 68.32872069487348. Arrivals time: 0.43563281651586294 Scheduler time: 67.69784967182204 Scheduler overhead time: 0.07599992584437132 Adapter cache time: 0.013761762995272875 Engine time: 0.07549501024186611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 66.7037868280895,
    "estimated_duration": 3600.0259516639144,
    "input_throughput": 6532.595130079638,
    "output_throughput": 5723.140131941878,
    "total_throughput": 12255.735262021515,
    "itl": 91.18380861077812,
    "ttft": 1817370.4825182643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8431743127759588,
    "arrivals": 390109,
    "finished_requests": 95272,
    "scheduler_time": 228.52984346707706
}
#Debug simulation 
Total elapsed time: 66.7039539818652. Arrivals time: 0.43443040922284126 Scheduler time: 66.06706622894853 Scheduler overhead time: 0.07920391205698252 Adapter cache time: 0.014399589505046606 Engine time: 0.07786635728552938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 67.40195516496897,
    "estimated_duration": 3600.1072946262557,
    "input_throughput": 6723.711272753317,
    "output_throughput": 5885.754858370066,
    "total_throughput": 12609.466131123383,
    "itl": 97.55862311205345,
    "ttft": 1797709.2648083207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1841793871391544,
    "arrivals": 390109,
    "finished_requests": 98048,
    "scheduler_time": 221.7626354209898
}
#Debug simulation 
Total elapsed time: 67.40212483191863. Arrivals time: 0.45867699291557074 Scheduler time: 66.74860820034519 Scheduler overhead time: 0.07573790475726128 Adapter cache time: 0.01462181843817234 Engine time: 0.07449128432199359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 63.22871518926695,
    "estimated_duration": 3600.0322135495394,
    "input_throughput": 6550.549439875308,
    "output_throughput": 5740.331134321842,
    "total_throughput": 12290.88057419715,
    "itl": 91.64637852724239,
    "ttft": 1816080.4920893116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8738186758291027,
    "arrivals": 390109,
    "finished_requests": 95580,
    "scheduler_time": 227.52612482918445
}
#Debug simulation 
Total elapsed time: 63.22897275723517. Arrivals time: 0.4432728085666895 Scheduler time: 62.58446711860597 Scheduler overhead time: 0.07834469899535179 Adapter cache time: 0.014275092631578445 Engine time: 0.07759467791765928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 68.22836237121373,
    "estimated_duration": 3600.100565358755,
    "input_throughput": 6720.0358881055745,
    "output_throughput": 5882.1709603797535,
    "total_throughput": 12602.206848485328,
    "itl": 97.68634408335055,
    "ttft": 1798898.2560663559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6534355236077625,
    "arrivals": 390109,
    "finished_requests": 98062,
    "scheduler_time": 221.69682296628557
}
#Debug simulation 
Total elapsed time: 68.22854245500639. Arrivals time: 0.4563187132589519 Scheduler time: 67.57344227097929 Scheduler overhead time: 0.07692023226991296 Adapter cache time: 0.014310993254184723 Engine time: 0.07767265010625124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 63.455790378153324,
    "estimated_duration": 3600.025533260434,
    "input_throughput": 6540.262223828148,
    "output_throughput": 5734.2718292622185,
    "total_throughput": 12274.534053090367,
    "itl": 91.665903532426,
    "ttft": 1816312.0391447712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.79688679620624,
    "arrivals": 390109,
    "finished_requests": 95451,
    "scheduler_time": 227.57659460250008
}
#Debug simulation 
Total elapsed time: 63.45597374998033. Arrivals time: 0.4314140980131924 Scheduler time: 62.8237287173979 Scheduler overhead time: 0.07839894900098443 Adapter cache time: 0.014258808922022581 Engine time: 0.0771586038172245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 78.19478737888858,
    "estimated_duration": 3600.030618971416,
    "input_throughput": 6817.759790891067,
    "output_throughput": 5939.826702393329,
    "total_throughput": 12757.586493284396,
    "itl": 100.07139707510929,
    "ttft": 1783725.897959648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7522883934667313,
    "arrivals": 388923,
    "finished_requests": 99051,
    "scheduler_time": 219.5222811679078
}
#Debug simulation 
Total elapsed time: 78.19495303789154. Arrivals time: 0.4535949514247477 Scheduler time: 77.54540146840736 Scheduler overhead time: 0.07662945613265038 Adapter cache time: 0.014386904425919056 Engine time: 0.07507229829207063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 73.655239273794,
    "estimated_duration": 3600.02319353371,
    "input_throughput": 6722.270579664084,
    "output_throughput": 5871.884669512493,
    "total_throughput": 12594.155249176578,
    "itl": 97.64055575790735,
    "ttft": 1790183.1782808015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7456532025057838,
    "arrivals": 388923,
    "finished_requests": 97835,
    "scheduler_time": 222.04121302790517
}
#Debug simulation 
Total elapsed time: 73.65542439557612. Arrivals time: 0.474085820838809 Scheduler time: 72.98073050938547 Scheduler overhead time: 0.07880094414576888 Adapter cache time: 0.014477498829364777 Engine time: 0.07697707088664174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 77.67308649094775,
    "estimated_duration": 3600.0335279853466,
    "input_throughput": 6553.277022728892,
    "output_throughput": 5716.027042535855,
    "total_throughput": 12269.304065264747,
    "itl": 91.24047662085538,
    "ttft": 1808290.0661250642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9163269317383014,
    "arrivals": 388923,
    "finished_requests": 95199,
    "scheduler_time": 228.65270587539072
}
#Debug simulation 
Total elapsed time: 77.67325219511986. Arrivals time: 0.44371473602950573 Scheduler time: 77.02118481509387 Scheduler overhead time: 0.08161577070131898 Adapter cache time: 0.014941911213099957 Engine time: 0.07987766433507204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 75.64801610307768,
    "estimated_duration": 3600.0732778187826,
    "input_throughput": 6748.524023022109,
    "output_throughput": 5892.420337858414,
    "total_throughput": 12640.944360880523,
    "itl": 97.77933008100092,
    "ttft": 1783654.8877659426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0129184119123944,
    "arrivals": 388923,
    "finished_requests": 98140,
    "scheduler_time": 221.173384816935
}
#Debug simulation 
Total elapsed time: 75.64817932387814. Arrivals time: 0.45309783797711134 Scheduler time: 74.99685775535181 Scheduler overhead time: 0.07710462855175138 Adapter cache time: 0.014840160962194204 Engine time: 0.07612182525917888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 76.99797012191266,
    "estimated_duration": 3600.025236465466,
    "input_throughput": 6536.691676946176,
    "output_throughput": 5717.56603023398,
    "total_throughput": 12254.257707180155,
    "itl": 91.2033406790683,
    "ttft": 1798849.4310294287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5114902499364726,
    "arrivals": 388923,
    "finished_requests": 95058,
    "scheduler_time": 228.667861141336
}
#Debug simulation 
Total elapsed time: 76.99814288225025. Arrivals time: 0.42466771323233843 Scheduler time: 76.36789965676144 Scheduler overhead time: 0.08054537884891033 Adapter cache time: 0.013823667075484991 Engine time: 0.07965300744399428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 75.34407371515408,
    "estimated_duration": 3600.0618837260818,
    "input_throughput": 6756.105251953669,
    "output_throughput": 5891.799275974299,
    "total_throughput": 12647.904527927969,
    "itl": 97.77849074810537,
    "ttft": 1791960.1648937778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.170533119793973,
    "arrivals": 388923,
    "finished_requests": 98258,
    "scheduler_time": 221.20919593224704
}
#Debug simulation 
Total elapsed time: 75.34424420818686. Arrivals time: 0.440125263761729 Scheduler time: 74.70416032755747 Scheduler overhead time: 0.07768373657017946 Adapter cache time: 0.015141268260776997 Engine time: 0.07639233488589525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.34096192894503,
    "estimated_duration": 3600.0816446588133,
    "input_throughput": 6563.1842086290435,
    "output_throughput": 5719.355845873148,
    "total_throughput": 12282.540054502191,
    "itl": 91.15929022700216,
    "ttft": 1810720.9274433453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8782192265056146,
    "arrivals": 388923,
    "finished_requests": 95248,
    "scheduler_time": 228.81154128961347
}
#Debug simulation 
Total elapsed time: 76.34112652298063. Arrivals time: 0.4376078164204955 Scheduler time: 75.69786346424371 Scheduler overhead time: 0.0801444691605866 Adapter cache time: 0.014553281012922525 Engine time: 0.07943989103659987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 71.91837261291221,
    "estimated_duration": 3600.1028386423736,
    "input_throughput": 6770.916302266625,
    "output_throughput": 5948.540905591435,
    "total_throughput": 12719.45720785806,
    "itl": 100.33849067793545,
    "ttft": 1792603.4902008672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.686164303147232,
    "arrivals": 388315,
    "finished_requests": 98774,
    "scheduler_time": 218.98389354903904
}
#Debug simulation 
Total elapsed time: 71.91854538209736. Arrivals time: 0.43828550912439823 Scheduler time: 71.28768381197006 Scheduler overhead time: 0.07502088695764542 Adapter cache time: 0.013845022302120924 Engine time: 0.07430071849375963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 74.3041811469011,
    "estimated_duration": 3600.0229977833574,
    "input_throughput": 6692.670023173535,
    "output_throughput": 5877.065233479718,
    "total_throughput": 12569.735256653252,
    "itl": 97.36012364249765,
    "ttft": 1795512.4246226314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7356618025712687,
    "arrivals": 388315,
    "finished_requests": 97614,
    "scheduler_time": 221.88207410518856
}
#Debug simulation 
Total elapsed time: 74.30434488365427. Arrivals time: 0.4339467529207468 Scheduler time: 73.67349399486557 Scheduler overhead time: 0.07648676820099354 Adapter cache time: 0.014096520375460386 Engine time: 0.07577752601355314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 64.43399623595178,
    "estimated_duration": 3600.0002884917517,
    "input_throughput": 6506.903923003302,
    "output_throughput": 5712.610653321929,
    "total_throughput": 12219.514576325231,
    "itl": 91.11676957985657,
    "ttft": 1824825.1104091331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8186411620583447,
    "arrivals": 388315,
    "finished_requests": 94870,
    "scheduler_time": 228.67133398726827
}
#Debug simulation 
Total elapsed time: 64.43415712192655. Arrivals time: 0.4139478034339845 Scheduler time: 63.82109517138451 Scheduler overhead time: 0.0775703969411552 Adapter cache time: 0.014211053494364023 Engine time: 0.07615019520744681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 77.97837153682485,
    "estimated_duration": 3600.0792979403604,
    "input_throughput": 6654.862023096718,
    "output_throughput": 5847.50341806186,
    "total_throughput": 12502.365441158578,
    "itl": 96.70177057243203,
    "ttft": 1786109.7133423253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6176630198396724,
    "arrivals": 388315,
    "finished_requests": 97032,
    "scheduler_time": 223.1290601067549
}
#Debug simulation 
Total elapsed time: 77.97853097319603. Arrivals time: 0.4455534820444882 Scheduler time: 77.33484009513631 Scheduler overhead time: 0.07765338569879532 Adapter cache time: 0.014013133011758327 Engine time: 0.07591745583340526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 60.10017587803304,
    "estimated_duration": 3600.0074644839165,
    "input_throughput": 6535.978114526802,
    "output_throughput": 5729.169231863449,
    "total_throughput": 12265.14734639025,
    "itl": 91.44452177722873,
    "ttft": 1822339.9057736367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7884550610184722,
    "arrivals": 388315,
    "finished_requests": 95187,
    "scheduler_time": 227.90994140977375
}
#Debug simulation 
Total elapsed time: 60.100348165258765. Arrivals time: 0.4353046896867454 Scheduler time: 59.46442532725632 Scheduler overhead time: 0.07827518368139863 Adapter cache time: 0.014296541921794415 Engine time: 0.0767264268361032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 71.73008456313983,
    "estimated_duration": 3600.0421816128423,
    "input_throughput": 6702.493410560522,
    "output_throughput": 5880.856093334747,
    "total_throughput": 12583.349503895268,
    "itl": 97.66451401883081,
    "ttft": 1799401.2889510253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.608748077023769,
    "arrivals": 388315,
    "finished_requests": 97745,
    "scheduler_time": 221.77971908144636
}
#Debug simulation 
Total elapsed time: 71.73024491406977. Arrivals time: 0.45169914001598954 Scheduler time: 71.08432738948613 Scheduler overhead time: 0.07548913639038801 Adapter cache time: 0.013850947842001915 Engine time: 0.07532831141725183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_160_slots_32_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 68.5848405980505,
    "estimated_duration": 3600.077210032686,
    "input_throughput": 6494.454600818887,
    "output_throughput": 5696.092001264,
    "total_throughput": 12190.546602082888,
    "itl": 90.93421457985268,
    "ttft": 1819261.186982556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8546123579144536,
    "arrivals": 388315,
    "finished_requests": 94662,
    "scheduler_time": 229.2885996423176
}
#Debug simulation 
Total elapsed time: 68.58500581001863. Arrivals time: 0.4225111799314618 Scheduler time: 67.9618909098208 Scheduler overhead time: 0.07780663669109344 Adapter cache time: 0.014316595625132322 Engine time: 0.0774173061363399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 64.54322711285204,
    "estimated_duration": 3600.0891046972442,
    "input_throughput": 6810.509208788575,
    "output_throughput": 5955.986470452433,
    "total_throughput": 12766.495679241008,
    "itl": 99.97419893833283,
    "ttft": 1736684.3269865955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8845365741057298,
    "arrivals": 339810,
    "finished_requests": 99054,
    "scheduler_time": 217.36160658289867
}
#Debug simulation 
Total elapsed time: 64.54341380018741. Arrivals time: 0.43560147704556584 Scheduler time: 63.916622104588896 Scheduler overhead time: 0.07428156863898039 Adapter cache time: 0.014342385809868574 Engine time: 0.07323344890028238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 62.61393442703411,
    "estimated_duration": 3600.0716504490733,
    "input_throughput": 6699.681656889065,
    "output_throughput": 5863.424689718854,
    "total_throughput": 12563.10634660792,
    "itl": 96.89830715912848,
    "ttft": 1747369.0958596275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1389726673625433,
    "arrivals": 339810,
    "finished_requests": 97555,
    "scheduler_time": 221.1605955415168
}
#Debug simulation 
Total elapsed time: 62.61410353798419. Arrivals time: 0.43068934231996536 Scheduler time: 61.994713987223804 Scheduler overhead time: 0.07315724482759833 Adapter cache time: 0.013986650854349136 Engine time: 0.072434495203197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 77.72772498289123,
    "estimated_duration": 3600.0087132622693,
    "input_throughput": 6533.714186120751,
    "output_throughput": 5719.0622689751435,
    "total_throughput": 12252.776455095895,
    "itl": 90.89625922172272,
    "ttft": 1734217.1765605437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4261973740719367,
    "arrivals": 339810,
    "finished_requests": 95029,
    "scheduler_time": 227.59647149915142
}
#Debug simulation 
Total elapsed time: 77.72788692777976. Arrivals time: 0.44316238118335605 Scheduler time: 77.07595347892493 Scheduler overhead time: 0.0813925820402801 Adapter cache time: 0.015339315868914127 Engine time: 0.0803221887908876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 71.71281138574705,
    "estimated_duration": 3600.099525010308,
    "input_throughput": 6737.011527460635,
    "output_throughput": 5879.058579620629,
    "total_throughput": 12616.070107081263,
    "itl": 97.1176301490035,
    "ttft": 1726378.326551536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9376995815988614,
    "arrivals": 339810,
    "finished_requests": 97865,
    "scheduler_time": 220.50753883427734
}
#Debug simulation 
Total elapsed time: 71.71299038780853. Arrivals time: 0.4444638369604945 Scheduler time: 71.06876216456294 Scheduler overhead time: 0.07741599576547742 Adapter cache time: 0.014659614767879248 Engine time: 0.07707644626498222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_160_slots_32_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 75.58899875590578,
    "estimated_duration": 3600.009323638053,
    "input_throughput": 6516.748955608738,
    "output_throughput": 5700.114126166396,
    "total_throughput": 12216.863081775135,
    "itl": 90.85643705759796,
    "ttft": 1743186.7806388952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5960953559726607,
    "arrivals": 339810,
    "finished_requests": 94818,
    "scheduler_time": 227.6998482847216
}
#Debug simulation 
Total elapsed time: 75.58916334668174. Arrivals time: 0.4356759861111641 Scheduler time: 74.94771492714062 Scheduler overhead time: 0.08006481034681201 Adapter cache time: 0.015622726641595364 Engine time: 0.07863273425027728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_160_slots_32_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_160_slots_32_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 59.86585703585297,
    "estimated_duration": 3600.0626176566248,
    "input_throughput": 6729.077955807545,
    "output_throughput": 5888.947291089068,
    "total_throughput": 12618.025246896614,
    "itl": 97.40271085625194,
    "ttft": 1748498.3086061305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.406738194595081,
    "arrivals": 339810,
    "finished_requests": 98049,
    "scheduler_time": 220.02402898837462
}
#Debug simulation 
Total elapsed time: 59.866028571967036. Arrivals time: 0.418069785926491 Scheduler time: 59.255513174925 Scheduler overhead time: 0.0740182981826365 Adapter cache time: 0.015181970782577991 Engine time: 0.0738305440172553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_160_slots_32_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_160_slots_32_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.64546542381868,
    "estimated_duration": 3600.0282377535523,
    "input_throughput": 6521.414124976424,
    "output_throughput": 5697.912806595113,
    "total_throughput": 12219.326931571537,
    "itl": 90.6799421629299,
    "ttft": 1738765.6056181274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5072559145838142,
    "arrivals": 339810,
    "finished_requests": 94808,
    "scheduler_time": 227.8419803248189
}
#Debug simulation 
Total elapsed time: 76.6456318940036. Arrivals time: 0.41680440306663513 Scheduler time: 76.02017535129562 Scheduler overhead time: 0.08186356630176306 Adapter cache time: 0.01562151638790965 Engine time: 0.07890671724453568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 62.6328924507834,
    "estimated_duration": 3600.0743648997036,
    "input_throughput": 6761.191167971366,
    "output_throughput": 5928.771696524284,
    "total_throughput": 12689.96286449565,
    "itl": 99.70578048925955,
    "ttft": 1730739.3910797182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9506606644252291,
    "arrivals": 335110,
    "finished_requests": 98788,
    "scheduler_time": 218.306928946809
}
#Debug simulation 
Total elapsed time: 62.633056581020355. Arrivals time: 0.4078817297704518 Scheduler time: 62.04062484158203 Scheduler overhead time: 0.0714054717682302 Adapter cache time: 0.013970488216727972 Engine time: 0.07028684997931123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 62.74981625424698,
    "estimated_duration": 3600.104753577739,
    "input_throughput": 6696.817079014309,
    "output_throughput": 5875.211264055589,
    "total_throughput": 12572.028343069896,
    "itl": 97.20236310386278,
    "ttft": 1737403.7267286957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.035715564461427,
    "arrivals": 335110,
    "finished_requests": 97833,
    "scheduler_time": 220.53132959369765
}
#Debug simulation 
Total elapsed time: 62.74997552111745. Arrivals time: 0.4463322125375271 Scheduler time: 62.11516186641529 Scheduler overhead time: 0.0729180732741952 Adapter cache time: 0.014069517608731985 Engine time: 0.07234112080186605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 58.330652094911784,
    "estimated_duration": 3600.0468939454695,
    "input_throughput": 6535.935695607749,
    "output_throughput": 5740.43605786237,
    "total_throughput": 12276.371753470119,
    "itl": 91.4776430305802,
    "ttft": 1760082.423250059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4482488291990134,
    "arrivals": 335110,
    "finished_requests": 95575,
    "scheduler_time": 225.91790889525066
}
#Debug simulation 
Total elapsed time: 58.3308135359548. Arrivals time: 0.4397558872587979 Scheduler time: 57.69205308286473 Scheduler overhead time: 0.07518708007410169 Adapter cache time: 0.0150040234439075 Engine time: 0.07841428415849805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 58.418779988307506,
    "estimated_duration": 3600.035291686345,
    "input_throughput": 6722.145490041611,
    "output_throughput": 5906.759594581409,
    "total_throughput": 12628.90508462302,
    "itl": 97.89676658303046,
    "ttft": 1738646.5937438242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.340169931659472,
    "arrivals": 335110,
    "finished_requests": 98338,
    "scheduler_time": 219.11906734665322
}
#Debug simulation 
Total elapsed time: 58.418941179290414. Arrivals time: 0.4525174484588206 Scheduler time: 57.779597620945424 Scheduler overhead time: 0.0720875314436853 Adapter cache time: 0.014500485733151436 Engine time: 0.07142264256253839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_160_slots_32_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 61.109754690900445,
    "estimated_duration": 3600.047332390819,
    "input_throughput": 6496.440696647226,
    "output_throughput": 5704.338333341289,
    "total_throughput": 12200.779029988515,
    "itl": 90.98806789016443,
    "ttft": 1758332.7814052491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.05019586274401,
    "arrivals": 335110,
    "finished_requests": 94963,
    "scheduler_time": 227.50019533125442
}
#Debug simulation 
Total elapsed time: 61.109928575810045. Arrivals time: 0.44826765870675445 Scheduler time: 60.466214234009385 Scheduler overhead time: 0.07561580557376146 Adapter cache time: 0.014385159127414227 Engine time: 0.07491534436121583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_160_slots_32_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_160_slots_32_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 58.582199384924024,
    "estimated_duration": 3600.0290295388886,
    "input_throughput": 6730.996278411605,
    "output_throughput": 5907.951248583188,
    "total_throughput": 12638.947526994792,
    "itl": 97.88806133149211,
    "ttft": 1738453.6744493956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.055622542863704,
    "arrivals": 335110,
    "finished_requests": 98390,
    "scheduler_time": 219.12349326893025
}
#Debug simulation 
Total elapsed time: 58.58236470678821. Arrivals time: 0.41665689554065466 Scheduler time: 57.98022526688874 Scheduler overhead time: 0.07115082768723369 Adapter cache time: 0.01448241388425231 Engine time: 0.07110484456643462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_160_slots_32_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_160_slots_32_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 57.28630940616131,
    "estimated_duration": 3600.0272524046118,
    "input_throughput": 6545.572671501428,
    "output_throughput": 5750.844243240506,
    "total_throughput": 12296.416914741934,
    "itl": 91.76612244842987,
    "ttft": 1760170.521914457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5941749428585306,
    "arrivals": 335110,
    "finished_requests": 95727,
    "scheduler_time": 225.46766917349962
}
#Debug simulation 
Total elapsed time: 57.28646814916283. Arrivals time: 0.4247508468106389 Scheduler time: 56.66874602716416 Scheduler overhead time: 0.0739193414337933 Adapter cache time: 0.014780948404222727 Engine time: 0.07378769712522626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_160_slots_32_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 65.90034508006647,
    "estimated_duration": 3600.105615781718,
    "input_throughput": 6812.881236728454,
    "output_throughput": 5945.146416309392,
    "total_throughput": 12758.027653037847,
    "itl": 99.81938862843576,
    "ttft": 1727288.188382385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8250248928181805,
    "arrivals": 332795,
    "finished_requests": 98918,
    "scheduler_time": 217.62015408686813
}
#Debug simulation 
Total elapsed time: 65.90050927503034. Arrivals time: 0.4237348805181682 Scheduler time: 65.28668757900596 Scheduler overhead time: 0.07374758459627628 Adapter cache time: 0.014377901330590248 Engine time: 0.07281592534855008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_160_slots_32_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 80.10065620904788,
    "estimated_duration": 3600.0651034213274,
    "input_throughput": 6726.536966508276,
    "output_throughput": 5892.446494881443,
    "total_throughput": 12618.98346138972,
    "itl": 97.38237903147389,
    "ttft": 1708554.99995745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2061455026408683,
    "arrivals": 332795,
    "finished_requests": 97786,
    "scheduler_time": 220.24541235035866
}
#Debug simulation 
Total elapsed time: 80.10081274574623. Arrivals time: 0.44215463614091277 Scheduler time: 79.45640365267172 Scheduler overhead time: 0.07923236675560474 Adapter cache time: 0.015057474374771118 Engine time: 0.07747170189395547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_160_slots_32_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 57.24232032895088,
    "estimated_duration": 3600.0700594014193,
    "input_throughput": 6570.491576470312,
    "output_throughput": 5739.2394200893405,
    "total_throughput": 12309.730996559652,
    "itl": 91.55185727995216,
    "ttft": 1762946.929306667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6007583061000465,
    "arrivals": 332795,
    "finished_requests": 95435,
    "scheduler_time": 225.81793072907607
}
#Debug simulation 
Total elapsed time: 57.242479636799544. Arrivals time: 0.39773417077958584 Scheduler time: 56.6517439186573 Scheduler overhead time: 0.07385856611654162 Adapter cache time: 0.015299320686608553 Engine time: 0.0733428611420095 
