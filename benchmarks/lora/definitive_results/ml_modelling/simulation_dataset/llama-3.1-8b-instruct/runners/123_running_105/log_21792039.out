INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 38.74341722065583,
    "estimated_duration": 3600.023033306462,
    "input_throughput": 5278.0526191656945,
    "output_throughput": 4593.92949628168,
    "total_throughput": 9871.982115447374,
    "itl": 56.96946866035611,
    "ttft": 515751.87697967194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.205776263028375,
    "arrivals": 83337,
    "finished_requests": 76362,
    "scheduler_time": 129.46718969697378
}
#Debug simulation 
Total elapsed time: 38.74360705865547. Arrivals time: 0.24308241019025445 Scheduler time: 38.2191445780918 Scheduler overhead time: 0.11241509020328522 Adapter cache time: 0.021394180599600077 Engine time: 0.10173809668049216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 42.86323674907908,
    "estimated_duration": 3600.0050676448145,
    "input_throughput": 5270.1642479665215,
    "output_throughput": 4602.3732435575275,
    "total_throughput": 9872.537491524048,
    "itl": 57.33013662386829,
    "ttft": 540308.7738864901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1091016755486205,
    "arrivals": 83337,
    "finished_requests": 76267,
    "scheduler_time": 136.53602528960616
}
#Debug simulation 
Total elapsed time: 42.8634062637575. Arrivals time: 0.24804876325652003 Scheduler time: 42.33166495198384 Scheduler overhead time: 0.11379973404109478 Adapter cache time: 0.02108590677380562 Engine time: 0.10278861876577139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 38.74337866809219,
    "estimated_duration": 3600.016017683093,
    "input_throughput": 5237.889750317195,
    "output_throughput": 4578.234907578923,
    "total_throughput": 9816.124657896118,
    "itl": 58.338997651659845,
    "ttft": 533978.9986674485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.70494973320046,
    "arrivals": 83337,
    "finished_requests": 75757,
    "scheduler_time": 129.79295435096998
}
#Debug simulation 
Total elapsed time: 38.74349759705365. Arrivals time: 0.2412591064348817 Scheduler time: 38.219970860052854 Scheduler overhead time: 0.11278362572193146 Adapter cache time: 0.021036373917013407 Engine time: 0.10265107220038772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 41.207665857858956,
    "estimated_duration": 3600.057667622271,
    "input_throughput": 5259.9721305316725,
    "output_throughput": 4573.347573866555,
    "total_throughput": 9833.319704398227,
    "itl": 58.001253127168106,
    "ttft": 538325.9890739413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.117168769836457,
    "arrivals": 83337,
    "finished_requests": 76032,
    "scheduler_time": 133.63101816962396
}
#Debug simulation 
Total elapsed time: 41.207819344010204. Arrivals time: 0.24723561201244593 Scheduler time: 40.675820235628635 Scheduler overhead time: 0.11458146199584007 Adapter cache time: 0.020990445278584957 Engine time: 0.10315894009545445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 37.47793102497235,
    "estimated_duration": 3599.9444501245584,
    "input_throughput": 5206.4250600732175,
    "output_throughput": 4534.425524103629,
    "total_throughput": 9740.850584176846,
    "itl": 55.531218424989895,
    "ttft": 491478.7974183839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.084942545569598,
    "arrivals": 81595,
    "finished_requests": 75152,
    "scheduler_time": 125.53024307946636
}
#Debug simulation 
Total elapsed time: 37.47802956402302. Arrivals time: 0.23820155765861273 Scheduler time: 36.95659515494481 Scheduler overhead time: 0.11254984652623534 Adapter cache time: 0.021519359666854143 Engine time: 0.10303305275738239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 35.935944746714085,
    "estimated_duration": 3599.9320015619733,
    "input_throughput": 5228.030416083959,
    "output_throughput": 4566.090968626043,
    "total_throughput": 9794.12138471,
    "itl": 54.83783482893465,
    "ttft": 472123.2270668913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.909235666543254,
    "arrivals": 81595,
    "finished_requests": 75498,
    "scheduler_time": 123.45642363130867
}
#Debug simulation 
Total elapsed time: 35.93609277671203. Arrivals time: 0.23735160659998655 Scheduler time: 35.41792984260246 Scheduler overhead time: 0.11136552970856428 Adapter cache time: 0.021646813955157995 Engine time: 0.10203064838424325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 36.92776993801817,
    "estimated_duration": 3599.9945368397994,
    "input_throughput": 5209.568461307523,
    "output_throughput": 4532.243544547931,
    "total_throughput": 9741.812005855454,
    "itl": 54.41263226368384,
    "ttft": 480502.7500534397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.948542836559962,
    "arrivals": 81595,
    "finished_requests": 75305,
    "scheduler_time": 123.8355041622617
}
#Debug simulation 
Total elapsed time: 36.92788913613185. Arrivals time: 0.23368024034425616 Scheduler time: 36.40787783963606 Scheduler overhead time: 0.1136878659017384 Adapter cache time: 0.021674174815416336 Engine time: 0.10440636705607176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 36.00859012128785,
    "estimated_duration": 3599.9994618326873,
    "input_throughput": 5187.82549775503,
    "output_throughput": 4521.456787027847,
    "total_throughput": 9709.282284782876,
    "itl": 55.17052589005562,
    "ttft": 493769.1046653147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.459197173435234,
    "arrivals": 81595,
    "finished_requests": 74964,
    "scheduler_time": 123.85432827007003
}
#Debug simulation 
Total elapsed time: 36.00871118530631. Arrivals time: 0.23230794537812471 Scheduler time: 35.49464465118945 Scheduler overhead time: 0.11240061838179827 Adapter cache time: 0.021300315856933594 Engine time: 0.10246538510546088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 40.60253076488152,
    "estimated_duration": 3599.962890021023,
    "input_throughput": 5131.270672596329,
    "output_throughput": 4464.577688995605,
    "total_throughput": 9595.848361591934,
    "itl": 53.683407906265565,
    "ttft": 542704.8981563898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.465064689726597,
    "arrivals": 81595,
    "finished_requests": 74060,
    "scheduler_time": 128.77694211863854
}
#Debug simulation 
Total elapsed time: 40.60266321571544. Arrivals time: 0.23871937580406666 Scheduler time: 40.07393079996109 Scheduler overhead time: 0.11651647975668311 Adapter cache time: 0.021648379508405924 Engine time: 0.10495500592514873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 38.709437849000096,
    "estimated_duration": 3599.9278291457636,
    "input_throughput": 5152.8471903843,
    "output_throughput": 4497.465440534095,
    "total_throughput": 9650.312630918395,
    "itl": 53.658193035264354,
    "ttft": 521157.464511568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.794324626368447,
    "arrivals": 81595,
    "finished_requests": 74381,
    "scheduler_time": 125.78155223375595
}
#Debug simulation 
Total elapsed time: 38.70957468217239. Arrivals time: 0.24100636783987284 Scheduler time: 38.180452725850046 Scheduler overhead time: 0.1156993480399251 Adapter cache time: 0.02200294891372323 Engine time: 0.10395735735073686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 36.13049171399325,
    "estimated_duration": 3600.015920347813,
    "input_throughput": 5227.144383900928,
    "output_throughput": 4544.905178757994,
    "total_throughput": 9772.049562658922,
    "itl": 55.52291358973109,
    "ttft": 476478.42281014356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.945932741276947,
    "arrivals": 81595,
    "finished_requests": 75458,
    "scheduler_time": 124.47283245087512
}
#Debug simulation 
Total elapsed time: 36.13071513082832. Arrivals time: 0.23625018633902073 Scheduler time: 35.60952855506912 Scheduler overhead time: 0.11365843703970313 Adapter cache time: 0.021944943815469742 Engine time: 0.1024825437925756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 37.81087630009279,
    "estimated_duration": 3600.01015468537,
    "input_throughput": 5122.7802721605885,
    "output_throughput": 4504.970625955748,
    "total_throughput": 9627.750898116336,
    "itl": 54.226258474306626,
    "ttft": 493943.9296311007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.813833775259642,
    "arrivals": 81010,
    "finished_requests": 74336,
    "scheduler_time": 122.88115116027323
}
#Debug simulation 
Total elapsed time: 37.8110063620843. Arrivals time: 0.24540207721292973 Scheduler time: 37.27570190373808 Scheduler overhead time: 0.11547440942376852 Adapter cache time: 0.02210299065336585 Engine time: 0.10513059049844742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 38.68439448904246,
    "estimated_duration": 3599.997261691896,
    "input_throughput": 5082.416365894979,
    "output_throughput": 4467.925342932271,
    "total_throughput": 9550.341708827249,
    "itl": 53.74546495115254,
    "ttft": 523763.2842107524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.2966341540031205,
    "arrivals": 81010,
    "finished_requests": 73653,
    "scheduler_time": 124.28067298279232
}
#Debug simulation 
Total elapsed time: 38.68453440209851. Arrivals time: 0.24675364000722766 Scheduler time: 38.14437209442258 Scheduler overhead time: 0.11809155019000173 Adapter cache time: 0.021874073892831802 Engine time: 0.10605942271649837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 36.69571319501847,
    "estimated_duration": 3600.0064360751553,
    "input_throughput": 5136.287484018815,
    "output_throughput": 4512.340543954759,
    "total_throughput": 9648.628027973575,
    "itl": 54.37240367170716,
    "ttft": 480028.16984137375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.651599956131569,
    "arrivals": 81010,
    "finished_requests": 74533,
    "scheduler_time": 121.08730250524562
}
#Debug simulation 
Total elapsed time: 36.69583252212033. Arrivals time: 0.23932852922007442 Scheduler time: 36.17180049372837 Scheduler overhead time: 0.11315142456442118 Adapter cache time: 0.02146861795336008 Engine time: 0.10380630474537611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 37.76738064084202,
    "estimated_duration": 3600.0016890371894,
    "input_throughput": 5144.398975255226,
    "output_throughput": 4529.355374930647,
    "total_throughput": 9673.754350185873,
    "itl": 54.769697025732235,
    "ttft": 490515.8550956725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.096692423112684,
    "arrivals": 81010,
    "finished_requests": 74614,
    "scheduler_time": 124.42826136056924
}
#Debug simulation 
Total elapsed time: 37.767523223068565. Arrivals time: 0.2443639962002635 Scheduler time: 37.2318652626127 Scheduler overhead time: 0.1158909723162651 Adapter cache time: 0.021522454917430878 Engine time: 0.10686658276244998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 36.416619083378464,
    "estimated_duration": 3600.0672050700186,
    "input_throughput": 5117.556409517549,
    "output_throughput": 4477.748909047512,
    "total_throughput": 9595.30531856506,
    "itl": 55.80788930598606,
    "ttft": 497380.15268598695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.649101860397522,
    "arrivals": 81010,
    "finished_requests": 74179,
    "scheduler_time": 122.20157714727351
}
#Debug simulation 
Total elapsed time: 36.41672849608585. Arrivals time: 0.23987779719755054 Scheduler time: 35.88723130105063 Scheduler overhead time: 0.1152882375754416 Adapter cache time: 0.022001156117767096 Engine time: 0.10530365817248821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 36.01751682488248,
    "estimated_duration": 3600.015259141166,
    "input_throughput": 5209.814861860993,
    "output_throughput": 4560.153726658485,
    "total_throughput": 9769.968588519478,
    "itl": 56.24839770722687,
    "ttft": 440788.8799491139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.883699519536434,
    "arrivals": 81010,
    "finished_requests": 75573,
    "scheduler_time": 121.3273793857362
}
#Debug simulation 
Total elapsed time: 36.01767109706998. Arrivals time: 0.2417702884413302 Scheduler time: 35.49084813753143 Scheduler overhead time: 0.11336354864761233 Adapter cache time: 0.02164214663207531 Engine time: 0.10362465912476182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 38.67482002498582,
    "estimated_duration": 3600.0471077860684,
    "input_throughput": 5116.718600754107,
    "output_throughput": 4493.625920897624,
    "total_throughput": 9610.34452165173,
    "itl": 53.88161495212112,
    "ttft": 500486.29620212666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.394804946165561,
    "arrivals": 81010,
    "finished_requests": 74228,
    "scheduler_time": 123.66815136637669
}
#Debug simulation 
Total elapsed time: 38.67492752382532. Arrivals time: 0.24196158116683364 Scheduler time: 38.14412824483588 Scheduler overhead time: 0.11502398457378149 Adapter cache time: 0.0215117740444839 Engine time: 0.10557295801118016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 37.49721620976925,
    "estimated_duration": 3600.0405928591767,
    "input_throughput": 5063.6773474607,
    "output_throughput": 4498.905660154469,
    "total_throughput": 9562.583007615169,
    "itl": 55.05829631078488,
    "ttft": 449743.95949577214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.674973185588689,
    "arrivals": 79794,
    "finished_requests": 74269,
    "scheduler_time": 121.06348138130991
}
#Debug simulation 
Total elapsed time: 37.497366385068744. Arrivals time: 0.24066327372565866 Scheduler time: 36.96867787698284 Scheduler overhead time: 0.11549356579780579 Adapter cache time: 0.021585537120699883 Engine time: 0.10411630943417549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 34.87604360282421,
    "estimated_duration": 3600.0180737357987,
    "input_throughput": 5102.177717941091,
    "output_throughput": 4523.286735364057,
    "total_throughput": 9625.464453305147,
    "itl": 55.20806190550211,
    "ttft": 417412.6748176579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4423594454675985,
    "arrivals": 79794,
    "finished_requests": 74761,
    "scheduler_time": 117.37334480376815
}
#Debug simulation 
Total elapsed time: 34.87618548097089. Arrivals time: 0.23763732332736254 Scheduler time: 34.350592704024166 Scheduler overhead time: 0.114530258346349 Adapter cache time: 0.021711782086640596 Engine time: 0.10491259209811687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 36.532236326951534,
    "estimated_duration": 3600.0114920969972,
    "input_throughput": 5080.134616277842,
    "output_throughput": 4514.7786432571975,
    "total_throughput": 9594.913259535038,
    "itl": 56.457450234806736,
    "ttft": 441324.06654884113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.442090007015531,
    "arrivals": 79794,
    "finished_requests": 74454,
    "scheduler_time": 120.53559279719025
}
#Debug simulation 
Total elapsed time: 36.53236104082316. Arrivals time: 0.23829103540629148 Scheduler time: 36.003423193935305 Scheduler overhead time: 0.11614026129245758 Adapter cache time: 0.02183846291154623 Engine time: 0.1058057826012373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 36.9501191386953,
    "estimated_duration": 3600.0183852202017,
    "input_throughput": 5064.948577723636,
    "output_throughput": 4490.1787352986685,
    "total_throughput": 9555.127313022303,
    "itl": 54.787583529429455,
    "ttft": 449000.7430511989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.845216917605132,
    "arrivals": 79794,
    "finished_requests": 74203,
    "scheduler_time": 120.26984422837052
}
#Debug simulation 
Total elapsed time: 36.95024543767795. Arrivals time: 0.23678240831941366 Scheduler time: 36.42374010384083 Scheduler overhead time: 0.11567788338288665 Adapter cache time: 0.021403306629508734 Engine time: 0.10564362769946456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 36.85530913202092,
    "estimated_duration": 3600.016818563513,
    "input_throughput": 5105.020594690804,
    "output_throughput": 4525.186914682352,
    "total_throughput": 9630.207509373156,
    "itl": 56.59694912663213,
    "ttft": 427579.9934720413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 715,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.328707359572902,
    "arrivals": 79794,
    "finished_requests": 74781,
    "scheduler_time": 120.70085797433548
}
#Debug simulation 
Total elapsed time: 36.85545637039468. Arrivals time: 0.23805220378562808 Scheduler time: 36.326069180853665 Scheduler overhead time: 0.11636028997600079 Adapter cache time: 0.0217318763025105 Engine time: 0.1062246453948319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 35.55499029904604,
    "estimated_duration": 3600.0146834086195,
    "input_throughput": 5072.379588938284,
    "output_throughput": 4510.179381998108,
    "total_throughput": 9582.558970936392,
    "itl": 54.50163803959987,
    "ttft": 437343.9077689027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.800708547309018,
    "arrivals": 79794,
    "finished_requests": 74356,
    "scheduler_time": 118.31781631244735
}
#Debug simulation 
Total elapsed time: 35.55514197424054. Arrivals time: 0.2390876915305853 Scheduler time: 35.031010346952826 Scheduler overhead time: 0.11360222799703479 Adapter cache time: 0.021424061618745327 Engine time: 0.103893568739295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 39.71114392206073,
    "estimated_duration": 3600.0388304470534,
    "input_throughput": 5024.408583324592,
    "output_throughput": 4446.438984107348,
    "total_throughput": 9470.84756743194,
    "itl": 55.00286365516177,
    "ttft": 488473.52156444726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.078965167962045,
    "arrivals": 79794,
    "finished_requests": 73564,
    "scheduler_time": 124.27761951907193
}
#Debug simulation 
Total elapsed time: 39.71129074692726. Arrivals time: 0.24722973722964525 Scheduler time: 39.17043125489727 Scheduler overhead time: 0.11768905213102698 Adapter cache time: 0.021901422180235386 Engine time: 0.10641174949705601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.362606521230191,
    "estimated_duration": 3599.778034785433,
    "input_throughput": 2267.1378404825596,
    "output_throughput": 2008.1585392614031,
    "total_throughput": 4275.296379743963,
    "itl": 28.459590512814128,
    "ttft": 147136.88350585615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.708538851890744,
    "arrivals": 33938,
    "finished_requests": 33167,
    "scheduler_time": 21.086193504471282
}
#Debug simulation 
Total elapsed time: 4.362691400106996. Arrivals time: 0.0968339336104691 Scheduler time: 3.9160152808763087 Scheduler overhead time: 0.13262125989422202 Adapter cache time: 0.03576229652389884 Engine time: 0.12385047320276499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.362993778195232,
    "estimated_duration": 3599.7761237485756,
    "input_throughput": 2267.3443345973105,
    "output_throughput": 2007.6634633806398,
    "total_throughput": 4275.007797977951,
    "itl": 28.49691225800954,
    "ttft": 146027.5279182197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.919232886214132,
    "arrivals": 33938,
    "finished_requests": 33178,
    "scheduler_time": 21.111567425438796
}
#Debug simulation 
Total elapsed time: 4.363069503102452. Arrivals time: 0.0953694162890315 Scheduler time: 3.921591455116868 Scheduler overhead time: 0.13186728162690997 Adapter cache time: 0.035375209990888834 Engine time: 0.12161064008250833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.346044396981597,
    "estimated_duration": 3599.7798467515586,
    "input_throughput": 2266.2510895942105,
    "output_throughput": 2006.7977230660272,
    "total_throughput": 4273.048812660238,
    "itl": 28.50236691591908,
    "ttft": 147688.64038089564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.651617874238358,
    "arrivals": 33938,
    "finished_requests": 33161,
    "scheduler_time": 21.069632358559865
}
#Debug simulation 
Total elapsed time: 4.346126131247729. Arrivals time: 0.09553738962858915 Scheduler time: 3.9043416948989034 Scheduler overhead time: 0.13248227210715413 Adapter cache time: 0.03521247487515211 Engine time: 0.12154585355892777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.382473964244127,
    "estimated_duration": 3599.7753027507706,
    "input_throughput": 2267.1395611175008,
    "output_throughput": 2008.1600633450682,
    "total_throughput": 4275.299624462569,
    "itl": 28.46905594845563,
    "ttft": 147147.4289166925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.48406729756447,
    "arrivals": 33938,
    "finished_requests": 33167,
    "scheduler_time": 21.09056334532144
}
#Debug simulation 
Total elapsed time: 4.382543857209384. Arrivals time: 0.09635411435738206 Scheduler time: 3.937990271486342 Scheduler overhead time: 0.13219957146793604 Adapter cache time: 0.035491108894348145 Engine time: 0.12335414160043001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.3778482978232205,
    "estimated_duration": 3599.766767731622,
    "input_throughput": 2267.586909566295,
    "output_throughput": 2007.2111517805674,
    "total_throughput": 4274.798061346863,
    "itl": 28.499659286268255,
    "ttft": 146217.12657059837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.453763115532396,
    "arrivals": 33938,
    "finished_requests": 33175,
    "scheduler_time": 21.057671633037465
}
#Debug simulation 
Total elapsed time: 4.377948098815978. Arrivals time: 0.09572283364832401 Scheduler time: 3.9343058546073735 Scheduler overhead time: 0.1323860427364707 Adapter cache time: 0.0354447360150516 Engine time: 0.12294462835416198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.366398160811514,
    "estimated_duration": 3599.781214769296,
    "input_throughput": 2268.965115571186,
    "output_throughput": 2009.268221725399,
    "total_throughput": 4278.233337296585,
    "itl": 28.475694538373364,
    "ttft": 145086.29873226178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.00948381541932,
    "arrivals": 33938,
    "finished_requests": 33184,
    "scheduler_time": 21.03753114196198
}
#Debug simulation 
Total elapsed time: 4.366498862858862. Arrivals time: 0.09610402351245284 Scheduler time: 3.923237083014101 Scheduler overhead time: 0.13250934146344662 Adapter cache time: 0.03535650623962283 Engine time: 0.12218864168971777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.366696308832616,
    "estimated_duration": 3599.8010170862303,
    "input_throughput": 2267.500887203753,
    "output_throughput": 2006.0211566485648,
    "total_throughput": 4273.522043852318,
    "itl": 28.49069980381251,
    "ttft": 147442.75822394647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.228057262004032,
    "arrivals": 33938,
    "finished_requests": 33164,
    "scheduler_time": 21.076866146757816
}
#Debug simulation 
Total elapsed time: 4.366766144055873. Arrivals time: 0.09563609771430492 Scheduler time: 3.9195675989612937 Scheduler overhead time: 0.1351937260478735 Adapter cache time: 0.03546310355886817 Engine time: 0.1232787542976439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.8874031980521977,
    "estimated_duration": 3599.7196763315355,
    "input_throughput": 2121.327405077835,
    "output_throughput": 1862.0980528214466,
    "total_throughput": 3983.4254578992814,
    "itl": 27.85184658995752,
    "ttft": 122364.32153428634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.652587107283566,
    "arrivals": 31534,
    "finished_requests": 30945,
    "scheduler_time": 15.59020248225724
}
#Debug simulation 
Total elapsed time: 3.8874693890102208. Arrivals time: 0.08934137271717191 Scheduler time: 3.4462593351490796 Scheduler overhead time: 0.1327661178074777 Adapter cache time: 0.03694350039586425 Engine time: 0.12380855670198798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.9072637343779206,
    "estimated_duration": 3599.7269848160036,
    "input_throughput": 2120.3535802007877,
    "output_throughput": 1861.4067200828265,
    "total_throughput": 3981.7603002836145,
    "itl": 27.862111023964836,
    "ttft": 124292.52251496309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.12483068261223,
    "arrivals": 31534,
    "finished_requests": 30931,
    "scheduler_time": 15.684179409529486
}
#Debug simulation 
Total elapsed time: 3.9073314489796758. Arrivals time: 0.08944109454751015 Scheduler time: 3.462387110106647 Scheduler overhead time: 0.13688377663493156 Adapter cache time: 0.036833678372204304 Engine time: 0.1233729631640017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.8716871510259807,
    "estimated_duration": 3599.7295272732313,
    "input_throughput": 2120.623769692622,
    "output_throughput": 1861.5584724433559,
    "total_throughput": 3982.182242135978,
    "itl": 27.87648795468813,
    "ttft": 123218.606484162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.923759993017615,
    "arrivals": 31534,
    "finished_requests": 30939,
    "scheduler_time": 15.635949077546737
}
#Debug simulation 
Total elapsed time: 3.871761592105031. Arrivals time: 0.0895467409864068 Scheduler time: 3.429304721299559 Scheduler overhead time: 0.13429931877180934 Adapter cache time: 0.03683865536004305 Engine time: 0.12346719531342387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 3.887846937868744,
    "estimated_duration": 3599.7394401804772,
    "input_throughput": 2121.108798812724,
    "output_throughput": 1859.6648760956912,
    "total_throughput": 3980.773674908415,
    "itl": 27.8526875325643,
    "ttft": 122522.26156708522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.503369630417524,
    "arrivals": 31534,
    "finished_requests": 30944,
    "scheduler_time": 15.58650015581307
}
#Debug simulation 
Total elapsed time: 3.8879287927411497. Arrivals time: 0.08959798561409116 Scheduler time: 3.447712492197752 Scheduler overhead time: 0.13258893182501197 Adapter cache time: 0.0365834697149694 Engine time: 0.12323460076004267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 3.9338397257961333,
    "estimated_duration": 3599.7241911493325,
    "input_throughput": 2121.23140399876,
    "output_throughput": 1862.6235355712702,
    "total_throughput": 3983.85493957003,
    "itl": 27.873385979914957,
    "ttft": 122328.50702528443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.67614973248536,
    "arrivals": 31534,
    "finished_requests": 30948,
    "scheduler_time": 15.668849561178384
}
#Debug simulation 
Total elapsed time: 3.9339094730094075. Arrivals time: 0.08970905467867851 Scheduler time: 3.490843342617154 Scheduler overhead time: 0.13363033579662442 Adapter cache time: 0.037150684744119644 Engine time: 0.12438938627019525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.9116398440673947,
    "estimated_duration": 3599.730766042857,
    "input_throughput": 2120.5102537129915,
    "output_throughput": 1860.7538828142053,
    "total_throughput": 3981.264136527197,
    "itl": 27.835752335092977,
    "ttft": 124085.21769257015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.707606785611308,
    "arrivals": 31534,
    "finished_requests": 30933,
    "scheduler_time": 15.649986388104633
}
#Debug simulation 
Total elapsed time: 3.911709090229124. Arrivals time: 0.08982601203024387 Scheduler time: 3.469783052802086 Scheduler overhead time: 0.13287474401295185 Adapter cache time: 0.03685130784288049 Engine time: 0.12449053907766938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.899020303040743,
    "estimated_duration": 3599.734754381801,
    "input_throughput": 2120.408452514117,
    "output_throughput": 1861.35797695758,
    "total_throughput": 3981.766429471697,
    "itl": 27.861611170798216,
    "ttft": 124294.81713171875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.338981285878372,
    "arrivals": 31534,
    "finished_requests": 30931,
    "scheduler_time": 15.684921292528811
}
#Debug simulation 
Total elapsed time: 3.899122663307935. Arrivals time: 0.08960453048348427 Scheduler time: 3.4584853160195053 Scheduler overhead time: 0.13333449140191078 Adapter cache time: 0.03661432536318898 Engine time: 0.12339071929454803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.608579113148153,
    "estimated_duration": 3599.977190551984,
    "input_throughput": 2041.5076571285497,
    "output_throughput": 1788.3185529330747,
    "total_throughput": 3829.8262100616244,
    "itl": 27.538833096461367,
    "ttft": 103553.62452920967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.274153556286713,
    "arrivals": 30357,
    "finished_requests": 29880,
    "scheduler_time": 12.262978523745394
}
#Debug simulation 
Total elapsed time: 3.608649604022503. Arrivals time: 0.08633697824552655 Scheduler time: 3.1681655454449356 Scheduler overhead time: 0.13409537822008133 Adapter cache time: 0.037628274876624346 Engine time: 0.12374857300892472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.6233144947327673,
    "estimated_duration": 3599.984715392838,
    "input_throughput": 2040.7208865602995,
    "output_throughput": 1787.503422579893,
    "total_throughput": 3828.2243091401924,
    "itl": 27.561685473662802,
    "ttft": 105843.98609949122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.794065924253466,
    "arrivals": 30357,
    "finished_requests": 29863,
    "scheduler_time": 12.319273297792188
}
#Debug simulation 
Total elapsed time: 3.62340543884784. Arrivals time: 0.08628285583108664 Scheduler time: 3.18343824474141 Scheduler overhead time: 0.13378820242360234 Adapter cache time: 0.03737479168921709 Engine time: 0.12418519426137209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.61287321196869,
    "estimated_duration": 3599.981615133918,
    "input_throughput": 2039.9168065548076,
    "output_throughput": 1787.8827416624379,
    "total_throughput": 3827.7995482172455,
    "itl": 27.55969385388398,
    "ttft": 103862.2605852135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.78478716180758,
    "arrivals": 30357,
    "finished_requests": 29876,
    "scheduler_time": 12.232261517616475
}
#Debug simulation 
Total elapsed time: 3.612951060757041. Arrivals time: 0.08583351643756032 Scheduler time: 3.1739963362924755 Scheduler overhead time: 0.13306353194639087 Adapter cache time: 0.03774191718548536 Engine time: 0.12366704735904932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6000965191051364,
    "estimated_duration": 3599.9665412794316,
    "input_throughput": 2040.648965973203,
    "output_throughput": 1787.2016104109118,
    "total_throughput": 3827.850576384115,
    "itl": 27.551196155124526,
    "ttft": 105178.71167559345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.183691684478656,
    "arrivals": 30357,
    "finished_requests": 29867,
    "scheduler_time": 12.27416219889993
}
#Debug simulation 
Total elapsed time: 3.6001823088154197. Arrivals time: 0.08584895869717002 Scheduler time: 3.161073098424822 Scheduler overhead time: 0.13396129989996552 Adapter cache time: 0.03739500464871526 Engine time: 0.12355976039543748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 3.5988276628777385,
    "estimated_duration": 3599.976493080583,
    "input_throughput": 2040.5486019476534,
    "output_throughput": 1787.4816717187823,
    "total_throughput": 3828.0302736664357,
    "itl": 27.564026275412036,
    "ttft": 105966.12750728703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.273104445111006,
    "arrivals": 30357,
    "finished_requests": 29862,
    "scheduler_time": 12.322564591939425
}
#Debug simulation 
Total elapsed time: 3.598898292053491. Arrivals time: 0.08570765890181065 Scheduler time: 3.1622563521377742 Scheduler overhead time: 0.13310783728957176 Adapter cache time: 0.037218043114989996 Engine time: 0.12265418469905853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.6265954710543156,
    "estimated_duration": 3599.988859647742,
    "input_throughput": 2038.5282527563397,
    "output_throughput": 1785.30802471119,
    "total_throughput": 3823.8362774675297,
    "itl": 27.503451558736838,
    "ttft": 107550.78044310166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.486445140361017,
    "arrivals": 30357,
    "finished_requests": 29845,
    "scheduler_time": 12.205662526452114
}
#Debug simulation 
Total elapsed time: 3.6266649290919304. Arrivals time: 0.08674497669562697 Scheduler time: 3.1823046263307333 Scheduler overhead time: 0.1357042253948748 Adapter cache time: 0.03800049750134349 Engine time: 0.12515936372801661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.6073444858193398,
    "estimated_duration": 3599.9585413446225,
    "input_throughput": 2040.55877745087,
    "output_throughput": 1787.4905852656013,
    "total_throughput": 3828.0493627164715,
    "itl": 27.5623508650626,
    "ttft": 105963.38446353197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.016072028932147,
    "arrivals": 30357,
    "finished_requests": 29862,
    "scheduler_time": 12.3207684167549
}
#Debug simulation 
Total elapsed time: 3.6074195406399667. Arrivals time: 0.08623399678617716 Scheduler time: 3.1685288148000836 Scheduler overhead time: 0.1335496660321951 Adapter cache time: 0.037380012683570385 Engine time: 0.12361829727888107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.4581140992231667,
    "estimated_duration": 3600.0087752969093,
    "input_throughput": 1999.5234593299908,
    "output_throughput": 1749.0462921109663,
    "total_throughput": 3748.569751440957,
    "itl": 27.38133534097653,
    "ttft": 93363.87913982595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.274153556286713,
    "arrivals": 29680,
    "finished_requests": 29260,
    "scheduler_time": 10.453707717339094
}
#Debug simulation 
Total elapsed time: 3.458199934102595. Arrivals time: 0.08460149262100458 Scheduler time: 3.016447660047561 Scheduler overhead time: 0.13464762549847364 Adapter cache time: 0.037777057848870754 Engine time: 0.12601284589618444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.4633775167167187,
    "estimated_duration": 3600.015612141834,
    "input_throughput": 2002.5857598186342,
    "output_throughput": 1751.4551822314663,
    "total_throughput": 3754.0409420501005,
    "itl": 27.41511605775834,
    "ttft": 88838.79612632823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3650,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.75936987760399,
    "arrivals": 29680,
    "finished_requests": 29300,
    "scheduler_time": 10.548973971012314
}
#Debug simulation 
Total elapsed time: 3.463471575640142. Arrivals time: 0.08449339959770441 Scheduler time: 3.023876261431724 Scheduler overhead time: 0.1351441997103393 Adapter cache time: 0.03739544935524464 Engine time: 0.12391798384487629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.426156493835151,
    "estimated_duration": 3600.027994095512,
    "input_throughput": 1999.921948331656,
    "output_throughput": 1749.124176347429,
    "total_throughput": 3749.046124679085,
    "itl": 27.406545701404173,
    "ttft": 93494.25444733734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.664114019801882,
    "arrivals": 29680,
    "finished_requests": 29258,
    "scheduler_time": 10.457338766152466
}
#Debug simulation 
Total elapsed time: 3.426227267831564. Arrivals time: 0.08429180597886443 Scheduler time: 2.9887527907267213 Scheduler overhead time: 0.13407753594219685 Adapter cache time: 0.03745026374235749 Engine time: 0.12309460481628776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4424805413000286,
    "estimated_duration": 3600.013586233515,
    "input_throughput": 1998.6930125805573,
    "output_throughput": 1749.9508957662472,
    "total_throughput": 3748.6439083468044,
    "itl": 27.382404406022218,
    "ttft": 93278.47975199106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.069602666912377,
    "arrivals": 29680,
    "finished_requests": 29260,
    "scheduler_time": 10.451176159159166
}
#Debug simulation 
Total elapsed time: 3.442625929135829. Arrivals time: 0.08493454707786441 Scheduler time: 3.000344442203641 Scheduler overhead time: 0.13627157220616937 Adapter cache time: 0.03738629166036844 Engine time: 0.12316971411928535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 3.4664196828380227,
    "estimated_duration": 3600.0258102156135,
    "input_throughput": 1999.2406664353712,
    "output_throughput": 1749.503290261906,
    "total_throughput": 3748.743956697277,
    "itl": 27.416674983300357,
    "ttft": 94008.76416337825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.35991823890807,
    "arrivals": 29680,
    "finished_requests": 29255,
    "scheduler_time": 10.490060736866715
}
#Debug simulation 
Total elapsed time: 3.466489457990974. Arrivals time: 0.0847413782030344 Scheduler time: 3.020404249895364 Scheduler overhead time: 0.13442681590095162 Adapter cache time: 0.03780989721417427 Engine time: 0.13037293264642358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.4366361810825765,
    "estimated_duration": 3600.0124771121377,
    "input_throughput": 2000.7805655657,
    "output_throughput": 1750.2706004659574,
    "total_throughput": 3751.0511660316574,
    "itl": 27.369534973203972,
    "ttft": 92290.91185489597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.486445140361017,
    "arrivals": 29680,
    "finished_requests": 29267,
    "scheduler_time": 10.415125836020568
}
#Debug simulation 
Total elapsed time: 3.436705713160336. Arrivals time: 0.08514192374423146 Scheduler time: 2.9940028660930693 Scheduler overhead time: 0.13544211769476533 Adapter cache time: 0.03746473090723157 Engine time: 0.1255860817618668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.4032558239996433,
    "estimated_duration": 3600.0267358544884,
    "input_throughput": 1999.9226473219758,
    "output_throughput": 1749.1247876817206,
    "total_throughput": 3749.0474350036966,
    "itl": 27.401427414944198,
    "ttft": 93491.49777443295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.1535686829323,
    "arrivals": 29680,
    "finished_requests": 29258,
    "scheduler_time": 10.454274542853394
}
#Debug simulation 
Total elapsed time: 3.4033401901833713. Arrivals time: 0.0840143826790154 Scheduler time: 2.9668719647452235 Scheduler overhead time: 0.13338142354041338 Adapter cache time: 0.03726575989276171 Engine time: 0.12304579233750701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.162431074306369,
    "estimated_duration": 3599.9523560031607,
    "input_throughput": 1784.192501683864,
    "output_throughput": 1573.0580407700895,
    "total_throughput": 3357.2505424539536,
    "itl": 26.73915198742858,
    "ttft": 89202.95796798111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.06967634062508,
    "arrivals": 26722,
    "finished_requests": 26368,
    "scheduler_time": 6.564804488104203
}
#Debug simulation 
Total elapsed time: 3.1625031819567084. Arrivals time: 0.07821471057832241 Scheduler time: 2.718945464119315 Scheduler overhead time: 0.13854876719415188 Adapter cache time: 0.04051728779450059 Engine time: 0.12614935589954257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.1295647202059627,
    "estimated_duration": 3599.9559405388463,
    "input_throughput": 1783.8140538572254,
    "output_throughput": 1571.982016855724,
    "total_throughput": 3355.796070712949,
    "itl": 26.762009887053225,
    "ttft": 90107.69280325179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.04812817162743,
    "arrivals": 26722,
    "finished_requests": 26361,
    "scheduler_time": 6.5635575092813445
}
#Debug simulation 
Total elapsed time: 3.129632033407688. Arrivals time: 0.07748395344242454 Scheduler time: 2.686352273914963 Scheduler overhead time: 0.13536009099334478 Adapter cache time: 0.04075827868655324 Engine time: 0.1301413713954389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.1199163771234453,
    "estimated_duration": 3599.967785774073,
    "input_throughput": 1784.8293046929061,
    "output_throughput": 1572.546293989332,
    "total_throughput": 3357.3755986822384,
    "itl": 26.78389505674808,
    "ttft": 87743.68411145362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.942639599816484,
    "arrivals": 26722,
    "finished_requests": 26379,
    "scheduler_time": 6.600140955697591
}
#Debug simulation 
Total elapsed time: 3.1199848260730505. Arrivals time: 0.0771117745898664 Scheduler time: 2.6833490999415517 Scheduler overhead time: 0.13527481816709042 Adapter cache time: 0.04029912408441305 Engine time: 0.12484575808048248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 3.1364937550388277,
    "estimated_duration": 3599.9510422453036,
    "input_throughput": 1785.4392808606494,
    "output_throughput": 1573.012780881628,
    "total_throughput": 3358.4520617422772,
    "itl": 26.740549868829042,
    "ttft": 87804.5132854465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.161507435847,
    "arrivals": 26722,
    "finished_requests": 26378,
    "scheduler_time": 6.572431699397669
}
#Debug simulation 
Total elapsed time: 3.136562677100301. Arrivals time: 0.07755899289622903 Scheduler time: 2.696707906201482 Scheduler overhead time: 0.13724575517699122 Adapter cache time: 0.04041117522865534 Engine time: 0.12467355001717806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 3.1187008637934923,
    "estimated_duration": 3599.9471294249743,
    "input_throughput": 1784.824545750015,
    "output_throughput": 1572.49142736833,
    "total_throughput": 3357.315973118345,
    "itl": 26.784454810127727,
    "ttft": 88726.07279645547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.639525287730216,
    "arrivals": 26722,
    "finished_requests": 26371,
    "scheduler_time": 6.58427473051082
}
#Debug simulation 
Total elapsed time: 3.118774300906807. Arrivals time: 0.0777183547616005 Scheduler time: 2.6817527138628066 Scheduler overhead time: 0.1348922192119062 Adapter cache time: 0.04031007690355182 Engine time: 0.12480503646656871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.149584027007222,
    "estimated_duration": 3599.9654139898694,
    "input_throughput": 1783.868526915262,
    "output_throughput": 1572.7601098603036,
    "total_throughput": 3356.6286367755656,
    "itl": 26.728929941229488,
    "ttft": 89515.34617830675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.22742281153585,
    "arrivals": 26722,
    "finished_requests": 26365,
    "scheduler_time": 6.537670731887958
}
#Debug simulation 
Total elapsed time: 3.149655343964696. Arrivals time: 0.07796164834871888 Scheduler time: 2.710220841690898 Scheduler overhead time: 0.13585907872766256 Adapter cache time: 0.040405366104096174 Engine time: 0.12562214443460107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.1278034732677042,
    "estimated_duration": 3599.961926664554,
    "input_throughput": 1784.8822101164214,
    "output_throughput": 1571.7630117389965,
    "total_throughput": 3356.6452218554177,
    "itl": 26.758898721404424,
    "ttft": 89810.74873991073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.36959153754781,
    "arrivals": 26722,
    "finished_requests": 26364,
    "scheduler_time": 6.598184425929311
}
#Debug simulation 
Total elapsed time: 3.1278737792745233. Arrivals time: 0.07701289281249046 Scheduler time: 2.692168455105275 Scheduler overhead time: 0.13462514523416758 Adapter cache time: 0.040101416409015656 Engine time: 0.12456010328605771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.927134482190013,
    "estimated_duration": 3600.0200988153983,
    "input_throughput": 1710.1882297895759,
    "output_throughput": 1500.6982882617044,
    "total_throughput": 3210.8865180512803,
    "itl": 26.46267921543225,
    "ttft": 73467.09898788134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.618506290276795,
    "arrivals": 25517,
    "finished_requests": 25250,
    "scheduler_time": 4.300921134667603
}
#Debug simulation 
Total elapsed time: 2.9272141130641103. Arrivals time: 0.0740636601112783 Scheduler time: 2.49512328626588 Scheduler overhead time: 0.1330131832510233 Adapter cache time: 0.040463951881974936 Engine time: 0.1247333250939846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.9202058003284037,
    "estimated_duration": 3600.020573114077,
    "input_throughput": 1711.2032764499402,
    "output_throughput": 1500.980033379596,
    "total_throughput": 3212.1833098295365,
    "itl": 26.488316206897775,
    "ttft": 71474.34669347682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.80812652740998,
    "arrivals": 25517,
    "finished_requests": 25263,
    "scheduler_time": 4.290589767763224
}
#Debug simulation 
Total elapsed time: 2.920278089120984. Arrivals time: 0.07383832754567266 Scheduler time: 2.4848705641925335 Scheduler overhead time: 0.13286925852298737 Adapter cache time: 0.04075597133487463 Engine time: 0.12841793289408088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.9723481871187687,
    "estimated_duration": 3600.0225778488425,
    "input_throughput": 1710.44927270413,
    "output_throughput": 1501.0369749483534,
    "total_throughput": 3211.4862476524836,
    "itl": 26.503310389566902,
    "ttft": 72909.10384050017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.66590556265453,
    "arrivals": 25517,
    "finished_requests": 25253,
    "scheduler_time": 4.300513035553137
}
#Debug simulation 
Total elapsed time: 2.9724225630052388. Arrivals time: 0.07525995559990406 Scheduler time: 2.5370781985111535 Scheduler overhead time: 0.13436086103320122 Adapter cache time: 0.04072904447093606 Engine time: 0.12466925196349621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.901906358078122,
    "estimated_duration": 3600.0152141197773,
    "input_throughput": 1709.0266662954434,
    "output_throughput": 1500.0642160675952,
    "total_throughput": 3209.090882363039,
    "itl": 26.474868999488034,
    "ttft": 74588.94557750673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.494859545729994,
    "arrivals": 25517,
    "finished_requests": 25243,
    "scheduler_time": 4.336154989683799
}
#Debug simulation 
Total elapsed time: 2.901987052988261. Arrivals time: 0.07569772284477949 Scheduler time: 2.4699811981990933 Scheduler overhead time: 0.13238582480698824 Adapter cache time: 0.040280294604599476 Engine time: 0.12445014948025346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.9038126170635223,
    "estimated_duration": 3600.00145117618,
    "input_throughput": 1709.3587553942475,
    "output_throughput": 1500.0968953041993,
    "total_throughput": 3209.455650698447,
    "itl": 26.505098150124848,
    "ttft": 73483.7896746462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.40363251372846,
    "arrivals": 25517,
    "finished_requests": 25247,
    "scheduler_time": 4.2856048419371024
}
#Debug simulation 
Total elapsed time: 2.9038863703608513. Arrivals time: 0.07396450219675899 Scheduler time: 2.474728188943118 Scheduler overhead time: 0.13138297945261002 Adapter cache time: 0.040369766764342785 Engine time: 0.12420875579118729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.922295539174229,
    "estimated_duration": 3600.0103788036067,
    "input_throughput": 1710.5603462305858,
    "output_throughput": 1501.285394014927,
    "total_throughput": 3211.845740245513,
    "itl": 26.455286598441763,
    "ttft": 72317.58403360697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.59769022608899,
    "arrivals": 25517,
    "finished_requests": 25258,
    "scheduler_time": 4.297411186225737
}
#Debug simulation 
Total elapsed time: 2.922377157025039. Arrivals time: 0.07903344929218292 Scheduler time: 2.4827376063913107 Scheduler overhead time: 0.13546785712242126 Adapter cache time: 0.040326515678316355 Engine time: 0.12421372393146157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.888900733087212,
    "estimated_duration": 3600.0192981037103,
    "input_throughput": 1710.45083098402,
    "output_throughput": 1501.0383424462207,
    "total_throughput": 3211.489173430241,
    "itl": 26.50133897945679,
    "ttft": 72902.68934706827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.056773946230855,
    "arrivals": 25517,
    "finished_requests": 25253,
    "scheduler_time": 4.296741189519628
}
#Debug simulation 
Total elapsed time: 2.888970597181469. Arrivals time: 0.07386912498623133 Scheduler time: 2.457638102117926 Scheduler overhead time: 0.1331845293752849 Adapter cache time: 0.04027874115854502 Engine time: 0.12456486281007528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.76635996485129,
    "estimated_duration": 3599.9293003163,
    "input_throughput": 1689.5023464670849,
    "output_throughput": 1480.3004602150884,
    "total_throughput": 3169.802806682173,
    "itl": 26.385212233065985,
    "ttft": 77114.07719553713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.301110656743273,
    "arrivals": 24947,
    "finished_requests": 24632,
    "scheduler_time": 3.2490012468285134
}
#Debug simulation 
Total elapsed time: 2.7664498020894825. Arrivals time: 0.07109251525253057 Scheduler time: 2.344565245322883 Scheduler overhead time: 0.12921085534617305 Adapter cache time: 0.03971268888562918 Engine time: 0.12262502079829574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.8022213303484023,
    "estimated_duration": 3599.9403210014343,
    "input_throughput": 1689.7944014549057,
    "output_throughput": 1480.764547373694,
    "total_throughput": 3170.5589488286,
    "itl": 26.402311711040973,
    "ttft": 76132.66296028826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.336547414855033,
    "arrivals": 24947,
    "finished_requests": 24641,
    "scheduler_time": 3.2896677095763356
}
#Debug simulation 
Total elapsed time: 2.802302725147456. Arrivals time: 0.07308761263266206 Scheduler time: 2.3566721649840474 Scheduler overhead time: 0.14264905266463757 Adapter cache time: 0.040951448027044535 Engine time: 0.1249010800383985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.810590097680688,
    "estimated_duration": 3599.940566124743,
    "input_throughput": 1688.7287132476906,
    "output_throughput": 1479.4038685291603,
    "total_throughput": 3168.132581776851,
    "itl": 26.408877056726457,
    "ttft": 77856.0347622887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.30980657042609,
    "arrivals": 24947,
    "finished_requests": 24628,
    "scheduler_time": 3.249220377580392
}
#Debug simulation 
Total elapsed time: 2.810661551076919. Arrivals time: 0.07209308445453644 Scheduler time: 2.3830491439439356 Scheduler overhead time: 0.13198257144540548 Adapter cache time: 0.040184770710766315 Engine time: 0.12347495136782527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.775490981992334,
    "estimated_duration": 3599.91803708713,
    "input_throughput": 1689.1837362276094,
    "output_throughput": 1479.5139625761124,
    "total_throughput": 3168.697698803722,
    "itl": 26.383464824850996,
    "ttft": 76961.42156056473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.32166264328725,
    "arrivals": 24947,
    "finished_requests": 24634,
    "scheduler_time": 3.272210195234472
}
#Debug simulation 
Total elapsed time: 2.7755700051784515. Arrivals time: 0.07162702269852161 Scheduler time: 2.3509799847379327 Scheduler overhead time: 0.1295037609525025 Adapter cache time: 0.040020549669861794 Engine time: 0.12411469547078013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.7808344261720777,
    "estimated_duration": 3599.919603014075,
    "input_throughput": 1689.6210667892014,
    "output_throughput": 1480.6864007565891,
    "total_throughput": 3170.3074675457906,
    "itl": 26.406786416217855,
    "ttft": 76929.0788417935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.894195575892525,
    "arrivals": 24947,
    "finished_requests": 24635,
    "scheduler_time": 3.2613851820516797
}
#Debug simulation 
Total elapsed time: 2.780951265245676. Arrivals time: 0.0716470624320209 Scheduler time: 2.35936211142689 Scheduler overhead time: 0.1280210162512958 Adapter cache time: 0.039728949312120676 Engine time: 0.12295626243576407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.786521746776998,
    "estimated_duration": 3599.9458798657884,
    "input_throughput": 1689.49456546462,
    "output_throughput": 1480.2936426918375,
    "total_throughput": 3169.7882081564576,
    "itl": 26.37893666871327,
    "ttft": 77103.80453868755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.32318162564442,
    "arrivals": 24947,
    "finished_requests": 24632,
    "scheduler_time": 3.243235667723258
}
#Debug simulation 
Total elapsed time: 2.7866191817447543. Arrivals time: 0.07161428779363632 Scheduler time: 2.366092504002154 Scheduler overhead time: 0.1274095932021737 Adapter cache time: 0.039815678261220455 Engine time: 0.12253616470843554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.7841743379831314,
    "estimated_duration": 3599.9447107762076,
    "input_throughput": 1688.697324101186,
    "output_throughput": 1479.427443443057,
    "total_throughput": 3168.1247675442432,
    "itl": 26.402499637164983,
    "ttft": 78176.23269998329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.70134817451385,
    "arrivals": 24947,
    "finished_requests": 24626,
    "scheduler_time": 3.2556068169966825
}
#Debug simulation 
Total elapsed time: 2.7842434807680547. Arrivals time: 0.07117731403559446 Scheduler time: 2.3631514492444694 Scheduler overhead time: 0.12780883722007275 Adapter cache time: 0.03974999487400055 Engine time: 0.12348090671002865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.538573865778744,
    "estimated_duration": 3599.2405067684012,
    "input_throughput": 1563.943001145549,
    "output_throughput": 1372.5745725271386,
    "total_throughput": 2936.5175736726874,
    "itl": 26.01358043717724,
    "ttft": 55671.5473910003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.58239177276546,
    "arrivals": 23153,
    "finished_requests": 22970,
    "scheduler_time": 1.3649042027891782
}
#Debug simulation 
Total elapsed time: 2.538645498920232. Arrivals time: 0.06678189989179373 Scheduler time: 2.1190299186855555 Scheduler overhead time: 0.12775736767798662 Adapter cache time: 0.04111256776377559 Engine time: 0.12377072731032968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.523212871979922,
    "estimated_duration": 3599.2636492031747,
    "input_throughput": 1564.3471967513442,
    "output_throughput": 1372.8196880197697,
    "total_throughput": 2937.166884771114,
    "itl": 26.039667602690336,
    "ttft": 54819.48025034001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.034821491529044,
    "arrivals": 23153,
    "finished_requests": 22974,
    "scheduler_time": 1.3398242783375296
}
#Debug simulation 
Total elapsed time: 2.5232855640351772. Arrivals time: 0.06616014568135142 Scheduler time: 2.1074628261849284 Scheduler overhead time: 0.12697457754984498 Adapter cache time: 0.041081083472818136 Engine time: 0.12210570834577084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.541673495899886,
    "estimated_duration": 3599.242451278252,
    "input_throughput": 1564.4358712206945,
    "output_throughput": 1372.5724418052212,
    "total_throughput": 2937.008313025916,
    "itl": 26.05662187849419,
    "ttft": 55209.92546170154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4650,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.02299891715486,
    "arrivals": 23153,
    "finished_requests": 22972,
    "scheduler_time": 1.4055088856197102
}
#Debug simulation 
Total elapsed time: 2.54175698524341. Arrivals time: 0.06672242050990462 Scheduler time: 2.124318447429687 Scheduler overhead time: 0.12723441189154983 Adapter cache time: 0.041364524979144335 Engine time: 0.12215671315789223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.5651673786342144,
    "estimated_duration": 3599.2467618373707,
    "input_throughput": 1564.037247928587,
    "output_throughput": 1372.5230101973243,
    "total_throughput": 2936.5602581259113,
    "itl": 26.019849263941857,
    "ttft": 55791.641530395325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.82949554886296,
    "arrivals": 23153,
    "finished_requests": 22968,
    "scheduler_time": 1.368631805725844
}
#Debug simulation 
Total elapsed time: 2.565238708630204. Arrivals time: 0.06725840922445059 Scheduler time: 2.143598113209009 Scheduler overhead time: 0.12778095109388232 Adapter cache time: 0.04127334011718631 Engine time: 0.12508005928248167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.558413313701749,
    "estimated_duration": 3599.2602820563125,
    "input_throughput": 1564.231413901373,
    "output_throughput": 1372.1516681139901,
    "total_throughput": 2936.383082015363,
    "itl": 26.053163475245455,
    "ttft": 57650.02789260115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.12629928526571,
    "arrivals": 23153,
    "finished_requests": 22959,
    "scheduler_time": 1.3975590393149309
}
#Debug simulation 
Total elapsed time: 2.558485558722168. Arrivals time: 0.06699447613209486 Scheduler time: 2.1331919031217694 Scheduler overhead time: 0.12652740394696593 Adapter cache time: 0.04102137591689825 Engine time: 0.13102264143526554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5460489662364125,
    "estimated_duration": 3599.249674300959,
    "input_throughput": 1565.2637382246019,
    "output_throughput": 1372.9508778686627,
    "total_throughput": 2938.2146160932643,
    "itl": 26.00095160646539,
    "ttft": 54755.380378822025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.653312768952976,
    "arrivals": 23153,
    "finished_requests": 22974,
    "scheduler_time": 1.3231071754062536
}
#Debug simulation 
Total elapsed time: 2.546121737919748. Arrivals time: 0.06699143489822745 Scheduler time: 2.1229000566527247 Scheduler overhead time: 0.1287293299101293 Adapter cache time: 0.0414171451702714 Engine time: 0.12476646061986685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.567990609910339,
    "estimated_duration": 3599.2542140842656,
    "input_throughput": 1564.3754692199623,
    "output_throughput": 1372.663253589326,
    "total_throughput": 2937.038722809288,
    "itl": 26.04769896431523,
    "ttft": 55964.382711075676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.08378232026577,
    "arrivals": 23153,
    "finished_requests": 22968,
    "scheduler_time": 1.3902230117464431
}
#Debug simulation 
Total elapsed time: 2.568072726018727. Arrivals time: 0.06847202405333519 Scheduler time: 2.1464446340687573 Scheduler overhead time: 0.12767789931967854 Adapter cache time: 0.0412556529045105 Engine time: 0.12453772639855742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.4132318501360714,
    "estimated_duration": 3600.013356287397,
    "input_throughput": 1516.0860418664183,
    "output_throughput": 1339.2464201777545,
    "total_throughput": 2855.332462044173,
    "itl": 25.87243883027716,
    "ttft": 54777.23935823289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.443531183094546,
    "arrivals": 22557,
    "finished_requests": 22357,
    "scheduler_time": 0.7085754065642866
}
#Debug simulation 
Total elapsed time: 2.4133276171050966. Arrivals time: 0.06493208557367325 Scheduler time: 1.9973308560438454 Scheduler overhead time: 0.12645369488745928 Adapter cache time: 0.040958198718726635 Engine time: 0.12404723418876529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.4448521081358194,
    "estimated_duration": 3600.022587563538,
    "input_throughput": 1516.5785400516295,
    "output_throughput": 1339.5729839750309,
    "total_throughput": 2856.1515240266604,
    "itl": 25.910609195946364,
    "ttft": 53853.435676914254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.54907683843637,
    "arrivals": 22557,
    "finished_requests": 22364,
    "scheduler_time": 0.7525009926312831
}
#Debug simulation 
Total elapsed time: 2.444959529209882. Arrivals time: 0.06571533298119903 Scheduler time: 2.0276342164725065 Scheduler overhead time: 0.12712224666029215 Adapter cache time: 0.04087429400533438 Engine time: 0.12348005315288901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.417044162284583,
    "estimated_duration": 3600.026781952766,
    "input_throughput": 1516.0864989563877,
    "output_throughput": 1339.7914216026195,
    "total_throughput": 2855.877920559007,
    "itl": 25.91620950750127,
    "ttft": 53765.31878547702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.57370958782826,
    "arrivals": 22557,
    "finished_requests": 22363,
    "scheduler_time": 0.7474831785690847
}
#Debug simulation 
Total elapsed time: 2.4171565612778068. Arrivals time: 0.06505957385525107 Scheduler time: 2.001816814765334 Scheduler overhead time: 0.12632193509489298 Adapter cache time: 0.041049299761652946 Engine time: 0.12316977512091398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4206788251176476,
    "estimated_duration": 3600.000242033802,
    "input_throughput": 1516.1001758479194,
    "output_throughput": 1339.7168543731211,
    "total_throughput": 2855.8170302210406,
    "itl": 25.883451364993714,
    "ttft": 54578.01957084034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.579682117450055,
    "arrivals": 22557,
    "finished_requests": 22358,
    "scheduler_time": 0.6912809232357443
}
#Debug simulation 
Total elapsed time: 2.4207493630237877. Arrivals time: 0.0652901204302907 Scheduler time: 1.9985306723974645 Scheduler overhead time: 0.1281532379798591 Adapter cache time: 0.041244049556553364 Engine time: 0.1268944814801216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.409723944030702,
    "estimated_duration": 3600.022650003895,
    "input_throughput": 1516.4146258896715,
    "output_throughput": 1339.287684757979,
    "total_throughput": 2855.7023106476504,
    "itl": 25.917072934195993,
    "ttft": 54746.49860888048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.25573171497889,
    "arrivals": 22557,
    "finished_requests": 22357,
    "scheduler_time": 0.7626734254566365
}
#Debug simulation 
Total elapsed time: 2.4097966481931508. Arrivals time: 0.06479582749307156 Scheduler time: 1.9957308662123978 Scheduler overhead time: 0.12492952588945627 Adapter cache time: 0.0408107740804553 Engine time: 0.12379772728309035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.433224471285939,
    "estimated_duration": 3600.023386969952,
    "input_throughput": 1516.837090493484,
    "output_throughput": 1339.9949059942771,
    "total_throughput": 2856.8319964877614,
    "itl": 25.869615634111497,
    "ttft": 53805.72001866526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.327732800983835,
    "arrivals": 22557,
    "finished_requests": 22363,
    "scheduler_time": 0.7234553115663541
}
#Debug simulation 
Total elapsed time: 2.4332970110699534. Arrivals time: 0.06518999487161636 Scheduler time: 2.017747538164258 Scheduler overhead time: 0.12708336021751165 Adapter cache time: 0.040931384079158306 Engine time: 0.12242711335420609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.414782610256225,
    "estimated_duration": 3600.002655004404,
    "input_throughput": 1515.4591601247932,
    "output_throughput": 1339.0667902143819,
    "total_throughput": 2854.5259503391753,
    "itl": 25.911165862296983,
    "ttft": 55453.06310949185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.846691752822316,
    "arrivals": 22557,
    "finished_requests": 22354,
    "scheduler_time": 0.7596681576399549
}
#Debug simulation 
Total elapsed time: 2.4148582532070577. Arrivals time: 0.06503818836063147 Scheduler time: 1.9983698292635381 Scheduler overhead time: 0.12699049850925803 Adapter cache time: 0.04090341180562973 Engine time: 0.1238011410459876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.2436270699836314,
    "estimated_duration": 3599.8725490896254,
    "input_throughput": 1443.8175044042641,
    "output_throughput": 1280.2925484585685,
    "total_throughput": 2724.1100528628326,
    "itl": 25.683217368243003,
    "ttft": 46340.877136204166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.040174232145695,
    "arrivals": 21252,
    "finished_requests": 21088,
    "scheduler_time": 0.27525630511919935
}
#Debug simulation 
Total elapsed time: 2.2436987082473934. Arrivals time: 0.062022457364946604 Scheduler time: 1.8301889249123633 Scheduler overhead time: 0.12665132246911526 Adapter cache time: 0.040654334239661694 Engine time: 0.1241038553416729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.26133966492489,
    "estimated_duration": 3599.879977569687,
    "input_throughput": 1444.287596363163,
    "output_throughput": 1280.1954589361826,
    "total_throughput": 2724.4830552993453,
    "itl": 25.711963034587388,
    "ttft": 46692.40403223625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.399829440334752,
    "arrivals": 21252,
    "finished_requests": 21095,
    "scheduler_time": 0.3628525460663794
}
#Debug simulation 
Total elapsed time: 2.2614136170595884. Arrivals time: 0.06122917588800192 Scheduler time: 1.8517936300486326 Scheduler overhead time: 0.12667454965412617 Adapter cache time: 0.03928220830857754 Engine time: 0.12244907347485423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.273584655020386,
    "estimated_duration": 3599.864566487018,
    "input_throughput": 1443.885152899611,
    "output_throughput": 1280.2376075212885,
    "total_throughput": 2724.1227604209,
    "itl": 25.722819174808727,
    "ttft": 47304.533024904515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.392581041153974,
    "arrivals": 21252,
    "finished_requests": 21091,
    "scheduler_time": 0.3824112867493835
}
#Debug simulation 
Total elapsed time: 2.2736659459769726. Arrivals time: 0.0621868297457695 Scheduler time: 1.8591776569373906 Scheduler overhead time: 0.1268846900202334 Adapter cache time: 0.03956658020615578 Engine time: 0.12573043163865805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2389812897890806,
    "estimated_duration": 3599.884255720027,
    "input_throughput": 1443.3977958440541,
    "output_throughput": 1280.443667786215,
    "total_throughput": 2723.841463630269,
    "itl": 25.69108642688972,
    "ttft": 46195.18084481728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.232995504076577,
    "arrivals": 21252,
    "finished_requests": 21087,
    "scheduler_time": 0.27388791814236557
}
#Debug simulation 
Total elapsed time: 2.2390529648400843. Arrivals time: 0.06185115734115243 Scheduler time: 1.8250915799289942 Scheduler overhead time: 0.12612398946657777 Adapter cache time: 0.040641735307872295 Engine time: 0.1252439017407596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.2762609641067684,
    "estimated_duration": 3599.874183539151,
    "input_throughput": 1443.891851489612,
    "output_throughput": 1280.0211243688,
    "total_throughput": 2723.9129758584118,
    "itl": 25.716246886449028,
    "ttft": 47462.27020295805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.07905900125538,
    "arrivals": 21252,
    "finished_requests": 21090,
    "scheduler_time": 0.3791117171498208
}
#Debug simulation 
Total elapsed time: 2.2763438150286674. Arrivals time: 0.062125442549586296 Scheduler time: 1.8647806169465184 Scheduler overhead time: 0.1262359470129013 Adapter cache time: 0.03961864998564124 Engine time: 0.12340735038742423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.234172106720507,
    "estimated_duration": 3599.8699553503657,
    "input_throughput": 1443.7524311886314,
    "output_throughput": 1280.5445911035254,
    "total_throughput": 2724.2970222921567,
    "itl": 25.675874616815904,
    "ttft": 45845.01951213881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.129831251826122,
    "arrivals": 21252,
    "finished_requests": 21090,
    "scheduler_time": 0.26125777821020574
}
#Debug simulation 
Total elapsed time: 2.2342432998120785. Arrivals time: 0.06164040137082338 Scheduler time: 1.8228456294164062 Scheduler overhead time: 0.1270038872025907 Adapter cache time: 0.040412343107163906 Engine time: 0.12225755443796515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.284833174198866,
    "estimated_duration": 3599.871296268002,
    "input_throughput": 1443.5463305000133,
    "output_throughput": 1279.7696419802835,
    "total_throughput": 2723.3159724802968,
    "itl": 25.714608139349636,
    "ttft": 48415.31756740299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.60577952103835,
    "arrivals": 21252,
    "finished_requests": 21085,
    "scheduler_time": 0.3524746024111605
}
#Debug simulation 
Total elapsed time: 2.284903754014522. Arrivals time: 0.06229311507195234 Scheduler time: 1.8725349502637982 Scheduler overhead time: 0.12676132330670953 Adapter cache time: 0.039362342562526464 Engine time: 0.12391828512772918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.970987075008452,
    "estimated_duration": 3599.558202305233,
    "input_throughput": 1173.8201641785015,
    "output_throughput": 1001.4820701305373,
    "total_throughput": 2175.302234309039,
    "itl": 24.904100799198332,
    "ttft": 65206.904588199635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.276183413606226,
    "arrivals": 17165,
    "finished_requests": 16983,
    "scheduler_time": 0.0006307679343153735
}
#Debug simulation 
Total elapsed time: 1.9710583039559424. Arrivals time: 0.05287296464666724 Scheduler time: 1.5466715218499303 Scheduler overhead time: 0.13420832343399525 Adapter cache time: 0.04724224843084812 Engine time: 0.12846105406060815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9550542440265417,
    "estimated_duration": 3599.565775986328,
    "input_throughput": 1173.640728607718,
    "output_throughput": 1001.2852172460731,
    "total_throughput": 2174.9259458537913,
    "itl": 24.929162248021495,
    "ttft": 65679.94689107085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.69137182501459,
    "arrivals": 17165,
    "finished_requests": 16981,
    "scheduler_time": 0.0004547531348452382
}
#Debug simulation 
Total elapsed time: 1.9551264462061226. Arrivals time: 0.0527178980410099 Scheduler time: 1.5435179295018315 Scheduler overhead time: 0.12696863850578666 Adapter cache time: 0.0470498176291585 Engine time: 0.12416306883096695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9615181982517242,
    "estimated_duration": 3599.5711017676263,
    "input_throughput": 1173.6389921358812,
    "output_throughput": 1001.2837357845507,
    "total_throughput": 2174.922727920432,
    "itl": 24.938697995037433,
    "ttft": 65688.17968340541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6094,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.8629129929268,
    "arrivals": 17165,
    "finished_requests": 16981,
    "scheduler_time": 0.0004460171470511403
}
#Debug simulation 
Total elapsed time: 1.961588627193123. Arrivals time: 0.05321851605549455 Scheduler time: 1.5480005126446486 Scheduler overhead time: 0.1269630268216133 Adapter cache time: 0.04720499971881509 Engine time: 0.12531864969059825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.977679566014558,
    "estimated_duration": 3599.5764006993363,
    "input_throughput": 1173.6372644234564,
    "output_throughput": 1001.2822617960733,
    "total_throughput": 2174.9195262195294,
    "itl": 24.906350452164446,
    "ttft": 65670.97713364019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.79915983136411,
    "arrivals": 17165,
    "finished_requests": 16981,
    "scheduler_time": 0.0005354625881302201
}
#Debug simulation 
Total elapsed time: 1.9777541211806238. Arrivals time: 0.05403336230665445 Scheduler time: 1.5617631515488029 Scheduler overhead time: 0.12722236150875688 Adapter cache time: 0.04750442272052169 Engine time: 0.12650708155706525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.9678088701330125,
    "estimated_duration": 3599.5797054791906,
    "input_throughput": 1173.6361869052166,
    "output_throughput": 1001.2813425172358,
    "total_throughput": 2174.9175294224524,
    "itl": 24.938274452298277,
    "ttft": 65653.93602782342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.48046196784694,
    "arrivals": 17165,
    "finished_requests": 16981,
    "scheduler_time": 0.0004491685213464249
}
#Debug simulation 
Total elapsed time: 1.9678808129392564. Arrivals time: 0.05299291480332613 Scheduler time: 1.553397482726723 Scheduler overhead time: 0.12895534932613373 Adapter cache time: 0.04714974155649543 Engine time: 0.12417119322344661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9387075193226337,
    "estimated_duration": 3599.5823778800786,
    "input_throughput": 1174.2962255775392,
    "output_throughput": 1001.4225600590191,
    "total_throughput": 2175.7187856365586,
    "itl": 24.89446823571388,
    "ttft": 64508.98188526685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.967453421246624,
    "arrivals": 17165,
    "finished_requests": 16986,
    "scheduler_time": 0.000747554418847589
}
#Debug simulation 
Total elapsed time: 1.938777768984437. Arrivals time: 0.05273139709606767 Scheduler time: 1.5285686305724084 Scheduler overhead time: 0.12697638664394617 Adapter cache time: 0.0468306140974164 Engine time: 0.12302519474178553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9546686350367963,
    "estimated_duration": 3599.5671483879614,
    "input_throughput": 1173.6402811354565,
    "output_throughput": 1001.2848354875418,
    "total_throughput": 2174.9251166229983,
    "itl": 24.93385476121236,
    "ttft": 65686.39623401822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.059184134098416,
    "arrivals": 17165,
    "finished_requests": 16981,
    "scheduler_time": 0.00044909108164031895
}
#Debug simulation 
Total elapsed time: 1.9547390332445502. Arrivals time: 0.05291256122291088 Scheduler time: 1.543453125283122 Scheduler overhead time: 0.12693875236436725 Adapter cache time: 0.04699708614498377 Engine time: 0.12369572883471847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.8558276039548218,
    "estimated_duration": 3599.608922031621,
    "input_throughput": 1072.0145114603374,
    "output_throughput": 958.5144038515889,
    "total_throughput": 2030.5289153119263,
    "itl": 24.83063877853072,
    "ttft": 51201.81485910983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.42165641230917,
    "arrivals": 15906,
    "finished_requests": 15778,
    "scheduler_time": 0.0004078162047401274
}
#Debug simulation 
Total elapsed time: 1.8559462260454893. Arrivals time: 0.050227073952555656 Scheduler time: 1.444340671878308 Scheduler overhead time: 0.12749804882332683 Adapter cache time: 0.04714562790468335 Engine time: 0.12591787287965417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.8171503231860697,
    "estimated_duration": 3599.6165873654504,
    "input_throughput": 1072.2355857418854,
    "output_throughput": 958.4370769124191,
    "total_throughput": 2030.6726626543045,
    "itl": 24.85382982226555,
    "ttft": 49818.42859797882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.89734780225743,
    "arrivals": 15906,
    "finished_requests": 15784,
    "scheduler_time": 0.0002737741424883266
}
#Debug simulation 
Total elapsed time: 1.817222482059151. Arrivals time: 0.05069792363792658 Scheduler time: 1.4065052210353315 Scheduler overhead time: 0.12718103267252445 Adapter cache time: 0.04716986836865544 Engine time: 0.12501313583925366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.8329775519669056,
    "estimated_duration": 3599.6070129365607,
    "input_throughput": 1072.2384377319308,
    "output_throughput": 958.4396262150528,
    "total_throughput": 2030.6780639469837,
    "itl": 24.872876372116885,
    "ttft": 49825.47340893072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.17991471689975,
    "arrivals": 15906,
    "finished_requests": 15784,
    "scheduler_time": 1.7040971674169578e-06
}
#Debug simulation 
Total elapsed time: 1.833069872111082. Arrivals time: 0.05104547180235386 Scheduler time: 1.419902436900884 Scheduler overhead time: 0.12821781681850553 Adapter cache time: 0.047348019666969776 Engine time: 0.12531061796471477 
