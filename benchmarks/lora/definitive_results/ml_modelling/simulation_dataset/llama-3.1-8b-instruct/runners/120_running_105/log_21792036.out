INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 98.13088038796559,
    "estimated_duration": 3600.0712429041528,
    "input_throughput": 7237.079280404022,
    "output_throughput": 6325.691760930049,
    "total_throughput": 13562.771041334072,
    "itl": 85.41538366490248,
    "ttft": 1709848.835194281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5313384217396366,
    "arrivals": 332795,
    "finished_requests": 105200,
    "scheduler_time": 278.0642120212694
}
#Debug simulation 
Total elapsed time: 98.13109549833462. Arrivals time: 0.4782610763795674 Scheduler time: 97.42095262557268 Scheduler overhead time: 0.08942509861662984 Adapter cache time: 0.0168339847587049 Engine time: 0.08956884313374758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 95.29472243739292,
    "estimated_duration": 3600.0739420009613,
    "input_throughput": 7113.465837806162,
    "output_throughput": 6214.732908392587,
    "total_throughput": 13328.198746198748,
    "itl": 82.96966544569734,
    "ttft": 1726183.8031116072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.809678047439087,
    "arrivals": 332795,
    "finished_requests": 103444,
    "scheduler_time": 283.54458717528576
}
#Debug simulation 
Total elapsed time: 95.29493791796267. Arrivals time: 0.47059117211028934 Scheduler time: 94.58604791481048 Scheduler overhead time: 0.09225451853126287 Adapter cache time: 0.017606728244572878 Engine time: 0.09208052000030875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 95.46049010520801,
    "estimated_duration": 3600.032795966015,
    "input_throughput": 7191.081433760469,
    "output_throughput": 6288.60882194411,
    "total_throughput": 13479.690255704578,
    "itl": 85.04373289568308,
    "ttft": 1712230.6939344131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4874535791529295,
    "arrivals": 332795,
    "finished_requests": 104543,
    "scheduler_time": 279.98246394626887
}
#Debug simulation 
Total elapsed time: 95.46067201625556. Arrivals time: 0.47410413855686784 Scheduler time: 94.75405034422874 Scheduler overhead time: 0.09006077470257878 Adapter cache time: 0.01677856780588627 Engine time: 0.08987122401595116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.48947407584637,
    "estimated_duration": 3600.046040692543,
    "input_throughput": 7113.813465305954,
    "output_throughput": 6215.059681763349,
    "total_throughput": 13328.873147069302,
    "itl": 82.96793933062393,
    "ttft": 1726150.511261597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7935229076631403,
    "arrivals": 332795,
    "finished_requests": 103450,
    "scheduler_time": 283.537016933322
}
#Debug simulation 
Total elapsed time: 95.48964963667095. Arrivals time: 0.4815025576390326 Scheduler time: 94.76967297075316 Scheduler overhead time: 0.09221954364329576 Adapter cache time: 0.017630749382078648 Engine time: 0.09212818276137114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.16457960801199,
    "estimated_duration": 3600.096880152998,
    "input_throughput": 7277.606373439189,
    "output_throughput": 6339.996605599678,
    "total_throughput": 13617.602979038867,
    "itl": 86.26506707312298,
    "ttft": 1693345.472841719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.87792416507378,
    "arrivals": 331579,
    "finished_requests": 105834,
    "scheduler_time": 277.2569706117307
}
#Debug simulation 
Total elapsed time: 96.16474662581459. Arrivals time: 0.48153046937659383 Scheduler time: 95.45113698905334 Scheduler overhead time: 0.08952281204983592 Adapter cache time: 0.017425304278731346 Engine time: 0.08958477852866054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.17065917793661,
    "estimated_duration": 3600.022591501155,
    "input_throughput": 7256.907793210891,
    "output_throughput": 6333.315255805856,
    "total_throughput": 13590.223049016748,
    "itl": 85.70196933264647,
    "ttft": 1690733.2868192182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9027581148780903,
    "arrivals": 331579,
    "finished_requests": 105582,
    "scheduler_time": 277.9469412275896
}
#Debug simulation 
Total elapsed time: 94.17082705302164. Arrivals time: 0.4794514225795865 Scheduler time: 93.45645815972239 Scheduler overhead time: 0.09065437223762274 Adapter cache time: 0.017397175077348948 Engine time: 0.09147298894822598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.60109018860385,
    "estimated_duration": 3600.094704320335,
    "input_throughput": 7243.371950384029,
    "output_throughput": 6304.868861577684,
    "total_throughput": 13548.240811961714,
    "itl": 83.90739574032376,
    "ttft": 1703341.2477593615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9936700526857807,
    "arrivals": 331579,
    "finished_requests": 105176,
    "scheduler_time": 279.02036360092427
}
#Debug simulation 
Total elapsed time: 93.6012655957602. Arrivals time: 0.4893710962496698 Scheduler time: 92.87726352596655 Scheduler overhead time: 0.09045733045786619 Adapter cache time: 0.017359368968755007 Engine time: 0.09134217537939548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 95.63785393768921,
    "estimated_duration": 3600.0358025626383,
    "input_throughput": 7248.889853101938,
    "output_throughput": 6317.752446742304,
    "total_throughput": 13566.642299844241,
    "itl": 85.43018124319768,
    "ttft": 1697679.389799221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8874592511216157,
    "arrivals": 331579,
    "finished_requests": 105464,
    "scheduler_time": 278.30958223511686
}
#Debug simulation 
Total elapsed time: 95.638035625685. Arrivals time: 0.4852589354850352 Scheduler time: 94.9163632565178 Scheduler overhead time: 0.091646249871701 Adapter cache time: 0.01763415476307273 Engine time: 0.09129774756729603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 94.1165519808419,
    "estimated_duration": 3600.0766160521575,
    "input_throughput": 7243.408344069031,
    "output_throughput": 6304.900539836498,
    "total_throughput": 13548.308883905529,
    "itl": 83.9069916451323,
    "ttft": 1703333.8781993184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9752366239670722,
    "arrivals": 331579,
    "finished_requests": 105176,
    "scheduler_time": 279.01999492525334
}
#Debug simulation 
Total elapsed time: 94.1167312739417. Arrivals time: 0.48129638377577066 Scheduler time: 93.40180685184896 Scheduler overhead time: 0.09102397644892335 Adapter cache time: 0.01744447136297822 Engine time: 0.08934779977425933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 95.22553085815161,
    "estimated_duration": 3600.04308798499,
    "input_throughput": 7235.720618716275,
    "output_throughput": 6324.562635372249,
    "total_throughput": 13560.283254088525,
    "itl": 85.47455749757559,
    "ttft": 1688290.4946347177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.698122970191756,
    "arrivals": 331579,
    "finished_requests": 105237,
    "scheduler_time": 279.10764697849555
}
#Debug simulation 
Total elapsed time: 95.22570734331384. Arrivals time: 0.4797468176111579 Scheduler time: 94.51281242677942 Scheduler overhead time: 0.0906845722347498 Adapter cache time: 0.01763770217075944 Engine time: 0.08937177527695894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 90.18207213003188,
    "estimated_duration": 3600.096376646054,
    "input_throughput": 7235.636570448687,
    "output_throughput": 6307.393087391359,
    "total_throughput": 13543.029657840047,
    "itl": 83.93810421099215,
    "ttft": 1707848.4449596063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9197867169231229,
    "arrivals": 331579,
    "finished_requests": 105191,
    "scheduler_time": 278.90971092605076
}
#Debug simulation 
Total elapsed time: 90.18224062211812. Arrivals time: 0.4913441492244601 Scheduler time: 89.45501896739006 Scheduler overhead time: 0.09042861592024565 Adapter cache time: 0.01763764163479209 Engine time: 0.09166759857907891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 99.18314509605989,
    "estimated_duration": 3600.03622961315,
    "input_throughput": 7349.790755534497,
    "output_throughput": 6388.462652352633,
    "total_throughput": 13738.25340788713,
    "itl": 86.8085915334235,
    "ttft": 1689878.8201525873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.679551894115282,
    "arrivals": 330904,
    "finished_requests": 106571,
    "scheduler_time": 274.61664480421314
}
#Debug simulation 
Total elapsed time: 99.1833114833571. Arrivals time: 0.490127332508564 Scheduler time: 98.45877284836024 Scheduler overhead time: 0.090971983037889 Adapter cache time: 0.017395430710166693 Engine time: 0.09045566152781248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 97.47039225604385,
    "estimated_duration": 3600.057261632371,
    "input_throughput": 7331.194223292096,
    "output_throughput": 6369.693405821633,
    "total_throughput": 13700.88762911373,
    "itl": 85.89667870525848,
    "ttft": 1695040.5369825652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6446153576252998,
    "arrivals": 330904,
    "finished_requests": 106329,
    "scheduler_time": 275.5380610609697
}
#Debug simulation 
Total elapsed time: 97.47056343732402. Arrivals time: 0.49628874752670527 Scheduler time: 96.74063277198002 Scheduler overhead time: 0.09084903029724956 Adapter cache time: 0.01702055800706148 Engine time: 0.08988000312820077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.02948939986527,
    "estimated_duration": 3600.0800579861616,
    "input_throughput": 7276.061803651337,
    "output_throughput": 6320.006675831391,
    "total_throughput": 13596.068479482727,
    "itl": 83.94843997372485,
    "ttft": 1703242.5225806965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6825887625012583,
    "arrivals": 330904,
    "finished_requests": 105503,
    "scheduler_time": 278.0299606488193
}
#Debug simulation 
Total elapsed time: 93.02966655092314. Arrivals time: 0.4926105332560837 Scheduler time: 92.30111410049722 Scheduler overhead time: 0.09115834766998887 Adapter cache time: 0.01751704653725028 Engine time: 0.09131633909419179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 99.52755725895986,
    "estimated_duration": 3600.0377484502524,
    "input_throughput": 7309.453355406567,
    "output_throughput": 6381.06725683336,
    "total_throughput": 13690.520612239929,
    "itl": 85.84541601069196,
    "ttft": 1680009.9098677537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6601312084030342,
    "arrivals": 330904,
    "finished_requests": 106021,
    "scheduler_time": 276.4573939625298
}
#Debug simulation 
Total elapsed time: 99.52771868184209. Arrivals time: 0.49354698369279504 Scheduler time: 98.79817292885855 Scheduler overhead time: 0.09128861268982291 Adapter cache time: 0.01750026596710086 Engine time: 0.09151219017803669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 93.42499203234911,
    "estimated_duration": 3600.064624494813,
    "input_throughput": 7276.092996157197,
    "output_throughput": 6320.03376972512,
    "total_throughput": 13596.126765882318,
    "itl": 83.94811426334374,
    "ttft": 1703235.7277002486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.667469208608385,
    "arrivals": 330904,
    "finished_requests": 105503,
    "scheduler_time": 278.0297478425857
}
#Debug simulation 
Total elapsed time: 93.42516525741667. Arrivals time: 0.4958146708086133 Scheduler time: 92.69314303435385 Scheduler overhead time: 0.09158185962587595 Adapter cache time: 0.01758782658725977 Engine time: 0.09061139449477196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 99.82054878911003,
    "estimated_duration": 3600.026865177801,
    "input_throughput": 7346.521842884576,
    "output_throughput": 6398.432529159016,
    "total_throughput": 13744.95437204359,
    "itl": 85.8396604573,
    "ttft": 1679802.0622677007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5768284723209165,
    "arrivals": 330904,
    "finished_requests": 106330,
    "scheduler_time": 275.3639315522664
}
#Debug simulation 
Total elapsed time: 99.82071774499491. Arrivals time: 0.49124242598190904 Scheduler time: 99.09503269707784 Scheduler overhead time: 0.09065066184848547 Adapter cache time: 0.017227587290108204 Engine time: 0.09095876663923264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.86774407373741,
    "estimated_duration": 3600.0875142322875,
    "input_throughput": 7278.911942113749,
    "output_throughput": 6319.500820482571,
    "total_throughput": 13598.412762596321,
    "itl": 83.9469953205893,
    "ttft": 1703120.7942272802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.672124676164243,
    "arrivals": 330904,
    "finished_requests": 105497,
    "scheduler_time": 278.04928987914184
}
#Debug simulation 
Total elapsed time: 92.86792202480137. Arrivals time: 0.4890157524496317 Scheduler time: 92.14289747923613 Scheduler overhead time: 0.09116575354710221 Adapter cache time: 0.017438046168535948 Engine time: 0.0912844780832529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.71730779623613,
    "estimated_duration": 3600.0318253948567,
    "input_throughput": 7317.41114458361,
    "output_throughput": 6345.365015625796,
    "total_throughput": 13662.776160209407,
    "itl": 86.62774026311543,
    "ttft": 1691900.8285475187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.494404441220684,
    "arrivals": 325545,
    "finished_requests": 106300,
    "scheduler_time": 276.5925705650808
}
#Debug simulation 
Total elapsed time: 96.7174851372838. Arrivals time: 0.48921417398378253 Scheduler time: 95.99439207278192 Scheduler overhead time: 0.09017318719998002 Adapter cache time: 0.01713527785614133 Engine time: 0.09098456706851721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 96.93649785034359,
    "estimated_duration": 3600.0518931537954,
    "input_throughput": 7219.764817676097,
    "output_throughput": 6268.647138924981,
    "total_throughput": 13488.411956601078,
    "itl": 85.10092822621189,
    "ttft": 1699335.9128171057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6848642881680296,
    "arrivals": 325545,
    "finished_requests": 104892,
    "scheduler_time": 280.46263261977356
}
#Debug simulation 
Total elapsed time: 96.93667864520103. Arrivals time: 0.49818820180371404 Scheduler time: 96.20273535093293 Scheduler overhead time: 0.09064814262092113 Adapter cache time: 0.017388810869306326 Engine time: 0.09154685493558645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 96.02649911399931,
    "estimated_duration": 3600.0700537453226,
    "input_throughput": 7120.65004772084,
    "output_throughput": 6179.25475557252,
    "total_throughput": 13299.904803293359,
    "itl": 82.87640721675906,
    "ttft": 1707882.5668754634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.827490124627952,
    "arrivals": 325545,
    "finished_requests": 103403,
    "scheduler_time": 284.84079111698696
}
#Debug simulation 
Total elapsed time: 96.02667479403317. Arrivals time: 0.4771910114213824 Scheduler time: 95.30814867094159 Scheduler overhead time: 0.0931099895387888 Adapter cache time: 0.017760023940354586 Engine time: 0.09278888069093227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 90.70174836134538,
    "estimated_duration": 3600.0937341542167,
    "input_throughput": 7288.711055231641,
    "output_throughput": 6321.698178046686,
    "total_throughput": 13610.409233278326,
    "itl": 85.63870200862641,
    "ttft": 1697880.1708881755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6706797922635435,
    "arrivals": 325545,
    "finished_requests": 105857,
    "scheduler_time": 277.76431673816614
}
#Debug simulation 
Total elapsed time: 90.7019231482409. Arrivals time: 0.49434511130675673 Scheduler time: 89.97385546891019 Scheduler overhead time: 0.08988363854587078 Adapter cache time: 0.01680617919191718 Engine time: 0.09093241672962904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 95.75901239737868,
    "estimated_duration": 3600.059617994006,
    "input_throughput": 7130.895797304749,
    "output_throughput": 6187.378922466802,
    "total_throughput": 13318.27471977155,
    "itl": 82.9645109699277,
    "ttft": 1709636.5476342486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.767797846617181,
    "arrivals": 325545,
    "finished_requests": 103568,
    "scheduler_time": 284.47694207726806
}
#Debug simulation 
Total elapsed time: 95.75918625900522. Arrivals time: 0.4809916326776147 Scheduler time: 95.03754181275144 Scheduler overhead time: 0.09349411632865667 Adapter cache time: 0.017354156356304884 Engine time: 0.09334061061963439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.30434485618025,
    "estimated_duration": 3600.055981659035,
    "input_throughput": 7273.4863383799475,
    "output_throughput": 6310.709643334578,
    "total_throughput": 13584.195981714525,
    "itl": 85.5683585594024,
    "ttft": 1698312.350887356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.570444551380346,
    "arrivals": 325545,
    "finished_requests": 105617,
    "scheduler_time": 278.40414164010446
}
#Debug simulation 
Total elapsed time: 94.30452743498608. Arrivals time: 0.475594665389508 Scheduler time: 93.594158786349 Scheduler overhead time: 0.09110717428848147 Adapter cache time: 0.01682976633310318 Engine time: 0.09069784544408321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.50531883863732,
    "estimated_duration": 3600.0273923736922,
    "input_throughput": 7188.196138401446,
    "output_throughput": 6239.40335775878,
    "total_throughput": 13427.599496160225,
    "itl": 83.2491622261549,
    "ttft": 1706322.0458407062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8077591308392624,
    "arrivals": 325545,
    "finished_requests": 104414,
    "scheduler_time": 281.86523641457876
}
#Debug simulation 
Total elapsed time: 91.50549551192671. Arrivals time: 0.48203833401203156 Scheduler time: 90.78453529113904 Scheduler overhead time: 0.09200449055060744 Adapter cache time: 0.017381352838128805 Engine time: 0.09286223677918315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 95.85974875697866,
    "estimated_duration": 3600.079147716979,
    "input_throughput": 7208.7034576608185,
    "output_throughput": 6313.912296737919,
    "total_throughput": 13522.615754398737,
    "itl": 86.6005142779647,
    "ttft": 1697205.4707607164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5539161225082334,
    "arrivals": 323217,
    "finished_requests": 105107,
    "scheduler_time": 278.2526841431122
}
#Debug simulation 
Total elapsed time: 95.85993030015379. Arrivals time: 0.49073303677141666 Scheduler time: 95.13435508683324 Scheduler overhead time: 0.09041676670312881 Adapter cache time: 0.017056520096957684 Engine time: 0.09122169483453035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.75023778202012,
    "estimated_duration": 3600.097374446819,
    "input_throughput": 7188.05029654963,
    "output_throughput": 6304.195870115142,
    "total_throughput": 13492.246166664772,
    "itl": 85.7749435066388,
    "ttft": 1696737.797336619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.687083546188662,
    "arrivals": 323217,
    "finished_requests": 104919,
    "scheduler_time": 278.70838184970455
}
#Debug simulation 
Total elapsed time: 95.75041348906234. Arrivals time: 0.5125075108371675 Scheduler time: 95.00183580862358 Scheduler overhead time: 0.09110347181558609 Adapter cache time: 0.01729129021987319 Engine time: 0.09130381001159549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.53996737580746,
    "estimated_duration": 3600.046333296903,
    "input_throughput": 7124.014700253265,
    "output_throughput": 6245.392119553514,
    "total_throughput": 13369.406819806778,
    "itl": 83.73912981254851,
    "ttft": 1703830.6094260807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7403621239122031,
    "arrivals": 323217,
    "finished_requests": 103956,
    "scheduler_time": 281.55893561542194
}
#Debug simulation 
Total elapsed time: 93.54014290682971. Arrivals time: 0.49474379187449813 Scheduler time: 92.80631059594452 Scheduler overhead time: 0.09184223553165793 Adapter cache time: 0.018019021023064852 Engine time: 0.09273147117346525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 94.57956626685336,
    "estimated_duration": 3600.0147069335353,
    "input_throughput": 7186.327586432729,
    "output_throughput": 6298.176214761394,
    "total_throughput": 13484.503801194121,
    "itl": 85.72368001583861,
    "ttft": 1699461.7768620814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5971230360446482,
    "arrivals": 323217,
    "finished_requests": 104858,
    "scheduler_time": 278.9233170299783
}
#Debug simulation 
Total elapsed time: 94.57974740071222. Arrivals time: 0.51274668937549 Scheduler time: 93.83148623164743 Scheduler overhead time: 0.09033580170944333 Adapter cache time: 0.017289564944803715 Engine time: 0.09187825256958604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 93.58077291119844,
    "estimated_duration": 3600.0369837466556,
    "input_throughput": 7122.417385088848,
    "output_throughput": 6245.683058677796,
    "total_throughput": 13368.100443766645,
    "itl": 83.70709454377719,
    "ttft": 1704583.5568153323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7677441223710801,
    "arrivals": 323217,
    "finished_requests": 103884,
    "scheduler_time": 281.64581177330916
}
#Debug simulation 
Total elapsed time: 93.58094994584098. Arrivals time: 0.5151307247579098 Scheduler time: 92.82871535699815 Scheduler overhead time: 0.09152043890208006 Adapter cache time: 0.01713423151522875 Engine time: 0.09190834499895573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.85375403799117,
    "estimated_duration": 3600.009687170075,
    "input_throughput": 7188.441490095754,
    "output_throughput": 6304.526090828755,
    "total_throughput": 13492.96758092451,
    "itl": 85.77171283408525,
    "ttft": 1696701.4857009912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4746857372717885,
    "arrivals": 323217,
    "finished_requests": 104922,
    "scheduler_time": 278.7161745826446
}
#Debug simulation 
Total elapsed time: 96.8539287908934. Arrivals time: 0.4959859331138432 Scheduler time: 96.12189399916679 Scheduler overhead time: 0.09161536395549774 Adapter cache time: 0.01722797518596053 Engine time: 0.09114134637638927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.98721144674346,
    "estimated_duration": 3600.041939236191,
    "input_throughput": 7124.43144632968,
    "output_throughput": 6244.524752611528,
    "total_throughput": 13368.956198941207,
    "itl": 83.71261047874732,
    "ttft": 1705100.863749838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7148333456926073,
    "arrivals": 323217,
    "finished_requests": 103927,
    "scheduler_time": 281.59846509870755
}
#Debug simulation 
Total elapsed time: 92.98739798599854. Arrivals time: 0.4832824720069766 Scheduler time: 92.26730920141563 Scheduler overhead time: 0.09204128943383694 Adapter cache time: 0.01734822615981102 Engine time: 0.09079973679035902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.53731414303184,
    "estimated_duration": 3600.0292542821953,
    "input_throughput": 7308.771440871602,
    "output_throughput": 6373.014322789046,
    "total_throughput": 13681.785763660648,
    "itl": 86.76270118921705,
    "ttft": 1687945.930446853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4877920321887341,
    "arrivals": 321998,
    "finished_requests": 106100,
    "scheduler_time": 275.2099743344682
}
#Debug simulation 
Total elapsed time: 91.53749346593395. Arrivals time: 0.48850028682500124 Scheduler time: 90.81648063333705 Scheduler overhead time: 0.09062763582915068 Adapter cache time: 0.017074272967875004 Engine time: 0.08951695216819644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.32585928402841,
    "estimated_duration": 3600.0746473215763,
    "input_throughput": 7275.860243477961,
    "output_throughput": 6346.529791263827,
    "total_throughput": 13622.39003474179,
    "itl": 85.84247102060505,
    "ttft": 1691315.657918353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6615478624263798,
    "arrivals": 321998,
    "finished_requests": 105631,
    "scheduler_time": 276.61076662394356
}
#Debug simulation 
Total elapsed time: 91.32603345578536. Arrivals time: 0.47022130666300654 Scheduler time: 90.62543014762923 Scheduler overhead time: 0.08881957223638892 Adapter cache time: 0.01670787064358592 Engine time: 0.08970569400116801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 88.93860728293657,
    "estimated_duration": 3600.018216091721,
    "input_throughput": 7197.527191440143,
    "output_throughput": 6274.951304142083,
    "total_throughput": 13472.478495582225,
    "itl": 83.72514600563284,
    "ttft": 1700496.8098703015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8580856117280249,
    "arrivals": 321998,
    "finished_requests": 104482,
    "scheduler_time": 280.15331304058355
}
#Debug simulation 
Total elapsed time: 88.93877449491993. Arrivals time: 0.48184142308309674 Scheduler time: 88.22395321493968 Scheduler overhead time: 0.0897533013485372 Adapter cache time: 0.01686939550563693 Engine time: 0.0897525898180902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 91.29201811272651,
    "estimated_duration": 3600.0164140905927,
    "input_throughput": 7269.761020412229,
    "output_throughput": 6342.704136188807,
    "total_throughput": 13612.465156601036,
    "itl": 85.75968385274142,
    "ttft": 1692922.8011034273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6085026569524763,
    "arrivals": 321998,
    "finished_requests": 105586,
    "scheduler_time": 276.84261446782176
}
#Debug simulation 
Total elapsed time: 91.29218988772482. Arrivals time: 0.4673731867223978 Scheduler time: 90.59459422761574 Scheduler overhead time: 0.08898511249572039 Adapter cache time: 0.016789985354989767 Engine time: 0.08935250202193856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 88.71571022318676,
    "estimated_duration": 3600.0619230798684,
    "input_throughput": 7202.616386613953,
    "output_throughput": 6278.783666215989,
    "total_throughput": 13481.400052829942,
    "itl": 83.75015080729976,
    "ttft": 1700773.3637788421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8258301941864241,
    "arrivals": 321998,
    "finished_requests": 104550,
    "scheduler_time": 279.969513957719
}
#Debug simulation 
Total elapsed time: 88.71588292298838. Arrivals time: 0.48038515029475093 Scheduler time: 88.00226977607235 Scheduler overhead time: 0.08994940482079983 Adapter cache time: 0.01710479613393545 Engine time: 0.09006187273189425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.13608604623005,
    "estimated_duration": 3600.023886406356,
    "input_throughput": 7271.600918773777,
    "output_throughput": 6344.996233567122,
    "total_throughput": 13616.597152340899,
    "itl": 85.82655950846774,
    "ttft": 1691294.9606933095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4491500535095065,
    "arrivals": 321998,
    "finished_requests": 105592,
    "scheduler_time": 276.67985880163536
}
#Debug simulation 
Total elapsed time: 91.13626222824678. Arrivals time: 0.47253395430743694 Scheduler time: 90.43120284751058 Scheduler overhead time: 0.08974322350695729 Adapter cache time: 0.017181793693453074 Engine time: 0.08938475186005235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 88.31303716404364,
    "estimated_duration": 3600.012965728599,
    "input_throughput": 7202.725447615743,
    "output_throughput": 6278.865163871771,
    "total_throughput": 13481.590611487514,
    "itl": 83.75089127586028,
    "ttft": 1700777.0465914458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8156280870363162,
    "arrivals": 321998,
    "finished_requests": 104553,
    "scheduler_time": 279.96797901019204
}
#Debug simulation 
Total elapsed time: 88.31320519931614. Arrivals time: 0.46919440664350986 Scheduler time: 87.61294232634827 Scheduler overhead time: 0.08853966230526567 Adapter cache time: 0.017175568267703056 Engine time: 0.09008272970095277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.94444976421073,
    "estimated_duration": 3600.074482181427,
    "input_throughput": 7322.845438471525,
    "output_throughput": 6382.545726130906,
    "total_throughput": 13705.391164602432,
    "itl": 86.95854519699428,
    "ttft": 1686651.5513860274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4679548050928843,
    "arrivals": 321377,
    "finished_requests": 106295,
    "scheduler_time": 274.4641486491096
}
#Debug simulation 
Total elapsed time: 91.94461376825348. Arrivals time: 0.48883773293346167 Scheduler time: 91.2261546892114 Scheduler overhead time: 0.0883625871501863 Adapter cache time: 0.016766891814768314 Engine time: 0.08914957754313946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 96.21883158572018,
    "estimated_duration": 3600.007657278261,
    "input_throughput": 7256.170677078338,
    "output_throughput": 6327.6570964913535,
    "total_throughput": 13583.827773569692,
    "itl": 85.5072381961043,
    "ttft": 1690857.266589473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5910414012754348,
    "arrivals": 321377,
    "finished_requests": 105350,
    "scheduler_time": 277.0946190146064
}
#Debug simulation 
Total elapsed time: 96.21898948587477. Arrivals time: 0.480044515337795 Scheduler time: 95.5026949136518 Scheduler overhead time: 0.09176268288865685 Adapter cache time: 0.01721014967188239 Engine time: 0.09174464317038655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.29277678672224,
    "estimated_duration": 3600.0623235711446,
    "input_throughput": 7194.26128554026,
    "output_throughput": 6271.8011441542185,
    "total_throughput": 13466.062429694479,
    "itl": 83.52271742748319,
    "ttft": 1697081.645916852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6689183113444621,
    "arrivals": 321377,
    "finished_requests": 104437,
    "scheduler_time": 279.8535594157786
}
#Debug simulation 
Total elapsed time: 95.29293685499579. Arrivals time: 0.4822487053461373 Scheduler time: 94.5718865385279 Scheduler overhead time: 0.09187723509967327 Adapter cache time: 0.017372407019138336 Engine time: 0.09249538043513894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 91.93168309656903,
    "estimated_duration": 3600.0418159176957,
    "input_throughput": 7268.955011659861,
    "output_throughput": 6339.423308665746,
    "total_throughput": 13608.378320325608,
    "itl": 85.86994360989134,
    "ttft": 1687697.5643641492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5291191637190047,
    "arrivals": 321377,
    "finished_requests": 105567,
    "scheduler_time": 276.57443390598985
}
#Debug simulation 
Total elapsed time: 91.9318439885974. Arrivals time: 0.47420394886285067 Scheduler time: 91.2254052516073 Scheduler overhead time: 0.08917128155007958 Adapter cache time: 0.01700671622529626 Engine time: 0.09022095380350947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 95.14184010401368,
    "estimated_duration": 3600.0495950113855,
    "input_throughput": 7196.474469657428,
    "output_throughput": 6274.792444888126,
    "total_throughput": 13471.266914545555,
    "itl": 83.55508506637632,
    "ttft": 1697306.1923598733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6609944931371163,
    "arrivals": 321377,
    "finished_requests": 104484,
    "scheduler_time": 279.8046636158221
}
#Debug simulation 
Total elapsed time: 95.14200820028782. Arrivals time: 0.49309515627101064 Scheduler time: 94.411498200614 Scheduler overhead time: 0.09147271141409874 Adapter cache time: 0.017589959781616926 Engine time: 0.09195112949237227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.7786611490883,
    "estimated_duration": 3600.0435699592563,
    "input_throughput": 7284.99322031728,
    "output_throughput": 6346.494300972746,
    "total_throughput": 13631.487521290026,
    "itl": 85.84582048391403,
    "ttft": 1689463.1062379754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4746857372717885,
    "arrivals": 321377,
    "finished_requests": 105733,
    "scheduler_time": 276.19269843665427
}
#Debug simulation 
Total elapsed time: 91.7788258921355. Arrivals time: 0.5186326373368502 Scheduler time: 91.02785887708887 Scheduler overhead time: 0.08944290969520807 Adapter cache time: 0.01679197372868657 Engine time: 0.08980524819344282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.41686353599653,
    "estimated_duration": 3600.058551490525,
    "input_throughput": 7195.034088897143,
    "output_throughput": 6272.887420303235,
    "total_throughput": 13467.921509200378,
    "itl": 83.53315920878936,
    "ttft": 1697141.710888041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6537438954412964,
    "arrivals": 321377,
    "finished_requests": 104453,
    "scheduler_time": 279.8832511928858
}
#Debug simulation 
Total elapsed time: 94.41702581383288. Arrivals time: 0.49124726839363575 Scheduler time: 93.68779837340117 Scheduler overhead time: 0.0929494732990861 Adapter cache time: 0.017540690023452044 Engine time: 0.09171397518366575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.1730991131626,
    "estimated_duration": 3600.0228428501027,
    "input_throughput": 7194.579904247137,
    "output_throughput": 6313.451050773338,
    "total_throughput": 13508.030955020475,
    "itl": 87.1344055667446,
    "ttft": 1692689.1697725179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.586978167667983,
    "arrivals": 318402,
    "finished_requests": 104787,
    "scheduler_time": 277.5945423568292
}
#Debug simulation 
Total elapsed time: 96.17326407320797. Arrivals time: 0.49151301151141524 Scheduler time: 95.44758550822735 Scheduler overhead time: 0.08960221754387021 Adapter cache time: 0.017432262655347586 Engine time: 0.09097722917795181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 97.21541639976203,
    "estimated_duration": 3600.0064243894776,
    "input_throughput": 7158.720002665151,
    "output_throughput": 6279.169072270079,
    "total_throughput": 13437.889074935229,
    "itl": 85.83169422428736,
    "ttft": 1697397.8516797314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7739653282146923,
    "arrivals": 318402,
    "finished_requests": 104215,
    "scheduler_time": 279.34440665786275
}
#Debug simulation 
Total elapsed time: 97.21558798803017. Arrivals time: 0.48993885703384876 Scheduler time: 96.48721008049324 Scheduler overhead time: 0.09141907561570406 Adapter cache time: 0.0177354016341269 Engine time: 0.0927143762819469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.42470980761573,
    "estimated_duration": 3600.0016471525705,
    "input_throughput": 7081.427871057745,
    "output_throughput": 6207.443270942739,
    "total_throughput": 13288.871142000484,
    "itl": 83.71089544762623,
    "ttft": 1701718.3807428933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8424014235800192,
    "arrivals": 318402,
    "finished_requests": 103022,
    "scheduler_time": 282.80046489676624
}
#Debug simulation 
Total elapsed time: 94.42487727059051. Arrivals time: 0.46698294999077916 Scheduler time: 93.71980970166624 Scheduler overhead time: 0.09187570912763476 Adapter cache time: 0.017628556583076715 Engine time: 0.09227217640727758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 97.0669083930552,
    "estimated_duration": 3600.0204054275755,
    "input_throughput": 7164.19550320209,
    "output_throughput": 6278.975520783268,
    "total_throughput": 13443.171023985356,
    "itl": 86.02279735252641,
    "ttft": 1694924.7408908885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6309880456468078,
    "arrivals": 318402,
    "finished_requests": 104195,
    "scheduler_time": 279.31879368291726
}
#Debug simulation 
Total elapsed time: 97.06707586394623. Arrivals time: 0.4862587829120457 Scheduler time: 96.34287958592176 Scheduler overhead time: 0.09206416737288237 Adapter cache time: 0.017720441333949566 Engine time: 0.09149078326299787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 92.58495215233415,
    "estimated_duration": 3600.0903663638937,
    "input_throughput": 7075.238232346462,
    "output_throughput": 6202.269034305411,
    "total_throughput": 13277.507266651872,
    "itl": 83.68228410680976,
    "ttft": 1703570.2111860148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8621734520001398,
    "arrivals": 318402,
    "finished_requests": 102970,
    "scheduler_time": 283.1304938785586
}
#Debug simulation 
Total elapsed time: 92.58511285996065. Arrivals time: 0.48008000338450074 Scheduler time: 91.86601756233722 Scheduler overhead time: 0.09208188625052571 Adapter cache time: 0.01787403365597129 Engine time: 0.09250266989693046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.07619958231226,
    "estimated_duration": 3600.0013417961663,
    "input_throughput": 7141.321504945051,
    "output_throughput": 6261.614888385874,
    "total_throughput": 13402.936393330925,
    "itl": 85.78221623850074,
    "ttft": 1697615.9362464806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.557676709499205,
    "arrivals": 318402,
    "finished_requests": 103990,
    "scheduler_time": 280.168586885629
}
#Debug simulation 
Total elapsed time: 94.07636403013021. Arrivals time: 0.4708101893775165 Scheduler time: 93.36996132833883 Scheduler overhead time: 0.09120702045038342 Adapter cache time: 0.017557579092681408 Engine time: 0.0909517421387136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.50562210194767,
    "estimated_duration": 3600.071632389179,
    "input_throughput": 7075.275050317791,
    "output_throughput": 6202.301309538553,
    "total_throughput": 13277.576359856344,
    "itl": 83.6819545117274,
    "ttft": 1703562.7951458935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8437400232814312,
    "arrivals": 318402,
    "finished_requests": 102970,
    "scheduler_time": 283.1302944637837
}
#Debug simulation 
Total elapsed time: 92.50578580377623. Arrivals time: 0.504972561262548 Scheduler time: 91.76336848642677 Scheduler overhead time: 0.09180272091180086 Adapter cache time: 0.017652835231274366 Engine time: 0.09195473603904247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.0772579680197,
    "estimated_duration": 3600.002671784731,
    "input_throughput": 7263.588775904005,
    "output_throughput": 6333.148077553241,
    "total_throughput": 13596.736853457245,
    "itl": 86.84564150065427,
    "ttft": 1677966.0523573242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.600202985731883,
    "arrivals": 317160,
    "finished_requests": 105582,
    "scheduler_time": 276.4407513305396
}
#Debug simulation 
Total elapsed time: 94.07741619413719. Arrivals time: 0.49202018370851874 Scheduler time: 93.35365023836493 Scheduler overhead time: 0.089347034227103 Adapter cache time: 0.017166287172585726 Engine time: 0.08972880057990551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.90702978288755,
    "estimated_duration": 3600.054444009598,
    "input_throughput": 7274.2913773362325,
    "output_throughput": 6352.477262685261,
    "total_throughput": 13626.768640021493,
    "itl": 86.13415518258691,
    "ttft": 1679689.5480264085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7939481280837224,
    "arrivals": 317160,
    "finished_requests": 105927,
    "scheduler_time": 275.54081552308656
}
#Debug simulation 
Total elapsed time: 94.90719194756821. Arrivals time: 0.48976413579657674 Scheduler time: 94.18333347328007 Scheduler overhead time: 0.09076721873134375 Adapter cache time: 0.01748368749395013 Engine time: 0.0899917222559452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.08378910785541,
    "estimated_duration": 3600.0450826792767,
    "input_throughput": 7188.343869499667,
    "output_throughput": 6274.576979238458,
    "total_throughput": 13462.920848738126,
    "itl": 83.9495562871267,
    "ttft": 1686283.1131397593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9026564805815045,
    "arrivals": 317160,
    "finished_requests": 104552,
    "scheduler_time": 279.43191557727215
}
#Debug simulation 
Total elapsed time: 93.08396284095943. Arrivals time: 0.48387415148317814 Scheduler time: 92.36647222936153 Scheduler overhead time: 0.0905587375164032 Adapter cache time: 0.01738247089087963 Engine time: 0.09011748665943742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 93.40919655095786,
    "estimated_duration": 3600.0201211745507,
    "input_throughput": 7240.75175210281,
    "output_throughput": 6321.093836713211,
    "total_throughput": 13561.845588816022,
    "itl": 85.9577463317524,
    "ttft": 1680083.9302992667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6942700711265186,
    "arrivals": 317160,
    "finished_requests": 105327,
    "scheduler_time": 277.28544676320917
}
#Debug simulation 
Total elapsed time: 93.4093600679189. Arrivals time: 0.48557462450116873 Scheduler time: 92.69040529569611 Scheduler overhead time: 0.08918593125417829 Adapter cache time: 0.017115222290158272 Engine time: 0.09148803725838661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 93.03415243094787,
    "estimated_duration": 3600.0281060926386,
    "input_throughput": 7188.377767441263,
    "output_throughput": 6274.606568146257,
    "total_throughput": 13462.98433558752,
    "itl": 83.94925408019706,
    "ttft": 1686276.8818053456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8852586377458695,
    "arrivals": 317160,
    "finished_requests": 104552,
    "scheduler_time": 279.43173004613965
}
#Debug simulation 
Total elapsed time: 93.03431642381474. Arrivals time: 0.4917214014567435 Scheduler time: 92.3030007253401 Scheduler overhead time: 0.09174513397738338 Adapter cache time: 0.017641623504459858 Engine time: 0.09372157929465175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.73762629972771,
    "estimated_duration": 3600.0483802338017,
    "input_throughput": 7279.394672551058,
    "output_throughput": 6357.722058866762,
    "total_throughput": 13637.11673141782,
    "itl": 86.20028200640137,
    "ttft": 1680053.3938226032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5129892629152115,
    "arrivals": 317160,
    "finished_requests": 105930,
    "scheduler_time": 275.4589991488572
}
#Debug simulation 
Total elapsed time: 94.73779460974038. Arrivals time: 0.4955067322589457 Scheduler time: 94.01009868690744 Scheduler overhead time: 0.09005494276061654 Adapter cache time: 0.017289663199335337 Engine time: 0.0890447311103344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.69918173272163,
    "estimated_duration": 3600.06417977564,
    "input_throughput": 7189.553215579909,
    "output_throughput": 6274.1809234655575,
    "total_throughput": 13463.734139045468,
    "itl": 83.95732874563004,
    "ttft": 1687929.0846589329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8774385575018873,
    "arrivals": 317160,
    "finished_requests": 104553,
    "scheduler_time": 279.52412514747533
}
#Debug simulation 
Total elapsed time: 92.69935075193644. Arrivals time: 0.4830259270966053 Scheduler time: 91.97847163584083 Scheduler overhead time: 0.09182301489636302 Adapter cache time: 0.01744849979877472 Engine time: 0.09193559177219868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 92.25176617922261,
    "estimated_duration": 3600.0695925098485,
    "input_throughput": 7355.360867215669,
    "output_throughput": 6401.077925811502,
    "total_throughput": 13756.438793027171,
    "itl": 87.46397403575624,
    "ttft": 1674671.1258369086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.593590576699933,
    "arrivals": 316555,
    "finished_requests": 107080,
    "scheduler_time": 273.07919941260764
}
#Debug simulation 
Total elapsed time: 92.25193535443395. Arrivals time: 0.5055001759901643 Scheduler time: 91.51456374814734 Scheduler overhead time: 0.08987227594479918 Adapter cache time: 0.017363990657031536 Engine time: 0.08954351209104061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.6491102441214,
    "estimated_duration": 3600.074501572168,
    "input_throughput": 7289.222761512328,
    "output_throughput": 6338.862151334436,
    "total_throughput": 13628.084912846763,
    "itl": 86.36742972385694,
    "ttft": 1678756.551475241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8397499425197037,
    "arrivals": 316555,
    "finished_requests": 106126,
    "scheduler_time": 276.06291957914425
}
#Debug simulation 
Total elapsed time: 93.64927973598242. Arrivals time: 0.5063497996889055 Scheduler time: 92.90747533086687 Scheduler overhead time: 0.09092678409069777 Adapter cache time: 0.017631915397942066 Engine time: 0.09131740173324943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 90.9912379286252,
    "estimated_duration": 3600.0900207226073,
    "input_throughput": 7232.20887536972,
    "output_throughput": 6293.600123769183,
    "total_throughput": 13525.808999138902,
    "itl": 84.15555604716444,
    "ttft": 1683765.3569664957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9447456538444432,
    "arrivals": 316555,
    "finished_requests": 105246,
    "scheduler_time": 278.4186128489261
}
#Debug simulation 
Total elapsed time: 90.99140162579715. Arrivals time: 0.5003060665912926 Scheduler time: 90.25845658779144 Scheduler overhead time: 0.08924610121175647 Adapter cache time: 0.01723288092762232 Engine time: 0.09024090645834804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 91.07613538997248,
    "estimated_duration": 3600.0941897547914,
    "input_throughput": 7306.874935344875,
    "output_throughput": 6355.952315113882,
    "total_throughput": 13662.827250458757,
    "itl": 86.39650006831212,
    "ttft": 1677818.4467759987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5971230360446482,
    "arrivals": 316555,
    "finished_requests": 106370,
    "scheduler_time": 275.3500436366215
}
#Debug simulation 
Total elapsed time: 91.0763162910007. Arrivals time: 0.49506447929888964 Scheduler time: 90.34984189877287 Scheduler overhead time: 0.08959408663213253 Adapter cache time: 0.017239201813936234 Engine time: 0.08952186023816466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 91.49336517509073,
    "estimated_duration": 3600.0001167166965,
    "input_throughput": 7206.708099682455,
    "output_throughput": 6268.752574536641,
    "total_throughput": 13475.460674219095,
    "itl": 84.25825232607932,
    "ttft": 1685358.6113476825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8328188126953362,
    "arrivals": 316555,
    "finished_requests": 104912,
    "scheduler_time": 279.6082943923182
}
#Debug simulation 
Total elapsed time: 91.49353880016133. Arrivals time: 0.4959223223850131 Scheduler time: 90.76138088852167 Scheduler overhead time: 0.09068372519686818 Adapter cache time: 0.01757701952010393 Engine time: 0.09137970395386219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.19862654106691,
    "estimated_duration": 3600.060838744486,
    "input_throughput": 7306.145695352462,
    "output_throughput": 6353.619570489553,
    "total_throughput": 13659.765265842016,
    "itl": 86.37281686112688,
    "ttft": 1677122.7085656156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.506605341974641,
    "arrivals": 316555,
    "finished_requests": 106326,
    "scheduler_time": 275.3983311300182
}
#Debug simulation 
Total elapsed time: 91.19880180992186. Arrivals time: 0.5006599822081625 Scheduler time: 90.46748307207599 Scheduler overhead time: 0.08909613592550159 Adapter cache time: 0.016868753358721733 Engine time: 0.08943157456815243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.71606342075393,
    "estimated_duration": 3600.0806036304684,
    "input_throughput": 7206.676421032459,
    "output_throughput": 6268.7176996097305,
    "total_throughput": 13475.39412064219,
    "itl": 84.2581894817534,
    "ttft": 1685333.0540188884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.815628087036316,
    "arrivals": 316555,
    "finished_requests": 104914,
    "scheduler_time": 279.6156939615681
}
#Debug simulation 
Total elapsed time: 91.7162295426242. Arrivals time: 0.5039724633097649 Scheduler time: 90.97654593223706 Scheduler overhead time: 0.09081128472462296 Adapter cache time: 0.017405197955667973 Engine time: 0.09150588978081942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.2601870703511,
    "estimated_duration": 3600.057336964799,
    "input_throughput": 7357.600315980466,
    "output_throughput": 6402.454695189032,
    "total_throughput": 13760.055011169497,
    "itl": 87.41251615315619,
    "ttft": 1671613.33114312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.586978167667983,
    "arrivals": 314729,
    "finished_requests": 106676,
    "scheduler_time": 273.5578667029108
}
#Debug simulation 
Total elapsed time: 94.26036127610132. Arrivals time: 0.5010647601448 Scheduler time: 93.52970569673926 Scheduler overhead time: 0.08834875002503395 Adapter cache time: 0.01719099096953869 Engine time: 0.08913030149415135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.90545122604817,
    "estimated_duration": 3600.0823614762858,
    "input_throughput": 7322.6821925234035,
    "output_throughput": 6367.620987037522,
    "total_throughput": 13690.303179560926,
    "itl": 86.1970086610635,
    "ttft": 1673183.5264315926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8178217377513668,
    "arrivals": 314729,
    "finished_requests": 106110,
    "scheduler_time": 275.30748135963574
}
#Debug simulation 
Total elapsed time: 95.90562324086204. Arrivals time: 0.5072712455876172 Scheduler time: 95.16308901738375 Scheduler overhead time: 0.0908775981515646 Adapter cache time: 0.01746429270133376 Engine time: 0.090407092589885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 96.05697427596897,
    "estimated_duration": 3600.050079686123,
    "input_throughput": 7255.2643496218425,
    "output_throughput": 6313.712447572876,
    "total_throughput": 13568.976797194719,
    "itl": 84.11631605404114,
    "ttft": 1678553.527784111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.03948176933453,
    "arrivals": 314729,
    "finished_requests": 105128,
    "scheduler_time": 277.96726855641424
}
#Debug simulation 
Total elapsed time: 96.05714178690687. Arrivals time: 0.5002259509637952 Scheduler time: 95.31679719639942 Scheduler overhead time: 0.09283062303438783 Adapter cache time: 0.018050678074359894 Engine time: 0.09255684819072485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 92.12896627094597,
    "estimated_duration": 3600.0838944819975,
    "input_throughput": 7324.242649015816,
    "output_throughput": 6379.048009186565,
    "total_throughput": 13703.29065820238,
    "itl": 86.40129537548852,
    "ttft": 1677325.0365149947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6998229550197705,
    "arrivals": 314729,
    "finished_requests": 106295,
    "scheduler_time": 274.7297927782571
}
#Debug simulation 
Total elapsed time: 92.12914147786796. Arrivals time: 0.4945134362205863 Scheduler time: 91.40137921879068 Scheduler overhead time: 0.09029842866584659 Adapter cache time: 0.017577321268618107 Engine time: 0.08976670214906335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 95.7013585800305,
    "estimated_duration": 3600.0775329443018,
    "input_throughput": 7227.495175283093,
    "output_throughput": 6292.892803747986,
    "total_throughput": 13520.387979031078,
    "itl": 84.05207273617675,
    "ttft": 1676916.9961496738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9433447095612115,
    "arrivals": 314729,
    "finished_requests": 104732,
    "scheduler_time": 278.98128053653903
}
#Debug simulation 
Total elapsed time: 95.70153413293883. Arrivals time: 0.497266651596874 Scheduler time: 94.96451297076419 Scheduler overhead time: 0.09313273523002863 Adapter cache time: 0.01765901641920209 Engine time: 0.09246490150690079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.8355987649411,
    "estimated_duration": 3600.044836874227,
    "input_throughput": 7313.625577747174,
    "output_throughput": 6367.605137913696,
    "total_throughput": 13681.230715660871,
    "itl": 86.30745872865609,
    "ttft": 1674551.4474580518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5512927885586345,
    "arrivals": 314729,
    "finished_requests": 106061,
    "scheduler_time": 275.2710180886229
}
#Debug simulation 
Total elapsed time: 91.83577099768445. Arrivals time: 0.494059425778687 Scheduler time: 91.11139409989119 Scheduler overhead time: 0.08906510006636381 Adapter cache time: 0.01700510224327445 Engine time: 0.08880044193938375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.62901157513261,
    "estimated_duration": 3600.0602824452467,
    "input_throughput": 7227.529807452809,
    "output_throughput": 6292.922957560103,
    "total_throughput": 13520.452765012911,
    "itl": 84.05175024510874,
    "ttft": 1676910.329313853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.926153983902191,
    "arrivals": 314729,
    "finished_requests": 104732,
    "scheduler_time": 278.98101850069975
}
#Debug simulation 
Total elapsed time: 95.6291830278933. Arrivals time: 0.48036944726482034 Scheduler time: 94.91021344950423 Scheduler overhead time: 0.09212303580716252 Adapter cache time: 0.017651221714913845 Engine time: 0.09282821603119373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.9637773167342,
    "estimated_duration": 3600.061771022576,
    "input_throughput": 7227.348488692594,
    "output_throughput": 6374.558676942237,
    "total_throughput": 13601.907165634831,
    "itl": 87.28123407153699,
    "ttft": 1671876.7472573696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6993891212111318,
    "arrivals": 314142,
    "finished_requests": 105918,
    "scheduler_time": 274.3695923175607
}
#Debug simulation 
Total elapsed time: 93.96394722908735. Arrivals time: 0.49645496625453234 Scheduler time: 93.2359366947785 Scheduler overhead time: 0.08922089450061321 Adapter cache time: 0.017110151704400778 Engine time: 0.08987262146547437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.11775131803006,
    "estimated_duration": 3600.0855917192525,
    "input_throughput": 7240.996175191184,
    "output_throughput": 6384.951250290318,
    "total_throughput": 13625.947425481503,
    "itl": 86.27894942579059,
    "ttft": 1675149.7166523815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9055345568247162,
    "arrivals": 314142,
    "finished_requests": 106069,
    "scheduler_time": 273.8868331457536
}
#Debug simulation 
Total elapsed time: 94.1179216792807. Arrivals time: 0.4942821632139385 Scheduler time: 93.39148918678984 Scheduler overhead time: 0.08876743027940392 Adapter cache time: 0.017695902846753597 Engine time: 0.08993415348231792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.0971744642593,
    "estimated_duration": 3600.037755441639,
    "input_throughput": 7173.342268692949,
    "output_throughput": 6327.5364169633585,
    "total_throughput": 13500.878685656307,
    "itl": 84.36393409832658,
    "ttft": 1679201.1613259686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2727519799722447,
    "arrivals": 314142,
    "finished_requests": 105074,
    "scheduler_time": 276.95451298460586
}
#Debug simulation 
Total elapsed time: 91.09734738990664. Arrivals time: 0.4663482550531626 Scheduler time: 90.39493591617793 Scheduler overhead time: 0.09143032599240541 Adapter cache time: 0.017828899435698986 Engine time: 0.09093492804095149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 95.09412762289867,
    "estimated_duration": 3600.0390353222515,
    "input_throughput": 7260.388496776488,
    "output_throughput": 6394.323720975825,
    "total_throughput": 13654.712217752314,
    "itl": 86.2820738942656,
    "ttft": 1674368.1671656559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8258392997365425,
    "arrivals": 314142,
    "finished_requests": 106303,
    "scheduler_time": 273.46818223972355
}
#Debug simulation 
Total elapsed time: 95.09429811267182. Arrivals time: 0.49505651323124766 Scheduler time: 94.36452077841386 Scheduler overhead time: 0.09064544085413218 Adapter cache time: 0.017707813996821642 Engine time: 0.09119035908952355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 91.35661004297435,
    "estimated_duration": 3600.017857936781,
    "input_throughput": 7173.381916166454,
    "output_throughput": 6327.571389619485,
    "total_throughput": 13500.953305785939,
    "itl": 84.36351885816194,
    "ttft": 1679193.8422615924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2532829653704622,
    "arrivals": 314142,
    "finished_requests": 105074,
    "scheduler_time": 276.9543878880148
}
#Debug simulation 
Total elapsed time: 91.35676900763065. Arrivals time: 0.47975536435842514 Scheduler time: 90.64032284077257 Scheduler overhead time: 0.09117505932226777 Adapter cache time: 0.018001603428274393 Engine time: 0.09150948980823159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.33463350031525,
    "estimated_duration": 3600.0084827270107,
    "input_throughput": 7230.048797074939,
    "output_throughput": 6371.9163746591275,
    "total_throughput": 13601.965171734066,
    "itl": 86.19478523660308,
    "ttft": 1666472.5520614474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7938817843003134,
    "arrivals": 314142,
    "finished_requests": 105847,
    "scheduler_time": 274.6211867244281
}
#Debug simulation 
Total elapsed time: 94.33479949040338. Arrivals time: 0.48539142962545156 Scheduler time: 93.6157884397544 Scheduler overhead time: 0.09013909520581365 Adapter cache time: 0.017672622110694647 Engine time: 0.09020944871008396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.48143908986822,
    "estimated_duration": 3600.053886308498,
    "input_throughput": 7175.362596165988,
    "output_throughput": 6320.091787106729,
    "total_throughput": 13495.454383272718,
    "itl": 84.21905153021007,
    "ttft": 1680256.7557596636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9355246293172292,
    "arrivals": 314142,
    "finished_requests": 105085,
    "scheduler_time": 277.09659325255444
}
#Debug simulation 
Total elapsed time: 92.48160438518971. Arrivals time: 0.4888233751989901 Scheduler time: 91.75711182737723 Scheduler overhead time: 0.09148065373301506 Adapter cache time: 0.017581362277269363 Engine time: 0.09096475876867771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.66433832189068,
    "estimated_duration": 3600.0086496766735,
    "input_throughput": 7368.523684625713,
    "output_throughput": 6435.340648995584,
    "total_throughput": 13803.864333621297,
    "itl": 87.70878603491258,
    "ttft": 1661059.1134596209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.87131175604183,
    "arrivals": 312976,
    "finished_requests": 107538,
    "scheduler_time": 271.1363028874805
}
#Debug simulation 
Total elapsed time: 93.66450891597196. Arrivals time: 0.4790645451284945 Scheduler time: 92.95562646910548 Scheduler overhead time: 0.08867384167388082 Adapter cache time: 0.017246836330741644 Engine time: 0.08873858861625195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 96.05811086855829,
    "estimated_duration": 3600.067910482734,
    "input_throughput": 7311.959289254149,
    "output_throughput": 6391.466653448385,
    "total_throughput": 13703.425942702534,
    "itl": 86.64590827733072,
    "ttft": 1665274.050989433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9904709339514393,
    "arrivals": 312976,
    "finished_requests": 106798,
    "scheduler_time": 273.22837108915826
}
#Debug simulation 
Total elapsed time: 96.05828334996477. Arrivals time: 0.49821868911385536 Scheduler time: 95.32554870704189 Scheduler overhead time: 0.09056297782808542 Adapter cache time: 0.01747738942503929 Engine time: 0.09090648218989372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.3968666982837,
    "estimated_duration": 3600.043881982994,
    "input_throughput": 7311.259213179873,
    "output_throughput": 6380.071952719742,
    "total_throughput": 13691.331165899614,
    "itl": 84.69127847490695,
    "ttft": 1667347.0695016594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2489917184505703,
    "arrivals": 312976,
    "finished_requests": 106621,
    "scheduler_time": 273.80816214769067
}
#Debug simulation 
Total elapsed time: 94.39704037411138. Arrivals time: 0.48331155302003026 Scheduler time: 93.6776477843523 Scheduler overhead time: 0.09117768844589591 Adapter cache time: 0.017655670642852783 Engine time: 0.09161333739757538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 92.47561322106048,
    "estimated_duration": 3600.09065091034,
    "input_throughput": 7337.198854512359,
    "output_throughput": 6403.107375690941,
    "total_throughput": 13740.3062302033,
    "itl": 86.67058284974803,
    "ttft": 1665753.4314662898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8974506510561306,
    "arrivals": 312976,
    "finished_requests": 107032,
    "scheduler_time": 272.6984086010452
}
#Debug simulation 
Total elapsed time: 92.47578448196873. Arrivals time: 0.4939391743391752 Scheduler time: 91.75047101965174 Scheduler overhead time: 0.08909363066777587 Adapter cache time: 0.017407827079296112 Engine time: 0.08978000190109015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 92.94109736196697,
    "estimated_duration": 3600.0733148208687,
    "input_throughput": 7286.204948108171,
    "output_throughput": 6362.221820790801,
    "total_throughput": 13648.426768898971,
    "itl": 84.60261440306066,
    "ttft": 1671818.9237409628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1523867000779213,
    "arrivals": 312976,
    "finished_requests": 106226,
    "scheduler_time": 274.762609600552
}
#Debug simulation 
Total elapsed time: 92.94126943033189. Arrivals time: 0.4965432183817029 Scheduler time: 92.20798066398129 Scheduler overhead time: 0.09207950858399272 Adapter cache time: 0.01779559999704361 Engine time: 0.09098138380795717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.78634789399803,
    "estimated_duration": 3600.0089707668744,
    "input_throughput": 7342.345314869964,
    "output_throughput": 6408.86875209236,
    "total_throughput": 13751.214066962324,
    "itl": 86.66269333570077,
    "ttft": 1664029.0803480726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8321853099437364,
    "arrivals": 312976,
    "finished_requests": 107188,
    "scheduler_time": 272.35032735952086
}
#Debug simulation 
Total elapsed time: 93.78651680471376. Arrivals time: 0.4909932869486511 Scheduler time: 93.06372331408784 Scheduler overhead time: 0.08901949180290103 Adapter cache time: 0.01725673396140337 Engine time: 0.08993866434320807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.15041544288397,
    "estimated_duration": 3600.052814756725,
    "input_throughput": 7286.246438518586,
    "output_throughput": 6362.258049691356,
    "total_throughput": 13648.504488209943,
    "itl": 84.60211036012578,
    "ttft": 1671811.8644400463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1314678652398364,
    "arrivals": 312976,
    "finished_requests": 106226,
    "scheduler_time": 274.76252271513744
}
#Debug simulation 
Total elapsed time: 93.15058276290074. Arrivals time: 0.5012781843543053 Scheduler time: 92.41337804216892 Scheduler overhead time: 0.09067877987399697 Adapter cache time: 0.017671008594334126 Engine time: 0.09160327585414052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 97.09992751618847,
    "estimated_duration": 3600.0076645842882,
    "input_throughput": 6844.83237144593,
    "output_throughput": 5974.813945981918,
    "total_throughput": 12819.646317427849,
    "itl": 84.40328129623224,
    "ttft": 1664752.211158397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.201932207639333,
    "arrivals": 250580,
    "finished_requests": 99929,
    "scheduler_time": 283.1825877850709
}
#Debug simulation 
Total elapsed time: 97.10009620711207. Arrivals time: 0.4913563383743167 Scheduler time: 96.36415901919827 Scheduler overhead time: 0.09416469652205706 Adapter cache time: 0.01855061948299408 Engine time: 0.09451176878064871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 97.0232209074311,
    "estimated_duration": 3600.004056073321,
    "input_throughput": 6370.033934076474,
    "output_throughput": 5563.475120593609,
    "total_throughput": 11933.509054670083,
    "itl": 74.98394132947564,
    "ttft": 1732221.9616084357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.961327771195213,
    "arrivals": 250580,
    "finished_requests": 93046,
    "scheduler_time": 303.47485635565636
}
#Debug simulation 
Total elapsed time: 97.02339042536914. Arrivals time: 0.46164766838774085 Scheduler time: 96.30474966997281 Scheduler overhead time: 0.09974640375003219 Adapter cache time: 0.018688883632421494 Engine time: 0.09851637482643127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.87238822225481,
    "estimated_duration": 3600.0652090782623,
    "input_throughput": 6117.249472166784,
    "output_throughput": 5343.949312775287,
    "total_throughput": 11461.19878494207,
    "itl": 68.92747762296148,
    "ttft": 1767812.4490677223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9596569527965084,
    "arrivals": 250580,
    "finished_requests": 89286,
    "scheduler_time": 314.50326982961303
}
#Debug simulation 
Total elapsed time: 93.87255060020834. Arrivals time: 0.4506648504175246 Scheduler time: 93.15929880132899 Scheduler overhead time: 0.10162496939301491 Adapter cache time: 0.01901801163330674 Engine time: 0.10107594914734364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 97.29262630781159,
    "estimated_duration": 3600.008113917685,
    "input_throughput": 6817.569356334287,
    "output_throughput": 5957.511850344233,
    "total_throughput": 12775.08120667852,
    "itl": 83.79715355801949,
    "ttft": 1669229.6528388825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2974278899747853,
    "arrivals": 250580,
    "finished_requests": 99578,
    "scheduler_time": 283.8989334598833
}
#Debug simulation 
Total elapsed time: 97.29279434680939. Arrivals time: 0.49561508977785707 Scheduler time: 96.55049906531349 Scheduler overhead time: 0.09647392900660634 Adapter cache time: 0.01888457126915455 Engine time: 0.09425376821309328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_16_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 90.61736817331985,
    "estimated_duration": 3600.0722237109394,
    "input_throughput": 6037.021939964576,
    "output_throughput": 5277.8730034516175,
    "total_throughput": 11314.894943416193,
    "itl": 67.63684638128159,
    "ttft": 1773292.1135595848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.017064955807296,
    "arrivals": 250580,
    "finished_requests": 88081,
    "scheduler_time": 317.7016877278337
}
#Debug simulation 
Total elapsed time: 90.61753946729004. Arrivals time: 0.45577244088053703 Scheduler time: 89.89668788155541 Scheduler overhead time: 0.10293919313699007 Adapter cache time: 0.01927546365186572 Engine time: 0.10099726309999824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_16_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_16_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.34309340687469,
    "estimated_duration": 3600.064203327932,
    "input_throughput": 6817.567302636326,
    "output_throughput": 5957.487919291519,
    "total_throughput": 12775.055221927843,
    "itl": 83.79361167114574,
    "ttft": 1669165.2241431093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.13222959415055,
    "arrivals": 250580,
    "finished_requests": 99579,
    "scheduler_time": 283.9141104522608
}
#Debug simulation 
Total elapsed time: 96.34326515579596. Arrivals time: 0.48578328965231776 Scheduler time: 95.61255670292303 Scheduler overhead time: 0.09447679575532675 Adapter cache time: 0.018845425453037024 Engine time: 0.09421173017472029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_16_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_16_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 90.72381666814908,
    "estimated_duration": 3600.0514190992535,
    "input_throughput": 6037.056827771048,
    "output_throughput": 5277.903504154408,
    "total_throughput": 11314.960331925457,
    "itl": 67.63644431979927,
    "ttft": 1773282.9699563065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9969745896756699,
    "arrivals": 250580,
    "finished_requests": 88081,
    "scheduler_time": 317.7009709461409
}
#Debug simulation 
Total elapsed time: 90.72398563614115. Arrivals time: 0.4482550942339003 Scheduler time: 90.01180990412831 Scheduler overhead time: 0.10251361364498734 Adapter cache time: 0.01936781406402588 Engine time: 0.10038184095174074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 98.48939110292122,
    "estimated_duration": 3600.0565342466916,
    "input_throughput": 6844.179741515025,
    "output_throughput": 5941.476139756167,
    "total_throughput": 12785.655881271192,
    "itl": 84.4987234991181,
    "ttft": 1657163.7095344667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9242110282974294,
    "arrivals": 240851,
    "finished_requests": 99661,
    "scheduler_time": 283.7925688527006
}
#Debug simulation 
Total elapsed time: 98.48957283282652. Arrivals time: 0.4990716711618006 Scheduler time: 97.74338172469288 Scheduler overhead time: 0.0959256449714303 Adapter cache time: 0.018482818733900785 Engine time: 0.09484935691580176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 97.24694035016,
    "estimated_duration": 3600.0690029272273,
    "input_throughput": 6847.564582777614,
    "output_throughput": 5957.866636045023,
    "total_throughput": 12805.431218822638,
    "itl": 84.02323480291498,
    "ttft": 1656344.2838319852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.132588746421973,
    "arrivals": 240851,
    "finished_requests": 99756,
    "scheduler_time": 283.05991279211565
}
#Debug simulation 
Total elapsed time: 97.24711304483935. Arrivals time: 0.4846675433218479 Scheduler time: 96.51484883762896 Scheduler overhead time: 0.0957766049541533 Adapter cache time: 0.018770867958664894 Engine time: 0.09518139809370041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.01069926517084,
    "estimated_duration": 3600.003317422101,
    "input_throughput": 6761.791268967833,
    "output_throughput": 5880.76374750677,
    "total_throughput": 12642.555016474604,
    "itl": 81.88109210489861,
    "ttft": 1666113.7807392757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1716485975030886,
    "arrivals": 240851,
    "finished_requests": 98495,
    "scheduler_time": 286.908707686383
}
#Debug simulation 
Total elapsed time: 95.01087686792016. Arrivals time: 0.4953236002475023 Scheduler time: 94.26646764716133 Scheduler overhead time: 0.0971214403398335 Adapter cache time: 0.018668779637664557 Engine time: 0.09547787625342607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 97.87908288417384,
    "estimated_duration": 3600.0160936517314,
    "input_throughput": 6856.333237933532,
    "output_throughput": 5963.221674996435,
    "total_throughput": 12819.554912929967,
    "itl": 84.13959713623426,
    "ttft": 1655394.5357293978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.005146269998511,
    "arrivals": 240851,
    "finished_requests": 99858,
    "scheduler_time": 282.79724323363047
}
#Debug simulation 
Total elapsed time: 97.87924961932003. Arrivals time: 0.4933181870728731 Scheduler time: 97.13988745957613 Scheduler overhead time: 0.09563806746155024 Adapter cache time: 0.0186881385743618 Engine time: 0.09457422653213143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_16_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 96.20639181975275,
    "estimated_duration": 3600.045213864589,
    "input_throughput": 6772.697716711815,
    "output_throughput": 5900.929221162568,
    "total_throughput": 12673.626937874382,
    "itl": 81.96050863284756,
    "ttft": 1655631.613107342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.086796251451603,
    "arrivals": 240851,
    "finished_requests": 98657,
    "scheduler_time": 286.65893336353605
}
#Debug simulation 
Total elapsed time: 96.20656527299434. Arrivals time: 0.4896465432830155 Scheduler time: 95.46709265839309 Scheduler overhead time: 0.09663069108501077 Adapter cache time: 0.01872488111257553 Engine time: 0.09601905988529325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_16_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_16_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 98.20885739522055,
    "estimated_duration": 3600.011234327306,
    "input_throughput": 6782.832722065872,
    "output_throughput": 5899.849644210567,
    "total_throughput": 12682.68236627644,
    "itl": 83.05215424242682,
    "ttft": 1654678.8709402543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.761962179597461,
    "arrivals": 240851,
    "finished_requests": 98790,
    "scheduler_time": 286.505347219049
}
#Debug simulation 
Total elapsed time: 98.20902932621539. Arrivals time: 0.4920079973526299 Scheduler time: 97.46847833599895 Scheduler overhead time: 0.09685637522488832 Adapter cache time: 0.01841185474768281 Engine time: 0.09524328028783202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_16_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_16_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 96.17942657275125,
    "estimated_duration": 3600.0095187858055,
    "input_throughput": 6769.277101305893,
    "output_throughput": 5887.937764994883,
    "total_throughput": 12657.214866300776,
    "itl": 81.66852046118812,
    "ttft": 1662482.0773260584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.221390271950522,
    "arrivals": 240851,
    "finished_requests": 98610,
    "scheduler_time": 286.4682414482815
}
#Debug simulation 
Total elapsed time: 96.17959727579728. Arrivals time: 0.49723483994603157 Scheduler time: 95.43210656614974 Scheduler overhead time: 0.09723960142582655 Adapter cache time: 0.018821530509740114 Engine time: 0.09654836123809218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_16_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_16_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.95166181074455,
    "estimated_duration": 3600.0702482232273,
    "input_throughput": 6854.574577309712,
    "output_throughput": 5980.5080222048455,
    "total_throughput": 12835.082599514559,
    "itl": 84.6596652860009,
    "ttft": 1629483.1415689003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0895212540961805,
    "arrivals": 236027,
    "finished_requests": 99989,
    "scheduler_time": 281.67767856070486
}
#Debug simulation 
Total elapsed time: 96.95182615704834. Arrivals time: 0.4822799498215318 Scheduler time: 96.22483507404104 Scheduler overhead time: 0.09496168745681643 Adapter cache time: 0.018132133409380913 Engine time: 0.09411233756691217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_16_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_16_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.73680509626865,
    "estimated_duration": 3600.0753097199263,
    "input_throughput": 6335.955511379159,
    "output_throughput": 5526.088286621902,
    "total_throughput": 11862.043798001061,
    "itl": 71.88548169524489,
    "ttft": 1697361.0860962176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.008791659725832,
    "arrivals": 236027,
    "finished_requests": 92268,
    "scheduler_time": 304.52469913218187
}
#Debug simulation 
Total elapsed time: 93.73698152136058. Arrivals time: 0.4689015210606158 Scheduler time: 93.00661550229415 Scheduler overhead time: 0.10101568652316928 Adapter cache time: 0.01919785002246499 Engine time: 0.10066141840070486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_16_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_16_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.30290954140946,
    "estimated_duration": 3600.0792953877817,
    "input_throughput": 6353.745049256237,
    "output_throughput": 5534.722811668996,
    "total_throughput": 11888.467860925233,
    "itl": 71.513424779534,
    "ttft": 1707805.7964788307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1334449956286767,
    "arrivals": 236027,
    "finished_requests": 92594,
    "scheduler_time": 303.5885537612205
}
#Debug simulation 
Total elapsed time: 91.30307631613687. Arrivals time: 0.4647398688830435 Scheduler time: 90.57781289983541 Scheduler overhead time: 0.1007772977463901 Adapter cache time: 0.01929473364725709 Engine time: 0.09956190641969442 
