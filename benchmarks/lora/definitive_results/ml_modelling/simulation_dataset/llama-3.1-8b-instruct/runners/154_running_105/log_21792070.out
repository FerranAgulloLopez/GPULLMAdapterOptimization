INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 83.96325369738042,
    "estimated_duration": 3600.057137105979,
    "input_throughput": 7282.177199297113,
    "output_throughput": 6342.213506742979,
    "total_throughput": 13624.39070604009,
    "itl": 85.61894415387145,
    "ttft": 1975400.7933911227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.48551124531777,
    "arrivals": 923294,
    "finished_requests": 106126,
    "scheduler_time": 292.3784881899304
}
#Debug simulation 
Total elapsed time: 83.96344675635919. Arrivals time: 0.517323661595583 Scheduler time: 83.22435819590464 Scheduler overhead time: 0.08451636927202344 Adapter cache time: 0.017459831666201353 Engine time: 0.08622924098744988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 81.58396778814495,
    "estimated_duration": 3600.0994091590314,
    "input_throughput": 7375.1102351371555,
    "output_throughput": 6447.290300081455,
    "total_throughput": 13822.40053521861,
    "itl": 89.0595056308533,
    "ttft": 1967456.4797500724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3077307521505355,
    "arrivals": 921863,
    "finished_requests": 107449,
    "scheduler_time": 286.2946935903358
}
#Debug simulation 
Total elapsed time: 81.5841550277546. Arrivals time: 0.5911742262542248 Scheduler time: 80.77420450607315 Scheduler overhead time: 0.0840944149531424 Adapter cache time: 0.017200776375830173 Engine time: 0.08517891447991133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 88.03571344073862,
    "estimated_duration": 3600.032673396142,
    "input_throughput": 7261.2482639886075,
    "output_throughput": 6347.204615352558,
    "total_throughput": 13608.452879341165,
    "itl": 86.93071276071164,
    "ttft": 1974418.2856949847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.365743526155131,
    "arrivals": 921863,
    "finished_requests": 105824,
    "scheduler_time": 291.4214466414997
}
#Debug simulation 
Total elapsed time: 88.0358738838695. Arrivals time: 0.5181916058063507 Scheduler time: 87.29537820117548 Scheduler overhead time: 0.0854368363507092 Adapter cache time: 0.01769980788230896 Engine time: 0.0859640957787633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 85.48318933090195,
    "estimated_duration": 3600.0793570722717,
    "input_throughput": 7180.06950297376,
    "output_throughput": 6284.368414144882,
    "total_throughput": 13464.437917118643,
    "itl": 85.16043780886899,
    "ttft": 1977325.3186090302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3589440634893353,
    "arrivals": 921863,
    "finished_requests": 104648,
    "scheduler_time": 294.6147105839751
}
#Debug simulation 
Total elapsed time: 85.48335082409903. Arrivals time: 0.5041594733484089 Scheduler time: 84.75463667837903 Scheduler overhead time: 0.08631211752071977 Adapter cache time: 0.017346374224871397 Engine time: 0.08716710703447461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 83.01378221390769,
    "estimated_duration": 3600.051011807825,
    "input_throughput": 7334.737178276838,
    "output_throughput": 6409.235570362995,
    "total_throughput": 13743.972748639831,
    "itl": 88.006201211547,
    "ttft": 1968720.3913556053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.352937773540613,
    "arrivals": 921863,
    "finished_requests": 106810,
    "scheduler_time": 288.2190273109863
}
#Debug simulation 
Total elapsed time: 83.01394272968173. Arrivals time: 0.5219320594333112 Scheduler time: 82.27254829322919 Scheduler overhead time: 0.08491497440263629 Adapter cache time: 0.017372373957186937 Engine time: 0.08451284701004624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 88.23721736716107,
    "estimated_duration": 3600.0897466901947,
    "input_throughput": 7196.273377300737,
    "output_throughput": 6296.566639995686,
    "total_throughput": 13492.840017296423,
    "itl": 85.36327162960806,
    "ttft": 1976758.2220628345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2351611708058123,
    "arrivals": 921863,
    "finished_requests": 104920,
    "scheduler_time": 294.0664305804476
}
#Debug simulation 
Total elapsed time: 88.23737598117441. Arrivals time: 0.518638922367245 Scheduler time: 87.49438862130046 Scheduler overhead time: 0.08630472188815475 Adapter cache time: 0.017588573042303324 Engine time: 0.08701795665547252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 82.6413476341404,
    "estimated_duration": 3600.0309287839505,
    "input_throughput": 7346.636604851024,
    "output_throughput": 6423.573701854662,
    "total_throughput": 13770.210306705687,
    "itl": 88.08845282497059,
    "ttft": 1969543.4172404255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2088366454373958,
    "arrivals": 921863,
    "finished_requests": 106968,
    "scheduler_time": 287.4941756017211
}
#Debug simulation 
Total elapsed time: 82.6415152088739. Arrivals time: 0.5259728250093758 Scheduler time: 81.89813451794907 Scheduler overhead time: 0.08399050030857325 Adapter cache time: 0.01676047034561634 Engine time: 0.08403779333457351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_16_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 88.23704259144142,
    "estimated_duration": 3600.073916206823,
    "input_throughput": 7196.305021230469,
    "output_throughput": 6296.594327675388,
    "total_throughput": 13492.899348905858,
    "itl": 85.36302020559707,
    "ttft": 1976754.0877160185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.214242335967727,
    "arrivals": 921863,
    "finished_requests": 104920,
    "scheduler_time": 294.0663612396052
}
#Debug simulation 
Total elapsed time: 88.23730188841. Arrivals time: 0.5220044385641813 Scheduler time: 87.49108188785613 Scheduler overhead time: 0.08654006011784077 Adapter cache time: 0.01738127088174224 Engine time: 0.08654924156144261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 92.09097012411803,
    "estimated_duration": 3600.0275888052633,
    "input_throughput": 7208.125315676209,
    "output_throughput": 6288.806527594826,
    "total_throughput": 13496.931843271033,
    "itl": 86.9937732228158,
    "ttft": 1967145.9168799773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8514745289459802,
    "arrivals": 921076,
    "finished_requests": 104806,
    "scheduler_time": 295.7757172878292
}
#Debug simulation 
Total elapsed time: 92.09112658910453. Arrivals time: 0.5246424833312631 Scheduler time: 91.3441204559058 Scheduler overhead time: 0.08573653269559145 Adapter cache time: 0.017263638321310282 Engine time: 0.0863287984393537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 84.89433872327209,
    "estimated_duration": 3600.019206006416,
    "input_throughput": 7392.346672928436,
    "output_throughput": 6431.351244285205,
    "total_throughput": 13823.697917213642,
    "itl": 87.66250048223276,
    "ttft": 1962962.049718925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.360747826187873,
    "arrivals": 921076,
    "finished_requests": 107551,
    "scheduler_time": 287.0975259219386
}
#Debug simulation 
Total elapsed time: 84.89449413307011. Arrivals time: 0.5054087564349174 Scheduler time: 84.16717117279768 Scheduler overhead time: 0.08593161683529615 Adapter cache time: 0.017201239708811045 Engine time: 0.08569222642108798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 84.17122969776392,
    "estimated_duration": 3600.030369134245,
    "input_throughput": 7301.792014138359,
    "output_throughput": 6372.545964248925,
    "total_throughput": 13674.337978387284,
    "itl": 85.8895953490082,
    "ttft": 1961134.5875708815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.318095738021666,
    "arrivals": 921076,
    "finished_requests": 106185,
    "scheduler_time": 291.1018748833083
}
#Debug simulation 
Total elapsed time: 84.1713906028308. Arrivals time: 0.5211909487843513 Scheduler time: 83.42681299429387 Scheduler overhead time: 0.08581518102437258 Adapter cache time: 0.017197296489030123 Engine time: 0.08614067314192653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 90.54976359196007,
    "estimated_duration": 3600.0436158727853,
    "input_throughput": 7325.820132766956,
    "output_throughput": 6392.090334278097,
    "total_throughput": 13717.910467045052,
    "itl": 87.73459125133827,
    "ttft": 1964024.183753658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0498337165825045,
    "arrivals": 921076,
    "finished_requests": 106713,
    "scheduler_time": 289.7519798193147
}
#Debug simulation 
Total elapsed time: 90.54992129281163. Arrivals time: 0.6196640864945948 Scheduler time: 89.70668015349656 Scheduler overhead time: 0.08546381024643779 Adapter cache time: 0.01752813206985593 Engine time: 0.08669881988316774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 84.19368299981579,
    "estimated_duration": 3600.067816043874,
    "input_throughput": 7315.342472892752,
    "output_throughput": 6380.989518481904,
    "total_throughput": 13696.331991374656,
    "itl": 86.11155081580522,
    "ttft": 1964122.3243192672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.320992744215774,
    "arrivals": 921076,
    "finished_requests": 106426,
    "scheduler_time": 290.2872075481615
}
#Debug simulation 
Total elapsed time: 84.1939343707636. Arrivals time: 0.5297540104947984 Scheduler time: 83.4400166105479 Scheduler overhead time: 0.0863344264216721 Adapter cache time: 0.01726559642702341 Engine time: 0.08694158820435405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 93.03408168302849,
    "estimated_duration": 3600.0957700740387,
    "input_throughput": 7276.6997527572,
    "output_throughput": 6338.133332361525,
    "total_throughput": 13614.833085118726,
    "itl": 86.69732252420349,
    "ttft": 1967125.9958520457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8321853099437364,
    "arrivals": 921076,
    "finished_requests": 105856,
    "scheduler_time": 292.62049780029776
}
#Debug simulation 
Total elapsed time: 93.03424236411229. Arrivals time: 0.623672285117209 Scheduler time: 92.18669412238523 Scheduler overhead time: 0.08619470940902829 Adapter cache time: 0.017484476789832115 Engine time: 0.08648730861023068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 82.23726173164323,
    "estimated_duration": 3600.0927965793016,
    "input_throughput": 7325.721443919191,
    "output_throughput": 6374.057363688994,
    "total_throughput": 13699.778807608185,
    "itl": 86.07627314859248,
    "ttft": 1968193.205118773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3835753248632052,
    "arrivals": 921076,
    "finished_requests": 106582,
    "scheduler_time": 290.0134656392891
}
#Debug simulation 
Total elapsed time: 82.23742327000946. Arrivals time: 0.5085191018879414 Scheduler time: 81.50635401718318 Scheduler overhead time: 0.08517633099108934 Adapter cache time: 0.01725020119920373 Engine time: 0.08670836873352528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 89.41601580008864,
    "estimated_duration": 3600.033530625835,
    "input_throughput": 7269.810899636343,
    "output_throughput": 6347.164215447661,
    "total_throughput": 13616.975115084004,
    "itl": 87.20801563829507,
    "ttft": 1945497.0864518415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3077307521505355,
    "arrivals": 851723,
    "finished_requests": 106085,
    "scheduler_time": 292.03489598706744
}
#Debug simulation 
Total elapsed time: 89.41617243271321. Arrivals time: 0.8511401899158955 Scheduler time: 88.34291533054784 Scheduler overhead time: 0.08501836936920881 Adapter cache time: 0.017696975730359554 Engine time: 0.0854817247018218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 90.49742428818718,
    "estimated_duration": 3600.0824076706763,
    "input_throughput": 7190.869004787549,
    "output_throughput": 6276.204942380558,
    "total_throughput": 13467.073947168108,
    "itl": 86.0407466239591,
    "ttft": 1966155.538925031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3116218635626167,
    "arrivals": 851723,
    "finished_requests": 104955,
    "scheduler_time": 294.6658565000119
}
#Debug simulation 
Total elapsed time: 90.49759653024375. Arrivals time: 0.5143035566434264 Scheduler time: 89.75935860769823 Scheduler overhead time: 0.0859048212878406 Adapter cache time: 0.01736818067729473 Engine time: 0.08656770875677466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 88.75387423671782,
    "estimated_duration": 3600.053338705605,
    "input_throughput": 7115.79595907061,
    "output_throughput": 6210.368540827973,
    "total_throughput": 13326.164499898583,
    "itl": 83.8070092962271,
    "ttft": 1964729.5308015337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.412994881514471,
    "arrivals": 851723,
    "finished_requests": 103817,
    "scheduler_time": 298.14019237031494
}
#Debug simulation 
Total elapsed time: 88.75403324095532. Arrivals time: 0.5128565323539078 Scheduler time: 88.01162826782092 Scheduler overhead time: 0.08779875189065933 Adapter cache time: 0.01777975121513009 Engine time: 0.08964236732572317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 90.53778462531045,
    "estimated_duration": 3600.0444804389394,
    "input_throughput": 7191.069205023699,
    "output_throughput": 6276.64744776846,
    "total_throughput": 13467.716652792158,
    "itl": 86.0397234703069,
    "ttft": 1966024.5339364242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1644704403914488,
    "arrivals": 851723,
    "finished_requests": 104958,
    "scheduler_time": 294.6687509095164
}
#Debug simulation 
Total elapsed time: 90.5379411522299. Arrivals time: 0.5225453171879053 Scheduler time: 89.789670182392 Scheduler overhead time: 0.08648553723469377 Adapter cache time: 0.01749448012560606 Engine time: 0.08791056042537093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 88.84818253619596,
    "estimated_duration": 3600.0312145657986,
    "input_throughput": 7115.839689487167,
    "output_throughput": 6210.406706903114,
    "total_throughput": 13326.246396390281,
    "itl": 83.80673849699805,
    "ttft": 1964721.2474068108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3906262264400824,
    "arrivals": 851723,
    "finished_requests": 103817,
    "scheduler_time": 298.1402346231394
}
#Debug simulation 
Total elapsed time: 88.84834214719012. Arrivals time: 0.5082943397574127 Scheduler time: 88.11269280593842 Scheduler overhead time: 0.08730703359469771 Adapter cache time: 0.017659337259829044 Engine time: 0.0880009732209146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 88.57035512011498,
    "estimated_duration": 3600.0197085367404,
    "input_throughput": 7226.940713214843,
    "output_throughput": 6317.262360000745,
    "total_throughput": 13544.203073215587,
    "itl": 86.2108964176355,
    "ttft": 1941599.6784821101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.432273878357363,
    "arrivals": 851723,
    "finished_requests": 105412,
    "scheduler_time": 294.1316586815509
}
#Debug simulation 
Total elapsed time: 88.57050963537768. Arrivals time: 0.5067454371601343 Scheduler time: 87.8380154822953 Scheduler overhead time: 0.08674830570816994 Adapter cache time: 0.018150466959923506 Engine time: 0.08745348080992699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 88.29400853114203,
    "estimated_duration": 3600.0087178033677,
    "input_throughput": 7115.8841569780925,
    "output_throughput": 6210.445516265879,
    "total_throughput": 13326.32967324397,
    "itl": 83.8065101969323,
    "ttft": 1964712.2973978638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3682575713656946,
    "arrivals": 851723,
    "finished_requests": 103817,
    "scheduler_time": 298.1401065157826
}
#Debug simulation 
Total elapsed time: 88.29416356887668. Arrivals time: 0.5166672579944134 Scheduler time: 87.55040837172419 Scheduler overhead time: 0.08772739209234715 Adapter cache time: 0.017930018715560436 Engine time: 0.08722439827397466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 90.44083545682952,
    "estimated_duration": 3600.007458951321,
    "input_throughput": 7177.636517321838,
    "output_throughput": 6311.8449778487675,
    "total_throughput": 13489.481495170607,
    "itl": 87.17241686894833,
    "ttft": 1957867.4817393327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.87792416507378,
    "arrivals": 839966,
    "finished_requests": 104736,
    "scheduler_time": 293.90388028255
}
#Debug simulation 
Total elapsed time: 90.44099439587444. Arrivals time: 0.5132370786741376 Scheduler time: 89.70449598645791 Scheduler overhead time: 0.08610228961333632 Adapter cache time: 0.017375950701534748 Engine time: 0.08586130663752556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 87.13953122217208,
    "estimated_duration": 3600.0194160996325,
    "input_throughput": 7165.196911061914,
    "output_throughput": 6303.519891730485,
    "total_throughput": 13468.716802792398,
    "itl": 86.31407137104807,
    "ttft": 1961630.606986387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1617319091782004,
    "arrivals": 839966,
    "finished_requests": 104600,
    "scheduler_time": 294.559865672017
}
#Debug simulation 
Total elapsed time: 87.1396992560476. Arrivals time: 0.5105209415778518 Scheduler time: 86.40457765385509 Scheduler overhead time: 0.08678545570001006 Adapter cache time: 0.01722502987831831 Engine time: 0.08669150155037642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 89.07163294684142,
    "estimated_duration": 3600.0736272565982,
    "input_throughput": 7109.78681275055,
    "output_throughput": 6233.234462235226,
    "total_throughput": 13343.021274985775,
    "itl": 84.24794645755338,
    "ttft": 1970038.7389604342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1036223977245454,
    "arrivals": 839966,
    "finished_requests": 103732,
    "scheduler_time": 296.77511531686383
}
#Debug simulation 
Total elapsed time: 89.07179447775707. Arrivals time: 0.509539408609271 Scheduler time: 88.33639521431178 Scheduler overhead time: 0.08710272517055273 Adapter cache time: 0.017453291919082403 Engine time: 0.08745507383719087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 86.93207018496469,
    "estimated_duration": 3600.083648988935,
    "input_throughput": 7157.463412617277,
    "output_throughput": 6278.163843872803,
    "total_throughput": 13435.627256490081,
    "itl": 86.28865006607792,
    "ttft": 1965595.8786090938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.057605858496388,
    "arrivals": 839966,
    "finished_requests": 104555,
    "scheduler_time": 294.46090328560086
}
#Debug simulation 
Total elapsed time: 86.93231831490993. Arrivals time: 0.5069368490949273 Scheduler time: 86.20195712288842 Scheduler overhead time: 0.08537280559539795 Adapter cache time: 0.017664275132119656 Engine time: 0.08653621841222048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 86.12056459859014,
    "estimated_duration": 3600.07085583369,
    "input_throughput": 7123.374518711053,
    "output_throughput": 6250.911135133389,
    "total_throughput": 13374.285653844441,
    "itl": 84.14386433419757,
    "ttft": 1965608.9765069787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.132402706188157,
    "arrivals": 839966,
    "finished_requests": 103998,
    "scheduler_time": 295.808287359516
}
#Debug simulation 
Total elapsed time: 86.1207163836807. Arrivals time: 0.5071648145094514 Scheduler time: 85.38920238241553 Scheduler overhead time: 0.08643568865954876 Adapter cache time: 0.01740133250132203 Engine time: 0.08669455628842115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 86.32447447115555,
    "estimated_duration": 3600.0855385764735,
    "input_throughput": 7221.874514204052,
    "output_throughput": 6335.582239809465,
    "total_throughput": 13557.456754013518,
    "itl": 86.92934109196092,
    "ttft": 1964973.5567528952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.864104914646589,
    "arrivals": 839966,
    "finished_requests": 105437,
    "scheduler_time": 291.69334348543373
}
#Debug simulation 
Total elapsed time: 86.32464877376333. Arrivals time: 0.5183489308692515 Scheduler time: 85.58498276909813 Scheduler overhead time: 0.08634474966675043 Adapter cache time: 0.016976051963865757 Engine time: 0.08464778354391456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 83.36970023205504,
    "estimated_duration": 3600.027024635111,
    "input_throughput": 7185.54244814924,
    "output_throughput": 6306.66099021888,
    "total_throughput": 13492.20343836812,
    "itl": 85.23934110234484,
    "ttft": 1961658.8695807154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.358886925950657,
    "arrivals": 839966,
    "finished_requests": 104952,
    "scheduler_time": 293.00249984211104
}
#Debug simulation 
Total elapsed time: 83.3698596060276. Arrivals time: 0.5097264559008181 Scheduler time: 82.63717705896124 Scheduler overhead time: 0.08519064448773861 Adapter cache time: 0.0174711300060153 Engine time: 0.08679313631728292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 89.33193349698558,
    "estimated_duration": 3600.03808855327,
    "input_throughput": 7320.218384297812,
    "output_throughput": 6387.069090494086,
    "total_throughput": 13707.287474791898,
    "itl": 88.1891975851685,
    "ttft": 1942358.818229054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4333665237575883,
    "arrivals": 834363,
    "finished_requests": 106882,
    "scheduler_time": 289.40206376310226
}
#Debug simulation 
Total elapsed time: 89.33208877407014. Arrivals time: 0.6105844373814762 Scheduler time: 88.49766957061365 Scheduler overhead time: 0.08606857480481267 Adapter cache time: 0.017670313827693462 Engine time: 0.08679083222523332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 87.90674829808995,
    "estimated_duration": 3600.014593710465,
    "input_throughput": 7263.701109902528,
    "output_throughput": 6348.9800957840935,
    "total_throughput": 13612.68120568662,
    "itl": 87.06150449996052,
    "ttft": 1938127.7110652167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.451794271133843,
    "arrivals": 834363,
    "finished_requests": 106007,
    "scheduler_time": 292.12915613066184
}
#Debug simulation 
Total elapsed time: 87.90701252128929. Arrivals time: 0.5176186403259635 Scheduler time: 87.1650869869627 Scheduler overhead time: 0.08614803198724985 Adapter cache time: 0.01784818386659026 Engine time: 0.08662810502573848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 85.15718179522082,
    "estimated_duration": 3600.0229231913786,
    "input_throughput": 7208.558543564706,
    "output_throughput": 6312.9664685170765,
    "total_throughput": 13521.525012081782,
    "itl": 85.14852497748221,
    "ttft": 1943019.6106335907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.72314025450034,
    "arrivals": 834363,
    "finished_requests": 105371,
    "scheduler_time": 293.96276426801876
}
#Debug simulation 
Total elapsed time: 85.15734571637586. Arrivals time: 0.5113425240851939 Scheduler time: 84.4220086177811 Scheduler overhead time: 0.08573713432997465 Adapter cache time: 0.01785507658496499 Engine time: 0.08679414633661509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 90.54651219304651,
    "estimated_duration": 3600.0793659519045,
    "input_throughput": 7228.207035130026,
    "output_throughput": 6309.648952417974,
    "total_throughput": 13537.855987548,
    "itl": 86.2733696724702,
    "ttft": 1946219.2674617185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.170854361332019,
    "arrivals": 834363,
    "finished_requests": 105538,
    "scheduler_time": 293.9117911168747
}
#Debug simulation 
Total elapsed time: 90.54667427577078. Arrivals time: 0.525898514315486 Scheduler time: 89.7948347129859 Scheduler overhead time: 0.08741016546264291 Adapter cache time: 0.01779351895675063 Engine time: 0.08731459360569715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 86.13145512901247,
    "estimated_duration": 3600.0908538081803,
    "input_throughput": 7206.399241996,
    "output_throughput": 6275.733007154771,
    "total_throughput": 13482.13224915077,
    "itl": 85.27284282810339,
    "ttft": 1953170.3967201828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4855676038423695,
    "arrivals": 834363,
    "finished_requests": 105179,
    "scheduler_time": 294.57285959443124
}
#Debug simulation 
Total elapsed time: 86.13161512603983. Arrivals time: 0.5904710991308093 Scheduler time: 85.31557286437601 Scheduler overhead time: 0.08650348149240017 Adapter cache time: 0.01783118164166808 Engine time: 0.08763372292742133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 87.64642231119797,
    "estimated_duration": 3600.042055211061,
    "input_throughput": 7272.106158344626,
    "output_throughput": 6371.113905961109,
    "total_throughput": 13643.220064305735,
    "itl": 87.13130919168815,
    "ttft": 1935798.8747138535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2918276176648122,
    "arrivals": 834363,
    "finished_requests": 106265,
    "scheduler_time": 291.16665902249997
}
#Debug simulation 
Total elapsed time: 87.64658525306731. Arrivals time: 0.852556639816612 Scheduler time: 86.57273586420342 Scheduler overhead time: 0.08448606031015515 Adapter cache time: 0.017690870445221663 Engine time: 0.0856903288513422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 85.01581558212638,
    "estimated_duration": 3600.0829791775923,
    "input_throughput": 7171.6533061407445,
    "output_throughput": 6258.889622912903,
    "total_throughput": 13430.542929053647,
    "itl": 84.95318828902553,
    "ttft": 1945064.4320050024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.775881955605019,
    "arrivals": 834363,
    "finished_requests": 104724,
    "scheduler_time": 295.6124336714857
}
#Debug simulation 
Total elapsed time: 85.01606149598956. Arrivals time: 0.5956610878929496 Scheduler time: 84.19423064542934 Scheduler overhead time: 0.0866176737472415 Adapter cache time: 0.01806441368535161 Engine time: 0.0872340789064765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 86.29466488119215,
    "estimated_duration": 3600.0132941054126,
    "input_throughput": 7341.906498866965,
    "output_throughput": 6409.301053910047,
    "total_throughput": 13751.207552777012,
    "itl": 88.25357126947397,
    "ttft": 1945528.8007497967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2614438889268844,
    "arrivals": 831492,
    "finished_requests": 106885,
    "scheduler_time": 288.4502602431739
}
#Debug simulation 
Total elapsed time: 86.29483085591346. Arrivals time: 0.5066446005366743 Scheduler time: 85.56871593510732 Scheduler overhead time: 0.08409611042588949 Adapter cache time: 0.017292512115091085 Engine time: 0.08497448451817036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 89.437188772019,
    "estimated_duration": 3600.062187285178,
    "input_throughput": 7180.248188849509,
    "output_throughput": 6263.022922113185,
    "total_throughput": 13443.271110962694,
    "itl": 85.8732493662185,
    "ttft": 1951786.2922245667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.260824349159378,
    "arrivals": 831492,
    "finished_requests": 104497,
    "scheduler_time": 295.7430870108193
}
#Debug simulation 
Total elapsed time: 89.43734853202477. Arrivals time: 0.5658106463961303 Scheduler time: 88.64965753303841 Scheduler overhead time: 0.08504538564011455 Adapter cache time: 0.017148989718407393 Engine time: 0.08623449271544814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 85.08631881792098,
    "estimated_duration": 3600.0542907510403,
    "input_throughput": 7204.363574914098,
    "output_throughput": 6291.494841672189,
    "total_throughput": 13495.858416586287,
    "itl": 84.75272352132326,
    "ttft": 1942713.5619805276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4091093101259418,
    "arrivals": 831492,
    "finished_requests": 104892,
    "scheduler_time": 294.8443876450853
}
#Debug simulation 
Total elapsed time: 85.08647460723296. Arrivals time: 0.5160912000574172 Scheduler time: 84.34595227567479 Scheduler overhead time: 0.085935371927917 Adapter cache time: 0.017502593342214823 Engine time: 0.08703014813363552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 85.22293799323961,
    "estimated_duration": 3600.041214188127,
    "input_throughput": 7318.054275648433,
    "output_throughput": 6399.435347907684,
    "total_throughput": 13717.489623556117,
    "itl": 87.34517081272668,
    "ttft": 1936482.8811826017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3082503269566197,
    "arrivals": 831492,
    "finished_requests": 106562,
    "scheduler_time": 289.6063785359643
}
#Debug simulation 
Total elapsed time: 85.22309992322698. Arrivals time: 0.5025810906663537 Scheduler time: 84.50117714190856 Scheduler overhead time: 0.08408949570730329 Adapter cache time: 0.017372240778058767 Engine time: 0.08473203331232071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 82.31730902800336,
    "estimated_duration": 3600.0048212487286,
    "input_throughput": 7257.794446768819,
    "output_throughput": 6320.364868874698,
    "total_throughput": 13578.159315643517,
    "itl": 85.41722873933709,
    "ttft": 1949134.3320212602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8244444093387737,
    "arrivals": 831492,
    "finished_requests": 105650,
    "scheduler_time": 292.4468015279049
}
#Debug simulation 
Total elapsed time: 82.31747048487887. Arrivals time: 0.5051196771673858 Scheduler time: 81.59063015319407 Scheduler overhead time: 0.08454714249819517 Adapter cache time: 0.017553819343447685 Engine time: 0.08583168126642704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 87.61218406120315,
    "estimated_duration": 3600.088335706206,
    "input_throughput": 7250.759305293399,
    "output_throughput": 6321.676547288274,
    "total_throughput": 13572.435852581673,
    "itl": 86.40151397869923,
    "ttft": 1954799.109040137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8960245193494414,
    "arrivals": 831492,
    "finished_requests": 105667,
    "scheduler_time": 292.5343955081875
}
#Debug simulation 
Total elapsed time: 87.61234650900587. Arrivals time: 0.506173076108098 Scheduler time: 86.88414945965633 Scheduler overhead time: 0.08520805044099689 Adapter cache time: 0.016810255590826273 Engine time: 0.08671699091792107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 87.88041112804785,
    "estimated_duration": 3600.044054297998,
    "input_throughput": 7226.863784885897,
    "output_throughput": 6317.979907175118,
    "total_throughput": 13544.843692061015,
    "itl": 85.18139253483834,
    "ttft": 1946886.944416884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.155435243938125,
    "arrivals": 831492,
    "finished_requests": 105256,
    "scheduler_time": 293.6790295441077
}
#Debug simulation 
Total elapsed time: 87.88057185895741. Arrivals time: 0.8433311223052442 Scheduler time: 86.81335135130212 Scheduler overhead time: 0.08539630752056837 Adapter cache time: 0.017595794517546892 Engine time: 0.08662249986082315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 88.27441909071058,
    "estimated_duration": 3600.0410003227034,
    "input_throughput": 7300.8374064750915,
    "output_throughput": 6382.741473761068,
    "total_throughput": 13683.578880236159,
    "itl": 87.83220405163053,
    "ttft": 1931225.4086362724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0498467999044796,
    "arrivals": 830076,
    "finished_requests": 106327,
    "scheduler_time": 290.38147640138396
}
#Debug simulation 
Total elapsed time: 88.27458017366007. Arrivals time: 0.5093631152994931 Scheduler time: 87.54381901491433 Scheduler overhead time: 0.08450740110129118 Adapter cache time: 0.017084913793951273 Engine time: 0.08644340466707945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 87.24801175994799,
    "estimated_duration": 3600.0125468424935,
    "input_throughput": 7364.820442988308,
    "output_throughput": 6428.299262539348,
    "total_throughput": 13793.119705527655,
    "itl": 87.74796304934686,
    "ttft": 1934272.7098326671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3371575473248987,
    "arrivals": 830076,
    "finished_requests": 107157,
    "scheduler_time": 287.93590192989416
}
#Debug simulation 
Total elapsed time: 87.24817678658292. Arrivals time: 0.5264290235936642 Scheduler time: 86.49847265519202 Scheduler overhead time: 0.08601764310151339 Adapter cache time: 0.017392147798091173 Engine time: 0.08693722914904356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 84.76413360703737,
    "estimated_duration": 3600.042510492771,
    "input_throughput": 7322.874361389555,
    "output_throughput": 6384.9662699826495,
    "total_throughput": 13707.840631372204,
    "itl": 85.79763735891319,
    "ttft": 1949510.6636747275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.38364024220967,
    "arrivals": 830076,
    "finished_requests": 106499,
    "scheduler_time": 290.0355121886115
}
#Debug simulation 
Total elapsed time: 84.76442006416619. Arrivals time: 0.5127561441622674 Scheduler time: 84.02960889274254 Scheduler overhead time: 0.08490828238427639 Adapter cache time: 0.01694345660507679 Engine time: 0.0865469896234572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 86.35921065881848,
    "estimated_duration": 3600.0458550405874,
    "input_throughput": 7385.961476787974,
    "output_throughput": 6433.497775471774,
    "total_throughput": 13819.459252259747,
    "itl": 87.76732954686275,
    "ttft": 1944852.4802652088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2877103431615953,
    "arrivals": 830076,
    "finished_requests": 107405,
    "scheduler_time": 287.03958555272203
}
#Debug simulation 
Total elapsed time: 86.35936624510214. Arrivals time: 0.5205059554427862 Scheduler time: 85.61879406543449 Scheduler overhead time: 0.08402539370581508 Adapter cache time: 0.017171735875308514 Engine time: 0.08580214157700539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 84.23833089182153,
    "estimated_duration": 3600.0487571349086,
    "input_throughput": 7239.686670450087,
    "output_throughput": 6323.282693014631,
    "total_throughput": 13562.969363464717,
    "itl": 84.9893464993758,
    "ttft": 1940065.7403323045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3255515361158294,
    "arrivals": 830076,
    "finished_requests": 105405,
    "scheduler_time": 293.1406599794481
}
#Debug simulation 
Total elapsed time: 84.2384945480153. Arrivals time: 0.5079871243797243 Scheduler time: 83.50626558577642 Scheduler overhead time: 0.0867887670174241 Adapter cache time: 0.017375189810991287 Engine time: 0.08603657269850373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 86.03940744325519,
    "estimated_duration": 3600.0977875513963,
    "input_throughput": 7386.555468563188,
    "output_throughput": 6433.676351817522,
    "total_throughput": 13820.23182038071,
    "itl": 87.76512865442113,
    "ttft": 1944761.376725336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.13222959415055,
    "arrivals": 830076,
    "finished_requests": 107412,
    "scheduler_time": 287.05329561334133
}
#Debug simulation 
Total elapsed time: 86.0395610560663. Arrivals time: 0.5068129301071167 Scheduler time: 85.3119662986137 Scheduler overhead time: 0.08441251330077648 Adapter cache time: 0.01730635017156601 Engine time: 0.0858355313539505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 84.60148836765438,
    "estimated_duration": 3600.0949743632805,
    "input_throughput": 7315.618389944837,
    "output_throughput": 6376.644828393766,
    "total_throughput": 13692.263218338603,
    "itl": 85.79664383493734,
    "ttft": 1952065.34014163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2580921846069497,
    "arrivals": 830076,
    "finished_requests": 106497,
    "scheduler_time": 289.5761453779246
}
#Debug simulation 
Total elapsed time: 84.60165371280164. Arrivals time: 0.4967189854942262 Scheduler time: 83.8842879710719 Scheduler overhead time: 0.08466679509729147 Adapter cache time: 0.016851705964654684 Engine time: 0.08591048838570714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 87.95703872479498,
    "estimated_duration": 3600.0762728276727,
    "input_throughput": 7431.665879396961,
    "output_throughput": 6465.129690632562,
    "total_throughput": 13896.795570029524,
    "itl": 88.63854313088049,
    "ttft": 1943483.664890283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0961336631281307,
    "arrivals": 829350,
    "finished_requests": 108229,
    "scheduler_time": 285.17256868335653
}
#Debug simulation 
Total elapsed time: 87.9572987598367. Arrivals time: 0.510880399029702 Scheduler time: 87.22703084768727 Scheduler overhead time: 0.0847283317707479 Adapter cache time: 0.017187186982482672 Engine time: 0.08505224995315075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 86.45392285101116,
    "estimated_duration": 3600.0159070191457,
    "input_throughput": 7402.067293103847,
    "output_throughput": 6447.643177004594,
    "total_throughput": 13849.71047010844,
    "itl": 87.70187362044453,
    "ttft": 1946456.4847632584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3110646796366225,
    "arrivals": 829350,
    "finished_requests": 107903,
    "scheduler_time": 286.0400152808417
}
#Debug simulation 
Total elapsed time: 86.45408689510077. Arrivals time: 0.49977214401587844 Scheduler time: 85.73534300317988 Scheduler overhead time: 0.08366881869733334 Adapter cache time: 0.0171299297362566 Engine time: 0.08511060010641813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 86.98382038762793,
    "estimated_duration": 3600.019681806501,
    "input_throughput": 7285.986832949163,
    "output_throughput": 6341.434496975914,
    "total_throughput": 13627.421329925077,
    "itl": 84.78770209878898,
    "ttft": 1941197.7025217956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2952713936986506,
    "arrivals": 829350,
    "finished_requests": 106097,
    "scheduler_time": 291.363620089397
}
#Debug simulation 
Total elapsed time: 86.98398664966226. Arrivals time: 0.5004107234999537 Scheduler time: 86.26040201447904 Scheduler overhead time: 0.08479326870292425 Adapter cache time: 0.017328903079032898 Engine time: 0.08717926917597651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 88.25972344819456,
    "estimated_duration": 3600.0454613360685,
    "input_throughput": 7382.597882565723,
    "output_throughput": 6435.563175194362,
    "total_throughput": 13818.161057760084,
    "itl": 87.28993958884708,
    "ttft": 1944814.2440071094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1900061241537307,
    "arrivals": 829350,
    "finished_requests": 107619,
    "scheduler_time": 286.74428198612713
}
#Debug simulation 
Total elapsed time: 88.25988693209365. Arrivals time: 0.526749653276056 Scheduler time: 87.51402486255392 Scheduler overhead time: 0.08375208545476198 Adapter cache time: 0.017079808749258518 Engine time: 0.08587554469704628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 86.83422646066174,
    "estimated_duration": 3600.084126947921,
    "input_throughput": 7286.05084632775,
    "output_throughput": 6341.553195690158,
    "total_throughput": 13627.604042017909,
    "itl": 84.7874815985464,
    "ttft": 1941171.4700060934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.27455967603718,
    "arrivals": 829350,
    "finished_requests": 106100,
    "scheduler_time": 291.3705334936856
}
#Debug simulation 
Total elapsed time: 86.83438189001754. Arrivals time: 0.5183198559097946 Scheduler time: 86.09329049149528 Scheduler overhead time: 0.085079082287848 Adapter cache time: 0.01725508412346244 Engine time: 0.08670995710417628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 86.62078741798177,
    "estimated_duration": 3600.059855913909,
    "input_throughput": 7402.706362290357,
    "output_throughput": 6447.985569425242,
    "total_throughput": 13850.691931715599,
    "itl": 87.69543890419754,
    "ttft": 1946451.9088395152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0237029381608513,
    "arrivals": 829350,
    "finished_requests": 107912,
    "scheduler_time": 286.0656335458638
}
#Debug simulation 
Total elapsed time: 86.6210539760068. Arrivals time: 0.5141464993357658 Scheduler time: 85.88807786256075 Scheduler overhead time: 0.08344079926609993 Adapter cache time: 0.016982192173600197 Engine time: 0.08543134341016412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 84.99062755005434,
    "estimated_duration": 3600.020021745079,
    "input_throughput": 7322.126221737598,
    "output_throughput": 6385.165321624346,
    "total_throughput": 13707.291543361944,
    "itl": 85.48272639014513,
    "ttft": 1948707.24182037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.389221571628016,
    "arrivals": 829350,
    "finished_requests": 106726,
    "scheduler_time": 289.72689091204353
}
#Debug simulation 
Total elapsed time: 84.99078184133396. Arrivals time: 0.5018810206092894 Scheduler time: 84.26790387323126 Scheduler overhead time: 0.08479069080203772 Adapter cache time: 0.017351226415485144 Engine time: 0.08585439855232835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 83.19175948388875,
    "estimated_duration": 3600.06359564038,
    "input_throughput": 7332.877128050893,
    "output_throughput": 6387.011059428211,
    "total_throughput": 13719.888187479104,
    "itl": 89.27269531349809,
    "ttft": 1938770.439428653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9771103005530288,
    "arrivals": 771049,
    "finished_requests": 106750,
    "scheduler_time": 289.1837482674677
}
#Debug simulation 
Total elapsed time: 83.19192680763081. Arrivals time: 0.5046192463487387 Scheduler time: 82.46720759524032 Scheduler overhead time: 0.08436934370547533 Adapter cache time: 0.016562241595238447 Engine time: 0.08568839635699987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 83.97333054617047,
    "estimated_duration": 3600.0739766829925,
    "input_throughput": 7248.749933756683,
    "output_throughput": 6319.225423517802,
    "total_throughput": 13567.975357274485,
    "itl": 87.87685494214591,
    "ttft": 1943541.0512265186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.042930522449317,
    "arrivals": 771049,
    "finished_requests": 105635,
    "scheduler_time": 292.52860934069355
}
#Debug simulation 
Total elapsed time: 83.97349556908011. Arrivals time: 0.4976999736391008 Scheduler time: 83.25239283358678 Scheduler overhead time: 0.08553149970248342 Adapter cache time: 0.016957849729806185 Engine time: 0.08689503092318773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 87.54139360692352,
    "estimated_duration": 3600.087739697382,
    "input_throughput": 7149.052428973143,
    "output_throughput": 6223.366934352356,
    "total_throughput": 13372.4193633255,
    "itl": 85.48285575453534,
    "ttft": 1948256.3850334906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.020379968397325,
    "arrivals": 771049,
    "finished_requests": 104006,
    "scheduler_time": 297.2700235281877
}
#Debug simulation 
Total elapsed time: 87.5415603062138. Arrivals time: 0.4864480528049171 Scheduler time: 86.8271720088087 Scheduler overhead time: 0.08788870414718986 Adapter cache time: 0.017279578372836113 Engine time: 0.08840933674946427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 81.41657287301496,
    "estimated_duration": 3600.0105615772145,
    "input_throughput": 7332.434877200798,
    "output_throughput": 6392.204857843007,
    "total_throughput": 13724.639735043806,
    "itl": 88.41577704606188,
    "ttft": 1938239.0869942114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1036815260536943,
    "arrivals": 771049,
    "finished_requests": 106827,
    "scheduler_time": 288.8409646325387
}
#Debug simulation 
Total elapsed time: 81.41680839797482. Arrivals time: 0.48985051922500134 Scheduler time: 80.70561268134043 Scheduler overhead time: 0.08511298801749945 Adapter cache time: 0.017127241007983685 Engine time: 0.08579482836648822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 89.38381469389424,
    "estimated_duration": 3600.0105231472144,
    "input_throughput": 7161.385733245464,
    "output_throughput": 6236.218715375666,
    "total_throughput": 13397.60444862113,
    "itl": 85.58452883991342,
    "ttft": 1947036.775053882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9847069380665254,
    "arrivals": 771049,
    "finished_requests": 104250,
    "scheduler_time": 296.6168565075011
}
#Debug simulation 
Total elapsed time: 89.38398022204638. Arrivals time: 0.48769153375178576 Scheduler time: 88.66962152160704 Scheduler overhead time: 0.08674524910748005 Adapter cache time: 0.017288321163505316 Engine time: 0.08835685439407825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 82.25483760703355,
    "estimated_duration": 3600.032548592717,
    "input_throughput": 7287.616610648629,
    "output_throughput": 6354.269771516998,
    "total_throughput": 13641.886382165627,
    "itl": 88.16829110214823,
    "ttft": 1941913.3959283885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8704888355871594,
    "arrivals": 771049,
    "finished_requests": 106191,
    "scheduler_time": 290.77223335318513
}
#Debug simulation 
Total elapsed time: 82.25500003108755. Arrivals time: 0.4775448739528656 Scheduler time: 81.55743431439623 Scheduler overhead time: 0.08441171236336231 Adapter cache time: 0.016865222714841366 Engine time: 0.08500607963651419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 80.54797190288082,
    "estimated_duration": 3600.0325051331833,
    "input_throughput": 7172.903567726172,
    "output_throughput": 6253.104372780432,
    "total_throughput": 13426.007940506604,
    "itl": 85.80347306964921,
    "ttft": 1950045.517656983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1554352439381264,
    "arrivals": 771049,
    "finished_requests": 104496,
    "scheduler_time": 295.78225701886566
}
#Debug simulation 
Total elapsed time: 80.54813158884645. Arrivals time: 0.47807781491428614 Scheduler time: 79.84450164111331 Scheduler overhead time: 0.08689031843096018 Adapter cache time: 0.017491497565060854 Engine time: 0.087263367138803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 90.80795260192826,
    "estimated_duration": 3600.0435979421914,
    "input_throughput": 7335.635328165285,
    "output_throughput": 6330.999717066756,
    "total_throughput": 13666.63504523204,
    "itl": 89.00156577150635,
    "ttft": 1932032.3944258925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7919628476584308,
    "arrivals": 765271,
    "finished_requests": 106354,
    "scheduler_time": 291.6564730860624
}
#Debug simulation 
Total elapsed time: 90.80812029680237. Arrivals time: 0.5811869520694017 Scheduler time: 90.00344300363213 Scheduler overhead time: 0.08549794042482972 Adapter cache time: 0.017285850830376148 Engine time: 0.08724983828142285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 83.48554894514382,
    "estimated_duration": 3600.051785261865,
    "input_throughput": 7424.761251887302,
    "output_throughput": 6415.346049895792,
    "total_throughput": 13840.107301783093,
    "itl": 88.51253337635869,
    "ttft": 1929262.6225088013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.277756853960457,
    "arrivals": 765271,
    "finished_requests": 107670,
    "scheduler_time": 287.4314434141541
}
#Debug simulation 
Total elapsed time: 83.48581559117883. Arrivals time: 0.49359887233003974 Scheduler time: 82.77138796634972 Scheduler overhead time: 0.08451178250834346 Adapter cache time: 0.017259053885936737 Engine time: 0.08586360700428486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 80.68651461601257,
    "estimated_duration": 3600.0235397819715,
    "input_throughput": 7327.098756025777,
    "output_throughput": 6329.425279641365,
    "total_throughput": 13656.524035667142,
    "itl": 86.35618207861965,
    "ttft": 1931949.9015624013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.356462367898796,
    "arrivals": 765271,
    "finished_requests": 106224,
    "scheduler_time": 291.83485122063365
}
#Debug simulation 
Total elapsed time: 80.68668911093846. Arrivals time: 0.5618606288917363 Scheduler time: 79.90251656528562 Scheduler overhead time: 0.0853227493353188 Adapter cache time: 0.01740279607474804 Engine time: 0.0862806523218751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 85.23003305401653,
    "estimated_duration": 3600.018274310226,
    "input_throughput": 7358.274036838201,
    "output_throughput": 6351.144704780938,
    "total_throughput": 13709.418741619138,
    "itl": 88.23592214161451,
    "ttft": 1934082.2515179452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7686578643927329,
    "arrivals": 765271,
    "finished_requests": 106641,
    "scheduler_time": 290.7417943139821
}
#Debug simulation 
Total elapsed time: 85.23019769322127. Arrivals time: 0.5111579187214375 Scheduler time: 84.49588566459715 Scheduler overhead time: 0.08600063296034932 Adapter cache time: 0.01693316362798214 Engine time: 0.08658486558124423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 81.51268691988662,
    "estimated_duration": 3600.0316386162544,
    "input_throughput": 7344.742672918079,
    "output_throughput": 6336.681810043302,
    "total_throughput": 13681.42448296138,
    "itl": 86.37944799666344,
    "ttft": 1931598.4938263264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4011858506687105,
    "arrivals": 765271,
    "finished_requests": 106477,
    "scheduler_time": 291.4458987602371
}
#Debug simulation 
Total elapsed time: 81.5128447539173. Arrivals time: 0.5788156129419804 Scheduler time: 80.71111728157848 Scheduler overhead time: 0.08502996619790792 Adapter cache time: 0.017318439669907093 Engine time: 0.08683450194075704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 85.64973857114092,
    "estimated_duration": 3600.07488462867,
    "input_throughput": 7328.362005092358,
    "output_throughput": 6329.310564424623,
    "total_throughput": 13657.67256951698,
    "itl": 87.98429482260104,
    "ttft": 1934579.9997963265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.685355128310615,
    "arrivals": 765271,
    "finished_requests": 106260,
    "scheduler_time": 291.8194988835073
}
#Debug simulation 
Total elapsed time: 85.64989804197103. Arrivals time: 0.49496544525027275 Scheduler time: 84.93334770947695 Scheduler overhead time: 0.08544258028268814 Adapter cache time: 0.016675511840730906 Engine time: 0.0859091654419899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 82.52811115141958,
    "estimated_duration": 3600.076048536348,
    "input_throughput": 7356.685148572799,
    "output_throughput": 6347.894514420357,
    "total_throughput": 13704.579662993157,
    "itl": 86.40716698769101,
    "ttft": 1932099.003778678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.385857683084917,
    "arrivals": 765271,
    "finished_requests": 106634,
    "scheduler_time": 290.760596488265
}
#Debug simulation 
Total elapsed time: 82.52836939832196. Arrivals time: 0.577544764149934 Scheduler time: 81.72750415233895 Scheduler overhead time: 0.08556965691968799 Adapter cache time: 0.01737641217187047 Engine time: 0.08684023888781667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 83.20586699573323,
    "estimated_duration": 3600.0048699872887,
    "input_throughput": 7382.300291192061,
    "output_throughput": 6446.152668699568,
    "total_throughput": 13828.452959891629,
    "itl": 89.85321918818829,
    "ttft": 1932344.5534893123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.102746072160081,
    "arrivals": 762397,
    "finished_requests": 107447,
    "scheduler_time": 285.73908895755017
}
#Debug simulation 
Total elapsed time: 83.20602873992175. Arrivals time: 0.5057259136810899 Scheduler time: 82.48144281562418 Scheduler overhead time: 0.08455738332122564 Adapter cache time: 0.016952110454440117 Engine time: 0.08479959797114134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 82.30800350010395,
    "estimated_duration": 3600.0928360434236,
    "input_throughput": 7324.243901715304,
    "output_throughput": 6395.057585598968,
    "total_throughput": 13719.301487314273,
    "itl": 88.53402869854371,
    "ttft": 1934565.3972682324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.210584018682132,
    "arrivals": 762397,
    "finished_requests": 106522,
    "scheduler_time": 288.40046699015994
}
#Debug simulation 
Total elapsed time: 82.308165169321. Arrivals time: 0.4886382017284632 Scheduler time: 81.60028304578736 Scheduler overhead time: 0.08369333017617464 Adapter cache time: 0.01706441631540656 Engine time: 0.08541573444381356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 81.10134516796097,
    "estimated_duration": 3600.019333108033,
    "input_throughput": 7206.339910847772,
    "output_throughput": 6297.93201150001,
    "total_throughput": 13504.271922347782,
    "itl": 86.12077847648388,
    "ttft": 1941456.8116746754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.182674325066627,
    "arrivals": 762397,
    "finished_requests": 104807,
    "scheduler_time": 293.2250949690879
}
#Debug simulation 
Total elapsed time: 81.10150233423337. Arrivals time: 0.4953459855169058 Scheduler time: 80.38482253672555 Scheduler overhead time: 0.08502000151202083 Adapter cache time: 0.016929814592003822 Engine time: 0.08559986716136336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 81.22767726471648,
    "estimated_duration": 3600.027729258037,
    "input_throughput": 7315.03504430714,
    "output_throughput": 6389.147453800449,
    "total_throughput": 13704.18249810759,
    "itl": 88.52946619705439,
    "ttft": 1934202.6111021535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1269979517953446,
    "arrivals": 762397,
    "finished_requests": 106371,
    "scheduler_time": 288.64364753559533
}
#Debug simulation 
Total elapsed time: 81.22783496696502. Arrivals time: 0.5055216928012669 Scheduler time: 80.50378451822326 Scheduler overhead time: 0.0830547590740025 Adapter cache time: 0.017101211939007044 Engine time: 0.08558426098898053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 79.23596360627562,
    "estimated_duration": 3600.0384362476534,
    "input_throughput": 7269.0657234415685,
    "output_throughput": 6359.781264964522,
    "total_throughput": 13628.84698840609,
    "itl": 86.59551158259514,
    "ttft": 1940194.3747261113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3093993893684917,
    "arrivals": 762397,
    "finished_requests": 105708,
    "scheduler_time": 290.1623507607904
}
#Debug simulation 
Total elapsed time: 79.23612755397335. Arrivals time: 0.49085590709000826 Scheduler time: 78.52359312120825 Scheduler overhead time: 0.0848781131207943 Adapter cache time: 0.016964937560260296 Engine time: 0.08639702200889587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 81.09421736374497,
    "estimated_duration": 3600.0834379080475,
    "input_throughput": 7379.343689722157,
    "output_throughput": 6455.142332341012,
    "total_throughput": 13834.486022063169,
    "itl": 89.11374239739843,
    "ttft": 1933800.5767744998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9726315706362874,
    "arrivals": 762397,
    "finished_requests": 107377,
    "scheduler_time": 285.49770613063737
}
#Debug simulation 
Total elapsed time: 81.09437949163839. Arrivals time: 0.5136688910424709 Scheduler time: 80.35918378038332 Scheduler overhead time: 0.08494879677891731 Adapter cache time: 0.01703749317675829 Engine time: 0.08633662294596434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 81.33229372603819,
    "estimated_duration": 3600.024386944272,
    "input_throughput": 7223.140791574458,
    "output_throughput": 6311.745021062753,
    "total_throughput": 13534.88581263721,
    "itl": 86.14891762928598,
    "ttft": 1943232.0639720925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.114228263627745,
    "arrivals": 762397,
    "finished_requests": 105082,
    "scheduler_time": 292.5640654645552
}
#Debug simulation 
Total elapsed time: 81.33245540317148. Arrivals time: 0.4840724519453943 Scheduler time: 80.62529575638473 Scheduler overhead time: 0.08452279446646571 Adapter cache time: 0.0168638383038342 Engine time: 0.08756405534222722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 84.65666078496724,
    "estimated_duration": 3600.093504597659,
    "input_throughput": 7421.423628547099,
    "output_throughput": 6436.51254346786,
    "total_throughput": 13857.936172014959,
    "itl": 89.75899246479452,
    "ttft": 1925486.0756809753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9175986192654795,
    "arrivals": 760968,
    "finished_requests": 107752,
    "scheduler_time": 286.45139131211556
}
#Debug simulation 
Total elapsed time: 84.65681995404884. Arrivals time: 0.8297763289883733 Scheduler time: 83.60878748027608 Scheduler overhead time: 0.08331938553601503 Adapter cache time: 0.01707484293729067 Engine time: 0.08488638559356332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 86.57823879504576,
    "estimated_duration": 3600.043456610582,
    "input_throughput": 7390.744950909655,
    "output_throughput": 6429.4201664421,
    "total_throughput": 13820.165117351755,
    "itl": 88.67237233894645,
    "ttft": 1922331.805976561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.296908616782169,
    "arrivals": 760968,
    "finished_requests": 107349,
    "scheduler_time": 288.13493562972775
}
#Debug simulation 
Total elapsed time: 86.57840360980481. Arrivals time: 0.4836754654534161 Scheduler time: 85.87315074633807 Scheduler overhead time: 0.08511840458959341 Adapter cache time: 0.017111333087086678 Engine time: 0.08574097603559494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 80.69037679210305,
    "estimated_duration": 3600.012658456214,
    "input_throughput": 7351.36748417683,
    "output_throughput": 6399.287220806365,
    "total_throughput": 13750.654704983195,
    "itl": 86.72552466895483,
    "ttft": 1922779.155700415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5914413849311093,
    "arrivals": 760968,
    "finished_requests": 106682,
    "scheduler_time": 289.57992711151195
}
#Debug simulation 
Total elapsed time: 80.69064237503335. Arrivals time: 0.49729959527030587 Scheduler time: 79.9733330453746 Scheduler overhead time: 0.08370897267013788 Adapter cache time: 0.0173227796331048 Engine time: 0.08515563327819109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 83.96673459094018,
    "estimated_duration": 3600.0267645853473,
    "input_throughput": 7418.900676722126,
    "output_throughput": 6431.915792344675,
    "total_throughput": 13850.816469066802,
    "itl": 88.71119991759403,
    "ttft": 1929931.1142374193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.064546963362953,
    "arrivals": 760968,
    "finished_requests": 107704,
    "scheduler_time": 286.72695077941825
}
#Debug simulation 
Total elapsed time: 83.96689595095813. Arrivals time: 0.8038732819259167 Scheduler time: 82.94510605558753 Scheduler overhead time: 0.08325546747073531 Adapter cache time: 0.016950892750173807 Engine time: 0.08495882200077176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 81.26188431819901,
    "estimated_duration": 3600.072036992443,
    "input_throughput": 7358.055541057943,
    "output_throughput": 6386.59775797377,
    "total_throughput": 13744.653299031714,
    "itl": 86.73215861041984,
    "ttft": 1934247.37162052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2414269138360496,
    "arrivals": 760968,
    "finished_requests": 106851,
    "scheduler_time": 288.8590916511861
}
#Debug simulation 
Total elapsed time: 81.26205683685839. Arrivals time: 0.4865216128528118 Scheduler time: 80.55560255609453 Scheduler overhead time: 0.0839562201872468 Adapter cache time: 0.016841823235154152 Engine time: 0.08575433073565364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 83.41007258696482,
    "estimated_duration": 3600.003621107437,
    "input_throughput": 7401.931165781113,
    "output_throughput": 6419.09965437514,
    "total_throughput": 13821.030820156253,
    "itl": 88.57324889888714,
    "ttft": 1928566.0159195852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9087923612305824,
    "arrivals": 760968,
    "finished_requests": 107461,
    "scheduler_time": 287.24118902812063
}
#Debug simulation 
Total elapsed time: 83.41023593116552. Arrivals time: 0.506720058619976 Scheduler time: 82.68438687175512 Scheduler overhead time: 0.08408466633409262 Adapter cache time: 0.016792636830359697 Engine time: 0.08538135979324579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 82.43769921408966,
    "estimated_duration": 3600.0421050888053,
    "input_throughput": 7319.467725878165,
    "output_throughput": 6345.1843987353905,
    "total_throughput": 13664.652124613556,
    "itl": 86.41169185346905,
    "ttft": 1935008.3134352164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.06587334733457,
    "arrivals": 760968,
    "finished_requests": 106254,
    "scheduler_time": 290.9928378598043
}
#Debug simulation 
Total elapsed time: 82.43786278599873. Arrivals time: 0.49239291762933135 Scheduler time: 81.7252535438165 Scheduler overhead time: 0.08412868669256568 Adapter cache time: 0.017120336182415485 Engine time: 0.0857218848541379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 83.03046977706254,
    "estimated_duration": 3600.0310615439926,
    "input_throughput": 7533.394722535671,
    "output_throughput": 6529.148387380592,
    "total_throughput": 14062.543109916262,
    "itl": 90.06614161061339,
    "ttft": 1923181.5439046635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9374358463613293,
    "arrivals": 760248,
    "finished_requests": 109287,
    "scheduler_time": 281.762927369314
}
#Debug simulation 
Total elapsed time: 83.03071448812261. Arrivals time: 0.5060497839003801 Scheduler time: 82.30771490558982 Scheduler overhead time: 0.08334965771064162 Adapter cache time: 0.01664882991462946 Engine time: 0.08424236020073295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 84.19827267201617,
    "estimated_duration": 3600.0772367194622,
    "input_throughput": 7443.9972361316095,
    "output_throughput": 6449.737456510407,
    "total_throughput": 13893.734692642018,
    "itl": 88.7137873090335,
    "ttft": 1924861.0958571755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.217525123548697,
    "arrivals": 760248,
    "finished_requests": 108035,
    "scheduler_time": 285.7201275184317
}
#Debug simulation 
Total elapsed time: 84.19842582615092. Arrivals time: 0.5122887822799385 Scheduler time: 83.46643998194486 Scheduler overhead time: 0.08359067281708121 Adapter cache time: 0.0171552998945117 Engine time: 0.08575065806508064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 80.91980673186481,
    "estimated_duration": 3600.0932285032263,
    "input_throughput": 7401.6377656638015,
    "output_throughput": 6407.44351211996,
    "total_throughput": 13809.081277783762,
    "itl": 86.68646213124899,
    "ttft": 1931660.8644390928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.270575214978316,
    "arrivals": 760248,
    "finished_requests": 107329,
    "scheduler_time": 287.7991179519723
}
#Debug simulation 
Total elapsed time: 80.91996718011796. Arrivals time: 0.4907698486931622 Scheduler time: 80.2102499124594 Scheduler overhead time: 0.08398876851424575 Adapter cache time: 0.016561236698180437 Engine time: 0.0856330175884068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 84.92116902116686,
    "estimated_duration": 3600.0620269802143,
    "input_throughput": 7407.378484078146,
    "output_throughput": 6425.78789660591,
    "total_throughput": 13833.166380684057,
    "itl": 88.52494468364719,
    "ttft": 1919205.579672141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3959631460299686,
    "arrivals": 760248,
    "finished_requests": 107430,
    "scheduler_time": 287.33489867770044
}
#Debug simulation 
Total elapsed time: 84.92132475785911. Arrivals time: 0.501567545812577 Scheduler time: 84.20020185317844 Scheduler overhead time: 0.08394997706636786 Adapter cache time: 0.017256473191082478 Engine time: 0.08514421107247472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 79.99770537298173,
    "estimated_duration": 3600.0514278914798,
    "input_throughput": 7370.86442555117,
    "output_throughput": 6389.684831106088,
    "total_throughput": 13760.549256657258,
    "itl": 86.55283784456877,
    "ttft": 1930448.2976618786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.267053085211674,
    "arrivals": 760248,
    "finished_requests": 106994,
    "scheduler_time": 288.7262188293481
}
#Debug simulation 
Total elapsed time: 79.99786319769919. Arrivals time: 0.4731489266268909 Scheduler time: 79.3051431607455 Scheduler overhead time: 0.0845396826043725 Adapter cache time: 0.016975415404886007 Engine time: 0.08513396140187979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 82.60019439738244,
    "estimated_duration": 3600.006558828416,
    "input_throughput": 7408.229836303232,
    "output_throughput": 6422.222466040221,
    "total_throughput": 13830.452302343454,
    "itl": 88.48669140098242,
    "ttft": 1921244.215059834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2790597757836712,
    "arrivals": 760248,
    "finished_requests": 107516,
    "scheduler_time": 287.044316844156
}
#Debug simulation 
Total elapsed time: 82.60044248308986. Arrivals time: 0.5067358589731157 Scheduler time: 81.87453163648024 Scheduler overhead time: 0.08384001208469272 Adapter cache time: 0.017145503778010607 Engine time: 0.08543466636911035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_192_slots_16_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 79.08630638569593,
    "estimated_duration": 3600.0757237901416,
    "input_throughput": 7381.0186336927645,
    "output_throughput": 6397.005165145372,
    "total_throughput": 13778.023798838136,
    "itl": 86.58436953477721,
    "ttft": 1932147.502893014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1872715788334682,
    "arrivals": 760248,
    "finished_requests": 107152,
    "scheduler_time": 288.2634202053679
}
#Debug simulation 
Total elapsed time: 79.08646441064775. Arrivals time: 0.47461532009765506 Scheduler time: 78.3922421108 Scheduler overhead time: 0.08307106560096145 Adapter cache time: 0.01697826012969017 Engine time: 0.08646668354049325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 84.8701787982136,
    "estimated_duration": 3600.095514557041,
    "input_throughput": 7336.1695247270745,
    "output_throughput": 6383.698962172596,
    "total_throughput": 13719.86848689967,
    "itl": 89.7742118843475,
    "ttft": 1932521.1176794225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7390635754028314,
    "arrivals": 753816,
    "finished_requests": 106862,
    "scheduler_time": 289.07493575436627
}
#Debug simulation 
Total elapsed time: 84.87034893082455. Arrivals time: 0.5018384652212262 Scheduler time: 84.14788566203788 Scheduler overhead time: 0.08513532672077417 Adapter cache time: 0.016768080182373524 Engine time: 0.08559315139427781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 81.59453703090549,
    "estimated_duration": 3600.0456754605043,
    "input_throughput": 7312.09028247475,
    "output_throughput": 6367.904761949319,
    "total_throughput": 13679.99504442407,
    "itl": 88.680177889938,
    "ttft": 1934143.8415364139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9332894986076303,
    "arrivals": 753816,
    "finished_requests": 106509,
    "scheduler_time": 289.90247206558774
}
#Debug simulation 
Total elapsed time: 81.59470554394647. Arrivals time: 0.49177737114951015 Scheduler time: 80.88301736395806 Scheduler overhead time: 0.0843499656766653 Adapter cache time: 0.01675661141052842 Engine time: 0.08537895837798715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 82.13472364330664,
    "estimated_duration": 3600.0115416055805,
    "input_throughput": 7229.41487804025,
    "output_throughput": 6296.570090964306,
    "total_throughput": 13525.984969004556,
    "itl": 86.53847662376756,
    "ttft": 1939406.352276343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0539251096872673,
    "arrivals": 753816,
    "finished_requests": 105302,
    "scheduler_time": 293.3768155333395
}
#Debug simulation 
Total elapsed time: 82.13489497546107. Arrivals time: 0.4936450943350792 Scheduler time: 81.41738994745538 Scheduler overhead time: 0.0859147678129375 Adapter cache time: 0.017051643691956997 Engine time: 0.08674056548625231 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 81.03887724503875,
    "estimated_duration": 3600.024017778703,
    "input_throughput": 7313.13870962579,
    "output_throughput": 6368.569455863376,
    "total_throughput": 13681.708165489166,
    "itl": 88.7074846060899,
    "ttft": 1934197.4887532447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8230628577899173,
    "arrivals": 753816,
    "finished_requests": 106523,
    "scheduler_time": 289.87504852917107
}
#Debug simulation 
Total elapsed time: 81.03904396295547. Arrivals time: 0.49134496692568064 Scheduler time: 80.32879714202136 Scheduler overhead time: 0.08434572862461209 Adapter cache time: 0.016733053140342236 Engine time: 0.08487609075382352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_192_slots_16_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 81.67869399534538,
    "estimated_duration": 3600.0809556529234,
    "input_throughput": 7226.9124834948,
    "output_throughput": 6294.530672822093,
    "total_throughput": 13521.443156316893,
    "itl": 86.57739882221401,
    "ttft": 1938781.7762046428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0214625749690516,
    "arrivals": 753816,
    "finished_requests": 105268,
    "scheduler_time": 293.48680858912746
}
#Debug simulation 
Total elapsed time: 81.67885905597359. Arrivals time: 0.4815016067586839 Scheduler time: 80.97494916059077 Scheduler overhead time: 0.08549269009381533 Adapter cache time: 0.017141083255410194 Engine time: 0.08631314476951957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_16_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_16_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 80.77754397084936,
    "estimated_duration": 3600.0787620144542,
    "input_throughput": 7366.0252325039355,
    "output_throughput": 6415.031316447425,
    "total_throughput": 13781.056548951361,
    "itl": 88.95260542831274,
    "ttft": 1928542.4628075021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9790154915768579,
    "arrivals": 753816,
    "finished_requests": 107207,
    "scheduler_time": 287.4693848879412
}
#Debug simulation 
Total elapsed time: 80.77770714089274. Arrivals time: 0.4960955479182303 Scheduler time: 80.06328052887693 Scheduler overhead time: 0.08374364720657468 Adapter cache time: 0.016850571613758802 Engine time: 0.08432505745440722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_192_slots_16_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_192_slots_16_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 81.09297482995316,
    "estimated_duration": 3600.07722994725,
    "input_throughput": 7224.417794054126,
    "output_throughput": 6289.82367701367,
    "total_throughput": 13514.241471067795,
    "itl": 86.53029692910299,
    "ttft": 1939307.9005128415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.958350828904663,
    "arrivals": 753816,
    "finished_requests": 105137,
    "scheduler_time": 293.7505098986046
}
#Debug simulation 
Total elapsed time: 81.09324323618785. Arrivals time: 0.4773537772707641 Scheduler time: 80.39321284880862 Scheduler overhead time: 0.08516397140920162 Adapter cache time: 0.01700883824378252 Engine time: 0.08637110376730561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 83.25864098826423,
    "estimated_duration": 3600.022843294814,
    "input_throughput": 7364.6721573951945,
    "output_throughput": 6447.671309428727,
    "total_throughput": 13812.343466823922,
    "itl": 90.19081492900511,
    "ttft": 1927009.3903023496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.030009572808629,
    "arrivals": 750836,
    "finished_requests": 107618,
    "scheduler_time": 285.90249485709757
}
#Debug simulation 
Total elapsed time: 83.25880272313952. Arrivals time: 0.5022827563807368 Scheduler time: 82.53981609456241 Scheduler overhead time: 0.08324550883844495 Adapter cache time: 0.01668274635449052 Engine time: 0.08428572863340378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 86.18007980985567,
    "estimated_duration": 3600.0103692932557,
    "input_throughput": 7317.8039220958735,
    "output_throughput": 6403.703777254892,
    "total_throughput": 13721.507699350765,
    "itl": 89.12232315645323,
    "ttft": 1932559.32865615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9693737662304214,
    "arrivals": 750836,
    "finished_requests": 107022,
    "scheduler_time": 288.0732394484223
}
#Debug simulation 
Total elapsed time: 86.18024186976254. Arrivals time: 0.8296704543754458 Scheduler time: 85.12904754234478 Scheduler overhead time: 0.08512759441509843 Adapter cache time: 0.017092842143028975 Engine time: 0.0855826586484909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 79.77270975615829,
    "estimated_duration": 3600.017031390803,
    "input_throughput": 7219.417234245476,
    "output_throughput": 6321.333149695759,
    "total_throughput": 13540.750383941235,
    "itl": 86.96170281462291,
    "ttft": 1935511.1956470362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.248523759851241,
    "arrivals": 750836,
    "finished_requests": 105506,
    "scheduler_time": 292.1807235611031
}
#Debug simulation 
Total elapsed time: 79.7728704479523. Arrivals time: 0.49405247904360294 Scheduler time: 79.0560889528133 Scheduler overhead time: 0.08507982036098838 Adapter cache time: 0.01728629507124424 Engine time: 0.08652240736410022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 82.99328015185893,
    "estimated_duration": 3600.0814181516685,
    "input_throughput": 7283.191115566979,
    "output_throughput": 6374.745827771485,
    "total_throughput": 13657.936943338464,
    "itl": 88.72894345781337,
    "ttft": 1935001.310114514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0320701747341054,
    "arrivals": 750836,
    "finished_requests": 106434,
    "scheduler_time": 289.5572507626691
}
#Debug simulation 
Total elapsed time: 82.99344610795379. Arrivals time: 0.5063921329565346 Scheduler time: 82.26519840722904 Scheduler overhead time: 0.08509077364578843 Adapter cache time: 0.017148497514426708 Engine time: 0.08620720589533448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 82.50296164210886,
    "estimated_duration": 3600.0739554149327,
    "input_throughput": 7189.606191580805,
    "output_throughput": 6309.688156776186,
    "total_throughput": 13499.29434835699,
    "itl": 86.83176766514455,
    "ttft": 1937145.3235745868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0835338868573383,
    "arrivals": 750836,
    "finished_requests": 105180,
    "scheduler_time": 292.75861076997353
}
#Debug simulation 
Total elapsed time: 82.5031233378686. Arrivals time: 0.4995007780380547 Scheduler time: 81.77537880465388 Scheduler overhead time: 0.08896703459322453 Adapter cache time: 0.01716806786134839 Engine time: 0.08784118946641684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_16_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 84.60058322083205,
    "estimated_duration": 3600.066018463707,
    "input_throughput": 7313.891707807147,
    "output_throughput": 6403.368405404257,
    "total_throughput": 13717.260113211403,
    "itl": 88.96551416240013,
    "ttft": 1931240.0326360334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6789712073700445,
    "arrivals": 750836,
    "finished_requests": 106977,
    "scheduler_time": 288.1236065900063
}
#Debug simulation 
Total elapsed time: 84.60073828697205. Arrivals time: 0.5067242216318846 Scheduler time: 83.87406166270375 Scheduler overhead time: 0.08649441692978144 Adapter cache time: 0.016467535868287086 Engine time: 0.08423947123810649 
