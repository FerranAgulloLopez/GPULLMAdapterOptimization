INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.732926200027578,
    "estimated_duration": 3600.0609464586732,
    "input_throughput": 5125.778778315422,
    "output_throughput": 4487.011259042704,
    "total_throughput": 9612.790037358125,
    "itl": 98.3980705576918,
    "ttft": 1773602.3256065564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.571966050919171,
    "arrivals": 209539,
    "finished_requests": 74669,
    "scheduler_time": 164.06622425261406
}
#Debug simulation 
Total elapsed time: 13.733074956981. Arrivals time: 0.2780963497934863 Scheduler time: 13.293777566635981 Scheduler overhead time: 0.057416114024817944 Adapter cache time: 0.02068405319005251 Engine time: 0.05709964164998382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 8640, 8640, 66, 1080, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 1080, 66, 66, 66, 66, 66, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 66, 1080, 1080, 8640, 66, 66, 66, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 1080, 66, 8640, 1080, 66, 1080, 1080, 66, 1080, 8640, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 626304 . Total input tokens: 139690067 . Total output tokens: 123054254
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 31.133153769013006,
    "estimated_duration": 3600.0071163610382,
    "input_throughput": 5572.9048169992475,
    "output_throughput": 4879.592854182091,
    "total_throughput": 10452.49767118134,
    "itl": 118.2395509185159,
    "ttft": 1683217.3436636415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4862657960131895,
    "arrivals": 208072,
    "finished_requests": 81423,
    "scheduler_time": 152.56406557669288
}
#Debug simulation 
Total elapsed time: 31.1333451080136. Arrivals time: 0.3584526827908121 Scheduler time: 30.620684071269352 Scheduler overhead time: 0.058202554821036756 Adapter cache time: 0.014586754725314677 Engine time: 0.057428366446401924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 8640, 8640, 66, 1080, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 1080, 66, 66, 66, 66, 66, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 66, 1080, 1080, 8640, 66, 66, 66, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 1080, 66, 8640, 1080, 66, 1080, 1080, 66, 1080, 8640, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 626304 . Total input tokens: 139690067 . Total output tokens: 123054254
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.2361378549831,
    "estimated_duration": 3600.0376580815296,
    "input_throughput": 5405.341512557951,
    "output_throughput": 4734.742138526257,
    "total_throughput": 10140.08365108421,
    "itl": 110.64178358959981,
    "ttft": 1716196.1208171216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8232797716045805,
    "arrivals": 208072,
    "finished_requests": 78988,
    "scheduler_time": 156.2478279006069
}
#Debug simulation 
Total elapsed time: 22.236280301003717. Arrivals time: 0.3074265119503252 Scheduler time: 21.772816410579253 Scheduler overhead time: 0.05856923299143091 Adapter cache time: 0.01594676880631596 Engine time: 0.057345590728800744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 8640, 8640, 66, 1080, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 1080, 66, 66, 66, 66, 66, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 66, 1080, 1080, 8640, 66, 66, 66, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 1080, 66, 8640, 1080, 66, 1080, 1080, 66, 1080, 8640, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 626304 . Total input tokens: 139690067 . Total output tokens: 123054254
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.785235438030213,
    "estimated_duration": 3600.0829323728176,
    "input_throughput": 5107.266789512926,
    "output_throughput": 4476.107996039695,
    "total_throughput": 9583.37478555262,
    "itl": 98.28613074686189,
    "ttft": 1769571.704541231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.162243287661141,
    "arrivals": 208072,
    "finished_requests": 74584,
    "scheduler_time": 163.83364301227127
}
#Debug simulation 
Total elapsed time: 12.785357669985387. Arrivals time: 0.2681513247662224 Scheduler time: 12.358113690803293 Scheduler overhead time: 0.05689866543980315 Adapter cache time: 0.0195550270145759 Engine time: 0.056944632437080145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 8640, 8640, 66, 1080, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 1080, 66, 66, 66, 66, 66, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 66, 1080, 1080, 8640, 66, 66, 66, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 1080, 66, 8640, 1080, 66, 1080, 1080, 66, 1080, 8640, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 626304 . Total input tokens: 139690067 . Total output tokens: 123054254
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 20.700651168008335,
    "estimated_duration": 3600.059018241809,
    "input_throughput": 5406.430256108839,
    "output_throughput": 4736.911232174298,
    "total_throughput": 10143.341488283137,
    "itl": 110.62802243645983,
    "ttft": 1715799.547980213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.699416341125028,
    "arrivals": 208072,
    "finished_requests": 79008,
    "scheduler_time": 156.30089237555717
}
#Debug simulation 
Total elapsed time: 20.700750677031465. Arrivals time: 0.3033927590586245 Scheduler time: 20.244039395241998 Scheduler overhead time: 0.056578176852781326 Adapter cache time: 0.01584793470101431 Engine time: 0.056840421340893954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 8640, 8640, 66, 1080, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 1080, 66, 66, 66, 66, 66, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 66, 1080, 1080, 8640, 66, 66, 66, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 1080, 66, 8640, 1080, 66, 1080, 1080, 66, 1080, 8640, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 626304 . Total input tokens: 139690067 . Total output tokens: 123054254
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.530727122968528,
    "estimated_duration": 3600.056379268072,
    "input_throughput": 5109.044709944085,
    "output_throughput": 4479.158741196831,
    "total_throughput": 9588.203451140917,
    "itl": 98.20082311638674,
    "ttft": 1769734.2303407628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 763,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.691141378693315,
    "arrivals": 208072,
    "finished_requests": 74652,
    "scheduler_time": 163.9443103072629
}
#Debug simulation 
Total elapsed time: 14.530816936981864. Arrivals time: 0.2918106386787258 Scheduler time: 14.077412101381924 Scheduler overhead time: 0.05832165788160637 Adapter cache time: 0.01907335832947865 Engine time: 0.05843553424347192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 8640, 8640, 66, 1080, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 1080, 66, 66, 66, 66, 66, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 66, 1080, 1080, 8640, 66, 66, 66, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 1080, 66, 8640, 1080, 66, 1080, 1080, 66, 1080, 8640, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 626304 . Total input tokens: 139690067 . Total output tokens: 123054254
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 20.88458809797885,
    "estimated_duration": 3600.0358650317753,
    "input_throughput": 5404.3564368290745,
    "output_throughput": 4735.908651801588,
    "total_throughput": 10140.265088630664,
    "itl": 110.61528314951765,
    "ttft": 1715961.6984517358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.41539770320522,
    "arrivals": 208072,
    "finished_requests": 78985,
    "scheduler_time": 156.30003972047177
}
#Debug simulation 
Total elapsed time: 20.884681580995675. Arrivals time: 0.30328897532308474 Scheduler time: 20.428457741683815 Scheduler overhead time: 0.056011711014434695 Adapter cache time: 0.01564377365866676 Engine time: 0.057212689716834575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 8640, 8640, 66, 1080, 8640, 66, 1080, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 1080, 66, 66, 66, 66, 66, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 66, 1080, 1080, 8640, 66, 66, 66, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 1080, 1080, 8640, 1080, 66, 1080, 8640, 8640, 1080, 8640, 1080, 66, 8640, 1080, 66, 1080, 1080, 66, 1080, 8640, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 1080, 66, 8640, 8640, 1080, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 626304 . Total input tokens: 139690067 . Total output tokens: 123054254
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.096438850974664,
    "estimated_duration": 3600.037009410741,
    "input_throughput": 5105.371125895283,
    "output_throughput": 4476.552868171166,
    "total_throughput": 9581.923994066448,
    "itl": 98.25454638245014,
    "ttft": 1770049.338050949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.03140972912315,
    "arrivals": 208072,
    "finished_requests": 74562,
    "scheduler_time": 163.8845865155626
}
#Debug simulation 
Total elapsed time: 13.096593390975613. Arrivals time: 0.2714300366351381 Scheduler time: 12.666455618687905 Scheduler overhead time: 0.05676920199766755 Adapter cache time: 0.019255261460784823 Engine time: 0.05691344238584861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 8640, 8640, 33, 1080, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 1080, 33, 33, 33, 33, 33, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 33, 1080, 1080, 8640, 33, 33, 33, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 1080, 33, 8640, 1080, 33, 1080, 1080, 33, 1080, 8640, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 624192 . Total input tokens: 139216668 . Total output tokens: 122626617
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 34.424212326004636,
    "estimated_duration": 3600.0399057949776,
    "input_throughput": 5604.087601230319,
    "output_throughput": 4873.319312866289,
    "total_throughput": 10477.406914096608,
    "itl": 118.06541353640272,
    "ttft": 1652120.7836804609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8860628102812906,
    "arrivals": 207395,
    "finished_requests": 81476,
    "scheduler_time": 152.31204105307276
}
#Debug simulation 
Total elapsed time: 34.42436288698809. Arrivals time: 0.3430620032013394 Scheduler time: 33.9263574439683 Scheduler overhead time: 0.05997867259429768 Adapter cache time: 0.011834132834337652 Engine time: 0.059297598141711205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 8640, 8640, 33, 1080, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 1080, 33, 33, 33, 33, 33, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 33, 1080, 1080, 8640, 33, 33, 33, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 1080, 33, 8640, 1080, 33, 1080, 1080, 33, 1080, 8640, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 624192 . Total input tokens: 139216668 . Total output tokens: 122626617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.94847462105099,
    "estimated_duration": 3600.0194364539284,
    "input_throughput": 5437.841474345754,
    "output_throughput": 4737.780809539326,
    "total_throughput": 10175.622283885079,
    "itl": 110.27403766238994,
    "ttft": 1708047.832043102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9569740178529207,
    "arrivals": 207395,
    "finished_requests": 79033,
    "scheduler_time": 156.3387238460089
}
#Debug simulation 
Total elapsed time: 18.948606680030935. Arrivals time: 0.30938151106238365 Scheduler time: 18.489138705539517 Scheduler overhead time: 0.0562085795099847 Adapter cache time: 0.014119816885795444 Engine time: 0.0554968120995909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 8640, 8640, 33, 1080, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 1080, 33, 33, 33, 33, 33, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 33, 1080, 1080, 8640, 33, 33, 33, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 1080, 33, 8640, 1080, 33, 1080, 1080, 33, 1080, 8640, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 624192 . Total input tokens: 139216668 . Total output tokens: 122626617
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.669681083003525,
    "estimated_duration": 3600.106162027149,
    "input_throughput": 5140.73840244171,
    "output_throughput": 4474.9422030734295,
    "total_throughput": 9615.68060551514,
    "itl": 97.71816115544254,
    "ttft": 1765697.4087604608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.884068055036508,
    "arrivals": 207395,
    "finished_requests": 74635,
    "scheduler_time": 164.1540978660888
}
#Debug simulation 
Total elapsed time: 14.669818469963502. Arrivals time: 0.2871121579082683 Scheduler time: 14.221824683074374 Scheduler overhead time: 0.058597836236003786 Adapter cache time: 0.0175806115148589 Engine time: 0.05845051270443946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 8640, 8640, 33, 1080, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 1080, 33, 33, 33, 33, 33, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 33, 1080, 1080, 8640, 33, 33, 33, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 1080, 33, 8640, 1080, 33, 1080, 1080, 33, 1080, 8640, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 624192 . Total input tokens: 139216668 . Total output tokens: 122626617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 19.28644587501185,
    "estimated_duration": 3600.077329347227,
    "input_throughput": 5438.739007184121,
    "output_throughput": 4735.6516097645335,
    "total_throughput": 10174.390616948654,
    "itl": 110.2173740884499,
    "ttft": 1706961.317718783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6546536095254085,
    "arrivals": 207395,
    "finished_requests": 79038,
    "scheduler_time": 156.3427863710108
}
#Debug simulation 
Total elapsed time: 19.286575803009328. Arrivals time: 0.30123858706792817 Scheduler time: 18.835116464586463 Scheduler overhead time: 0.05648642004234716 Adapter cache time: 0.013768510718364269 Engine time: 0.05615620512980968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 8640, 8640, 33, 1080, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 1080, 33, 33, 33, 33, 33, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 33, 1080, 1080, 8640, 33, 33, 33, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 1080, 33, 8640, 1080, 33, 1080, 1080, 33, 1080, 8640, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 624192 . Total input tokens: 139216668 . Total output tokens: 122626617
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.772402197006159,
    "estimated_duration": 3600.009825200897,
    "input_throughput": 5145.409290366673,
    "output_throughput": 4475.26195268118,
    "total_throughput": 9620.671243047853,
    "itl": 97.9577781605178,
    "ttft": 1764477.5964688475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.71161711539145,
    "arrivals": 207395,
    "finished_requests": 74670,
    "scheduler_time": 163.88468150650584
}
#Debug simulation 
Total elapsed time: 11.772523933032062. Arrivals time: 0.2674745012191124 Scheduler time: 11.349678241764195 Scheduler overhead time: 0.05628921004245058 Adapter cache time: 0.017096667375881225 Engine time: 0.056410567194689065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 8640, 8640, 33, 1080, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 1080, 33, 33, 33, 33, 33, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 33, 1080, 1080, 8640, 33, 33, 33, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 1080, 33, 8640, 1080, 33, 1080, 1080, 33, 1080, 8640, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 624192 . Total input tokens: 139216668 . Total output tokens: 122626617
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.678637577977497,
    "estimated_duration": 3600.079466011616,
    "input_throughput": 5455.36791213059,
    "output_throughput": 4741.357562006917,
    "total_throughput": 10196.725474137507,
    "itl": 110.10001723922596,
    "ttft": 1710680.663095367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6940146369207536,
    "arrivals": 207395,
    "finished_requests": 79206,
    "scheduler_time": 156.53741748040636
}
#Debug simulation 
Total elapsed time: 24.678764308977406. Arrivals time: 0.31008481967728585 Scheduler time: 24.21284631511662 Scheduler overhead time: 0.05853126128204167 Adapter cache time: 0.014667804935015738 Engine time: 0.05812157184118405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 8640, 8640, 33, 1080, 8640, 33, 1080, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 1080, 33, 33, 33, 33, 33, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 33, 1080, 1080, 8640, 33, 33, 33, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 1080, 1080, 8640, 1080, 33, 1080, 8640, 8640, 1080, 8640, 1080, 33, 8640, 1080, 33, 1080, 1080, 33, 1080, 8640, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 1080, 33, 8640, 8640, 1080, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 624192 . Total input tokens: 139216668 . Total output tokens: 122626617
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.419339723011944,
    "estimated_duration": 3600.1125108710335,
    "input_throughput": 5145.938618323269,
    "output_throughput": 4476.5562052117,
    "total_throughput": 9622.49482353497,
    "itl": 97.94077343004346,
    "ttft": 1766612.7336084284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.620342999100719,
    "arrivals": 207395,
    "finished_requests": 74699,
    "scheduler_time": 163.91467104444718
}
#Debug simulation 
Total elapsed time: 14.419460489996709. Arrivals time: 0.2785365419113077 Scheduler time: 13.982023369113449 Scheduler overhead time: 0.058421408757567406 Adapter cache time: 0.01676893071271479 Engine time: 0.05775276658823714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 32.84103818598669,
    "estimated_duration": 3600.0372149435148,
    "input_throughput": 5628.324595060587,
    "output_throughput": 4874.782940341174,
    "total_throughput": 10503.107535401761,
    "itl": 118.16311819322273,
    "ttft": 1620546.911547804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9918613547924895,
    "arrivals": 200999,
    "finished_requests": 81626,
    "scheduler_time": 151.8328916318548
}
#Debug simulation 
Total elapsed time: 32.84127209801227. Arrivals time: 0.3539796434924938 Scheduler time: 32.33287777606165 Scheduler overhead time: 0.059466370032168925 Adapter cache time: 0.011730850616004318 Engine time: 0.059491222724318504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.131059738982003,
    "estimated_duration": 3600.070623055793,
    "input_throughput": 5480.809702352944,
    "output_throughput": 4742.620017133868,
    "total_throughput": 10223.429719486812,
    "itl": 110.44374166538752,
    "ttft": 1686380.0486615794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.908773332657298,
    "arrivals": 200999,
    "finished_requests": 79490,
    "scheduler_time": 155.79295438101298
}
#Debug simulation 
Total elapsed time: 22.131149376975372. Arrivals time: 0.3199272002093494 Scheduler time: 21.657104593876284 Scheduler overhead time: 0.056746750604361296 Adapter cache time: 0.01678360265213996 Engine time: 0.05640436033718288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.518565202015452,
    "estimated_duration": 3600.0853592173517,
    "input_throughput": 5165.643629084085,
    "output_throughput": 4470.190952221918,
    "total_throughput": 9635.834581306002,
    "itl": 97.86219996642635,
    "ttft": 1745364.353459406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.55083882392386,
    "arrivals": 200999,
    "finished_requests": 74887,
    "scheduler_time": 163.35396795231495
}
#Debug simulation 
Total elapsed time: 12.518650369020179. Arrivals time: 0.2878795513533987 Scheduler time: 12.068811398406979 Scheduler overhead time: 0.05683971365215257 Adapter cache time: 0.021799251902848482 Engine time: 0.05746555054793134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 20.549900287005585,
    "estimated_duration": 3600.110142756585,
    "input_throughput": 5482.476706917385,
    "output_throughput": 4743.617090260415,
    "total_throughput": 10226.0937971778,
    "itl": 110.34660689382241,
    "ttft": 1688321.9135742912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.764927102308716,
    "arrivals": 200999,
    "finished_requests": 79503,
    "scheduler_time": 155.85539870417776
}
#Debug simulation 
Total elapsed time: 20.549986409023404. Arrivals time: 0.30034036963479593 Scheduler time: 20.096398091933224 Scheduler overhead time: 0.056087265140376985 Adapter cache time: 0.016720796760637313 Engine time: 0.0562829818809405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.401450977020431,
    "estimated_duration": 3600.097066503391,
    "input_throughput": 5172.881635129784,
    "output_throughput": 4476.7004062069,
    "total_throughput": 9649.582041336684,
    "itl": 98.14793112777721,
    "ttft": 1745294.0147784983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.064180607730548,
    "arrivals": 200999,
    "finished_requests": 75000,
    "scheduler_time": 163.11272379905367
}
#Debug simulation 
Total elapsed time: 13.401544576045126. Arrivals time: 0.2695717350579798 Scheduler time: 12.971151614852715 Scheduler overhead time: 0.057339000166393816 Adapter cache time: 0.019900764513295144 Engine time: 0.057735920301638544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 21.352043690974824,
    "estimated_duration": 3600.006358046989,
    "input_throughput": 5482.522817183974,
    "output_throughput": 4742.022736110172,
    "total_throughput": 10224.545553294147,
    "itl": 110.39922530778784,
    "ttft": 1687668.9499916192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.428165545086361,
    "arrivals": 200999,
    "finished_requests": 79472,
    "scheduler_time": 155.76796176295093
}
#Debug simulation 
Total elapsed time: 21.352153512998484. Arrivals time: 0.3027746752486564 Scheduler time: 20.897908534738235 Scheduler overhead time: 0.05518201639642939 Adapter cache time: 0.016237018862739205 Engine time: 0.056173165794461966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.023293242033105,
    "estimated_duration": 3600.026805730674,
    "input_throughput": 5162.4046161033975,
    "output_throughput": 4474.3472394036,
    "total_throughput": 9636.751855506996,
    "itl": 98.0462689020555,
    "ttft": 1739542.848510564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1932154634781496,
    "arrivals": 200999,
    "finished_requests": 74849,
    "scheduler_time": 163.25326243747398
}
#Debug simulation 
Total elapsed time: 14.023402533028275. Arrivals time: 0.2954114660387859 Scheduler time: 13.568231812212616 Scheduler overhead time: 0.057736755057703704 Adapter cache time: 0.018238838063552976 Engine time: 0.05789828352862969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 28.549195970990695,
    "estimated_duration": 3600.099828828322,
    "input_throughput": 5574.389865330871,
    "output_throughput": 4874.105395491458,
    "total_throughput": 10448.495260822328,
    "itl": 118.1682500354474,
    "ttft": 1625950.7122946915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2563577160704866,
    "arrivals": 198139,
    "finished_requests": 81273,
    "scheduler_time": 151.50121547849537
}
#Debug simulation 
Total elapsed time: 28.549321727012284. Arrivals time: 0.33553066360764205 Scheduler time: 28.06139460229315 Scheduler overhead time: 0.058210541086737067 Adapter cache time: 0.012239646981470287 Engine time: 0.057911282405257225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.45636658096919,
    "estimated_duration": 3600.060379002838,
    "input_throughput": 5419.727156188515,
    "output_throughput": 4741.623807078527,
    "total_throughput": 10161.350963267041,
    "itl": 110.3812296827335,
    "ttft": 1682533.509722416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.82689672828187,
    "arrivals": 198139,
    "finished_requests": 79215,
    "scheduler_time": 155.52288706601638
}
#Debug simulation 
Total elapsed time: 18.456533610005863. Arrivals time: 0.2926662878599018 Scheduler time: 18.014097182429396 Scheduler overhead time: 0.05461819830816239 Adapter cache time: 0.015952290559653193 Engine time: 0.05523372272728011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.701745569997001,
    "estimated_duration": 3600.0395412936427,
    "input_throughput": 5112.515512367465,
    "output_throughput": 4474.991681399966,
    "total_throughput": 9587.507193767431,
    "itl": 98.17964403783625,
    "ttft": 1741078.0799755624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.802103793169393,
    "arrivals": 198139,
    "finished_requests": 74690,
    "scheduler_time": 162.76590855149382
}
#Debug simulation 
Total elapsed time: 10.701835822954308. Arrivals time: 0.2663399160373956 Scheduler time: 10.277941454842221 Scheduler overhead time: 0.05555169133003801 Adapter cache time: 0.02068268205039203 Engine time: 0.05575659096939489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 18.411790620011743,
    "estimated_duration": 3600.02605287405,
    "input_throughput": 5419.581334536136,
    "output_throughput": 4741.755128791904,
    "total_throughput": 10161.33646332804,
    "itl": 110.47386655166342,
    "ttft": 1682848.929159442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.435172993736337,
    "arrivals": 198139,
    "finished_requests": 79212,
    "scheduler_time": 155.4344078757845
}
#Debug simulation 
Total elapsed time: 18.411897899000905. Arrivals time: 0.29771332209929824 Scheduler time: 17.964302075910382 Scheduler overhead time: 0.05476530676241964 Adapter cache time: 0.01566836965503171 Engine time: 0.05567632016027346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.02977603400359,
    "estimated_duration": 3600.074421673107,
    "input_throughput": 5117.410876033508,
    "output_throughput": 4477.376329489564,
    "total_throughput": 9594.787205523073,
    "itl": 97.85141548729418,
    "ttft": 1742014.6650925782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.986944935275267,
    "arrivals": 198139,
    "finished_requests": 74783,
    "scheduler_time": 163.18354907402798
}
#Debug simulation 
Total elapsed time: 14.029886845033616. Arrivals time: 0.27680728957057 Scheduler time: 13.590632347215433 Scheduler overhead time: 0.05812681250972673 Adapter cache time: 0.01996763818897307 Engine time: 0.05830757040530443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 18.610483499011025,
    "estimated_duration": 3600.018008439024,
    "input_throughput": 5417.107901761851,
    "output_throughput": 4739.261570360275,
    "total_throughput": 10156.369472122127,
    "itl": 110.32158497271442,
    "ttft": 1682420.405826409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.045130288652131,
    "arrivals": 198139,
    "finished_requests": 79164,
    "scheduler_time": 155.50999204790833
}
#Debug simulation 
Total elapsed time: 18.61061447300017. Arrivals time: 0.293380661518313 Scheduler time: 18.168678997608367 Scheduler overhead time: 0.053817582433111966 Adapter cache time: 0.015277944155968726 Engine time: 0.05554911802755669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.713070234982297,
    "estimated_duration": 3600.018918347993,
    "input_throughput": 5104.655118988354,
    "output_throughput": 4468.928737569719,
    "total_throughput": 9573.583856558073,
    "itl": 97.84839890480421,
    "ttft": 1738899.301050288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.317617073413016,
    "arrivals": 198139,
    "finished_requests": 74553,
    "scheduler_time": 163.12604788841045
}
#Debug simulation 
Total elapsed time: 10.71319419296924. Arrivals time: 0.2584366532973945 Scheduler time: 10.299936023773625 Scheduler overhead time: 0.055487666686531156 Adapter cache time: 0.018017540511209518 Engine time: 0.055769942002370954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 23.348231916024815,
    "estimated_duration": 3600.09072403173,
    "input_throughput": 5562.352878033611,
    "output_throughput": 4867.930656029084,
    "total_throughput": 10430.283534062695,
    "itl": 117.91435728096907,
    "ttft": 1645368.7365134906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3687686696136354,
    "arrivals": 196768,
    "finished_requests": 80836,
    "scheduler_time": 151.6842739842211
}
#Debug simulation 
Total elapsed time: 23.348387601028662. Arrivals time: 0.3180183132644743 Scheduler time: 22.88300977490144 Scheduler overhead time: 0.05653268564492464 Adapter cache time: 0.011578183039091527 Engine time: 0.056171268224716187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.917704395018518,
    "estimated_duration": 3600.0943838900694,
    "input_throughput": 5424.950547795518,
    "output_throughput": 4738.841313811772,
    "total_throughput": 10163.791861607291,
    "itl": 109.96195858000439,
    "ttft": 1690982.1630299238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.534879483743575,
    "arrivals": 196768,
    "finished_requests": 78801,
    "scheduler_time": 155.873385715806
}
#Debug simulation 
Total elapsed time: 15.917798474023584. Arrivals time: 0.28706717456225306 Scheduler time: 15.483929234091192 Scheduler overhead time: 0.054119560692925006 Adapter cache time: 0.014933819649741054 Engine time: 0.0539965940406546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.816882967017591,
    "estimated_duration": 3600.099863530301,
    "input_throughput": 5105.623926213983,
    "output_throughput": 4461.531515475644,
    "total_throughput": 9567.155441689627,
    "itl": 97.49283546502339,
    "ttft": 1747980.059799086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.736388163850668,
    "arrivals": 196768,
    "finished_requests": 74109,
    "scheduler_time": 163.3666489067398
}
#Debug simulation 
Total elapsed time: 10.817029555968475. Arrivals time: 0.25991124782012776 Scheduler time: 10.399510040937457 Scheduler overhead time: 0.056158219289500266 Adapter cache time: 0.01875617599580437 Engine time: 0.056802820530720055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 18.79552673402941,
    "estimated_duration": 3600.0350118324263,
    "input_throughput": 5431.845228095864,
    "output_throughput": 4746.119674903685,
    "total_throughput": 10177.964902999549,
    "itl": 109.78925252492078,
    "ttft": 1688756.6027804024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0873814901942342,
    "arrivals": 196768,
    "finished_requests": 78891,
    "scheduler_time": 156.10104368546317
}
#Debug simulation 
Total elapsed time: 18.79561500699492. Arrivals time: 0.30842559557640925 Scheduler time: 18.33848420693539 Scheduler overhead time: 0.05520087806507945 Adapter cache time: 0.01472235779510811 Engine time: 0.05486535240197554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.012035280989949,
    "estimated_duration": 3600.054120469622,
    "input_throughput": 5110.3665068235305,
    "output_throughput": 4464.436217393144,
    "total_throughput": 9574.802724216674,
    "itl": 97.57634396136017,
    "ttft": 1748255.0299642698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.463716393439127,
    "arrivals": 196768,
    "finished_requests": 74178,
    "scheduler_time": 163.32126084793097
}
#Debug simulation 
Total elapsed time: 11.012123945984058. Arrivals time: 0.25907029875088483 Scheduler time: 10.597467515501194 Scheduler overhead time: 0.055842093424871564 Adapter cache time: 0.018034526554401964 Engine time: 0.0561476371367462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.682150036038365,
    "estimated_duration": 3600.036091637568,
    "input_throughput": 5424.766725357072,
    "output_throughput": 4737.763335100785,
    "total_throughput": 10162.530060457857,
    "itl": 109.97340508258736,
    "ttft": 1691591.5924779319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1536569446418294,
    "arrivals": 196768,
    "finished_requests": 78792,
    "scheduler_time": 155.82924757840826
}
#Debug simulation 
Total elapsed time: 16.682236177031882. Arrivals time: 0.30408342386363074 Scheduler time: 16.230761893675663 Scheduler overhead time: 0.05395304807461798 Adapter cache time: 0.015099167765583843 Engine time: 0.054691702709533274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.671544406039175,
    "estimated_duration": 3600.009856260099,
    "input_throughput": 5116.4615474511675,
    "output_throughput": 4469.589429601124,
    "total_throughput": 9586.050977052291,
    "itl": 97.71777511423517,
    "ttft": 1748248.4603163279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.19507766280326,
    "arrivals": 196768,
    "finished_requests": 74250,
    "scheduler_time": 163.22292048955035
}
#Debug simulation 
Total elapsed time: 10.67164260201389. Arrivals time: 0.2730172230512835 Scheduler time: 10.243573976971675 Scheduler overhead time: 0.05572838115040213 Adapter cache time: 0.01779688009992242 Engine time: 0.05583568359725177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 20.54212988296058,
    "estimated_duration": 3600.0910340975397,
    "input_throughput": 5603.713575275501,
    "output_throughput": 4872.283737790825,
    "total_throughput": 10475.997313066327,
    "itl": 117.85813364022069,
    "ttft": 1642505.1017597504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1688701624795823,
    "arrivals": 196098,
    "finished_requests": 81459,
    "scheduler_time": 151.2472831364643
}
#Debug simulation 
Total elapsed time: 20.542224301956594. Arrivals time: 0.30800355412065983 Scheduler time: 20.090002793178428 Scheduler overhead time: 0.053989542939234525 Adapter cache time: 0.013099998293910176 Engine time: 0.05437148705823347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.288243148010224,
    "estimated_duration": 3600.0607494976775,
    "input_throughput": 5388.253518418166,
    "output_throughput": 4688.109777690541,
    "total_throughput": 10076.363296108708,
    "itl": 107.92742429072875,
    "ttft": 1671400.469630642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9433751389244605,
    "arrivals": 196098,
    "finished_requests": 78329,
    "scheduler_time": 156.58319701755227
}
#Debug simulation 
Total elapsed time: 14.288331867021043. Arrivals time: 0.2969656477216631 Scheduler time: 13.846234697848558 Scheduler overhead time: 0.053454272157978266 Adapter cache time: 0.013547227077651769 Engine time: 0.054262562189251184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.096549829992,
    "estimated_duration": 3600.0850434274007,
    "input_throughput": 5132.7768030746065,
    "output_throughput": 4470.229398991845,
    "total_throughput": 9603.006202066452,
    "itl": 97.76871689227846,
    "ttft": 1730225.8974589584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.2206184131373,
    "arrivals": 196098,
    "finished_requests": 74674,
    "scheduler_time": 162.60970788866578
}
#Debug simulation 
Total elapsed time: 10.096638260001782. Arrivals time: 0.26047137763816863 Scheduler time: 9.681034001754597 Scheduler overhead time: 0.05593325401423499 Adapter cache time: 0.017324139829725027 Engine time: 0.056278055417351425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 14.230274047004059,
    "estimated_duration": 3600.0234417212737,
    "input_throughput": 5449.863957168926,
    "output_throughput": 4734.460004474498,
    "total_throughput": 10184.323961643426,
    "itl": 110.24111072669874,
    "ttft": 1672845.4129305417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1487181107746385,
    "arrivals": 196098,
    "finished_requests": 79186,
    "scheduler_time": 155.0054720569735
}
#Debug simulation 
Total elapsed time: 14.230426265974529. Arrivals time: 0.2820473540923558 Scheduler time: 13.80475819320418 Scheduler overhead time: 0.052789129491429776 Adapter cache time: 0.014255636953748763 Engine time: 0.05289458972401917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.880578646960203,
    "estimated_duration": 3600.075780197711,
    "input_throughput": 5132.426962130576,
    "output_throughput": 4466.346816487556,
    "total_throughput": 9598.773778618131,
    "itl": 97.7667651867789,
    "ttft": 1730441.7962589255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.887441055444096,
    "arrivals": 196098,
    "finished_requests": 74657,
    "scheduler_time": 162.59115891739455
}
#Debug simulation 
Total elapsed time: 9.88066629099194. Arrivals time: 0.25856560992542654 Scheduler time: 9.466265143884812 Scheduler overhead time: 0.05544308276148513 Adapter cache time: 0.018772576295305043 Engine time: 0.05596702604088932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 13.871723885997199,
    "estimated_duration": 3600.0598410289113,
    "input_throughput": 5452.9521360371045,
    "output_throughput": 4737.028480928256,
    "total_throughput": 10189.98061696536,
    "itl": 110.17492651748636,
    "ttft": 1671662.9923506738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.045130288652131,
    "arrivals": 196098,
    "finished_requests": 79231,
    "scheduler_time": 155.0895393633085
}
#Debug simulation 
Total elapsed time: 13.871831892989576. Arrivals time: 0.2845071530318819 Scheduler time: 13.443565181281883 Scheduler overhead time: 0.052818432392086834 Adapter cache time: 0.014490055211354047 Engine time: 0.052940077090170234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.1272556129843,
    "estimated_duration": 3600.0206612317866,
    "input_throughput": 5139.912445299335,
    "output_throughput": 4473.987100532085,
    "total_throughput": 9613.89954583142,
    "itl": 97.79177948250933,
    "ttft": 1730618.4970505256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.331072627585408,
    "arrivals": 196098,
    "finished_requests": 74761,
    "scheduler_time": 162.63152544661952
}
#Debug simulation 
Total elapsed time: 10.127361356979236. Arrivals time: 0.26343594485661015 Scheduler time: 9.70866072550416 Scheduler overhead time: 0.05608386604581028 Adapter cache time: 0.017756267508957535 Engine time: 0.05587738752365112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 19.11980364099145,
    "estimated_duration": 3600.0255915002417,
    "input_throughput": 5581.674210161973,
    "output_throughput": 4880.06725326603,
    "total_throughput": 10461.741463428003,
    "itl": 118.58973165521444,
    "ttft": 1624410.0195884155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 192525,
    "finished_requests": 81436,
    "scheduler_time": 151.01902734195295
}
#Debug simulation 
Total elapsed time: 19.11994716199115. Arrivals time: 0.31521473539760336 Scheduler time: 18.666467342874967 Scheduler overhead time: 0.05281946709146723 Adapter cache time: 0.009955652989447117 Engine time: 0.05285545316291973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.752252687991131,
    "estimated_duration": 3600.056149590782,
    "input_throughput": 5419.197142860573,
    "output_throughput": 4739.081084037903,
    "total_throughput": 10158.278226898476,
    "itl": 110.82978489488555,
    "ttft": 1675666.6819329748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.383053602143196,
    "arrivals": 192525,
    "finished_requests": 78945,
    "scheduler_time": 154.86797504775922
}
#Debug simulation 
Total elapsed time: 14.752372819988523. Arrivals time: 0.28413430257933214 Scheduler time: 14.322974700888153 Scheduler overhead time: 0.05307420273311436 Adapter cache time: 0.014270221057813615 Engine time: 0.054379713139496744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.941206960997079,
    "estimated_duration": 3600.0887072970813,
    "input_throughput": 5109.91325372415,
    "output_throughput": 4475.826100434562,
    "total_throughput": 9585.739354158713,
    "itl": 98.31087770084815,
    "ttft": 1733775.7249163084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.438070630161118,
    "arrivals": 192525,
    "finished_requests": 74446,
    "scheduler_time": 162.41355370024453
}
#Debug simulation 
Total elapsed time: 9.941323167004157. Arrivals time: 0.2697948712739162 Scheduler time: 9.515264461864717 Scheduler overhead time: 0.05537312716478482 Adapter cache time: 0.019577459315769374 Engine time: 0.05576568318065256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 14.969891007000115,
    "estimated_duration": 3600.0485330400325,
    "input_throughput": 5420.539979087833,
    "output_throughput": 4739.657769444371,
    "total_throughput": 10160.197748532204,
    "itl": 110.81594723771791,
    "ttft": 1675567.8362421896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1628836513124368,
    "arrivals": 192525,
    "finished_requests": 78955,
    "scheduler_time": 154.88684855797936
}
#Debug simulation 
Total elapsed time: 14.970055461977609. Arrivals time: 0.2773435839335434 Scheduler time: 14.547162283968646 Scheduler overhead time: 0.05350113532040268 Adapter cache time: 0.014629041193984449 Engine time: 0.054029172053560615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.729459710011724,
    "estimated_duration": 3600.106311996967,
    "input_throughput": 5108.49302941793,
    "output_throughput": 4474.181205794783,
    "total_throughput": 9582.674235212713,
    "itl": 98.22174614878693,
    "ttft": 1734336.5894958563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.975863628201212,
    "arrivals": 192525,
    "finished_requests": 74423,
    "scheduler_time": 162.48357846388228
}
#Debug simulation 
Total elapsed time: 9.729583683016244. Arrivals time: 0.24371961160795763 Scheduler time: 9.33114153414499 Scheduler overhead time: 0.05508128320798278 Adapter cache time: 0.018844053149223328 Engine time: 0.05538052023621276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 19.214853242971003,
    "estimated_duration": 3600.0893140082467,
    "input_throughput": 5370.172324551311,
    "output_throughput": 4699.3092460709,
    "total_throughput": 10069.48157062221,
    "itl": 108.66275446610395,
    "ttft": 1665996.6445964042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4131221155356517,
    "arrivals": 192525,
    "finished_requests": 78312,
    "scheduler_time": 156.34882835740333
}
#Debug simulation 
Total elapsed time: 19.214977116964292. Arrivals time: 0.2975135868182406 Scheduler time: 18.769181890587788 Scheduler overhead time: 0.05499582184711471 Adapter cache time: 0.01354993024142459 Engine time: 0.05578299961052835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.33664770796895,
    "estimated_duration": 3600.0243871541343,
    "input_throughput": 5110.966766129361,
    "output_throughput": 4478.567716799664,
    "total_throughput": 9589.534482929024,
    "itl": 98.43334246103431,
    "ttft": 1733133.7831569696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.307845077551925,
    "arrivals": 192525,
    "finished_requests": 74468,
    "scheduler_time": 162.31625209179836
}
#Debug simulation 
Total elapsed time: 9.336715817975346. Arrivals time: 0.25310829747468233 Scheduler time: 8.928610108967405 Scheduler overhead time: 0.0549568961141631 Adapter cache time: 0.019510512065608054 Engine time: 0.055218297347892076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.164735920960084,
    "estimated_duration": 3600.002660345446,
    "input_throughput": 5590.4550354051125,
    "output_throughput": 4878.2847283548435,
    "total_throughput": 10468.739763759957,
    "itl": 118.23824140027334,
    "ttft": 1615098.8726217556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8397759470576411,
    "arrivals": 191098,
    "finished_requests": 81648,
    "scheduler_time": 150.87487504265982
}
#Debug simulation 
Total elapsed time: 17.164803578983992. Arrivals time: 0.30151184066198766 Scheduler time: 16.72825620434014 Scheduler overhead time: 0.051296528487000614 Adapter cache time: 0.00980885507306084 Engine time: 0.051677893148735166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.392279358988162,
    "estimated_duration": 3600.0412875875004,
    "input_throughput": 5431.78548185601,
    "output_throughput": 4742.553108728764,
    "total_throughput": 10174.338590584774,
    "itl": 110.50523459281212,
    "ttft": 1649522.8982852353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.41617294705473,
    "arrivals": 191098,
    "finished_requests": 79248,
    "scheduler_time": 154.75000474397226
}
#Debug simulation 
Total elapsed time: 17.39235296600964. Arrivals time: 0.29541577224154025 Scheduler time: 16.95251788618043 Scheduler overhead time: 0.05403714015847072 Adapter cache time: 0.011260806466452777 Engine time: 0.0554299833602272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.812213634024374,
    "estimated_duration": 3600.0883778513885,
    "input_throughput": 5118.187129338474,
    "output_throughput": 4471.400229793054,
    "total_throughput": 9589.587359131527,
    "itl": 97.82927836256246,
    "ttft": 1721810.997366164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.275910078957704,
    "arrivals": 191098,
    "finished_requests": 74686,
    "scheduler_time": 162.440743205592
}
#Debug simulation 
Total elapsed time: 9.812280311016366. Arrivals time: 0.26039834087714553 Scheduler time: 9.39773919142317 Scheduler overhead time: 0.055545719515066594 Adapter cache time: 0.017607749032322317 Engine time: 0.055558307096362114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 16.67185366601916,
    "estimated_duration": 3600.0898555205545,
    "input_throughput": 5435.139339645931,
    "output_throughput": 4742.273855698357,
    "total_throughput": 10177.413195344287,
    "itl": 110.54197212010581,
    "ttft": 1664438.3719543046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1461497146170556,
    "arrivals": 191098,
    "finished_requests": 79327,
    "scheduler_time": 154.68439583397605
}
#Debug simulation 
Total elapsed time: 16.671946183021646. Arrivals time: 0.28956780332373455 Scheduler time: 16.238295316463336 Scheduler overhead time: 0.05363340151961893 Adapter cache time: 0.01270966517040506 Engine time: 0.054128456744365394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.032387748011388,
    "estimated_duration": 3600.0317838309784,
    "input_throughput": 5118.698696707165,
    "output_throughput": 4474.210220127389,
    "total_throughput": 9592.908916834554,
    "itl": 98.08998496716958,
    "ttft": 1722683.7531142326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 753,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.601266771685362,
    "arrivals": 191098,
    "finished_requests": 74707,
    "scheduler_time": 162.19635760835985
}
#Debug simulation 
Total elapsed time: 9.032467232027557. Arrivals time: 0.26118463347665966 Scheduler time: 8.617683122109156 Scheduler overhead time: 0.05505279259523377 Adapter cache time: 0.018064138828776777 Engine time: 0.055115325027145445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.47245955397375,
    "estimated_duration": 3600.095599664478,
    "input_throughput": 5433.769314854625,
    "output_throughput": 4741.145485578427,
    "total_throughput": 10174.914800433053,
    "itl": 110.57602917908933,
    "ttft": 1664915.6629340984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8472287394944455,
    "arrivals": 191098,
    "finished_requests": 79306,
    "scheduler_time": 154.66833926325026
}
#Debug simulation 
Total elapsed time: 12.472593740967568. Arrivals time: 0.280656106013339 Scheduler time: 12.050901842187159 Scheduler overhead time: 0.051783976319711655 Adapter cache time: 0.013793094840366393 Engine time: 0.052092454861849546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.285727987007704,
    "estimated_duration": 3600.0373019157582,
    "input_throughput": 5123.157749000342,
    "output_throughput": 4476.072787197212,
    "total_throughput": 9599.230536197554,
    "itl": 98.14071194792197,
    "ttft": 1722223.4639808729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4794416162185655,
    "arrivals": 191098,
    "finished_requests": 74755,
    "scheduler_time": 162.16605973198372
}
#Debug simulation 
Total elapsed time: 9.285793504968751. Arrivals time: 0.2549285117420368 Scheduler time: 8.877442956960294 Scheduler overhead time: 0.054953386657871306 Adapter cache time: 0.018171947333030403 Engine time: 0.05493417335674167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.594358172966167,
    "estimated_duration": 3600.0105622089645,
    "input_throughput": 5581.111680870048,
    "output_throughput": 4877.505411880171,
    "total_throughput": 10458.617092750219,
    "itl": 118.4936876818046,
    "ttft": 1628897.6252162063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9771103005530288,
    "arrivals": 190328,
    "finished_requests": 81519,
    "scheduler_time": 150.66863432888772
}
#Debug simulation 
Total elapsed time: 16.594445809954777. Arrivals time: 0.293068821541965 Scheduler time: 16.16502225707518 Scheduler overhead time: 0.05111619096715003 Adapter cache time: 0.011801278044003993 Engine time: 0.05140476603992283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.092166029033251,
    "estimated_duration": 3600.0659457274924,
    "input_throughput": 5429.06388234241,
    "output_throughput": 4745.764176980234,
    "total_throughput": 10174.828059322645,
    "itl": 110.88007229482493,
    "ttft": 1660570.487296556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8148562053823873,
    "arrivals": 190328,
    "finished_requests": 79299,
    "scheduler_time": 154.3782907460233
}
#Debug simulation 
Total elapsed time: 11.092256985022686. Arrivals time: 0.2689838856458664 Scheduler time: 10.685281618498266 Scheduler overhead time: 0.05100725271040574 Adapter cache time: 0.01271398167591542 Engine time: 0.05117859150050208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.655934640031774,
    "estimated_duration": 3600.0828897915862,
    "input_throughput": 5117.204954429951,
    "output_throughput": 4480.821829336786,
    "total_throughput": 9598.026783766738,
    "itl": 98.40747806180808,
    "ttft": 1721384.4538244195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.466155199133818,
    "arrivals": 190328,
    "finished_requests": 74773,
    "scheduler_time": 161.84787122993546
}
#Debug simulation 
Total elapsed time: 8.655996526009403. Arrivals time: 0.24273296497995034 Scheduler time: 8.261241400497966 Scheduler overhead time: 0.054429731622803956 Adapter cache time: 0.017839649808593094 Engine time: 0.05457448883680627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 11.518657032982446,
    "estimated_duration": 3600.1054608543645,
    "input_throughput": 5435.879090985234,
    "output_throughput": 4751.928849312131,
    "total_throughput": 10187.807940297365,
    "itl": 110.784497121177,
    "ttft": 1661563.771780822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1001493320753752,
    "arrivals": 190328,
    "finished_requests": 79395,
    "scheduler_time": 154.5372489035946
}
#Debug simulation 
Total elapsed time: 11.518742421001662. Arrivals time: 0.2724835068802349 Scheduler time: 11.10609372262843 Scheduler overhead time: 0.051607444416731596 Adapter cache time: 0.013817795144859701 Engine time: 0.05147152574500069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.562942470016424,
    "estimated_duration": 3600.092400943844,
    "input_throughput": 5123.830431453343,
    "output_throughput": 4486.389014839049,
    "total_throughput": 9610.219446292393,
    "itl": 98.59779173587305,
    "ttft": 1720702.9290274375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0053554247506264,
    "arrivals": 190328,
    "finished_requests": 74896,
    "scheduler_time": 161.7033820014052
}
#Debug simulation 
Total elapsed time: 8.563032120000571. Arrivals time: 0.24424982379423454 Scheduler time: 8.166377080022357 Scheduler overhead time: 0.0546645856811665 Adapter cache time: 0.017418968258425593 Engine time: 0.054916966939345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 11.35510142100975,
    "estimated_duration": 3600.072730464826,
    "input_throughput": 5430.992778158549,
    "output_throughput": 4747.13298300321,
    "total_throughput": 10178.12576116176,
    "itl": 110.89753067078101,
    "ttft": 1660575.2184189109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4514256411790747,
    "arrivals": 190328,
    "finished_requests": 79321,
    "scheduler_time": 154.37296767331438
}
#Debug simulation 
Total elapsed time: 11.355166518012993. Arrivals time: 0.2703450358239934 Scheduler time: 10.945545244961977 Scheduler overhead time: 0.051264755544252694 Adapter cache time: 0.012878421635832638 Engine time: 0.05196882539894432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.518806429987308,
    "estimated_duration": 3600.0977754524606,
    "input_throughput": 5125.108302837994,
    "output_throughput": 4486.3725952471095,
    "total_throughput": 9611.480898085103,
    "itl": 98.59261238569945,
    "ttft": 1720397.9944098247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.316475894302161,
    "arrivals": 190328,
    "finished_requests": 74900,
    "scheduler_time": 161.70440806094433
}
#Debug simulation 
Total elapsed time: 8.518947308999486. Arrivals time: 0.24846318631898612 Scheduler time: 8.117567005800083 Scheduler overhead time: 0.054790357302408665 Adapter cache time: 0.017838794214185327 Engine time: 0.0550129622570239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.540083685016725,
    "estimated_duration": 3600.046766788012,
    "input_throughput": 5595.720362814449,
    "output_throughput": 4876.546372108218,
    "total_throughput": 10472.266734922667,
    "itl": 118.20172555749228,
    "ttft": 1611577.235411843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7273649935144924,
    "arrivals": 188114,
    "finished_requests": 81554,
    "scheduler_time": 150.54716901343312
}
#Debug simulation 
Total elapsed time: 12.540178268041927. Arrivals time: 0.27628137182909995 Scheduler time: 12.133892654208466 Scheduler overhead time: 0.049224102462176234 Adapter cache time: 0.009237157995812595 Engine time: 0.049422227195464075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.497884776967112,
    "estimated_duration": 3600.07062724286,
    "input_throughput": 5431.91732184892,
    "output_throughput": 4739.345909184854,
    "total_throughput": 10171.263231033774,
    "itl": 110.49308831759957,
    "ttft": 1652256.0985568347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.287842494277288,
    "arrivals": 188114,
    "finished_requests": 79230,
    "scheduler_time": 154.36400004688159
}
#Debug simulation 
Total elapsed time: 10.497951922006905. Arrivals time: 0.4904598572757095 Scheduler time: 9.868726347689517 Scheduler overhead time: 0.050765202089678496 Adapter cache time: 0.01359171885997057 Engine time: 0.05108800792368129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.4378011910012,
    "estimated_duration": 3600.0530364374526,
    "input_throughput": 5123.463686038521,
    "output_throughput": 4473.562705047612,
    "total_throughput": 9597.026391086132,
    "itl": 97.99988375144787,
    "ttft": 1713541.078096684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.426539624333414,
    "arrivals": 188114,
    "finished_requests": 74743,
    "scheduler_time": 161.91213131836312
}
#Debug simulation 
Total elapsed time: 8.437877552991267. Arrivals time: 0.23128489538794383 Scheduler time: 8.054771557683125 Scheduler overhead time: 0.054988706193398684 Adapter cache time: 0.01650830142898485 Engine time: 0.05493613670114428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 10.149642218020745,
    "estimated_duration": 3600.0905860720554,
    "input_throughput": 5431.768877053643,
    "output_throughput": 4738.351325379282,
    "total_throughput": 10170.120202432925,
    "itl": 110.49773384560316,
    "ttft": 1652221.9279044126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.976909429305229,
    "arrivals": 188114,
    "finished_requests": 79208,
    "scheduler_time": 154.36716164268594
}
#Debug simulation 
Total elapsed time: 10.149732388032135. Arrivals time: 0.2622142652980983 Scheduler time: 9.749490227433853 Scheduler overhead time: 0.05068718479014933 Adapter cache time: 0.013167506142053753 Engine time: 0.05098348006140441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.468650871014688,
    "estimated_duration": 3600.075515467413,
    "input_throughput": 5118.33180188378,
    "output_throughput": 4472.835619924305,
    "total_throughput": 9591.167421808084,
    "itl": 97.94759850901208,
    "ttft": 1713816.7716540985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.258179159238966,
    "arrivals": 188114,
    "finished_requests": 74707,
    "scheduler_time": 161.96099140058024
}
#Debug simulation 
Total elapsed time: 8.468739782983903. Arrivals time: 0.24724177620373666 Scheduler time: 8.070231302292086 Scheduler overhead time: 0.05474694474833086 Adapter cache time: 0.01614458143012598 Engine time: 0.055109718116000295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.451599297055509,
    "estimated_duration": 3600.1114033238514,
    "input_throughput": 5429.2081022698685,
    "output_throughput": 4737.290902790938,
    "total_throughput": 10166.499005060807,
    "itl": 110.4441497517087,
    "ttft": 1652277.554321007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8599965813755865,
    "arrivals": 188114,
    "finished_requests": 79189,
    "scheduler_time": 154.40237493794282
}
#Debug simulation 
Total elapsed time: 10.451693339040503. Arrivals time: 0.2639719973085448 Scheduler time: 10.048155743221287 Scheduler overhead time: 0.05102335149422288 Adapter cache time: 0.013748491066507995 Engine time: 0.05153669259743765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.43080957600614,
    "estimated_duration": 3600.089223799998,
    "input_throughput": 5129.656753481047,
    "output_throughput": 4479.508422565671,
    "total_throughput": 9609.165176046718,
    "itl": 98.19605057668514,
    "ttft": 1713405.488158634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.628211955297768,
    "arrivals": 188114,
    "finished_requests": 74851,
    "scheduler_time": 161.75404278588357
}
#Debug simulation 
Total elapsed time: 8.430905245011672. Arrivals time: 0.24966040783328936 Scheduler time: 8.029484438011423 Scheduler overhead time: 0.05490193911828101 Adapter cache time: 0.01654137158766389 Engine time: 0.05488086474360898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.65014720900217,
    "estimated_duration": 3600.0196080045043,
    "input_throughput": 5592.573150222355,
    "output_throughput": 4874.003730698027,
    "total_throughput": 10466.576880920382,
    "itl": 118.20335877826575,
    "ttft": 1621710.3339015478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7919628476584308,
    "arrivals": 187444,
    "finished_requests": 81387,
    "scheduler_time": 150.38788820105086
}
#Debug simulation 
Total elapsed time: 12.65029996400699. Arrivals time: 0.27962754026521 Scheduler time: 12.238176226324867 Scheduler overhead time: 0.04937965131830424 Adapter cache time: 0.011397129099350423 Engine time: 0.04966785776196048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.856616172008216,
    "estimated_duration": 3600.074266036738,
    "input_throughput": 5436.286741258098,
    "output_throughput": 4739.871107932823,
    "total_throughput": 10176.157849190922,
    "itl": 110.5727832666298,
    "ttft": 1652465.5901875896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.597519562598321,
    "arrivals": 187444,
    "finished_requests": 79152,
    "scheduler_time": 154.1536178079644
}
#Debug simulation 
Total elapsed time: 9.856696506030858. Arrivals time: 0.2460141558549367 Scheduler time: 9.473320652265102 Scheduler overhead time: 0.050910918856970966 Adapter cache time: 0.012537534581497312 Engine time: 0.050886812910903245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.027229742030613,
    "estimated_duration": 3600.001419085339,
    "input_throughput": 5133.123254350013,
    "output_throughput": 4480.219345051781,
    "total_throughput": 9613.342599401794,
    "itl": 98.25913039764337,
    "ttft": 1711442.3494968272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9837594645796686,
    "arrivals": 187444,
    "finished_requests": 74693,
    "scheduler_time": 161.5845069847301
}
#Debug simulation 
Total elapsed time: 8.027325297996867. Arrivals time: 0.23939668369712308 Scheduler time: 7.637544187367894 Scheduler overhead time: 0.05481874942779541 Adapter cache time: 0.015449260419700295 Engine time: 0.05472201097290963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 9.963895833992865,
    "estimated_duration": 3600.111671485329,
    "input_throughput": 5436.41886306408,
    "output_throughput": 4740.09657399305,
    "total_throughput": 10176.51543705713,
    "itl": 110.57837637016816,
    "ttft": 1652106.5973243902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.447865550601852,
    "arrivals": 187444,
    "finished_requests": 79155,
    "scheduler_time": 154.15631256761122
}
#Debug simulation 
Total elapsed time: 9.963993060984649. Arrivals time: 0.2614990980946459 Scheduler time: 9.565721763297915 Scheduler overhead time: 0.050538232433609664 Adapter cache time: 0.012372165860142559 Engine time: 0.05082633951678872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.944472639996093,
    "estimated_duration": 3600.0342675222046,
    "input_throughput": 5127.016474958084,
    "output_throughput": 4476.860163637482,
    "total_throughput": 9603.876638595566,
    "itl": 98.14559214265708,
    "ttft": 1711348.1189240105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.250153099582564,
    "arrivals": 187444,
    "finished_requests": 74611,
    "scheduler_time": 161.66430320285303
}
#Debug simulation 
Total elapsed time: 7.944587003963534. Arrivals time: 0.2394026771071367 Scheduler time: 7.5547225142945535 Scheduler overhead time: 0.05470412928843871 Adapter cache time: 0.015742763062007725 Engine time: 0.05476752365939319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.04427857598057,
    "estimated_duration": 3600.0131366101873,
    "input_throughput": 5439.656539264581,
    "output_throughput": 4741.228254536836,
    "total_throughput": 10180.884793801417,
    "itl": 110.61676332917442,
    "ttft": 1652698.5089245287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3620507480110877,
    "arrivals": 187444,
    "finished_requests": 79177,
    "scheduler_time": 154.12823235414527
}
#Debug simulation 
Total elapsed time: 10.044395899982192. Arrivals time: 0.2598185548558831 Scheduler time: 9.647140100423712 Scheduler overhead time: 0.05072510050376877 Adapter cache time: 0.012654774589464068 Engine time: 0.05084940401138738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.982911577040795,
    "estimated_duration": 3600.071309221103,
    "input_throughput": 5126.027351939494,
    "output_throughput": 4476.473273938207,
    "total_throughput": 9602.500625877701,
    "itl": 98.16971807597932,
    "ttft": 1711162.8153624122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.182744479291175,
    "arrivals": 187444,
    "finished_requests": 74608,
    "scheduler_time": 161.66272890280902
}
#Debug simulation 
Total elapsed time: 7.9829989389982074. Arrivals time: 0.25830645399400964 Scheduler time: 7.573439989704639 Scheduler overhead time: 0.054742790933232754 Adapter cache time: 0.016133896075189114 Engine time: 0.054991791665088385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.667390915972646,
    "estimated_duration": 3600.0624883498267,
    "input_throughput": 5592.286540900639,
    "output_throughput": 4877.690333661134,
    "total_throughput": 10469.976874561773,
    "itl": 118.47180153251848,
    "ttft": 1621747.1051603083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.49949061407709,
    "arrivals": 185958,
    "finished_requests": 81494,
    "scheduler_time": 150.17231113725006
}
#Debug simulation 
Total elapsed time: 10.667491143976804. Arrivals time: 0.24996283964719623 Scheduler time: 10.287791264301632 Scheduler overhead time: 0.04782503983005881 Adapter cache time: 0.012172712595202029 Engine time: 0.048044329741969705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.59905506495852,
    "estimated_duration": 3600.0280703153007,
    "input_throughput": 5432.878471496754,
    "output_throughput": 4741.549139783509,
    "total_throughput": 10174.427611280264,
    "itl": 110.74074633792269,
    "ttft": 1650561.3834970472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6930045235855538,
    "arrivals": 185958,
    "finished_requests": 79163,
    "scheduler_time": 154.01846738695085
}
#Debug simulation 
Total elapsed time: 8.599148781970143. Arrivals time: 0.25571205897722393 Scheduler time: 8.207726698776241 Scheduler overhead time: 0.049986676836851984 Adapter cache time: 0.012380818778183311 Engine time: 0.05044145241845399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.702580185024999,
    "estimated_duration": 3600.1025916038425,
    "input_throughput": 5134.507567398256,
    "output_throughput": 4479.101800489587,
    "total_throughput": 9613.609367887842,
    "itl": 98.36378309949671,
    "ttft": 1710322.702825777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.506832399470764,
    "arrivals": 185958,
    "finished_requests": 74764,
    "scheduler_time": 161.49546462344273
}
#Debug simulation 
Total elapsed time: 6.7027047270094045. Arrivals time: 0.23245866008801386 Scheduler time: 6.320955184986815 Scheduler overhead time: 0.05399820668390021 Adapter cache time: 0.016172606265172362 Engine time: 0.05396534950705245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.318422903947067,
    "estimated_duration": 3600.0165676890324,
    "input_throughput": 5432.8036086109,
    "output_throughput": 4742.518174287127,
    "total_throughput": 10175.321782898027,
    "itl": 110.75043952196197,
    "ttft": 1650521.4037448473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5963672840129552,
    "arrivals": 185958,
    "finished_requests": 79180,
    "scheduler_time": 154.01576243692085
}
#Debug simulation 
Total elapsed time: 8.31854113197187. Arrivals time: 0.2495556324138306 Scheduler time: 7.933034723624587 Scheduler overhead time: 0.05019431049004197 Adapter cache time: 0.01266504026716575 Engine time: 0.050116502039600164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.279787476989441,
    "estimated_duration": 3600.011534474684,
    "input_throughput": 5133.271608446829,
    "output_throughput": 4480.5525886609985,
    "total_throughput": 9613.824197107828,
    "itl": 98.37204264543574,
    "ttft": 1710341.2827993429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.105255447984708,
    "arrivals": 185958,
    "finished_requests": 74758,
    "scheduler_time": 161.49860020372253
}
#Debug simulation 
Total elapsed time: 7.279862812021747. Arrivals time: 0.24990885180886835 Scheduler time: 6.879762114025652 Scheduler overhead time: 0.05451546877156943 Adapter cache time: 0.015785570431035012 Engine time: 0.05453321221284568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.325530400965363,
    "estimated_duration": 3600.0829295955027,
    "input_throughput": 5429.682144071135,
    "output_throughput": 4740.08080750444,
    "total_throughput": 10169.762951575574,
    "itl": 110.62081689999042,
    "ttft": 1649954.4477362304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.381202510832799,
    "arrivals": 185958,
    "finished_requests": 79124,
    "scheduler_time": 154.10415218546964
}
#Debug simulation 
Total elapsed time: 8.325650488957763. Arrivals time: 0.25117466575466096 Scheduler time: 7.938656469457783 Scheduler overhead time: 0.050201722828205675 Adapter cache time: 0.012388415983878076 Engine time: 0.050133128475863487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.132476204016712,
    "estimated_duration": 3600.0413230876748,
    "input_throughput": 5074.452307767329,
    "output_throughput": 4432.789395404214,
    "total_throughput": 9507.241703171543,
    "itl": 96.37946621421692,
    "ttft": 1717138.270451335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7488703581318568,
    "arrivals": 185958,
    "finished_requests": 73947,
    "scheduler_time": 163.07828183984023
}
#Debug simulation 
Total elapsed time: 7.132577555021271. Arrivals time: 0.22381036583101377 Scheduler time: 6.756740945857018 Scheduler overhead time: 0.05542084906483069 Adapter cache time: 0.015360871970187873 Engine time: 0.055499156296718866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 37.412629378028214,
    "estimated_duration": 3600.059856132798,
    "input_throughput": 5611.424478286456,
    "output_throughput": 4881.684111463207,
    "total_throughput": 10493.108589749663,
    "itl": 115.58683093065605,
    "ttft": 1294778.5556399252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6052891585882922,
    "arrivals": 126417,
    "finished_requests": 81400,
    "scheduler_time": 135.21274197709616
}
#Debug simulation 
Total elapsed time: 37.41274794499623. Arrivals time: 0.32484016474336386 Scheduler time: 36.93088939343579 Scheduler overhead time: 0.058799996972084045 Adapter cache time: 0.014621735143009573 Engine time: 0.059424888575449586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.04632995801512,
    "estimated_duration": 3600.051619477653,
    "input_throughput": 5430.62213170062,
    "output_throughput": 4744.217529435905,
    "total_throughput": 10174.839661136526,
    "itl": 108.67827706295493,
    "ttft": 1380380.7171709582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.14063413179946,
    "arrivals": 126417,
    "finished_requests": 79058,
    "scheduler_time": 138.71813587454693
}
#Debug simulation 
Total elapsed time: 25.046438043995295. Arrivals time: 0.29671512957429513 Scheduler time: 24.592661530012265 Scheduler overhead time: 0.056988093885593116 Adapter cache time: 0.01822064514271915 Engine time: 0.05727516574552283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.797542913001962,
    "estimated_duration": 3600.002472929056,
    "input_throughput": 5122.21981475383,
    "output_throughput": 4478.100257215488,
    "total_throughput": 9600.32007196932,
    "itl": 97.04788499647663,
    "ttft": 1459408.5544211501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.135838302546207,
    "arrivals": 126417,
    "finished_requests": 74519,
    "scheduler_time": 146.02108648422774
}
#Debug simulation 
Total elapsed time: 18.797720872040372. Arrivals time: 0.28327197255566716 Scheduler time: 18.345791317231487 Scheduler overhead time: 0.06028868298744783 Adapter cache time: 0.02014449395937845 Engine time: 0.06147697434062138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 32.16484375798609,
    "estimated_duration": 3600.0781165959384,
    "input_throughput": 5439.052811030354,
    "output_throughput": 4741.791274279723,
    "total_throughput": 10180.844085310076,
    "itl": 108.77969339017886,
    "ttft": 1381250.5171554005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.144354879749001,
    "arrivals": 126417,
    "finished_requests": 79070,
    "scheduler_time": 138.59258833979027
}
#Debug simulation 
Total elapsed time: 32.164959613990504. Arrivals time: 0.2950833057402633 Scheduler time: 31.708950462460052 Scheduler overhead time: 0.0593651351518929 Adapter cache time: 0.0171172734699212 Engine time: 0.05959588260157034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 15.388035117008258,
    "estimated_duration": 3600.075548957477,
    "input_throughput": 5124.408293415485,
    "output_throughput": 4477.46520338104,
    "total_throughput": 9601.873496796525,
    "itl": 97.20773876815151,
    "ttft": 1460288.4371123551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.3695325769018645,
    "arrivals": 126417,
    "finished_requests": 74541,
    "scheduler_time": 145.72263443686757
}
#Debug simulation 
Total elapsed time: 15.388127726968378. Arrivals time: 0.2639449901180342 Scheduler time: 14.958167030999903 Scheduler overhead time: 0.058661371120251715 Adapter cache time: 0.021889579656999558 Engine time: 0.059182170196436346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 22.360640238970518,
    "estimated_duration": 3600.0570936826293,
    "input_throughput": 5451.259379868621,
    "output_throughput": 4744.729196093644,
    "total_throughput": 10195.988575962265,
    "itl": 108.37965648555215,
    "ttft": 1374963.0222992655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3219144767662305,
    "arrivals": 126417,
    "finished_requests": 79151,
    "scheduler_time": 138.8358951158348
}
#Debug simulation 
Total elapsed time: 22.36077262699837. Arrivals time: 0.29350071551743895 Scheduler time: 21.91515005781548 Scheduler overhead time: 0.05545875267125666 Adapter cache time: 0.016909825208131224 Engine time: 0.05543292168295011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.987999682023656,
    "estimated_duration": 3600.062110567291,
    "input_throughput": 5117.603928532452,
    "output_throughput": 4475.674170371742,
    "total_throughput": 9593.278098904195,
    "itl": 97.00629474569676,
    "ttft": 1455717.2751677705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 967,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.125736714359397,
    "arrivals": 126417,
    "finished_requests": 74446,
    "scheduler_time": 146.02034339667097
}
#Debug simulation 
Total elapsed time: 17.988149487995543. Arrivals time: 0.2828760637785308 Scheduler time: 17.53551852836972 Scheduler overhead time: 0.059843264461960644 Adapter cache time: 0.02222365519264713 Engine time: 0.06101057259365916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.938329552998766,
    "estimated_duration": 3600.1235548538016,
    "input_throughput": 5659.70381003422,
    "output_throughput": 4879.982792899853,
    "total_throughput": 10539.686602934073,
    "itl": 116.75132156792328,
    "ttft": 1288155.7487567784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.767546912035991,
    "arrivals": 120741,
    "finished_requests": 82200,
    "scheduler_time": 129.94109860544273
}
#Debug simulation 
Total elapsed time: 24.938480737968348. Arrivals time: 0.30089055409189314 Scheduler time: 24.490204719651956 Scheduler overhead time: 0.0530751773621887 Adapter cache time: 0.017783269460778683 Engine time: 0.05344843119382858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.03629074501805,
    "estimated_duration": 3600.050482003307,
    "input_throughput": 5495.419883387576,
    "output_throughput": 4748.423136135428,
    "total_throughput": 10243.843019523003,
    "itl": 109.33835690068018,
    "ttft": 1327162.503246643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.961601014658815,
    "arrivals": 120741,
    "finished_requests": 79871,
    "scheduler_time": 134.0009815370603
}
#Debug simulation 
Total elapsed time: 25.036383380007464. Arrivals time: 0.30873639695346355 Scheduler time: 24.569590137223713 Scheduler overhead time: 0.05776857677847147 Adapter cache time: 0.017779012152459472 Engine time: 0.05787199304904789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.421745009021834,
    "estimated_duration": 3600.0448072884824,
    "input_throughput": 5198.735294102204,
    "output_throughput": 4492.910468017926,
    "total_throughput": 9691.64576212013,
    "itl": 97.47456949542001,
    "ttft": 1406683.3331596996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.406242392393779,
    "arrivals": 120741,
    "finished_requests": 75497,
    "scheduler_time": 141.7606551347955
}
#Debug simulation 
Total elapsed time: 14.421833080006763. Arrivals time: 0.27433166542323306 Scheduler time: 13.983169287792407 Scheduler overhead time: 0.05782624863786623 Adapter cache time: 0.022232073359191418 Engine time: 0.05828935204772279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 30.68917454802431,
    "estimated_duration": 3600.0536144740636,
    "input_throughput": 5503.377205368211,
    "output_throughput": 4749.201770568014,
    "total_throughput": 10252.578975936225,
    "itl": 109.12641506382613,
    "ttft": 1327875.1334724675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9395122257247506,
    "arrivals": 120741,
    "finished_requests": 79925,
    "scheduler_time": 134.10201637089082
}
#Debug simulation 
Total elapsed time: 30.689412717998493. Arrivals time: 0.31916288542561233 Scheduler time: 30.208091743756086 Scheduler overhead time: 0.06013856903882697 Adapter cache time: 0.016799503762740642 Engine time: 0.059898509876802564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.323214407020714,
    "estimated_duration": 3600.032793867395,
    "input_throughput": 5191.91464917763,
    "output_throughput": 4494.65572301562,
    "total_throughput": 9686.570372193251,
    "itl": 97.53141634474808,
    "ttft": 1406144.8580501266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1070,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.9456073983339754,
    "arrivals": 120741,
    "finished_requests": 75488,
    "scheduler_time": 141.71995930440787
}
#Debug simulation 
Total elapsed time: 14.323304029006977. Arrivals time: 0.26954699942143634 Scheduler time: 13.888143894844688 Scheduler overhead time: 0.05779275804525241 Adapter cache time: 0.023175947251729667 Engine time: 0.058611422893591225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.181310590007342,
    "estimated_duration": 3600.115819932206,
    "input_throughput": 5508.867489816888,
    "output_throughput": 4756.076986523849,
    "total_throughput": 10264.944476340737,
    "itl": 109.49594388907377,
    "ttft": 1326580.6162079026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.57727131438905,
    "arrivals": 120741,
    "finished_requests": 80065,
    "scheduler_time": 133.86018706395245
}
#Debug simulation 
Total elapsed time: 24.181418721040245. Arrivals time: 0.3060769042931497 Scheduler time: 23.7185658494127 Scheduler overhead time: 0.05681608454324305 Adapter cache time: 0.01824893004959449 Engine time: 0.057247751974500716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.099026783020236,
    "estimated_duration": 3600.006352058397,
    "input_throughput": 5197.7461065592215,
    "output_throughput": 4493.725404331614,
    "total_throughput": 9691.471510890835,
    "itl": 97.51782133857094,
    "ttft": 1406383.7416928005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.161357096694438,
    "arrivals": 120741,
    "finished_requests": 75496,
    "scheduler_time": 141.72814715097346
}
#Debug simulation 
Total elapsed time: 14.099127741006669. Arrivals time: 0.27198100317036733 Scheduler time: 13.66324715752853 Scheduler overhead time: 0.05816810793476179 Adapter cache time: 0.021160590404178947 Engine time: 0.058522499282844365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 29.177482018014416,
    "estimated_duration": 3600.007661505565,
    "input_throughput": 5579.4467369549375,
    "output_throughput": 4873.976849444234,
    "total_throughput": 10453.423586399173,
    "itl": 116.61961528452066,
    "ttft": 1272094.3627003205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.724312521163395,
    "arrivals": 117840,
    "finished_requests": 81435,
    "scheduler_time": 128.20786069643455
}
#Debug simulation 
Total elapsed time: 29.177644507028162. Arrivals time: 0.31624697911320254 Scheduler time: 28.712480563961435 Scheduler overhead time: 0.05521352106006816 Adapter cache time: 0.013975781504996121 Engine time: 0.056158897932618856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 23.102415025990922,
    "estimated_duration": 3600.084469096633,
    "input_throughput": 5456.786686155028,
    "output_throughput": 4768.074234743532,
    "total_throughput": 10224.86092089856,
    "itl": 109.43031264834997,
    "ttft": 1305409.222400046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6027979837125255,
    "arrivals": 117840,
    "finished_requests": 79731,
    "scheduler_time": 131.9926127472923
}
#Debug simulation 
Total elapsed time: 23.102532189979684. Arrivals time: 0.30702070059487596 Scheduler time: 22.637861012131907 Scheduler overhead time: 0.05632853490533307 Adapter cache time: 0.019365518644917756 Engine time: 0.0573073496343568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.23783454601653,
    "estimated_duration": 3600.006009800744,
    "input_throughput": 5145.048910911452,
    "output_throughput": 4501.998873301061,
    "total_throughput": 9647.047784212515,
    "itl": 97.54519952033117,
    "ttft": 1390328.4473555326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.701810619560991,
    "arrivals": 117840,
    "finished_requests": 75129,
    "scheduler_time": 139.99277549205001
}
#Debug simulation 
Total elapsed time: 13.237921871012077. Arrivals time: 0.2654677290120162 Scheduler time: 12.807320531690493 Scheduler overhead time: 0.05723630212014541 Adapter cache time: 0.02401166030904278 Engine time: 0.05790873582009226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 21.9759056410403,
    "estimated_duration": 3600.0826851759393,
    "input_throughput": 5443.101093396788,
    "output_throughput": 4759.443740154715,
    "total_throughput": 10202.544833551503,
    "itl": 109.57212955286661,
    "ttft": 1313157.55617411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0336842507542965,
    "arrivals": 117840,
    "finished_requests": 79458,
    "scheduler_time": 131.99050024147115
}
#Debug simulation 
Total elapsed time: 21.976002639043145. Arrivals time: 0.2911417745053768 Scheduler time: 21.529755888564978 Scheduler overhead time: 0.055741607036907226 Adapter cache time: 0.0185537010547705 Engine time: 0.05646654294105247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.377906280977186,
    "estimated_duration": 3600.023685655378,
    "input_throughput": 5141.116174803896,
    "output_throughput": 4493.36071439073,
    "total_throughput": 9634.476889194626,
    "itl": 97.49685030158327,
    "ttft": 1394252.981617043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.647647022972796,
    "arrivals": 117840,
    "finished_requests": 75020,
    "scheduler_time": 140.09672471147596
}
#Debug simulation 
Total elapsed time: 13.378065075026825. Arrivals time: 0.27827732102014124 Scheduler time: 12.930882020154968 Scheduler overhead time: 0.058908245991915464 Adapter cache time: 0.024371014325879514 Engine time: 0.05936229374492541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.78812545503024,
    "estimated_duration": 3600.0505570945165,
    "input_throughput": 5424.657429189342,
    "output_throughput": 4742.070904075861,
    "total_throughput": 10166.728333265202,
    "itl": 109.18498017940642,
    "ttft": 1309640.0835408517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2708431092416665,
    "arrivals": 117840,
    "finished_requests": 79196,
    "scheduler_time": 132.42473086779864
}
#Debug simulation 
Total elapsed time: 25.788277523010038. Arrivals time: 0.2990186613169499 Scheduler time: 25.33303197362693 Scheduler overhead time: 0.05627884162822738 Adapter cache time: 0.018204228254035115 Engine time: 0.057133904250804335 
