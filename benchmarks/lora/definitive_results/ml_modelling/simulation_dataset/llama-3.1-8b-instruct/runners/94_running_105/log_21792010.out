INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 22.079553336370736,
    "estimated_duration": 3599.9055254215805,
    "input_throughput": 4906.027359685145,
    "output_throughput": 4301.974285335272,
    "total_throughput": 9208.001645020417,
    "itl": 56.49610768556413,
    "ttft": 201044.06879068137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.354525079704027,
    "arrivals": 73678,
    "finished_requests": 71303,
    "scheduler_time": 68.68677621764887
}
#Debug simulation 
Total elapsed time: 22.079661588184536. Arrivals time: 0.19653794215992093 Scheduler time: 21.64219548832625 Scheduler overhead time: 0.09261073265224695 Adapter cache time: 0.02088357089087367 Engine time: 0.08716201828792691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 21.87440441409126,
    "estimated_duration": 3599.900342765592,
    "input_throughput": 4911.340125159475,
    "output_throughput": 4315.149176620278,
    "total_throughput": 9226.489301779753,
    "itl": 56.200131487544134,
    "ttft": 194512.07939946963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.170522959246311,
    "arrivals": 73678,
    "finished_requests": 71412,
    "scheduler_time": 68.49348439938541
}
#Debug simulation 
Total elapsed time: 21.874568754807115. Arrivals time: 0.20156739512458444 Scheduler time: 21.430411859881133 Scheduler overhead time: 0.09409688971936703 Adapter cache time: 0.021139902994036674 Engine time: 0.08693191362544894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 22.264737077988684,
    "estimated_duration": 3599.856808526386,
    "input_throughput": 4897.154508547387,
    "output_throughput": 4305.71681720445,
    "total_throughput": 9202.871325751838,
    "itl": 55.9482207966868,
    "ttft": 204981.41082570294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.093615323817379,
    "arrivals": 73678,
    "finished_requests": 71199,
    "scheduler_time": 68.7007923869012
}
#Debug simulation 
Total elapsed time: 22.264958443585783. Arrivals time: 0.20174693828448653 Scheduler time: 21.818991558160633 Scheduler overhead time: 0.09464573673903942 Adapter cache time: 0.02123112790286541 Engine time: 0.08788625802844763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 21.788216879125684,
    "estimated_duration": 3599.896238658172,
    "input_throughput": 4911.345724395152,
    "output_throughput": 4315.154096160893,
    "total_throughput": 9226.499820556044,
    "itl": 56.185214323387136,
    "ttft": 194505.47565146282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.699916049293231,
    "arrivals": 73678,
    "finished_requests": 71412,
    "scheduler_time": 68.4934892661712
}
#Debug simulation 
Total elapsed time: 21.788337822072208. Arrivals time: 0.19907607743516564 Scheduler time: 21.34576367912814 Scheduler overhead time: 0.09424488246440887 Adapter cache time: 0.02128972439095378 Engine time: 0.08737605530768633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 21.06868324195966,
    "estimated_duration": 3599.8803371353865,
    "input_throughput": 4927.227946169623,
    "output_throughput": 4325.80989966788,
    "total_throughput": 9253.037845837503,
    "itl": 56.58274551328288,
    "ttft": 181310.8647858384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.3518231614260205,
    "arrivals": 73678,
    "finished_requests": 71620,
    "scheduler_time": 68.01195564020566
}
#Debug simulation 
Total elapsed time: 21.06877965386957. Arrivals time: 0.1999617163091898 Scheduler time: 20.629308216273785 Scheduler overhead time: 0.09221718413755298 Adapter cache time: 0.020948684308677912 Engine time: 0.08627526555210352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 22.72516543464735,
    "estimated_duration": 3599.853310913053,
    "input_throughput": 4901.469442243661,
    "output_throughput": 4307.545241632911,
    "total_throughput": 9209.014683876572,
    "itl": 55.60039759901758,
    "ttft": 205530.98162419526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.007269605076842,
    "arrivals": 73678,
    "finished_requests": 71261,
    "scheduler_time": 69.17748034724066
}
#Debug simulation 
Total elapsed time: 22.725307958666235. Arrivals time: 0.20556897716596723 Scheduler time: 22.272543960250914 Scheduler overhead time: 0.0951290326192975 Adapter cache time: 0.021056757774204016 Engine time: 0.09081625286489725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 21.783018027897924,
    "estimated_duration": 3599.9042513069257,
    "input_throughput": 4911.334792746571,
    "output_throughput": 4315.144491512636,
    "total_throughput": 9226.479284259207,
    "itl": 56.20195474498158,
    "ttft": 194513.12021394097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.228393655028215,
    "arrivals": 73678,
    "finished_requests": 71412,
    "scheduler_time": 68.49356816464753
}
#Debug simulation 
Total elapsed time: 21.783183694817126. Arrivals time: 0.199378767516464 Scheduler time: 21.343951092101634 Scheduler overhead time: 0.09195561893284321 Adapter cache time: 0.020975337363779545 Engine time: 0.0866742106154561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 18.176088847219944,
    "estimated_duration": 3600.06536287328,
    "input_throughput": 4831.494222126502,
    "output_throughput": 4191.190847701037,
    "total_throughput": 9022.685069827538,
    "itl": 53.853931973176934,
    "ttft": 150215.32513976187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.392673297720201,
    "arrivals": 71837,
    "finished_requests": 70214,
    "scheduler_time": 63.104259017131874
}
#Debug simulation 
Total elapsed time: 18.17620759597048. Arrivals time: 0.18972725979983807 Scheduler time: 17.742749923374504 Scheduler overhead time: 0.09327491093426943 Adapter cache time: 0.021837202832102776 Engine time: 0.08762869844213128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 18.069442986045033,
    "estimated_duration": 3600.016667349294,
    "input_throughput": 4822.385728781285,
    "output_throughput": 4187.317280144524,
    "total_throughput": 9009.70300892581,
    "itl": 53.97612016304753,
    "ttft": 156308.7560787962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.161456836741426,
    "arrivals": 71837,
    "finished_requests": 70083,
    "scheduler_time": 63.00955541063943
}
#Debug simulation 
Total elapsed time: 18.06953709386289. Arrivals time: 0.19261241238564253 Scheduler time: 17.632299918215722 Scheduler overhead time: 0.09421579027548432 Adapter cache time: 0.022068653255701065 Engine time: 0.08778175106272101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 18.08359644981101,
    "estimated_duration": 3600.0190502189034,
    "input_throughput": 4822.382536821399,
    "output_throughput": 4187.314508539443,
    "total_throughput": 9009.697045360843,
    "itl": 53.98274686320713,
    "ttft": 156360.63529155173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.382348325406202,
    "arrivals": 71837,
    "finished_requests": 70083,
    "scheduler_time": 63.010242072515595
}
#Debug simulation 
Total elapsed time: 18.083695721812546. Arrivals time: 0.19214901607483625 Scheduler time: 17.64964221790433 Scheduler overhead time: 0.09233194682747126 Adapter cache time: 0.02186684124171734 Engine time: 0.08711747638881207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 18.184791998006403,
    "estimated_duration": 3600.0100047356414,
    "input_throughput": 4822.394653671203,
    "output_throughput": 4187.3250297000095,
    "total_throughput": 9009.719683371213,
    "itl": 53.96208109270053,
    "ttft": 156303.84541327384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.633932866882519,
    "arrivals": 71837,
    "finished_requests": 70083,
    "scheduler_time": 63.00888894683885
}
#Debug simulation 
Total elapsed time: 18.18489905819297. Arrivals time: 0.19654176756739616 Scheduler time: 17.741627513896674 Scheduler overhead time: 0.09522506967186928 Adapter cache time: 0.02227292535826564 Engine time: 0.0884216739796102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 18.343625518027693,
    "estimated_duration": 3600.0251644270843,
    "input_throughput": 4822.374346586773,
    "output_throughput": 4187.307396891203,
    "total_throughput": 9009.681743477977,
    "itl": 53.98180431929822,
    "ttft": 156358.8402750832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.303643798292617,
    "arrivals": 71837,
    "finished_requests": 70083,
    "scheduler_time": 63.00995718548363
}
#Debug simulation 
Total elapsed time: 18.343766826670617. Arrivals time: 0.19930074829608202 Scheduler time: 17.898845174349844 Scheduler overhead time: 0.09419492166489363 Adapter cache time: 0.022232466377317905 Engine time: 0.08810004033148289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 18.02301888493821,
    "estimated_duration": 3600.0397397145016,
    "input_throughput": 4818.046814498649,
    "output_throughput": 4181.538285239546,
    "total_throughput": 8999.585099738195,
    "itl": 54.07668744873383,
    "ttft": 158275.62737368688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1563753743795315,
    "arrivals": 71837,
    "finished_requests": 70041,
    "scheduler_time": 62.920695165421684
}
#Debug simulation 
Total elapsed time: 18.023176272865385. Arrivals time: 0.19377492554485798 Scheduler time: 17.584979138337076 Scheduler overhead time: 0.0942130759358406 Adapter cache time: 0.02189749013632536 Engine time: 0.0877072480507195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 17.98972688196227,
    "estimated_duration": 3600.0157421935237,
    "input_throughput": 4842.000771190783,
    "output_throughput": 4207.676600539075,
    "total_throughput": 9049.677371729858,
    "itl": 54.542751313971586,
    "ttft": 140692.10874644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.284576687179506,
    "arrivals": 71837,
    "finished_requests": 70393,
    "scheduler_time": 63.1134890241959
}
#Debug simulation 
Total elapsed time: 17.98985190084204. Arrivals time: 0.19696512399241328 Scheduler time: 17.54697734862566 Scheduler overhead time: 0.09481066232547164 Adapter cache time: 0.02227000519633293 Engine time: 0.08812902681529522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 17.141403316054493,
    "estimated_duration": 3600.0073696342974,
    "input_throughput": 4812.3487596526475,
    "output_throughput": 4135.335423358398,
    "total_throughput": 8947.684183011044,
    "itl": 52.81720861281556,
    "ttft": 135425.07413878405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.319936798368749,
    "arrivals": 70891,
    "finished_requests": 69464,
    "scheduler_time": 60.923556047030864
}
#Debug simulation 
Total elapsed time: 17.141495036892593. Arrivals time: 0.19534664740785956 Scheduler time: 16.699539127293974 Scheduler overhead time: 0.09507339773699641 Adapter cache time: 0.022056926507502794 Engine time: 0.08847954124212265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 17.88903348101303,
    "estimated_duration": 3600.0121882476283,
    "input_throughput": 4803.433737377817,
    "output_throughput": 4132.985451708298,
    "total_throughput": 8936.419189086115,
    "itl": 52.63497485064316,
    "ttft": 144653.61425697798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.62019282239956,
    "arrivals": 70891,
    "finished_requests": 69338,
    "scheduler_time": 61.412209651874306
}
#Debug simulation 
Total elapsed time: 17.889128868933767. Arrivals time: 0.19388983165845275 Scheduler time: 17.446768066845834 Scheduler overhead time: 0.09638860775157809 Adapter cache time: 0.021769674494862556 Engine time: 0.0889904098585248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 17.482537400908768,
    "estimated_duration": 3600.0243184118603,
    "input_throughput": 4790.428751216845,
    "output_throughput": 4126.5846244487575,
    "total_throughput": 8917.013375665601,
    "itl": 53.145723253096996,
    "ttft": 151187.62800823516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.922643129709193,
    "arrivals": 70891,
    "finished_requests": 69161,
    "scheduler_time": 60.935981919575674
}
#Debug simulation 
Total elapsed time: 17.482631016988307. Arrivals time: 0.19507469283416867 Scheduler time: 17.040767724625766 Scheduler overhead time: 0.09489445947110653 Adapter cache time: 0.021751931868493557 Engine time: 0.08884150860831141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 16.60872551659122,
    "estimated_duration": 3600.033271913229,
    "input_throughput": 4807.301403301346,
    "output_throughput": 4135.932608224761,
    "total_throughput": 8943.234011526107,
    "itl": 52.747016528613095,
    "ttft": 134970.6175964486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.869864088562303,
    "arrivals": 70891,
    "finished_requests": 69403,
    "scheduler_time": 60.18577329924394
}
#Debug simulation 
Total elapsed time: 16.608816797845066. Arrivals time: 0.19589004898443818 Scheduler time: 16.164641140028834 Scheduler overhead time: 0.09598657861351967 Adapter cache time: 0.022541475482285023 Engine time: 0.08879762329161167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 17.554584270808846,
    "estimated_duration": 3600.026068476967,
    "input_throughput": 4816.720676507774,
    "output_throughput": 4140.990014082555,
    "total_throughput": 8957.71069059033,
    "itl": 53.848496570991294,
    "ttft": 133273.99587525404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.82561340138318,
    "arrivals": 70891,
    "finished_requests": 69543,
    "scheduler_time": 61.38924202731668
}
#Debug simulation 
Total elapsed time: 17.554690727964044. Arrivals time: 0.19595905765891075 Scheduler time: 17.115353292785585 Scheduler overhead time: 0.0933881769888103 Adapter cache time: 0.021492110565304756 Engine time: 0.08759048022329807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 17.266125451307744,
    "estimated_duration": 3600.00921311632,
    "input_throughput": 4802.136321488746,
    "output_throughput": 4134.059697896425,
    "total_throughput": 8936.19601938517,
    "itl": 52.52027365961749,
    "ttft": 140788.1625437904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.00316127180584,
    "arrivals": 70891,
    "finished_requests": 69353,
    "scheduler_time": 60.833058422737004
}
#Debug simulation 
Total elapsed time: 17.266266520135105. Arrivals time: 0.19674768764525652 Scheduler time: 16.82102846354246 Scheduler overhead time: 0.09592162678018212 Adapter cache time: 0.022204283624887466 Engine time: 0.08928274177014828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 17.709416282363236,
    "estimated_duration": 3600.0409428443318,
    "input_throughput": 4798.251818311872,
    "output_throughput": 4124.061430331901,
    "total_throughput": 8922.313248643773,
    "itl": 53.54740124637631,
    "ttft": 145607.50001142148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.747324605137128,
    "arrivals": 70891,
    "finished_requests": 69292,
    "scheduler_time": 61.198467118184006
}
#Debug simulation 
Total elapsed time: 17.709570973180234. Arrivals time: 0.19533769227564335 Scheduler time: 17.27001461526379 Scheduler overhead time: 0.09297327930107713 Adapter cache time: 0.02155353222042322 Engine time: 0.0886093215085566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 16.368212088011205,
    "estimated_duration": 3600.0096964802087,
    "input_throughput": 4700.069840518281,
    "output_throughput": 4139.95107140177,
    "total_throughput": 8840.02091192005,
    "itl": 52.62414652992205,
    "ttft": 143653.08779712408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.797556484844687,
    "arrivals": 70422,
    "finished_requests": 68731,
    "scheduler_time": 59.78608964055237
}
#Debug simulation 
Total elapsed time: 16.368331687990576. Arrivals time: 0.19559268513694406 Scheduler time: 15.925874424166977 Scheduler overhead time: 0.09569205669686198 Adapter cache time: 0.02168793138116598 Engine time: 0.08855347335338593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.873810824006796,
    "estimated_duration": 3600.035970407556,
    "input_throughput": 4714.542060000184,
    "output_throughput": 4153.273779180409,
    "total_throughput": 8867.815839180594,
    "itl": 53.015270472441955,
    "ttft": 132815.16430905127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.71428956241348,
    "arrivals": 70422,
    "finished_requests": 68916,
    "scheduler_time": 59.548622704496566
}
#Debug simulation 
Total elapsed time: 15.873934241943061. Arrivals time: 0.19252384640276432 Scheduler time: 15.434636008925736 Scheduler overhead time: 0.09512336924672127 Adapter cache time: 0.021979200188070536 Engine time: 0.08873238181695342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 16.372120189946145,
    "estimated_duration": 3600.0334145179922,
    "input_throughput": 4722.140058879456,
    "output_throughput": 4160.886657216091,
    "total_throughput": 8883.026716095546,
    "itl": 53.774820246708046,
    "ttft": 130096.33356677298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.652878123591676,
    "arrivals": 70422,
    "finished_requests": 69010,
    "scheduler_time": 60.05394840639601
}
#Debug simulation 
Total elapsed time: 16.372213382739574. Arrivals time: 0.19393545342609286 Scheduler time: 15.935063563287258 Scheduler overhead time: 0.09304801002144814 Adapter cache time: 0.021277976222336292 Engine time: 0.08807639731094241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 15.866845520678908,
    "estimated_duration": 3600.0507040817934,
    "input_throughput": 4714.522765125584,
    "output_throughput": 4153.256781369014,
    "total_throughput": 8867.779546494598,
    "itl": 53.00270593720723,
    "ttft": 132810.1490329279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.220082895914081,
    "arrivals": 70422,
    "finished_requests": 68916,
    "scheduler_time": 59.54788754814205
}
#Debug simulation 
Total elapsed time: 15.86693972768262. Arrivals time: 0.19190883869305253 Scheduler time: 15.43265554588288 Scheduler overhead time: 0.09274014038965106 Adapter cache time: 0.02160013187676668 Engine time: 0.08735176082700491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 15.848917241208255,
    "estimated_duration": 3600.04629716039,
    "input_throughput": 4708.734721931484,
    "output_throughput": 4149.872464635807,
    "total_throughput": 8858.607186567291,
    "itl": 53.00891609074179,
    "ttft": 136595.29328053156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8884613129962435,
    "arrivals": 70422,
    "finished_requests": 68813,
    "scheduler_time": 59.248642240580175
}
#Debug simulation 
Total elapsed time: 15.84901966387406. Arrivals time: 0.1956478413194418 Scheduler time: 15.406235891859978 Scheduler overhead time: 0.09565745107829571 Adapter cache time: 0.02193753933534026 Engine time: 0.08841964742168784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 17.50056382920593,
    "estimated_duration": 3600.0205572072973,
    "input_throughput": 4704.773967496184,
    "output_throughput": 4143.726337932969,
    "total_throughput": 8848.500305429154,
    "itl": 52.45759765685095,
    "ttft": 149041.27390112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.98173392131456,
    "arrivals": 70422,
    "finished_requests": 68727,
    "scheduler_time": 60.82043136514223
}
#Debug simulation 
Total elapsed time: 17.500667500309646. Arrivals time: 0.19515395304188132 Scheduler time: 17.060515171382576 Scheduler overhead time: 0.09422988537698984 Adapter cache time: 0.021075963508337736 Engine time: 0.08855279861018062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.97922305483371,
    "estimated_duration": 3600.0093232971144,
    "input_throughput": 4713.738347893573,
    "output_throughput": 4153.259799423582,
    "total_throughput": 8866.998147317156,
    "itl": 52.91621855361908,
    "ttft": 134138.50122974318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.720353848002872,
    "arrivals": 70422,
    "finished_requests": 68888,
    "scheduler_time": 59.53710559434476
}
#Debug simulation 
Total elapsed time: 15.979377434123307. Arrivals time: 0.19318630592897534 Scheduler time: 15.5427107764408 Scheduler overhead time: 0.0928610940463841 Adapter cache time: 0.021341157145798206 Engine time: 0.08839515317231417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 15.384637986775488,
    "estimated_duration": 3600.015859338136,
    "input_throughput": 4599.392515744131,
    "output_throughput": 4059.275450716122,
    "total_throughput": 8658.667966460253,
    "itl": 52.17522336430566,
    "ttft": 110352.24875156247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8224798847969605,
    "arrivals": 68030,
    "finished_requests": 67023,
    "scheduler_time": 57.74677075109683
}
#Debug simulation 
Total elapsed time: 15.3847605320625. Arrivals time: 0.18838762864470482 Scheduler time: 14.950184676330537 Scheduler overhead time: 0.09262601286172867 Adapter cache time: 0.022536790929734707 Engine time: 0.08979405555874109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.333948841318488,
    "estimated_duration": 3600.019414317137,
    "input_throughput": 4597.016042242409,
    "output_throughput": 4055.06507602239,
    "total_throughput": 8652.081118264798,
    "itl": 52.16526791153706,
    "ttft": 112002.51548207102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.868155089295447,
    "arrivals": 68030,
    "finished_requests": 66971,
    "scheduler_time": 57.50274631340955
}
#Debug simulation 
Total elapsed time: 15.334069170989096. Arrivals time: 0.1894636950455606 Scheduler time: 14.897877089679241 Scheduler overhead time: 0.09366838680580258 Adapter cache time: 0.02266432298347354 Engine time: 0.08901498606428504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 14.866756672039628,
    "estimated_duration": 3600.0167705627036,
    "input_throughput": 4594.884150335345,
    "output_throughput": 4056.7277684423857,
    "total_throughput": 8651.61191877773,
    "itl": 52.19120573548991,
    "ttft": 110318.78187681524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.258428695742012,
    "arrivals": 68030,
    "finished_requests": 66974,
    "scheduler_time": 57.21203601741522
}
#Debug simulation 
Total elapsed time: 14.866855665110052. Arrivals time: 0.18950428580865264 Scheduler time: 14.42852929374203 Scheduler overhead time: 0.09557177824899554 Adapter cache time: 0.022888637613505125 Engine time: 0.08896122639998794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 15.474885200150311,
    "estimated_duration": 3600.0248415576048,
    "input_throughput": 4595.131069385233,
    "output_throughput": 4055.676180746258,
    "total_throughput": 8650.807250131491,
    "itl": 51.98654430984229,
    "ttft": 113363.46525208479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.022247154088678,
    "arrivals": 68030,
    "finished_requests": 66965,
    "scheduler_time": 57.74206925705911
}
#Debug simulation 
Total elapsed time: 15.474976780824363. Arrivals time: 0.1888474803417921 Scheduler time: 15.039916546549648 Scheduler overhead time: 0.09229710791260004 Adapter cache time: 0.02222534455358982 Engine time: 0.09048782801255584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 14.87539666518569,
    "estimated_duration": 3600.010989826715,
    "input_throughput": 4594.891528593979,
    "output_throughput": 4056.734282553668,
    "total_throughput": 8651.625811147647,
    "itl": 52.19027155127806,
    "ttft": 110317.7674435406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.171025247210604,
    "arrivals": 68030,
    "finished_requests": 66974,
    "scheduler_time": 57.21182110357214
}
#Debug simulation 
Total elapsed time: 14.875489332247525. Arrivals time: 0.18958472087979317 Scheduler time: 14.436487376689911 Scheduler overhead time: 0.09575132885947824 Adapter cache time: 0.0230085588991642 Engine time: 0.08923303009942174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 15.6230628201738,
    "estimated_duration": 3600.040217190352,
    "input_throughput": 4588.797903178122,
    "output_throughput": 4045.1584208593845,
    "total_throughput": 8633.956324037506,
    "itl": 51.78558768217667,
    "ttft": 119720.49628158868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.475571421408056,
    "arrivals": 68030,
    "finished_requests": 66862,
    "scheduler_time": 57.83833945126412
}
#Debug simulation 
Total elapsed time: 15.623158277012408. Arrivals time: 0.19017660850659013 Scheduler time: 15.184651041869074 Scheduler overhead time: 0.09478308213874698 Adapter cache time: 0.02258882997557521 Engine time: 0.08954103663563728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 14.918056635651737,
    "estimated_duration": 3600.00874026675,
    "input_throughput": 4594.894399832571,
    "output_throughput": 4056.736817510578,
    "total_throughput": 8651.631217343149,
    "itl": 52.1878222193075,
    "ttft": 110315.97154391222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.088592610917958,
    "arrivals": 68030,
    "finished_requests": 66974,
    "scheduler_time": 57.211271906441965
}
#Debug simulation 
Total elapsed time: 14.918147346936166. Arrivals time: 0.18579261051490903 Scheduler time: 14.487094912678003 Scheduler overhead time: 0.09267928311601281 Adapter cache time: 0.02240307768806815 Engine time: 0.08873762330040336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 13.434849369805306,
    "estimated_duration": 3600.001632284735,
    "input_throughput": 4541.8182184609595,
    "output_throughput": 3991.469856884634,
    "total_throughput": 8533.288075345594,
    "itl": 50.562618337508106,
    "ttft": 93352.82863931214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.457271151864175,
    "arrivals": 67080,
    "finished_requests": 66210,
    "scheduler_time": 54.48228465100113
}
#Debug simulation 
Total elapsed time: 13.434942928142846. Arrivals time: 0.18440302414819598 Scheduler time: 12.999850771855563 Scheduler overhead time: 0.09558767545968294 Adapter cache time: 0.023633536882698536 Engine time: 0.08958840882405639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 13.90744048776105,
    "estimated_duration": 3600.027905759977,
    "input_throughput": 4539.248424673052,
    "output_throughput": 3986.810484728761,
    "total_throughput": 8526.058909401812,
    "itl": 50.91446903710564,
    "ttft": 98392.66651003338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.938935403567712,
    "arrivals": 67080,
    "finished_requests": 66165,
    "scheduler_time": 54.990867380463726
}
#Debug simulation 
Total elapsed time: 13.907536150887609. Arrivals time: 0.18342173239216208 Scheduler time: 13.478825352154672 Scheduler overhead time: 0.09282033611088991 Adapter cache time: 0.022434736602008343 Engine time: 0.08845218364149332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 13.649933777283877,
    "estimated_duration": 3600.037594871018,
    "input_throughput": 4538.444549378484,
    "output_throughput": 3989.577225655218,
    "total_throughput": 8528.021775033703,
    "itl": 50.56535049724905,
    "ttft": 96584.06787884091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.362949691000342,
    "arrivals": 67080,
    "finished_requests": 66171,
    "scheduler_time": 54.69536791498507
}
#Debug simulation 
Total elapsed time: 13.650034910999238. Arrivals time: 0.18200872419402003 Scheduler time: 13.22117530182004 Scheduler overhead time: 0.09354904713109136 Adapter cache time: 0.02265775576233864 Engine time: 0.08931237459182739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 13.42145934002474,
    "estimated_duration": 3600.0062074376583,
    "input_throughput": 4535.860234425102,
    "output_throughput": 3982.6070217264432,
    "total_throughput": 8518.467256151545,
    "itl": 50.62083903818365,
    "ttft": 96989.14474488707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.793332322291121,
    "arrivals": 67080,
    "finished_requests": 66142,
    "scheduler_time": 54.455467379810905
}
#Debug simulation 
Total elapsed time: 13.421556537039578. Arrivals time: 0.1835274430923164 Scheduler time: 12.99138375138864 Scheduler overhead time: 0.09271198464557528 Adapter cache time: 0.022857793141156435 Engine time: 0.08953807735815644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 13.939869648776948,
    "estimated_duration": 3600.0435169627676,
    "input_throughput": 4546.843370885089,
    "output_throughput": 3998.1191705546985,
    "total_throughput": 8544.962541439787,
    "itl": 51.08241090582158,
    "ttft": 91701.17335821492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.099378027995076,
    "arrivals": 67080,
    "finished_requests": 66294,
    "scheduler_time": 55.10732552690974
}
#Debug simulation 
Total elapsed time: 13.939979502931237. Arrivals time: 0.18746646121144295 Scheduler time: 13.50316707463935 Scheduler overhead time: 0.09549107728525996 Adapter cache time: 0.02293406706303358 Engine time: 0.08930691378191113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 13.806554337963462,
    "estimated_duration": 3600.042266960516,
    "input_throughput": 4532.717059951944,
    "output_throughput": 3984.1982222364036,
    "total_throughput": 8516.915282188347,
    "itl": 50.33935947707161,
    "ttft": 101289.024797125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.954365491950844,
    "arrivals": 67080,
    "finished_requests": 66096,
    "scheduler_time": 54.73552497341228
}
#Debug simulation 
Total elapsed time: 13.80665749264881. Arrivals time: 0.17876169877126813 Scheduler time: 13.37588589033112 Scheduler overhead time: 0.096878491807729 Adapter cache time: 0.023136261850595474 Engine time: 0.09005409386008978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 14.060372185893357,
    "estimated_duration": 3600.0374151739056,
    "input_throughput": 4542.286958206536,
    "output_throughput": 3994.7715374800587,
    "total_throughput": 8537.058495686595,
    "itl": 51.02058876508949,
    "ttft": 93913.43948358374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.863035749532255,
    "arrivals": 67080,
    "finished_requests": 66264,
    "scheduler_time": 55.23591593569746
}
#Debug simulation 
Total elapsed time: 14.060472221113741. Arrivals time: 0.17702022707089782 Scheduler time: 13.636090835556388 Scheduler overhead time: 0.0941633633337915 Adapter cache time: 0.022380476351827383 Engine time: 0.08929615607485175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 12.503727320116013,
    "estimated_duration": 3600.0081463785473,
    "input_throughput": 4514.64978387607,
    "output_throughput": 3961.246036163964,
    "total_throughput": 8475.895820040034,
    "itl": 49.780140378350666,
    "ttft": 92438.82564783195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.014239746723515,
    "arrivals": 66631,
    "finished_requests": 65684,
    "scheduler_time": 52.82014162180015
}
#Debug simulation 
Total elapsed time: 12.5038749743253. Arrivals time: 0.17267592577263713 Scheduler time: 12.086249716579914 Scheduler overhead time: 0.09273632150143385 Adapter cache time: 0.022326047997921705 Engine time: 0.08826779527589679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 12.852950768079609,
    "estimated_duration": 3600.0565262050545,
    "input_throughput": 4492.271408040341,
    "output_throughput": 3938.7650990434304,
    "total_throughput": 8431.036507083772,
    "itl": 49.79090066128368,
    "ttft": 110921.76669614797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.543113349885674,
    "arrivals": 66631,
    "finished_requests": 65356,
    "scheduler_time": 52.86519418347347
}
#Debug simulation 
Total elapsed time: 12.85304405912757. Arrivals time: 0.175366947427392 Scheduler time: 12.424426630139351 Scheduler overhead time: 0.09806730970740318 Adapter cache time: 0.022740366868674755 Engine time: 0.09066265029832721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 12.766029814723879,
    "estimated_duration": 3600.0285011406095,
    "input_throughput": 4510.435402068443,
    "output_throughput": 3956.391177316319,
    "total_throughput": 8466.826579384762,
    "itl": 49.69685578042405,
    "ttft": 96979.17536652631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.844535216693748,
    "arrivals": 66631,
    "finished_requests": 65621,
    "scheduler_time": 52.983543185253176
}
#Debug simulation 
Total elapsed time: 12.766128399875015. Arrivals time: 0.1777812410145998 Scheduler time: 12.335102195385844 Scheduler overhead time: 0.09801607299596071 Adapter cache time: 0.022873113863170147 Engine time: 0.09054078022018075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 12.758288348093629,
    "estimated_duration": 3600.0157413377638,
    "input_throughput": 4517.86580076346,
    "output_throughput": 3961.1121241100373,
    "total_throughput": 8478.977924873498,
    "itl": 49.95718406737152,
    "ttft": 89987.55270415686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.063053268557402,
    "arrivals": 66631,
    "finished_requests": 65750,
    "scheduler_time": 53.09874195595645
}
#Debug simulation 
Total elapsed time: 12.758399215061218. Arrivals time: 0.1760580730624497 Scheduler time: 12.332121693529189 Scheduler overhead time: 0.0961193535476923 Adapter cache time: 0.022502728272229433 Engine time: 0.0897886692546308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 12.700669769197702,
    "estimated_duration": 3600.026964243323,
    "input_throughput": 4506.272081050868,
    "output_throughput": 3951.334848679358,
    "total_throughput": 8457.606929730226,
    "itl": 49.58784376446578,
    "ttft": 100807.56613084821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.958202919783044,
    "arrivals": 66631,
    "finished_requests": 65538,
    "scheduler_time": 52.83214536844295
}
#Debug simulation 
Total elapsed time: 12.700804566964507. Arrivals time: 0.1814450491219759 Scheduler time: 12.265860304236412 Scheduler overhead time: 0.09791275626048446 Adapter cache time: 0.02303039887920022 Engine time: 0.09054282261058688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 13.033178776036948,
    "estimated_duration": 3600.0234388716026,
    "input_throughput": 4504.809281209351,
    "output_throughput": 3949.0492885391036,
    "total_throughput": 8453.858569748454,
    "itl": 49.785624764221296,
    "ttft": 102089.27543949246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.418116132942922,
    "arrivals": 66631,
    "finished_requests": 65542,
    "scheduler_time": 53.18045752427093
}
#Debug simulation 
Total elapsed time: 13.03330081794411. Arrivals time: 0.17851566523313522 Scheduler time: 12.606929514091462 Scheduler overhead time: 0.09442212991416454 Adapter cache time: 0.022206193767488003 Engine time: 0.08951919572427869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 12.624856940004975,
    "estimated_duration": 3600.028358116476,
    "input_throughput": 4506.270336294703,
    "output_throughput": 3951.3333187859753,
    "total_throughput": 8457.603655080678,
    "itl": 49.58763068378262,
    "ttft": 100806.16619378877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.875770283490397,
    "arrivals": 66631,
    "finished_requests": 65538,
    "scheduler_time": 52.831763409362985
}
#Debug simulation 
Total elapsed time: 12.62500813184306. Arrivals time: 0.17412175005301833 Scheduler time: 12.203968836925924 Scheduler overhead time: 0.0935697010718286 Adapter cache time: 0.02240104367956519 Engine time: 0.08906176779419184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 11.352959936950356,
    "estimated_duration": 3599.8731637874985,
    "input_throughput": 4417.390634749237,
    "output_throughput": 3901.6230186350813,
    "total_throughput": 8319.013653384318,
    "itl": 49.008075129380906,
    "ttft": 78204.0483395003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.867240511845084,
    "arrivals": 65160,
    "finished_requests": 64394,
    "scheduler_time": 50.53784448346784
}
#Debug simulation 
Total elapsed time: 11.353114828001708. Arrivals time: 0.16894844733178616 Scheduler time: 10.933697478380054 Scheduler overhead time: 0.0945670884102583 Adapter cache time: 0.02344266651198268 Engine time: 0.09014093317091465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 11.999320610892028,
    "estimated_duration": 3599.9191940293013,
    "input_throughput": 4416.051623149462,
    "output_throughput": 3898.3127797078478,
    "total_throughput": 8314.36440285731,
    "itl": 49.0935830305438,
    "ttft": 83487.93901826342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.224002065556096,
    "arrivals": 65160,
    "finished_requests": 64360,
    "scheduler_time": 51.19663064294589
}
#Debug simulation 
Total elapsed time: 11.999436805956066. Arrivals time: 0.17071227030828595 Scheduler time: 11.579649188555777 Scheduler overhead time: 0.09416848421096802 Adapter cache time: 0.022705350071191788 Engine time: 0.09019482135772705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 11.93522323621437,
    "estimated_duration": 3599.9183881151444,
    "input_throughput": 4408.006318251136,
    "output_throughput": 3891.194324361986,
    "total_throughput": 8299.200642613121,
    "itl": 49.358979290729245,
    "ttft": 89018.77949623244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.461103419279638,
    "arrivals": 65160,
    "finished_requests": 64250,
    "scheduler_time": 51.05100987032701
}
#Debug simulation 
Total elapsed time: 11.935341704171151. Arrivals time: 0.17000088701024652 Scheduler time: 11.512855078093708 Scheduler overhead time: 0.09719586605206132 Adapter cache time: 0.023206325247883797 Engine time: 0.0899400687776506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 11.795145738869905,
    "estimated_duration": 3599.88705943606,
    "input_throughput": 4415.961316989299,
    "output_throughput": 3899.719565701933,
    "total_throughput": 8315.680882691233,
    "itl": 49.329056720446566,
    "ttft": 82303.47832127742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.61680179397577,
    "arrivals": 65160,
    "finished_requests": 64363,
    "scheduler_time": 51.04497791568988
}
#Debug simulation 
Total elapsed time: 11.795263262931257. Arrivals time: 0.17058229818940163 Scheduler time: 11.371637952048331 Scheduler overhead time: 0.09642854565754533 Adapter cache time: 0.02292068162932992 Engine time: 0.09140184754505754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 11.730938715860248,
    "estimated_duration": 3599.895383184983,
    "input_throughput": 4417.34198006911,
    "output_throughput": 3898.0549450258636,
    "total_throughput": 8315.396925094974,
    "itl": 49.57525741345523,
    "ttft": 81562.8809935199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.475685546169943,
    "arrivals": 65160,
    "finished_requests": 64365,
    "scheduler_time": 50.93234273361733
}
#Debug simulation 
Total elapsed time: 11.731058098841459. Arrivals time: 0.1702499920502305 Scheduler time: 11.306857495103031 Scheduler overhead time: 0.09790405770763755 Adapter cache time: 0.02325814589858055 Engine time: 0.09072572318837047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 11.958549212198704,
    "estimated_duration": 3599.8788502652246,
    "input_throughput": 4414.259107311133,
    "output_throughput": 3897.4906055425417,
    "total_throughput": 8311.749712853676,
    "itl": 49.45955288190077,
    "ttft": 84645.37570001149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.820303152198863,
    "arrivals": 65160,
    "finished_requests": 64335,
    "scheduler_time": 51.226175358505614
}
#Debug simulation 
Total elapsed time: 11.958672113250941. Arrivals time: 0.1675768904387951 Scheduler time: 11.543650139123201 Scheduler overhead time: 0.09358666557818651 Adapter cache time: 0.022354510612785816 Engine time: 0.08955914434045553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 11.684343562927097,
    "estimated_duration": 3599.882042540535,
    "input_throughput": 4416.960003716832,
    "output_throughput": 3898.063279344796,
    "total_throughput": 8315.023283061628,
    "itl": 49.57445261992584,
    "ttft": 81775.93754771889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.38683227740224,
    "arrivals": 65160,
    "finished_requests": 64361,
    "scheduler_time": 50.93162382241629
}
#Debug simulation 
Total elapsed time: 11.684462824836373. Arrivals time: 0.16822057170793414 Scheduler time: 11.262055158149451 Scheduler overhead time: 0.09787074290215969 Adapter cache time: 0.023263313807547092 Engine time: 0.09070893097668886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 10.839161282870919,
    "estimated_duration": 3599.9529151963316,
    "input_throughput": 4404.8142777265175,
    "output_throughput": 3856.958501148273,
    "total_throughput": 8261.77277887479,
    "itl": 48.179301096053095,
    "ttft": 79709.56676301811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.014239746723515,
    "arrivals": 64686,
    "finished_requests": 63841,
    "scheduler_time": 49.193341221699306
}
#Debug simulation 
Total elapsed time: 10.839283908251673. Arrivals time: 0.16706785932183266 Scheduler time: 10.418110148049891 Scheduler overhead time: 0.0977893858216703 Adapter cache time: 0.022758226841688156 Engine time: 0.09104948025196791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 11.055311373900622,
    "estimated_duration": 3599.9892283122117,
    "input_throughput": 4406.626796335569,
    "output_throughput": 3855.845981658076,
    "total_throughput": 8262.472777993646,
    "itl": 48.2653297156575,
    "ttft": 80174.97920552902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.653868741579341,
    "arrivals": 64686,
    "finished_requests": 63852,
    "scheduler_time": 49.45818727948944
}
#Debug simulation 
Total elapsed time: 11.055431347806007. Arrivals time: 0.1661012340337038 Scheduler time: 10.637579173315316 Scheduler overhead time: 0.09683279227465391 Adapter cache time: 0.022416134364902973 Engine time: 0.09039059933274984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 11.015715141780674,
    "estimated_duration": 3599.9714687187006,
    "input_throughput": 4400.883489679114,
    "output_throughput": 3853.1913712463647,
    "total_throughput": 8254.074860925479,
    "itl": 48.05693245507944,
    "ttft": 83403.15728838877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.882433887971546,
    "arrivals": 64686,
    "finished_requests": 63787,
    "scheduler_time": 49.30788803265918
}
#Debug simulation 
Total elapsed time: 11.015809840988368. Arrivals time: 0.16532670659944415 Scheduler time: 10.600586448330432 Scheduler overhead time: 0.0951311094686389 Adapter cache time: 0.022234010510146618 Engine time: 0.09037314727902412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 10.810581421945244,
    "estimated_duration": 3599.9611967759884,
    "input_throughput": 4404.978035374854,
    "output_throughput": 3856.9243503054336,
    "total_throughput": 8261.902385680287,
    "itl": 48.07460080472291,
    "ttft": 78488.29717773414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.454153475393554,
    "arrivals": 64686,
    "finished_requests": 63860,
    "scheduler_time": 49.15712000700401
}
#Debug simulation 
Total elapsed time: 10.810670118313283. Arrivals time: 0.16707872273400426 Scheduler time: 10.389033885207027 Scheduler overhead time: 0.09734995942562819 Adapter cache time: 0.022747597191482782 Engine time: 0.09185188682749867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 10.873374079819769,
    "estimated_duration": 3599.989132319878,
    "input_throughput": 4405.548299469356,
    "output_throughput": 3857.7735902914897,
    "total_throughput": 8263.321889760846,
    "itl": 48.27972367701924,
    "ttft": 80231.90017374267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.099124607630044,
    "arrivals": 64686,
    "finished_requests": 63831,
    "scheduler_time": 49.20048257133661
}
#Debug simulation 
Total elapsed time: 10.873512232676148. Arrivals time: 0.1691620391793549 Scheduler time: 10.45390545623377 Scheduler overhead time: 0.09496742393821478 Adapter cache time: 0.02259145164862275 Engine time: 0.09036987042054534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 10.80755421333015,
    "estimated_duration": 3599.963533811299,
    "input_throughput": 4409.603555954269,
    "output_throughput": 3863.2352437403874,
    "total_throughput": 8272.838799694657,
    "itl": 48.246564093135134,
    "ttft": 76862.16477228362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.77561570561487,
    "arrivals": 64686,
    "finished_requests": 63889,
    "scheduler_time": 49.19703841587283
}
#Debug simulation 
Total elapsed time: 10.80767161725089. Arrivals time: 0.16676735132932663 Scheduler time: 10.385685395915061 Scheduler overhead time: 0.09845768893137574 Adapter cache time: 0.02280254615470767 Engine time: 0.09145354432985187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 11.16909280512482,
    "estimated_duration": 3599.955036905479,
    "input_throughput": 4407.586994097395,
    "output_throughput": 3859.310424038717,
    "total_throughput": 8266.897418136114,
    "itl": 48.14764471606299,
    "ttft": 79862.50507989858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.822969948332736,
    "arrivals": 64686,
    "finished_requests": 63854,
    "scheduler_time": 49.37436864915404
}
#Debug simulation 
Total elapsed time: 11.169183156918734. Arrivals time: 0.16850781859830022 Scheduler time: 10.7491215611808 Scheduler overhead time: 0.09604380978271365 Adapter cache time: 0.022455614991486073 Engine time: 0.09045143518596888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 9.252927714027464,
    "estimated_duration": 3600.037561775671,
    "input_throughput": 4364.818624906102,
    "output_throughput": 3809.7113612434664,
    "total_throughput": 8174.529986149569,
    "itl": 47.184531939589114,
    "ttft": 61549.39197216533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.9944025196276645,
    "arrivals": 63755,
    "finished_requests": 63099,
    "scheduler_time": 46.60040838930096
}
#Debug simulation 
Total elapsed time: 9.253020372241735. Arrivals time: 0.16286886390298605 Scheduler time: 8.840074263513088 Scheduler overhead time: 0.09537766873836517 Adapter cache time: 0.022356145083904266 Engine time: 0.08985255612060428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 9.646344237960875,
    "estimated_duration": 3600.027502199721,
    "input_throughput": 4364.385824941495,
    "output_throughput": 3809.9961713123225,
    "total_throughput": 8174.381996253818,
    "itl": 47.17631781103318,
    "ttft": 63581.27102785583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.469556593666782,
    "arrivals": 63755,
    "finished_requests": 63096,
    "scheduler_time": 46.978677447550545
}
#Debug simulation 
Total elapsed time: 9.646438012830913. Arrivals time: 0.16670467611402273 Scheduler time: 9.229164633899927 Scheduler overhead time: 0.09557722136378288 Adapter cache time: 0.02205018326640129 Engine time: 0.09049488371238112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 9.379768565762788,
    "estimated_duration": 3600.0386252667518,
    "input_throughput": 4365.865935351012,
    "output_throughput": 3810.3246736647416,
    "total_throughput": 8176.190609015754,
    "itl": 47.07628224964052,
    "ttft": 60670.83673663804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.077337468732113,
    "arrivals": 63755,
    "finished_requests": 63124,
    "scheduler_time": 46.69984834663586
}
#Debug simulation 
Total elapsed time: 9.379859775770456. Arrivals time: 0.16275253612548113 Scheduler time: 8.967548503074795 Scheduler overhead time: 0.09480666136369109 Adapter cache time: 0.02229301305487752 Engine time: 0.09014115622267127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 9.585553728975356,
    "estimated_duration": 3600.010575310561,
    "input_throughput": 4366.0527298990155,
    "output_throughput": 3808.3293682595036,
    "total_throughput": 8174.3820981585195,
    "itl": 47.21104283588914,
    "ttft": 62275.309104940075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.05195697845424,
    "arrivals": 63755,
    "finished_requests": 63110,
    "scheduler_time": 46.89039087539724
}
#Debug simulation 
Total elapsed time: 9.585648832842708. Arrivals time: 0.16470987210050225 Scheduler time: 9.169774510432035 Scheduler overhead time: 0.09559950465336442 Adapter cache time: 0.022248728200793266 Engine time: 0.09058001916855574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 9.667331906035542,
    "estimated_duration": 3600.027696582596,
    "input_throughput": 4366.86029247034,
    "output_throughput": 3809.0481951061256,
    "total_throughput": 8175.908487576466,
    "itl": 47.11694522120401,
    "ttft": 62395.97307800374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.64272365168667,
    "arrivals": 63755,
    "finished_requests": 63116,
    "scheduler_time": 46.98031602424172
}
#Debug simulation 
Total elapsed time: 9.66745392093435. Arrivals time: 0.16533534321933985 Scheduler time: 9.251889830920845 Scheduler overhead time: 0.09555279230698943 Adapter cache time: 0.02213001437485218 Engine time: 0.09004454920068383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 9.248027021996677,
    "estimated_duration": 3600.0336665207005,
    "input_throughput": 4368.835532363365,
    "output_throughput": 3810.9982491523765,
    "total_throughput": 8179.833781515741,
    "itl": 47.205235667254485,
    "ttft": 59342.668571995244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.730928259030876,
    "arrivals": 63755,
    "finished_requests": 63137,
    "scheduler_time": 46.61789085653475
}
#Debug simulation 
Total elapsed time: 9.248147577047348. Arrivals time: 0.16338431648910046 Scheduler time: 8.834664650727063 Scheduler overhead time: 0.09496366651728749 Adapter cache time: 0.022397172637283802 Engine time: 0.09034795919433236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 9.601168793160468,
    "estimated_duration": 3600.0459440919944,
    "input_throughput": 4369.025630301254,
    "output_throughput": 3810.3547046424774,
    "total_throughput": 8179.380334943731,
    "itl": 47.23203316226254,
    "ttft": 61127.524290628804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.588763461746264,
    "arrivals": 63755,
    "finished_requests": 63137,
    "scheduler_time": 46.98647824754288
}
#Debug simulation 
Total elapsed time: 9.601298135239631. Arrivals time: 0.16459106467664242 Scheduler time: 9.1865513199009 Scheduler overhead time: 0.09557614102959633 Adapter cache time: 0.022055976558476686 Engine time: 0.09017327427864075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.6349150841124356,
    "estimated_duration": 3599.954382886374,
    "input_throughput": 1847.3111858345187,
    "output_throughput": 1601.980854928524,
    "total_throughput": 3449.2920407630427,
    "itl": 31.358107199140964,
    "ttft": 29439.80123808942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.26193598051547,
    "arrivals": 27111,
    "finished_requests": 26961,
    "scheduler_time": 4.086998629892315
}
#Debug simulation 
Total elapsed time: 2.6350085302256048. Arrivals time: 0.080559101421386 Scheduler time: 2.2158796321600676 Scheduler overhead time: 0.10902318358421326 Adapter cache time: 0.06966924434527755 Engine time: 0.10828117746859789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6341198259033263,
    "estimated_duration": 3599.9638665141,
    "input_throughput": 1847.4021536332416,
    "output_throughput": 1601.9444121766194,
    "total_throughput": 3449.3465658098607,
    "itl": 31.411328380891543,
    "ttft": 28990.941992016604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8753,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.05369330465103,
    "arrivals": 27111,
    "finished_requests": 26965,
    "scheduler_time": 4.134194340609979
}
#Debug simulation 
Total elapsed time: 2.63420457392931. Arrivals time: 0.0768042029812932 Scheduler time: 2.2204416883178055 Scheduler overhead time: 0.1087020835839212 Adapter cache time: 0.06928610987961292 Engine time: 0.10732383141294122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.597137519158423,
    "estimated_duration": 3599.986236555839,
    "input_throughput": 1847.3906740162183,
    "output_throughput": 1601.9344578154055,
    "total_throughput": 3449.325131831624,
    "itl": 31.43394218698116,
    "ttft": 29066.50779302574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.57236339470862,
    "arrivals": 27111,
    "finished_requests": 26965,
    "scheduler_time": 4.152282372988808
}
#Debug simulation 
Total elapsed time: 2.5972283449955285. Arrivals time: 0.0765554504469037 Scheduler time: 2.1898191403597593 Scheduler overhead time: 0.10747348889708519 Adapter cache time: 0.06843765312805772 Engine time: 0.10357668111100793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.6306528337299824,
    "estimated_duration": 3599.9724443989317,
    "input_throughput": 1847.792476953431,
    "output_throughput": 1602.0144845755674,
    "total_throughput": 3449.8069615289987,
    "itl": 31.379503099347556,
    "ttft": 28801.04802378666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.45950390559813,
    "arrivals": 27111,
    "finished_requests": 26966,
    "scheduler_time": 4.100952837356828
}
#Debug simulation 
Total elapsed time: 2.630738095846027. Arrivals time: 0.07627874892205 Scheduler time: 2.2155467947013676 Scheduler overhead time: 0.10837613604962826 Adapter cache time: 0.06947423471137881 Engine time: 0.10901929391548038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.617818450089544,
    "estimated_duration": 3599.9578997951407,
    "input_throughput": 1847.4052155938984,
    "output_throughput": 1601.9470673054743,
    "total_throughput": 3449.3522828993728,
    "itl": 31.424827967073785,
    "ttft": 29022.78533723841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.11605809638279,
    "arrivals": 27111,
    "finished_requests": 26965,
    "scheduler_time": 4.144211997701013
}
#Debug simulation 
Total elapsed time: 2.6179022169671953. Arrivals time: 0.07631369354203343 Scheduler time: 2.2061146097257733 Scheduler overhead time: 0.10782868880778551 Adapter cache time: 0.06897768145427108 Engine time: 0.10660883877426386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.6511819013394415,
    "estimated_duration": 3599.9606556216277,
    "input_throughput": 1847.860473033786,
    "output_throughput": 1602.238344186571,
    "total_throughput": 3450.0988172203574,
    "itl": 31.33848879354298,
    "ttft": 28750.819036308596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.376405826184794,
    "arrivals": 27111,
    "finished_requests": 26966,
    "scheduler_time": 4.072190819299538
}
#Debug simulation 
Total elapsed time: 2.6512728882953525. Arrivals time: 0.07564378483220935 Scheduler time: 2.238719316199422 Scheduler overhead time: 0.10841215308755636 Adapter cache time: 0.06994780758395791 Engine time: 0.10680021159350872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6124554201960564,
    "estimated_duration": 3599.956722538895,
    "input_throughput": 1847.40581973153,
    "output_throughput": 1601.9475911734914,
    "total_throughput": 3449.3534109050215,
    "itl": 31.411142050792943,
    "ttft": 29024.98299526751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.3992942375081,
    "arrivals": 27111,
    "finished_requests": 26965,
    "scheduler_time": 4.142837136287132
}
#Debug simulation 
Total elapsed time: 2.612536897882819. Arrivals time: 0.07524549029767513 Scheduler time: 2.2034623585641384 Scheduler overhead time: 0.10823388863354921 Adapter cache time: 0.06870302883908153 Engine time: 0.10524960793554783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.3394412281922996,
    "estimated_duration": 3600.010335479074,
    "input_throughput": 1725.5903236659221,
    "output_throughput": 1485.2571247655742,
    "total_throughput": 3210.8474484314966,
    "itl": 30.846906731482076,
    "ttft": 23279.864485261533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.02795665637751,
    "arrivals": 25189,
    "finished_requests": 25066,
    "scheduler_time": 1.8445916499938393
}
#Debug simulation 
Total elapsed time: 2.3395304642617702. Arrivals time: 0.07096978882327676 Scheduler time: 1.9286406263709068 Scheduler overhead time: 0.10872374614700675 Adapter cache time: 0.07299131993204355 Engine time: 0.10618541622534394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.3546514860354364,
    "estimated_duration": 3600.024953089377,
    "input_throughput": 1725.556095012371,
    "output_throughput": 1485.2424829476602,
    "total_throughput": 3210.7985779600313,
    "itl": 30.91872254255188,
    "ttft": 23462.897258152316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 70.55860745661863,
    "arrivals": 25189,
    "finished_requests": 25065,
    "scheduler_time": 1.8780782608525453
}
#Debug simulation 
Total elapsed time: 2.3547443100251257. Arrivals time: 0.07183547224849463 Scheduler time: 1.9386662705801427 Scheduler overhead time: 0.10950273927301168 Adapter cache time: 0.07379605388268828 Engine time: 0.10878181271255016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.3521904163062572,
    "estimated_duration": 3600.0013721650084,
    "input_throughput": 1725.5673978435548,
    "output_throughput": 1485.2522116635796,
    "total_throughput": 3210.8196095071344,
    "itl": 30.934532090273546,
    "ttft": 23337.470524787983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 72.37727493947695,
    "arrivals": 25189,
    "finished_requests": 25065,
    "scheduler_time": 1.8902070458845812
}
#Debug simulation 
Total elapsed time: 2.352273832075298. Arrivals time: 0.07150899898260832 Scheduler time: 1.9391793864779174 Scheduler overhead time: 0.10919867595657706 Adapter cache time: 0.07358048669993877 Engine time: 0.10681648692116141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.3683608323335648,
    "estimated_duration": 3600.0314456064584,
    "input_throughput": 1725.5802050233224,
    "output_throughput": 1485.2484154063434,
    "total_throughput": 3210.8286204296655,
    "itl": 30.877488174450708,
    "ttft": 23284.00483315718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.65735684702301,
    "arrivals": 25189,
    "finished_requests": 25066,
    "scheduler_time": 1.856716571559375
}
#Debug simulation 
Total elapsed time: 2.3684586072340608. Arrivals time: 0.07331103039905429 Scheduler time: 1.9513469468802214 Scheduler overhead time: 0.10925046913325787 Adapter cache time: 0.07480843039229512 Engine time: 0.10740671306848526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.344849627930671,
    "estimated_duration": 3600.025691682839,
    "input_throughput": 1725.5557409914393,
    "output_throughput": 1485.2421782302827,
    "total_throughput": 3210.797919221722,
    "itl": 30.92747455844207,
    "ttft": 23473.839398141274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.87789112367966,
    "arrivals": 25189,
    "finished_requests": 25065,
    "scheduler_time": 1.88614320685
}
#Debug simulation 
Total elapsed time: 2.3449356402270496. Arrivals time: 0.07389340084046125 Scheduler time: 1.93006956204772 Scheduler overhead time: 0.10917647136375308 Adapter cache time: 0.07338743889704347 Engine time: 0.10647399071604013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.3687108079902828,
    "estimated_duration": 3600.0320526479422,
    "input_throughput": 1725.579914054033,
    "output_throughput": 1485.2481649620727,
    "total_throughput": 3210.8280790161057,
    "itl": 30.82416869599411,
    "ttft": 23253.4038906443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.904881360719614,
    "arrivals": 25189,
    "finished_requests": 25066,
    "scheduler_time": 1.833996733942944
}
#Debug simulation 
Total elapsed time: 2.368793598841876. Arrivals time: 0.0722237266600132 Scheduler time: 1.9498841539025307 Scheduler overhead time: 0.11010774690657854 Adapter cache time: 0.07425016770139337 Engine time: 0.10969859315082431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.407983925193548,
    "estimated_duration": 3600.0046048348427,
    "input_throughput": 1725.565848348405,
    "output_throughput": 1485.250877962502,
    "total_throughput": 3210.816726310907,
    "itl": 30.926018954472767,
    "ttft": 23328.11741778898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.16768333203889,
    "arrivals": 25189,
    "finished_requests": 25065,
    "scheduler_time": 1.883179524621222
}
#Debug simulation 
Total elapsed time: 2.4080694392323494. Arrivals time: 0.07189950160682201 Scheduler time: 1.9954786733724177 Scheduler overhead time: 0.1084723211824894 Adapter cache time: 0.07372057111933827 Engine time: 0.10623763129115105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.323847355786711,
    "estimated_duration": 3599.9460013419625,
    "input_throughput": 1644.7571707444495,
    "output_throughput": 1452.7684576519869,
    "total_throughput": 3097.5256283964363,
    "itl": 30.67775516639244,
    "ttft": 16236.100357087216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.78838369505117,
    "arrivals": 24288,
    "finished_requests": 24208,
    "scheduler_time": 1.2989130538932485
}
#Debug simulation 
Total elapsed time: 2.323934509884566. Arrivals time: 0.07023518020287156 Scheduler time: 1.9075897433795035 Scheduler overhead time: 0.11023357091471553 Adapter cache time: 0.0746457683853805 Engine time: 0.108698935713619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2669637468643486,
    "estimated_duration": 3599.9701164426174,
    "input_throughput": 1644.7461530183455,
    "output_throughput": 1452.7587259996533,
    "total_throughput": 3097.5048790179985,
    "itl": 30.745017269699357,
    "ttft": 16281.191493652874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.36691021566266,
    "arrivals": 24288,
    "finished_requests": 24208,
    "scheduler_time": 1.3306344134304837
}
#Debug simulation 
Total elapsed time: 2.267048412002623. Arrivals time: 0.0692533366382122 Scheduler time: 1.8519885842688382 Scheduler overhead time: 0.1093948008492589 Adapter cache time: 0.07448499789461493 Engine time: 0.10896235425025225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2697594412602484,
    "estimated_duration": 3599.9613169275176,
    "input_throughput": 1644.7504511113655,
    "output_throughput": 1452.8811671965275,
    "total_throughput": 3097.631618307893,
    "itl": 30.7649173083075,
    "ttft": 16152.371046801172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.2345795648813,
    "arrivals": 24288,
    "finished_requests": 24209,
    "scheduler_time": 1.3437571695920332
}
#Debug simulation 
Total elapsed time: 2.2698437361977994. Arrivals time: 0.06958969961851835 Scheduler time: 1.8563493136316538 Scheduler overhead time: 0.10941400565207005 Adapter cache time: 0.0745654278434813 Engine time: 0.10758629161864519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.23663883889094,
    "estimated_duration": 3599.9406108591274,
    "input_throughput": 1644.759633572661,
    "output_throughput": 1452.7706329999385,
    "total_throughput": 3097.5302665725994,
    "itl": 30.705857273477196,
    "ttft": 16246.555993827073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.46985270203655,
    "arrivals": 24288,
    "finished_requests": 24208,
    "scheduler_time": 1.3125431964505787
}
#Debug simulation 
Total elapsed time: 2.2367361248470843. Arrivals time: 0.07021013926714659 Scheduler time: 1.8253451106138527 Scheduler overhead time: 0.10918417107313871 Adapter cache time: 0.07419080706313252 Engine time: 0.105825733859092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.322738232091069,
    "estimated_duration": 3599.9546139564413,
    "input_throughput": 1644.7532357894452,
    "output_throughput": 1452.7649820152096,
    "total_throughput": 3097.518217804655,
    "itl": 30.759835349673097,
    "ttft": 16290.363455501505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 72.68399976485735,
    "arrivals": 24288,
    "finished_requests": 24208,
    "scheduler_time": 1.3365074601523959
}
#Debug simulation 
Total elapsed time: 2.322825045324862. Arrivals time: 0.07038621371611953 Scheduler time: 1.9072160925716162 Scheduler overhead time: 0.10937248542904854 Adapter cache time: 0.07442332757636905 Engine time: 0.10868097329512239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.331265142187476,
    "estimated_duration": 3599.955013786414,
    "input_throughput": 1644.7530531144844,
    "output_throughput": 1452.7648206634758,
    "total_throughput": 3097.51787377796,
    "itl": 30.654074414738258,
    "ttft": 16209.75881678531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.59434482230132,
    "arrivals": 24288,
    "finished_requests": 24208,
    "scheduler_time": 1.287642641688591
}
#Debug simulation 
Total elapsed time: 2.3313464601524174. Arrivals time: 0.06953643029555678 Scheduler time: 1.9130197535268962 Scheduler overhead time: 0.10955234104767442 Adapter cache time: 0.07511873915791512 Engine time: 0.11166305933147669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2647707099094987,
    "estimated_duration": 3599.947718453709,
    "input_throughput": 1644.7566640060186,
    "output_throughput": 1452.8866553224793,
    "total_throughput": 3097.643319328498,
    "itl": 30.75575995692081,
    "ttft": 16127.791328196065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9747,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.9924220435118,
    "arrivals": 24288,
    "finished_requests": 24209,
    "scheduler_time": 1.3329716369866798
}
#Debug simulation 
Total elapsed time: 2.264868717174977. Arrivals time: 0.07065872149541974 Scheduler time: 1.8506437987089157 Scheduler overhead time: 0.10967365652322769 Adapter cache time: 0.07417001388967037 Engine time: 0.10742294089868665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.1765784760937095,
    "estimated_duration": 3599.8991098578167,
    "input_throughput": 1626.6578093715752,
    "output_throughput": 1410.1061849481925,
    "total_throughput": 3036.763994319768,
    "itl": 30.52389433242315,
    "ttft": 15176.603082465186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.9358903942569,
    "arrivals": 23803,
    "finished_requests": 23723,
    "scheduler_time": 0.8031322244090441
}
#Debug simulation 
Total elapsed time: 2.1766771469265223. Arrivals time: 0.06863476056605577 Scheduler time: 1.7610336639918387 Scheduler overhead time: 0.10930909588932991 Adapter cache time: 0.07671709032729268 Engine time: 0.108646001201123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1704262010753155,
    "estimated_duration": 3599.908581061368,
    "input_throughput": 1626.5188040618702,
    "output_throughput": 1409.9955278596203,
    "total_throughput": 3036.5143319214903,
    "itl": 30.566099074053202,
    "ttft": 15740.644186061743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.75915322340099,
    "arrivals": 23803,
    "finished_requests": 23722,
    "scheduler_time": 0.8500221252589756
}
#Debug simulation 
Total elapsed time: 2.1705209971405566. Arrivals time: 0.06871647061780095 Scheduler time: 1.7603141060099006 Scheduler overhead time: 0.10932997008785605 Adapter cache time: 0.07371365884318948 Engine time: 0.10606777714565396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.183730036020279,
    "estimated_duration": 3599.914584020516,
    "input_throughput": 1626.6508172146753,
    "output_throughput": 1410.1001236342308,
    "total_throughput": 3036.750940848906,
    "itl": 30.614820325855405,
    "ttft": 15231.27233905222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.84142942990226,
    "arrivals": 23803,
    "finished_requests": 23723,
    "scheduler_time": 0.83455696374907
}
#Debug simulation 
Total elapsed time: 2.183816234115511. Arrivals time: 0.06817874452099204 Scheduler time: 1.7690177881158888 Scheduler overhead time: 0.10927486885339022 Adapter cache time: 0.0768794254399836 Engine time: 0.10798873985186219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.160968700889498,
    "estimated_duration": 3599.9117729015516,
    "input_throughput": 1626.652087442739,
    "output_throughput": 1410.1012247609942,
    "total_throughput": 3036.753312203733,
    "itl": 30.552201483657743,
    "ttft": 15192.550581226642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 70.93254469516692,
    "arrivals": 23803,
    "finished_requests": 23723,
    "scheduler_time": 0.8144963352525537
}
#Debug simulation 
Total elapsed time: 2.1610559429973364. Arrivals time: 0.06852716393768787 Scheduler time: 1.745086848270148 Scheduler overhead time: 0.10949472803622484 Adapter cache time: 0.07644659839570522 Engine time: 0.1090004169382155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.177374911028892,
    "estimated_duration": 3599.900806357568,
    "input_throughput": 1626.6570427880727,
    "output_throughput": 1410.10552041744,
    "total_throughput": 3036.762563205513,
    "itl": 30.60778613667286,
    "ttft": 15226.59850056539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.25791913656079,
    "arrivals": 23803,
    "finished_requests": 23723,
    "scheduler_time": 0.8306122596939296
}
#Debug simulation 
Total elapsed time: 2.177461991086602. Arrivals time: 0.06858216179534793 Scheduler time: 1.7622337420471013 Scheduler overhead time: 0.10863259853795171 Adapter cache time: 0.07677344838157296 Engine time: 0.1089275786653161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.1660102671012282,
    "estimated_duration": 3599.8984660240912,
    "input_throughput": 1626.6581002956575,
    "output_throughput": 1410.106437142505,
    "total_throughput": 3036.7645374381623,
    "itl": 30.49952760904436,
    "ttft": 15161.3331299194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.6650107947143,
    "arrivals": 23803,
    "finished_requests": 23723,
    "scheduler_time": 0.7963158471385069
}
#Debug simulation 
Total elapsed time: 2.1660916693508625. Arrivals time: 0.06820324575528502 Scheduler time: 1.7534808702766895 Scheduler overhead time: 0.10942705301567912 Adapter cache time: 0.07658556709066033 Engine time: 0.10584923112764955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1867960449308157,
    "estimated_duration": 3599.909663700944,
    "input_throughput": 1626.5183149013653,
    "output_throughput": 1409.9951038164907,
    "total_throughput": 3036.513418717856,
    "itl": 30.572421405522736,
    "ttft": 15735.419929583722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 72.43782725335876,
    "arrivals": 23803,
    "finished_requests": 23722,
    "scheduler_time": 0.8529913836428523
}
#Debug simulation 
Total elapsed time: 2.186885402072221. Arrivals time: 0.06925245048478246 Scheduler time: 1.7716535096988082 Scheduler overhead time: 0.10931499628350139 Adapter cache time: 0.07492500962689519 Engine time: 0.10926654143258929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9522091131657362,
    "estimated_duration": 3599.7492725407574,
    "input_throughput": 1450.407682509195,
    "output_throughput": 1291.4493893955955,
    "total_throughput": 2741.8570719047902,
    "itl": 29.931169558536364,
    "ttft": 12935.775425399645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.52337602625028,
    "arrivals": 21290,
    "finished_requests": 21222,
    "scheduler_time": 0.19351799105208564
}
#Debug simulation 
Total elapsed time: 1.952293197158724. Arrivals time: 0.061785563826560974 Scheduler time: 1.5403845007531345 Scheduler overhead time: 0.10872051026672125 Adapter cache time: 0.0806107772514224 Engine time: 0.10825139563530684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9771342957392335,
    "estimated_duration": 3599.7476876779233,
    "input_throughput": 1450.5277738974635,
    "output_throughput": 1291.4505135772022,
    "total_throughput": 2741.9782874746656,
    "itl": 30.036019675298636,
    "ttft": 13119.14589600654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.42584674616974,
    "arrivals": 21290,
    "finished_requests": 21223,
    "scheduler_time": 0.20934487623211168
}
#Debug simulation 
Total elapsed time: 1.9772187187336385. Arrivals time: 0.06202073022723198 Scheduler time: 1.5651532686315477 Scheduler overhead time: 0.1076878565363586 Adapter cache time: 0.07887705322355032 Engine time: 0.11109383217990398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9691032096743584,
    "estimated_duration": 3599.7283993563715,
    "input_throughput": 1450.5355462188775,
    "output_throughput": 1291.4574335194895,
    "total_throughput": 2741.992979738367,
    "itl": 30.056745276285387,
    "ttft": 13130.030663041476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 80.45134972629792,
    "arrivals": 21290,
    "finished_requests": 21223,
    "scheduler_time": 0.21215180996199282
}
#Debug simulation 
Total elapsed time: 1.9691877765581012. Arrivals time: 0.061953413765877485 Scheduler time: 1.5573120024055243 Scheduler overhead time: 0.10903741233050823 Adapter cache time: 0.07825064659118652 Engine time: 0.10979232098907232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9543644082732499,
    "estimated_duration": 3599.737266448329,
    "input_throughput": 1450.4125200091028,
    "output_throughput": 1291.453696726822,
    "total_throughput": 2741.866216735925,
    "itl": 29.967011929290745,
    "ttft": 12953.150462091991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.72482012536251,
    "arrivals": 21290,
    "finished_requests": 21222,
    "scheduler_time": 0.19787467436342768
}
#Debug simulation 
Total elapsed time: 1.9544539540074766. Arrivals time: 0.062466331757605076 Scheduler time: 1.5413755988702178 Scheduler overhead time: 0.10658900672569871 Adapter cache time: 0.08279333682730794 Engine time: 0.1081694788299501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0172878094017506,
    "estimated_duration": 3599.750123372323,
    "input_throughput": 1450.5267924286798,
    "output_throughput": 1291.449639744665,
    "total_throughput": 2741.976432173345,
    "itl": 30.04962345616957,
    "ttft": 13125.071107782807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.87115067350379,
    "arrivals": 21290,
    "finished_requests": 21223,
    "scheduler_time": 0.21076667959511153
}
#Debug simulation 
Total elapsed time: 2.0173746184445918. Arrivals time: 0.06269362382590771 Scheduler time: 1.6061868448741734 Scheduler overhead time: 0.10897101368755102 Adapter cache time: 0.07853619335219264 Engine time: 0.10813932633027434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9479224937967956,
    "estimated_duration": 3599.728603869008,
    "input_throughput": 1450.4160103593167,
    "output_throughput": 1291.4568045500273,
    "total_throughput": 2741.872814909344,
    "itl": 29.904886222811967,
    "ttft": 12925.286132136907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.05304006855056,
    "arrivals": 21290,
    "finished_requests": 21222,
    "scheduler_time": 0.19119995613857327
}
#Debug simulation 
Total elapsed time: 1.9480001446790993. Arrivals time: 0.06210875138640404 Scheduler time: 1.5370244793593884 Scheduler overhead time: 0.1081031602807343 Adapter cache time: 0.08028010232374072 Engine time: 0.10769749246537685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0403380328789353,
    "estimated_duration": 3599.741346165864,
    "input_throughput": 1450.5303292308852,
    "output_throughput": 1291.4527886709432,
    "total_throughput": 2741.9831179018283,
    "itl": 30.040596487659485,
    "ttft": 13122.89031675881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.0386885268999,
    "arrivals": 21290,
    "finished_requests": 21223,
    "scheduler_time": 0.2078484186945621
}
#Debug simulation 
Total elapsed time: 2.0404258240014315. Arrivals time: 0.062244529370218515 Scheduler time: 1.6300885789096355 Scheduler overhead time: 0.10886124707758427 Adapter cache time: 0.07844784669578075 Engine time: 0.1081104283221066 
