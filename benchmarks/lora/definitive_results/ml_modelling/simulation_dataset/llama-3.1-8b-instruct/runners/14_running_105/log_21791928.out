INFO 05-31 19:30:53 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:54 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.697774400934577,
    "estimated_duration": 3599.971885307452,
    "input_throughput": 1286.0844882972165,
    "output_throughput": 1132.7616242346655,
    "total_throughput": 2418.8461125318818,
    "itl": 24.739122251032217,
    "ttft": 6602.560585586828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.708031387561977,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.0048517341138820435
}
#Debug simulation 
Total elapsed time: 1.6979862917214632. Arrivals time: 0.060627315659075975 Scheduler time: 1.2873916989192367 Scheduler overhead time: 0.12595739495009184 Adapter cache time: 0.03417997807264328 Engine time: 0.12638789135962725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6843237970024347,
    "estimated_duration": 3599.9637491900876,
    "input_throughput": 1286.0873949193567,
    "output_throughput": 1132.764184338645,
    "total_throughput": 2418.8515792580015,
    "itl": 24.753268733554687,
    "ttft": 6603.482621610349,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.707110076527517,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.004899173864851115
}
#Debug simulation 
Total elapsed time: 1.6844535050913692. Arrivals time: 0.05887453816831112 Scheduler time: 1.2824990255758166 Scheduler overhead time: 0.12481537600979209 Adapter cache time: 0.03388474229723215 Engine time: 0.12328249728307128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.705068666022271,
    "estimated_duration": 3599.9580066408575,
    "input_throughput": 1286.0894464488929,
    "output_throughput": 1132.7659912914157,
    "total_throughput": 2418.8554377403084,
    "itl": 24.759726584913633,
    "ttft": 6603.393568342388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.26674171538571,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.004950943137014715
}
#Debug simulation 
Total elapsed time: 1.7052550250664353. Arrivals time: 0.05904676578938961 Scheduler time: 1.3037536065094173 Scheduler overhead time: 0.12397091882303357 Adapter cache time: 0.033858937211334705 Engine time: 0.12361556198447943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6895916610956192,
    "estimated_duration": 3599.9748173936887,
    "input_throughput": 1286.0834408147148,
    "output_throughput": 1132.760701629665,
    "total_throughput": 2418.84414244438,
    "itl": 24.744829166414224,
    "ttft": 6602.919371449981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.306952298381805,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.004838636383130071
}
#Debug simulation 
Total elapsed time: 1.6897174301557243. Arrivals time: 0.05891562066972256 Scheduler time: 1.2847418710589409 Scheduler overhead time: 0.12490896414965391 Adapter cache time: 0.03391415858641267 Engine time: 0.12612170865759254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6822167658247054,
    "estimated_duration": 3599.9583177460117,
    "input_throughput": 1286.0893353062015,
    "output_throughput": 1132.7658933987993,
    "total_throughput": 2418.855228705001,
    "itl": 24.757158697595038,
    "ttft": 6603.400379259936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.10512946955871,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.004901328248630187
}
#Debug simulation 
Total elapsed time: 1.6823271508328617. Arrivals time: 0.05718859890475869 Scheduler time: 1.2819143701344728 Scheduler overhead time: 0.12475235154852271 Adapter cache time: 0.03415874019265175 Engine time: 0.12335664359852672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6745115779340267,
    "estimated_duration": 3599.9577128279934,
    "input_throughput": 1286.0895514139102,
    "output_throughput": 1132.7660837428407,
    "total_throughput": 2418.855635156751,
    "itl": 24.734861305202315,
    "ttft": 6602.549592867408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.083372436967917,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.004808966140077009
}
#Debug simulation 
Total elapsed time: 1.6746284989640117. Arrivals time: 0.055732496082782745 Scheduler time: 1.2786555048078299 Scheduler overhead time: 0.12382029974833131 Adapter cache time: 0.03405612986534834 Engine time: 0.12190721882507205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7235862440429628,
    "estimated_duration": 3599.968328618721,
    "input_throughput": 1286.085758920119,
    "output_throughput": 1132.7627433779844,
    "total_throughput": 2418.8485022981035,
    "itl": 24.756759388801015,
    "ttft": 6603.366270597127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.86762841256344,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.00491871399330392
}
#Debug simulation 
Total elapsed time: 1.7237620730884373. Arrivals time: 0.06199862388893962 Scheduler time: 1.3124000644311309 Scheduler overhead time: 0.12695282883942127 Adapter cache time: 0.034529490396380424 Engine time: 0.12583639286458492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6966496682725847,
    "estimated_duration": 3599.899793881958,
    "input_throughput": 1269.0283790020958,
    "output_throughput": 1093.7604448578463,
    "total_throughput": 2362.788823859942,
    "itl": 24.390260896802523,
    "ttft": 6691.720204432563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1962,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.973546520686128,
    "arrivals": 18499,
    "finished_requests": 18465,
    "scheduler_time": 0.003142129487644519
}
#Debug simulation 
Total elapsed time: 1.696748643182218. Arrivals time: 0.06229679239913821 Scheduler time: 1.2761676404625177 Scheduler overhead time: 0.12921600649133325 Adapter cache time: 0.03306932793930173 Engine time: 0.1303568654693663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7257215762510896,
    "estimated_duration": 3599.907409576874,
    "input_throughput": 1269.0256943405545,
    "output_throughput": 1093.7581309800403,
    "total_throughput": 2362.7838253205946,
    "itl": 24.573424419663144,
    "ttft": 6730.111749662599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.023644096674028,
    "arrivals": 18499,
    "finished_requests": 18465,
    "scheduler_time": 0.00024741403895292135
}
#Debug simulation 
Total elapsed time: 1.7258246201090515. Arrivals time: 0.06124312477186322 Scheduler time: 1.3131262548267841 Scheduler overhead time: 0.12672719126567245 Adapter cache time: 0.032658040057867765 Engine time: 0.12884748307988048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7126228823326528,
    "estimated_duration": 3599.913138625285,
    "input_throughput": 1269.023674761371,
    "output_throughput": 1093.7563903287964,
    "total_throughput": 2362.7800650901677,
    "itl": 24.40675281022452,
    "ttft": 6691.98835119181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1962,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.978891117074161,
    "arrivals": 18499,
    "finished_requests": 18465,
    "scheduler_time": 0.0031454334413016692
}
#Debug simulation 
Total elapsed time: 1.712721399962902. Arrivals time: 0.06030944408848882 Scheduler time: 1.3006730596534908 Scheduler overhead time: 0.1277580140158534 Adapter cache time: 0.033230014611035585 Engine time: 0.1279790997505188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7183090769685805,
    "estimated_duration": 3599.8961177167116,
    "input_throughput": 1269.0296749167198,
    "output_throughput": 1093.7615617912256,
    "total_throughput": 2362.7912367079452,
    "itl": 24.394237354752555,
    "ttft": 6691.916815987192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.408718608352597,
    "arrivals": 18499,
    "finished_requests": 18465,
    "scheduler_time": 0.0031339467399370937
}
#Debug simulation 
Total elapsed time: 1.7184572089463472. Arrivals time: 0.06241044495254755 Scheduler time: 1.2980552376247942 Scheduler overhead time: 0.1304468121379614 Adapter cache time: 0.03312142193317413 Engine time: 0.1300896513275802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7278368882834911,
    "estimated_duration": 3599.9139192111547,
    "input_throughput": 1269.023399593139,
    "output_throughput": 1093.7561531645747,
    "total_throughput": 2362.7795527577136,
    "itl": 24.57691239724849,
    "ttft": 6730.309252652892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.273206364311832,
    "arrivals": 18499,
    "finished_requests": 18465,
    "scheduler_time": 0.0002465716557132631
}
#Debug simulation 
Total elapsed time: 1.727942684199661. Arrivals time: 0.06307626329362392 Scheduler time: 1.3102873610332608 Scheduler overhead time: 0.1276234551332891 Adapter cache time: 0.03281885711476207 Engine time: 0.1313703623600304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7270970260724425,
    "estimated_duration": 3599.897186450336,
    "input_throughput": 1269.029298168548,
    "output_throughput": 1093.7612370764634,
    "total_throughput": 2362.7905352450116,
    "itl": 24.386069752649096,
    "ttft": 6691.606467360742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1965,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.544404648221663,
    "arrivals": 18499,
    "finished_requests": 18465,
    "scheduler_time": 0.0031561708910515136
}
#Debug simulation 
Total elapsed time: 1.7271975167095661. Arrivals time: 0.06318629020825028 Scheduler time: 1.3089000433683395 Scheduler overhead time: 0.12891813926398754 Adapter cache time: 0.03344596130773425 Engine time: 0.129307865165174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7599018029868603,
    "estimated_duration": 3599.9063261733245,
    "input_throughput": 1269.0260762579762,
    "output_throughput": 1093.758460150117,
    "total_throughput": 2362.784536408093,
    "itl": 24.57288614075395,
    "ttft": 6730.240834337671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2023,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.104982830490545,
    "arrivals": 18499,
    "finished_requests": 18465,
    "scheduler_time": 0.0002499159969800005
}
#Debug simulation 
Total elapsed time: 1.7600735630840063. Arrivals time: 0.06394557096064091 Scheduler time: 1.3378700101748109 Scheduler overhead time: 0.12965252110734582 Adapter cache time: 0.033167940098792315 Engine time: 0.13127325428649783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6859202980995178,
    "estimated_duration": 3599.9592301049906,
    "input_throughput": 1248.0180226565983,
    "output_throughput": 1086.5689720285861,
    "total_throughput": 2334.5869946851844,
    "itl": 24.243049697409102,
    "ttft": 6359.166832372708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.712102631759176,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.00371793076808317
}
#Debug simulation 
Total elapsed time: 1.6860118387266994. Arrivals time: 0.05692195985466242 Scheduler time: 1.2822331474162638 Scheduler overhead time: 0.12564796674996614 Adapter cache time: 0.031772559974342585 Engine time: 0.12753029447048903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6894966983236372,
    "estimated_duration": 3599.973746000259,
    "input_throughput": 1248.0129903702018,
    "output_throughput": 1086.56459074069,
    "total_throughput": 2334.5775811108915,
    "itl": 24.25555515030517,
    "ttft": 6359.129674552536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.05224016284547,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.003704128371941369
}
#Debug simulation 
Total elapsed time: 1.689597344957292. Arrivals time: 0.05567341484129429 Scheduler time: 1.285871631000191 Scheduler overhead time: 0.12553752632811666 Adapter cache time: 0.03189140744507313 Engine time: 0.12884704396128654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.664175479207188,
    "estimated_duration": 3599.976263154349,
    "input_throughput": 1248.0121177419471,
    "output_throughput": 1086.5638309994295,
    "total_throughput": 2334.5759487413766,
    "itl": 24.259264597118605,
    "ttft": 6359.323945608177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.421930790631793,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.003713051974032894
}
#Debug simulation 
Total elapsed time: 1.6642719563096762. Arrivals time: 0.05831486918032169 Scheduler time: 1.2624449129216373 Scheduler overhead time: 0.12554501229897141 Adapter cache time: 0.03174574067816138 Engine time: 0.12441348982974887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.667095503769815,
    "estimated_duration": 3599.9829032911744,
    "input_throughput": 1248.0098157945645,
    "output_throughput": 1086.561826841993,
    "total_throughput": 2334.5716426365575,
    "itl": 24.24633966645251,
    "ttft": 6359.158772805735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.06242913119044,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0037090071659916448
}
#Debug simulation 
Total elapsed time: 1.6672015930525959. Arrivals time: 0.05853486806154251 Scheduler time: 1.2626428524963558 Scheduler overhead time: 0.12610849784687161 Adapter cache time: 0.03178468160331249 Engine time: 0.12642100872471929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7284830529242754,
    "estimated_duration": 3599.9823518424428,
    "input_throughput": 1248.0100069658988,
    "output_throughput": 1086.5619932825703,
    "total_throughput": 2334.572000248469,
    "itl": 24.256532673562578,
    "ttft": 6359.201231828149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.290976376486709,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0037219755761244196
}
#Debug simulation 
Total elapsed time: 1.7286060149781406. Arrivals time: 0.06344909500330687 Scheduler time: 1.3106812089681625 Scheduler overhead time: 0.12884872173890471 Adapter cache time: 0.0326780304312706 Engine time: 0.12954582553356886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7039868249557912,
    "estimated_duration": 3599.976006732309,
    "input_throughput": 1248.0122066363765,
    "output_throughput": 1086.5639083940882,
    "total_throughput": 2334.5761150304647,
    "itl": 24.242654644536017,
    "ttft": 6358.977369889946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.36110368654625,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0037000835639001196
}
#Debug simulation 
Total elapsed time: 1.7040925342589617. Arrivals time: 0.05835775099694729 Scheduler time: 1.2891349759884179 Scheduler overhead time: 0.12879837350919843 Adapter cache time: 0.03221171582117677 Engine time: 0.13233537506312132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.713406153023243,
    "estimated_duration": 3599.9767243505535,
    "input_throughput": 1248.01195785801,
    "output_throughput": 1086.5636917987754,
    "total_throughput": 2334.5756496567856,
    "itl": 24.25610572568352,
    "ttft": 6359.2256893646745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.174424268062934,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.003742199616330666
}
#Debug simulation 
Total elapsed time: 1.7136311773210764. Arrivals time: 0.05757647380232811 Scheduler time: 1.2998484899289906 Scheduler overhead time: 0.12796995183452964 Adapter cache time: 0.03226535301655531 Engine time: 0.13313580956310034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7131618540734053,
    "estimated_duration": 3599.8577203871896,
    "input_throughput": 1235.3729912196852,
    "output_throughput": 1096.605840181763,
    "total_throughput": 2331.978831401448,
    "itl": 24.299527506917872,
    "ttft": 4803.717052078576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.184636145378692,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.0001918576859930756
}
#Debug simulation 
Total elapsed time: 1.7132526319473982. Arrivals time: 0.05917922733351588 Scheduler time: 1.30048861913383 Scheduler overhead time: 0.12913651019334793 Adapter cache time: 0.031838950235396624 Engine time: 0.1293990695849061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7273176317103207,
    "estimated_duration": 3599.8558524642267,
    "input_throughput": 1235.373632240235,
    "output_throughput": 1096.6064091976664,
    "total_throughput": 2331.9800414379015,
    "itl": 24.30775896035323,
    "ttft": 4803.747259836779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.361549137662967,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00020244926010265344
}
#Debug simulation 
Total elapsed time: 1.727429123595357. Arrivals time: 0.06068584509193897 Scheduler time: 1.312932857312262 Scheduler overhead time: 0.1288270871154964 Adapter cache time: 0.031659791711717844 Engine time: 0.1300406097434461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7264516856521368,
    "estimated_duration": 3599.857935237591,
    "input_throughput": 1235.3729174888915,
    "output_throughput": 1096.6057747330121,
    "total_throughput": 2331.9786922219037,
    "itl": 24.310554303908763,
    "ttft": 4803.954665615871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.659049252993302,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00020566008213487635
}
#Debug simulation 
Total elapsed time: 1.726574717555195. Arrivals time: 0.060838745441287756 Scheduler time: 1.3137389090843499 Scheduler overhead time: 0.12772709131240845 Adapter cache time: 0.031364094000309706 Engine time: 0.12850984698161483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7193090301007032,
    "estimated_duration": 3599.8599055249247,
    "input_throughput": 1235.3722413404648,
    "output_throughput": 1096.605174535081,
    "total_throughput": 2331.977415875546,
    "itl": 24.300212237553886,
    "ttft": 4803.712646664757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.461150909909097,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00020399211011682355
}
#Debug simulation 
Total elapsed time: 1.719486161135137. Arrivals time: 0.05701359128579497 Scheduler time: 1.3110270211473107 Scheduler overhead time: 0.12799056665971875 Adapter cache time: 0.03149521257728338 Engine time: 0.12880305899307132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.708385564852506,
    "estimated_duration": 3599.8587661266956,
    "input_throughput": 1235.3726323505114,
    "output_throughput": 1096.6055216236962,
    "total_throughput": 2331.9781539742075,
    "itl": 24.31068745200814,
    "ttft": 4803.763625618946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.536072022551554,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00021374969821737498
}
#Debug simulation 
Total elapsed time: 1.708534061908722. Arrivals time: 0.05883040791377425 Scheduler time: 1.2989858849905431 Scheduler overhead time: 0.12708612950518727 Adapter cache time: 0.03125204797834158 Engine time: 0.12951180571690202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7089928989298642,
    "estimated_duration": 3599.8618994249155,
    "input_throughput": 1235.371557089577,
    "output_throughput": 1096.604567144823,
    "total_throughput": 2331.9761242344002,
    "itl": 24.297331530989254,
    "ttft": 4803.606000291604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.84811442363083,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00019994730207557423
}
#Debug simulation 
Total elapsed time: 1.7090863306075335. Arrivals time: 0.059383844025433064 Scheduler time: 1.2952785170637071 Scheduler overhead time: 0.12884703371673822 Adapter cache time: 0.031403105705976486 Engine time: 0.13075061840936542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7125099441036582,
    "estimated_duration": 3599.84916535848,
    "input_throughput": 1235.3759270791954,
    "output_throughput": 1096.6084462616332,
    "total_throughput": 2331.9843733408284,
    "itl": 24.311087258055363,
    "ttft": 4803.813708057257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.468961567785477,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00020803691815807286
}
#Debug simulation 
Total elapsed time: 1.712704855017364. Arrivals time: 0.06056873966008425 Scheduler time: 1.299450530204922 Scheduler overhead time: 0.12862500082701445 Adapter cache time: 0.0316130667924881 Engine time: 0.12923887884244323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6572024109773338,
    "estimated_duration": 3599.7884738138346,
    "input_throughput": 1217.4832026607164,
    "output_throughput": 1054.166662181565,
    "total_throughput": 2271.6498648422817,
    "itl": 23.97566811555446,
    "ttft": 4764.892850476555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.6439448409343065,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.657325768377632. Arrivals time: 0.05988777568563819 Scheduler time: 1.2422040570527315 Scheduler overhead time: 0.13052938971668482 Adapter cache time: 0.02995080640539527 Engine time: 0.13050043489784002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6232707579620183,
    "estimated_duration": 3599.8090396203656,
    "input_throughput": 1217.4762471462086,
    "output_throughput": 1054.1606396988757,
    "total_throughput": 2271.636886845084,
    "itl": 23.958772226467683,
    "ttft": 4764.770136047204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.603921219590095,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.6234108470380306. Arrivals time: 0.05776700796559453 Scheduler time: 1.21622822759673 Scheduler overhead time: 0.1295867022126913 Adapter cache time: 0.030082249082624912 Engine time: 0.12666305666789412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6849441342055798,
    "estimated_duration": 3599.796534427278,
    "input_throughput": 1217.480476489563,
    "output_throughput": 1054.164301706497,
    "total_throughput": 2271.64477819606,
    "itl": 23.959844279840404,
    "ttft": 4764.806379871989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.841606687912689,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.685062468983233. Arrivals time: 0.06047646375373006 Scheduler time: 1.265504694543779 Scheduler overhead time: 0.13079056097194552 Adapter cache time: 0.030727576930075884 Engine time: 0.13382814452052116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6531755169853568,
    "estimated_duration": 3599.790767611553,
    "input_throughput": 1217.4824268766856,
    "output_throughput": 1054.1659904633345,
    "total_throughput": 2271.64841734002,
    "itl": 23.976817320061127,
    "ttft": 4764.792764799241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.82932234953156,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6532880240119994. Arrivals time: 0.05287962593138218 Scheduler time: 1.2492754305712879 Scheduler overhead time: 0.1284763142466545 Adapter cache time: 0.030114396009594202 Engine time: 0.1295227063819766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6499377209693193,
    "estimated_duration": 3599.795195909695,
    "input_throughput": 1217.4809291872684,
    "output_throughput": 1054.164693678089,
    "total_throughput": 2271.6456228653574,
    "itl": 23.958872559446263,
    "ttft": 4764.871858752784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.747315007057022,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6500603631138802. Arrivals time: 0.05998712871223688 Scheduler time: 1.2375923581421375 Scheduler overhead time: 0.13011540425941348 Adapter cache time: 0.030662402044981718 Engine time: 0.12816294049844146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6529405280016363,
    "estimated_duration": 3599.804861401402,
    "input_throughput": 1217.477660245679,
    "output_throughput": 1054.1618632413024,
    "total_throughput": 2271.6395234869815,
    "itl": 23.949806290965615,
    "ttft": 4764.703780022185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.450035737645774,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6530617172829807. Arrivals time: 0.05655793147161603 Scheduler time: 1.2425858108326793 Scheduler overhead time: 0.12989281676709652 Adapter cache time: 0.030318669509142637 Engine time: 0.12987003987655044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6602248260751367,
    "estimated_duration": 3599.789537119596,
    "input_throughput": 1217.4828430405526,
    "output_throughput": 1054.1663508018376,
    "total_throughput": 2271.64919384239,
    "itl": 23.9597657551338,
    "ttft": 4764.805158254445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.677723635714488,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6603963770903647. Arrivals time: 0.05931972060352564 Scheduler time: 1.248663012869656 Scheduler overhead time: 0.12931275088340044 Adapter cache time: 0.030451403930783272 Engine time: 0.1290847542695701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6608242890797555,
    "estimated_duration": 3599.820690574604,
    "input_throughput": 1186.071576059106,
    "output_throughput": 1054.6522525248313,
    "total_throughput": 2240.723828583937,
    "itl": 23.93017537702459,
    "ttft": 5032.550818087124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.242114126160875,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 4.16993004513202e-06
}
#Debug simulation 
Total elapsed time: 1.6609584633260965. Arrivals time: 0.06047049490734935 Scheduler time: 1.2421981757506728 Scheduler overhead time: 0.13181887846440077 Adapter cache time: 0.030199331231415272 Engine time: 0.131993449293077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6174612590111792,
    "estimated_duration": 3599.828159273883,
    "input_throughput": 1186.0691152716647,
    "output_throughput": 1054.6500643980182,
    "total_throughput": 2240.719179669683,
    "itl": 23.935992519389856,
    "ttft": 5032.6099514980015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.96541592978408,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 5.0039160541584245e-06
}
#Debug simulation 
Total elapsed time: 1.6175744142383337. Arrivals time: 0.05351476091891527 Scheduler time: 1.2134961714036763 Scheduler overhead time: 0.12941150600090623 Adapter cache time: 0.029439174570143223 Engine time: 0.12857078341767192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6458815890364349,
    "estimated_duration": 3599.8340932479086,
    "input_throughput": 1186.067160152862,
    "output_throughput": 1054.6483259106528,
    "total_throughput": 2240.715486063515,
    "itl": 23.93672858460569,
    "ttft": 5032.599567879887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.176105989357487,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 4.16993004513202e-06
}
#Debug simulation 
Total elapsed time: 1.645995310973376. Arrivals time: 0.058958366978913546 Scheduler time: 1.231567622628063 Scheduler overhead time: 0.13030425226315856 Adapter cache time: 0.029650666285306215 Engine time: 0.13159565208479762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.652991820126772,
    "estimated_duration": 3599.827055967421,
    "input_throughput": 1186.0694787884945,
    "output_throughput": 1054.6503876363886,
    "total_throughput": 2240.719866424883,
    "itl": 23.930014459753473,
    "ttft": 5032.525377680414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.425397971165355,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 4.16993004513202e-06
}
#Debug simulation 
Total elapsed time: 1.6530948132276535. Arrivals time: 0.0573494303971529 Scheduler time: 1.240125426556915 Scheduler overhead time: 0.12979359505698085 Adapter cache time: 0.029715928714722395 Engine time: 0.13247838476672769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6471940414048731,
    "estimated_duration": 3599.8358430697817,
    "input_throughput": 1186.066583624834,
    "output_throughput": 1054.6478132631908,
    "total_throughput": 2240.7143968880246,
    "itl": 23.93624392588071,
    "ttft": 5032.634928721845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.087461334280699,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 4.16993004513202e-06
}
#Debug simulation 
Total elapsed time: 1.6473430022597313. Arrivals time: 0.05818966589868069 Scheduler time: 1.2354534133337438 Scheduler overhead time: 0.12950703082606196 Adapter cache time: 0.029709658585488796 Engine time: 0.13046160340309143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.649854861665517,
    "estimated_duration": 3599.8370818580474,
    "input_throughput": 1186.066175471539,
    "output_throughput": 1054.647450334173,
    "total_throughput": 2240.713625805712,
    "itl": 23.929102368773734,
    "ttft": 5032.590039619452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.032805288839124,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 4.16993004513202e-06
}
#Debug simulation 
Total elapsed time: 1.6499713086523116. Arrivals time: 0.05915871821343899 Scheduler time: 1.2366718230769038 Scheduler overhead time: 0.1305494667030871 Adapter cache time: 0.029797024093568325 Engine time: 0.12984861759468913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6065307538956404,
    "estimated_duration": 3599.8153897769807,
    "input_throughput": 1186.0733225723882,
    "output_throughput": 1054.6538055206238,
    "total_throughput": 2240.7271280930117,
    "itl": 23.936524020364775,
    "ttft": 5032.672101180854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.026983118709207,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 5.0039160541584245e-06
}
#Debug simulation 
Total elapsed time: 1.6066887257620692. Arrivals time: 0.05472832219675183 Scheduler time: 1.2075646021403372 Scheduler overhead time: 0.12760912533849478 Adapter cache time: 0.029066831804811954 Engine time: 0.1253734463825822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6009386237710714,
    "estimated_duration": 3599.9088085508656,
    "input_throughput": 1192.5882649589173,
    "output_throughput": 1025.819596104311,
    "total_throughput": 2218.407861063228,
    "itl": 23.704068049801318,
    "ttft": 6114.182769016708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.972531592026446,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 1.3218654140539758e-05
}
#Debug simulation 
Total elapsed time: 1.6010390748269856. Arrivals time: 0.05467674741521478 Scheduler time: 1.198010346852243 Scheduler overhead time: 0.12772811762988567 Adapter cache time: 0.028885914012789726 Engine time: 0.1285850154235959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6570110581815243,
    "estimated_duration": 3599.8887143118973,
    "input_throughput": 1192.5949218740302,
    "output_throughput": 1025.8253221324574,
    "total_throughput": 2218.420244006488,
    "itl": 23.70856122025445,
    "ttft": 6114.309601000074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.588387023103436,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 1.726346218178907e-05
}
#Debug simulation 
Total elapsed time: 1.6571503411978483. Arrivals time: 0.05940862279385328 Scheduler time: 1.2329903445206583 Scheduler overhead time: 0.13602983253076673 Adapter cache time: 0.02979345852509141 Engine time: 0.1329235234297812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5992158153094351,
    "estimated_duration": 3599.8932876796057,
    "input_throughput": 1192.593406780479,
    "output_throughput": 1025.8240189059372,
    "total_throughput": 2218.417425686416,
    "itl": 23.710620236092886,
    "ttft": 6114.300870830749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7673308323650065,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 1.726346218178907e-05
}
#Debug simulation 
Total elapsed time: 1.5993248280137777. Arrivals time: 0.05660841008648276 Scheduler time: 1.1896282057277858 Scheduler overhead time: 0.1305664898827672 Adapter cache time: 0.029337559826672077 Engine time: 0.12949124490842223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6037567141465843,
    "estimated_duration": 3599.8889633612293,
    "input_throughput": 1192.5948393673275,
    "output_throughput": 1025.8252511632932,
    "total_throughput": 2218.4200905306207,
    "itl": 23.705253752813555,
    "ttft": 6114.2003998751115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.090015693684099,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 2.2142256232064787e-05
}
#Debug simulation 
Total elapsed time: 1.6039887689985335. Arrivals time: 0.057584463618695736 Scheduler time: 1.1933347000740469 Scheduler overhead time: 0.1293391310609877 Adapter cache time: 0.02933982154354453 Engine time: 0.13068000506609678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6190049033612013,
    "estimated_duration": 3599.901515761067,
    "input_throughput": 1192.5906809404364,
    "output_throughput": 1025.821674240797,
    "total_throughput": 2218.412355181233,
    "itl": 23.70992756901861,
    "ttft": 6114.19149441577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.684899692586663,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 1.8097448190815474e-05
}
#Debug simulation 
Total elapsed time: 1.6191042982973158. Arrivals time: 0.05551851214841008 Scheduler time: 1.2047950746491551 Scheduler overhead time: 0.13309850171208382 Adapter cache time: 0.02950588194653392 Engine time: 0.13202435057610273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6011809427291155,
    "estimated_duration": 3599.913480689861,
    "input_throughput": 1192.5867171611249,
    "output_throughput": 1025.8182647468316,
    "total_throughput": 2218.4049819079564,
    "itl": 23.70342889233098,
    "ttft": 6114.101278359987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.794324626368447,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 1.4052640149566162e-05
}
#Debug simulation 
Total elapsed time: 1.6012963256798685. Arrivals time: 0.05792914377525449 Scheduler time: 1.1912881270982325 Scheduler overhead time: 0.13050793763250113 Adapter cache time: 0.029279413633048534 Engine time: 0.1285175527445972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6171752009540796,
    "estimated_duration": 3599.902172409005,
    "input_throughput": 1192.5904634033552,
    "output_throughput": 1025.8214871235768,
    "total_throughput": 2218.411950526932,
    "itl": 23.709622686818292,
    "ttft": 6114.280487259948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.640783733967731,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 1.726346218178907e-05
}
#Debug simulation 
Total elapsed time: 1.6173884361051023. Arrivals time: 0.0567565131932497 Scheduler time: 1.203159115742892 Scheduler overhead time: 0.1307767415419221 Adapter cache time: 0.02957801427692175 Engine time: 0.13287465274333954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5927495271898806,
    "estimated_duration": 3599.556506629252,
    "input_throughput": 1157.691785731206,
    "output_throughput": 1009.9180255414796,
    "total_throughput": 2167.6098112726854,
    "itl": 23.610814368474983,
    "ttft": 5604.65451079918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8351972385310202,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.001075857281418929
}
#Debug simulation 
Total elapsed time: 1.5928550530225039. Arrivals time: 0.0565363341011107 Scheduler time: 1.1800070237368345 Scheduler overhead time: 0.13145964546129107 Adapter cache time: 0.02829171484336257 Engine time: 0.13223654497414827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5833464302122593,
    "estimated_duration": 3599.5619941084037,
    "input_throughput": 1157.6900208471593,
    "output_throughput": 1009.9164859363501,
    "total_throughput": 2167.6065067835093,
    "itl": 23.613957093291837,
    "ttft": 5604.740624596712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.269068302642561,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010655159513171162
}
#Debug simulation 
Total elapsed time: 1.5834415941499174. Arrivals time: 0.054780036211013794 Scheduler time: 1.1756131243892014 Scheduler overhead time: 0.13087640143930912 Adapter cache time: 0.02796242479234934 Engine time: 0.1302208611741662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.590095235966146,
    "estimated_duration": 3599.549977828884,
    "input_throughput": 1157.6938855321819,
    "output_throughput": 1009.9198573130114,
    "total_throughput": 2167.6137428451934,
    "itl": 23.614770582662388,
    "ttft": 5604.903048704704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.390207856856321,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010517135551753156
}
#Debug simulation 
Total elapsed time: 1.5902029173448682. Arrivals time: 0.057200551964342594 Scheduler time: 1.177810515742749 Scheduler overhead time: 0.13145936280488968 Adapter cache time: 0.02846852270886302 Engine time: 0.1308288862928748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.580878634005785,
    "estimated_duration": 3599.568305388917,
    "input_throughput": 1157.6879910186217,
    "output_throughput": 1009.9147152056132,
    "total_throughput": 2167.602706224235,
    "itl": 23.610923683874418,
    "ttft": 5604.7617861676335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.941448152940713,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010816951834821133
}
#Debug simulation 
Total elapsed time: 1.5809906320646405. Arrivals time: 0.052654145285487175 Scheduler time: 1.1746631185524166 Scheduler overhead time: 0.1287007536739111 Adapter cache time: 0.028499006293714046 Engine time: 0.1329049258492887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5928389341570437,
    "estimated_duration": 3599.548895548755,
    "input_throughput": 1157.6942336172126,
    "output_throughput": 1009.9201609666707,
    "total_throughput": 2167.614394583883,
    "itl": 23.61346434806571,
    "ttft": 5604.843774416207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3413282031752525,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.001067892787340313
}
#Debug simulation 
Total elapsed time: 1.592938028741628. Arrivals time: 0.057281739078462124 Scheduler time: 1.1785926185548306 Scheduler overhead time: 0.13222339330241084 Adapter cache time: 0.028446674346923828 Engine time: 0.1317425067536533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.578237112145871,
    "estimated_duration": 3599.5562896638035,
    "input_throughput": 1157.6918555117836,
    "output_throughput": 1009.9180864149039,
    "total_throughput": 2167.6099419266875,
    "itl": 23.609015854508257,
    "ttft": 5604.688188179864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7026741455308922,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010695607593583652
}
#Debug simulation 
Total elapsed time: 1.5783494478091598. Arrivals time: 0.05584168480709195 Scheduler time: 1.16841602884233 Scheduler overhead time: 0.13099395344033837 Adapter cache time: 0.028002512641251087 Engine time: 0.13112504873424768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.578777777031064,
    "estimated_duration": 3599.5696143411146,
    "input_throughput": 1157.687570035448,
    "output_throughput": 1009.9143479589067,
    "total_throughput": 2167.6019179943546,
    "itl": 23.614493380723907,
    "ttft": 5604.85938564811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.305704048797525,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010598031712578144
}
#Debug simulation 
Total elapsed time: 1.5789234209805727. Arrivals time: 0.054783827159553766 Scheduler time: 1.1708720647729933 Scheduler overhead time: 0.13048445666208863 Adapter cache time: 0.028355173766613007 Engine time: 0.1301261493936181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5868693003430963,
    "estimated_duration": 3599.912799187442,
    "input_throughput": 1136.70392264047,
    "output_throughput": 1005.3487964533208,
    "total_throughput": 2142.052719093791,
    "itl": 23.485272609355047,
    "ttft": 6081.731931668482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.585451931492442,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5870817741379142. Arrivals time: 0.056887530256062746 Scheduler time: 1.169820030219853 Scheduler overhead time: 0.13197951717302203 Adapter cache time: 0.027839332818984985 Engine time: 0.13586179818958044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.560369732324034,
    "estimated_duration": 3599.8938623450917,
    "input_throughput": 1136.709902145368,
    "output_throughput": 1005.3540849791478,
    "total_throughput": 2142.0639871245157,
    "itl": 23.487341611521412,
    "ttft": 6081.834092693504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.90286183294375,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5604770560748875. Arrivals time: 0.052099084947258234 Scheduler time: 1.1577248857356608 Scheduler overhead time: 0.13022285979241133 Adapter cache time: 0.027315677143633366 Engine time: 0.12960392329841852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5762931099161506,
    "estimated_duration": 3599.9076612871413,
    "input_throughput": 1136.7055449797008,
    "output_throughput": 1005.3502313184256,
    "total_throughput": 2142.055776298126,
    "itl": 23.488319291824208,
    "ttft": 6081.812860151684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9822055890597614,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.576400576159358. Arrivals time: 0.054220059886574745 Scheduler time: 1.1651839609257877 Scheduler overhead time: 0.13182306243106723 Adapter cache time: 0.02757358504459262 Engine time: 0.13253797590732574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5884644309990108,
    "estimated_duration": 3599.895584900256,
    "input_throughput": 1136.7093582280609,
    "output_throughput": 1005.3536039157864,
    "total_throughput": 2142.0629621438475,
    "itl": 23.48552764491236,
    "ttft": 6081.8401087449665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6396570319402914,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5885640569031239. Arrivals time: 0.05619428725913167 Scheduler time: 1.172712156549096 Scheduler overhead time: 0.13525489391759038 Adapter cache time: 0.027840828988701105 Engine time: 0.13180296821519732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5724271326325834,
    "estimated_duration": 3599.898105688858,
    "input_throughput": 1136.708562259978,
    "output_throughput": 1005.3528999281092,
    "total_throughput": 2142.0614621880873,
    "itl": 23.48738022135327,
    "ttft": 6081.823140530331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.952172101936324,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5725271529518068. Arrivals time: 0.055447299499064684 Scheduler time: 1.1625955295749009 Scheduler overhead time: 0.130409084726125 Adapter cache time: 0.027427627705037594 Engine time: 0.1326676569879055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5900969351641834,
    "estimated_duration": 3599.909455847383,
    "input_throughput": 1136.7049783302884,
    "output_throughput": 1005.3497301498334,
    "total_throughput": 2142.054708480122,
    "itl": 23.48431476923028,
    "ttft": 6081.812866176525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4897291668224977,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.590201310813427. Arrivals time: 0.057209671940654516 Scheduler time: 1.1763581582345068 Scheduler overhead time: 0.13249521143734455 Adapter cache time: 0.027893129736185074 Engine time: 0.13133848505094647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5763536980375648,
    "estimated_duration": 3599.8945008848164,
    "input_throughput": 1136.7097005187848,
    "output_throughput": 1005.3539066521106,
    "total_throughput": 2142.0636071708955,
    "itl": 23.487751746739853,
    "ttft": 6081.783522070263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9295963296853214,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5765041369013488. Arrivals time: 0.05522970762103796 Scheduler time: 1.1679046326316893 Scheduler overhead time: 0.1310174553655088 Adapter cache time: 0.027562869247049093 Engine time: 0.13068586261942983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5540790655650198,
    "estimated_duration": 3599.9359699768947,
    "input_throughput": 1119.4910225100105,
    "output_throughput": 978.8421320234249,
    "total_throughput": 2098.3331545334354,
    "itl": 23.377135403453423,
    "ttft": 5292.323018374756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.692776712179182,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5541813615709543. Arrivals time: 0.054935059044510126 Scheduler time: 1.1420640163123608 Scheduler overhead time: 0.13126243837177753 Adapter cache time: 0.027266889810562134 Engine time: 0.13434891775250435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5545233390294015,
    "estimated_duration": 3599.9412635574067,
    "input_throughput": 1119.4893763398575,
    "output_throughput": 978.8406926722647,
    "total_throughput": 2098.3300690121223,
    "itl": 23.399104643341403,
    "ttft": 5292.305866936836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8625091843353603,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5546449422836304. Arrivals time: 0.05554442899301648 Scheduler time: 1.1437971568666399 Scheduler overhead time: 0.13219849579036236 Adapter cache time: 0.026509637013077736 Engine time: 0.13187469774857163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5632350407540798,
    "estimated_duration": 3599.9348575096906,
    "input_throughput": 1119.4913684598948,
    "output_throughput": 978.8424345093902,
    "total_throughput": 2098.333802969285,
    "itl": 23.378011725287678,
    "ttft": 5292.275605848029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.92051743372344,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5633406369015574. Arrivals time: 0.05616371240466833 Scheduler time: 1.150104749482125 Scheduler overhead time: 0.13401977438479662 Adapter cache time: 0.027742804028093815 Engine time: 0.1301569272764027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5634454861283302,
    "estimated_duration": 3599.9360543217063,
    "input_throughput": 1119.4909962808613,
    "output_throughput": 978.8421090896134,
    "total_throughput": 2098.3331053704746,
    "itl": 23.37717641388243,
    "ttft": 5292.142635617969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7161887982115116,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5635415893048048. Arrivals time: 0.05259797954931855 Scheduler time: 1.1543909003958106 Scheduler overhead time: 0.13205498736351728 Adapter cache time: 0.02729605743661523 Engine time: 0.13261329801753163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5340258632786572,
    "estimated_duration": 3599.932118095488,
    "input_throughput": 1119.492220351112,
    "output_throughput": 978.8431793720096,
    "total_throughput": 2098.3353997231216,
    "itl": 23.378018013589756,
    "ttft": 5292.171064915801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8975274271192082,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5341206272132695. Arrivals time: 0.05237224930897355 Scheduler time: 1.1284082918427885 Scheduler overhead time: 0.13133177440613508 Adapter cache time: 0.027062708046287298 Engine time: 0.1302738538943231 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5556217702105641,
    "estimated_duration": 3599.9204156136648,
    "input_throughput": 1119.495859553052,
    "output_throughput": 978.8463613574959,
    "total_throughput": 2098.342220910548,
    "itl": 23.376069386367345,
    "ttft": 5292.209118247418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.634283760786051,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.555735080037266. Arrivals time: 0.05603156238794327 Scheduler time: 1.1437962991185486 Scheduler overhead time: 0.13211885374039412 Adapter cache time: 0.02726273564621806 Engine time: 0.1318474905565381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.549736789893359,
    "estimated_duration": 3599.9243361493664,
    "input_throughput": 1119.494640354237,
    "output_throughput": 978.8452953345054,
    "total_throughput": 2098.3399356887426,
    "itl": 23.37839492993745,
    "ttft": 5292.188633824817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8853075136989408,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.549909451045096. Arrivals time: 0.05576010886579752 Scheduler time: 1.1376952729187906 Scheduler overhead time: 0.1321334238164127 Adapter cache time: 0.0272663701325655 Engine time: 0.13241119543090463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9667346579954028,
    "estimated_duration": 3599.5588474221963,
    "input_throughput": 476.83954416502974,
    "output_throughput": 412.35469759383693,
    "total_throughput": 889.1942417588667,
    "itl": 21.88616865661361,
    "ttft": 7322.6540701267995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.157675201734467,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9668078999966383. Arrivals time: 0.03187689185142517 Scheduler time: 0.5566089204512537 Scheduler overhead time: 0.13569769775494933 Adapter cache time: 0.03706067614257336 Engine time: 0.13810048950836062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9583890568464994,
    "estimated_duration": 3599.5681337530737,
    "input_throughput": 476.83831399251517,
    "output_throughput": 412.35363378228556,
    "total_throughput": 889.1919477748007,
    "itl": 21.90024033549682,
    "ttft": 7323.085633184455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.24394505251139,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9585148668847978. Arrivals time: 0.03210185933858156 Scheduler time: 0.5509865116328001 Scheduler overhead time: 0.1343140290118754 Adapter cache time: 0.03692061407491565 Engine time: 0.13684881897643209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.963362374342978,
    "estimated_duration": 3599.561351705118,
    "input_throughput": 476.839212418739,
    "output_throughput": 412.3544107108737,
    "total_throughput": 889.1936231296128,
    "itl": 21.902556498252125,
    "ttft": 7323.127256817048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.815141815599226,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.963477976154536. Arrivals time: 0.031175703275948763 Scheduler time: 0.5571725154295564 Scheduler overhead time: 0.1350431269966066 Adapter cache time: 0.03689387207850814 Engine time: 0.1357516059651971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9771637506783009,
    "estimated_duration": 3599.5544073185047,
    "input_throughput": 476.84013235367223,
    "output_throughput": 412.35520623946576,
    "total_throughput": 889.195338593138,
    "itl": 21.891141249117105,
    "ttft": 7322.886279829384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.916248618099218,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.977228014729917. Arrivals time: 0.03161673108115792 Scheduler time: 0.566652299836278 Scheduler overhead time: 0.13548812782391906 Adapter cache time: 0.036822373047471046 Engine time: 0.13881210703402758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9598563862964511,
    "estimated_duration": 3599.5583762327747,
    "input_throughput": 476.8396065842839,
    "output_throughput": 412.3547515718951,
    "total_throughput": 889.194358156179,
    "itl": 21.903542501669996,
    "ttft": 7323.153980591743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.630752666401822,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9599423413164914. Arrivals time: 0.03145579155534506 Scheduler time: 0.5535980048589408 Scheduler overhead time: 0.13428581971675158 Adapter cache time: 0.03680993476882577 Engine time: 0.13679281249642372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9429423627443612,
    "estimated_duration": 3599.552775987448,
    "input_throughput": 476.8403484594402,
    "output_throughput": 412.3553931204191,
    "total_throughput": 889.1957415798593,
    "itl": 21.880932226043985,
    "ttft": 7322.588364792801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.530246902807914,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.943036044947803. Arrivals time: 0.029369674623012543 Scheduler time: 0.5437607984058559 Scheduler overhead time: 0.1334381392225623 Adapter cache time: 0.036311131436377764 Engine time: 0.1334703592583537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9587959023192525,
    "estimated_duration": 3599.567141716141,
    "input_throughput": 476.8384454086549,
    "output_throughput": 412.35374742651493,
    "total_throughput": 889.1921928351699,
    "itl": 21.90176719924977,
    "ttft": 7323.016272501055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.427465481665106,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9589401111006737. Arrivals time: 0.031115188263356686 Scheduler time: 0.5536408741027117 Scheduler overhead time: 0.1346660302951932 Adapter cache time: 0.03662430075928569 Engine time: 0.13557600136846304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9458609139546752,
    "estimated_duration": 3599.6553955241457,
    "input_throughput": 427.3989676658981,
    "output_throughput": 392.99234081100553,
    "total_throughput": 820.3913084769036,
    "itl": 21.474808274568087,
    "ttft": 8409.590994661497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.481175779970762,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.945976962801069. Arrivals time: 0.031051590107381344 Scheduler time: 0.5394224780611694 Scheduler overhead time: 0.1360610774718225 Adapter cache time: 0.03521044971421361 Engine time: 0.1367450882680714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9385687219910324,
    "estimated_duration": 3599.6572464045676,
    "input_throughput": 427.3987479048688,
    "output_throughput": 392.99213874125843,
    "total_throughput": 820.3908866461272,
    "itl": 21.487641064680133,
    "ttft": 8409.683391132869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.212772331814765,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9386408380232751. Arrivals time: 0.029940114822238684 Scheduler time: 0.5345945195294917 Scheduler overhead time: 0.13413979997858405 Adapter cache time: 0.0346169606782496 Engine time: 0.13809354463592172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9336060639470816,
    "estimated_duration": 3599.6520685451783,
    "input_throughput": 427.3993626894584,
    "output_throughput": 392.9927040342358,
    "total_throughput": 820.3920667236943,
    "itl": 21.491461220037653,
    "ttft": 8409.75337612564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.702796163642432,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.933670470956713. Arrivals time: 0.029219869058579206 Scheduler time: 0.5312891867943108 Scheduler overhead time: 0.13510961551219225 Adapter cache time: 0.034954375587403774 Engine time: 0.1359900296665728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9567149858921766,
    "estimated_duration": 3599.6446452136074,
    "input_throughput": 427.40024408956737,
    "output_throughput": 392.9935144795532,
    "total_throughput": 820.3937585691206,
    "itl": 21.481406783918867,
    "ttft": 8409.447340305382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.120516278939526,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9568311278708279. Arrivals time: 0.03143189940601587 Scheduler time: 0.5451134382747114 Scheduler overhead time: 0.136609623208642 Adapter cache time: 0.0352934654802084 Engine time: 0.14044569386169314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9213166581466794,
    "estimated_duration": 3599.6489808601,
    "input_throughput": 427.39972930149247,
    "output_throughput": 392.9930411331348,
    "total_throughput": 820.3927704346272,
    "itl": 21.488645577997435,
    "ttft": 8409.724298506357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.558534381212294,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9213845208287239. Arrivals time: 0.028649596963077784 Scheduler time: 0.5251812115311623 Scheduler overhead time: 0.13191779982298613 Adapter cache time: 0.03418153990060091 Engine time: 0.13479080330580473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.915015357080847,
    "estimated_duration": 3599.6550257230806,
    "input_throughput": 427.3990115736038,
    "output_throughput": 392.9923811840372,
    "total_throughput": 820.3913927576409,
    "itl": 21.47480272346306,
    "ttft": 8409.35943268416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.987170780790796,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9151134840212762. Arrivals time: 0.02886089775711298 Scheduler time: 0.5219212765805423 Scheduler overhead time: 0.13240789994597435 Adapter cache time: 0.033975495491176844 Engine time: 0.13202958833426237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9174060737714171,
    "estimated_duration": 3599.6425761254454,
    "input_throughput": 427.4004897608436,
    "output_throughput": 392.99374037371115,
    "total_throughput": 820.3942301345547,
    "itl": 21.486856249045857,
    "ttft": 8409.85063884473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.374047838858868,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9175360477529466. Arrivals time: 0.029202732257544994 Scheduler time: 0.5233148587867618 Scheduler overhead time: 0.13262458657845855 Adapter cache time: 0.03414806677028537 Engine time: 0.13247988559305668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9050819990225136,
    "estimated_duration": 3600.027270298222,
    "input_throughput": 419.2304354058341,
    "output_throughput": 373.57161460851734,
    "total_throughput": 792.8020500143514,
    "itl": 21.478947997169627,
    "ttft": 5802.670160575632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.968460347829705,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9051551287993789. Arrivals time: 0.028153322637081146 Scheduler time: 0.5070419739931822 Scheduler overhead time: 0.13313046423718333 Adapter cache time: 0.0339453243650496 Engine time: 0.13632078329101205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9060323829762638,
    "estimated_duration": 3600.031015336246,
    "input_throughput": 419.2299992890577,
    "output_throughput": 373.57122598967055,
    "total_throughput": 792.8012252787282,
    "itl": 21.488704734895776,
    "ttft": 5803.018938733613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.50201374406428,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9061477677896619. Arrivals time: 0.028895066119730473 Scheduler time: 0.5074329795315862 Scheduler overhead time: 0.13335475511848927 Adapter cache time: 0.03337215445935726 Engine time: 0.13626428321003914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.921169426292181,
    "estimated_duration": 3600.0278091066034,
    "input_throughput": 419.2303726605209,
    "output_throughput": 373.5715586968612,
    "total_throughput": 792.801931357382,
    "itl": 21.490827761839796,
    "ttft": 5803.10205864266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.928107912116351,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9212703919038177. Arrivals time: 0.029518029652535915 Scheduler time: 0.516606270801276 Scheduler overhead time: 0.1358180893585086 Adapter cache time: 0.03385399281978607 Engine time: 0.13790516136214137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9154568840749562,
    "estimated_duration": 3600.010843657034,
    "input_throughput": 419.2323483300548,
    "output_throughput": 373.57331919418044,
    "total_throughput": 792.8056675242352,
    "itl": 21.48432096558006,
    "ttft": 5802.939054888539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.513600411065978,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9155307980254292. Arrivals time: 0.029485187027603388 Scheduler time: 0.5106052509509027 Scheduler overhead time: 0.13536819070577621 Adapter cache time: 0.03428989602252841 Engine time: 0.13793392525985837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9202558728866279,
    "estimated_duration": 3600.0269179368597,
    "input_throughput": 419.2304764390293,
    "output_throughput": 373.57165117274474,
    "total_throughput": 792.802127611774,
    "itl": 21.488655158420976,
    "ttft": 5803.104806900324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.766197142013954,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9203702020458877. Arrivals time: 0.029674267396330833 Scheduler time: 0.5150307877920568 Scheduler overhead time: 0.13587412890046835 Adapter cache time: 0.03429949702695012 Engine time: 0.13731065671890974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9158442779444158,
    "estimated_duration": 3600.0176991663343,
    "input_throughput": 419.2315499864067,
    "output_throughput": 373.57260779896575,
    "total_throughput": 792.8041577853725,
    "itl": 21.474847219525817,
    "ttft": 5802.630224469542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.567664744314241,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9159460328519344. Arrivals time: 0.028971105348318815 Scheduler time: 0.512725920882076 Scheduler overhead time: 0.1350213880650699 Adapter cache time: 0.033628422766923904 Engine time: 0.13815956562757492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9208265850320458,
    "estimated_duration": 3600.0194435604258,
    "input_throughput": 419.2313468472153,
    "output_throughput": 373.572426783874,
    "total_throughput": 792.8037736310894,
    "itl": 21.48832562075307,
    "ttft": 5803.207267972811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.630482025835347,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9209037539549172. Arrivals time: 0.029964089393615723 Scheduler time: 0.5152342631481588 Scheduler overhead time: 0.13557941792532802 Adapter cache time: 0.03427237505093217 Engine time: 0.13800430297851562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.907622863072902,
    "estimated_duration": 3599.758838274455,
    "input_throughput": 405.6557857359071,
    "output_throughput": 369.4236363448884,
    "total_throughput": 775.0794220807954,
    "itl": 21.360881320802953,
    "ttft": 2971.265502495442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.44099386144922,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9077193108387291. Arrivals time: 0.028208942618221045 Scheduler time: 0.5061532659456134 Scheduler overhead time: 0.13487916253507137 Adapter cache time: 0.034012716729193926 Engine time: 0.13717849552631378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9106872580014169,
    "estimated_duration": 3599.7403516214426,
    "input_throughput": 405.6578690022043,
    "output_throughput": 369.42553353910586,
    "total_throughput": 775.0834025413102,
    "itl": 21.369744596367227,
    "ttft": 2971.447352044515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.796052288175328,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9107866617850959. Arrivals time: 0.02878772048279643 Scheduler time: 0.5084324199706316 Scheduler overhead time: 0.13503324380144477 Adapter cache time: 0.03323437413200736 Engine time: 0.13731333380565047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9151009540073574,
    "estimated_duration": 3599.741263415822,
    "input_throughput": 405.65776625132924,
    "output_throughput": 369.42543996567923,
    "total_throughput": 775.0832062170085,
    "itl": 21.372718202386146,
    "ttft": 2971.4276311295057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.165999263673793,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9151766919530928. Arrivals time: 0.029505816288292408 Scheduler time: 0.509557144716382 Scheduler overhead time: 0.13602648582309484 Adapter cache time: 0.03360488172620535 Engine time: 0.1385709340684116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9081870643422008,
    "estimated_duration": 3599.761226243068,
    "input_throughput": 405.65551663659096,
    "output_throughput": 369.42339128084296,
    "total_throughput": 775.078907917434,
    "itl": 21.36205948528084,
    "ttft": 2971.23709649838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.895654060421583,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9083440690301359. Arrivals time: 0.02855943562462926 Scheduler time: 0.5070184641517699 Scheduler overhead time: 0.1355446889065206 Adapter cache time: 0.03343765065073967 Engine time: 0.13612451730296016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.918089484795928,
    "estimated_duration": 3599.741056298645,
    "input_throughput": 405.6577895915334,
    "output_throughput": 369.42546122119535,
    "total_throughput": 775.0832508127288,
    "itl": 21.37131367990639,
    "ttft": 2971.3568343204297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.038983068913003,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.918184548150748. Arrivals time: 0.029726993292570114 Scheduler time: 0.5110697168856859 Scheduler overhead time: 0.13715273747220635 Adapter cache time: 0.033805244602262974 Engine time: 0.13875955948606133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9147703042253852,
    "estimated_duration": 3599.7581528101814,
    "input_throughput": 405.65586298069314,
    "output_throughput": 369.4237066903654,
    "total_throughput": 775.0795696710585,
    "itl": 21.356688916118184,
    "ttft": 2971.091732369321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.080211165161108,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.914852746296674. Arrivals time: 0.028862779960036278 Scheduler time: 0.5085749565623701 Scheduler overhead time: 0.1356707401573658 Adapter cache time: 0.03333507338538766 Engine time: 0.13873199000954628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9156040600501001,
    "estimated_duration": 3599.740642064292,
    "input_throughput": 405.6578362719498,
    "output_throughput": 369.425503732235,
    "total_throughput": 775.0833400041848,
    "itl": 21.370125648857098,
    "ttft": 2971.4807507627215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.910002433378036,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9157410669140518. Arrivals time: 0.02950145723298192 Scheduler time: 0.5101448427885771 Scheduler overhead time: 0.13601464172825217 Adapter cache time: 0.03359996946528554 Engine time: 0.13843867555260658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8416503532789648,
    "estimated_duration": 3598.9024490964734,
    "input_throughput": 359.80636272180556,
    "output_throughput": 324.3427729732025,
    "total_throughput": 684.149135695008,
    "itl": 21.107687366308983,
    "ttft": 4678.539882343075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.865714275669557,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8417237498797476. Arrivals time: 0.026499264407902956 Scheduler time: 0.4504898367449641 Scheduler overhead time: 0.1324375495314598 Adapter cache time: 0.031524231657385826 Engine time: 0.13402102887630463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8524363003671169,
    "estimated_duration": 3598.905625036273,
    "input_throughput": 359.8060452021297,
    "output_throughput": 324.3424867492143,
    "total_throughput": 684.148531951344,
    "itl": 21.115648242639978,
    "ttft": 4678.578536727567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.016033221790444,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8525394229218364. Arrivals time: 0.026485038921236992 Scheduler time: 0.45667098881676793 Scheduler overhead time: 0.13469805801287293 Adapter cache time: 0.031358616426587105 Engine time: 0.13551817694678903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8504192591644824,
    "estimated_duration": 3598.9162352087146,
    "input_throughput": 359.80498443718386,
    "output_throughput": 324.34153053642973,
    "total_throughput": 684.1465149736136,
    "itl": 21.117864304165824,
    "ttft": 4678.762536686366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.332575676976564,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8504929202608764. Arrivals time: 0.026696495711803436 Scheduler time: 0.45612499909475446 Scheduler overhead time: 0.13351772772148252 Adapter cache time: 0.03161963541060686 Engine time: 0.13484165631234646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8435713979415596,
    "estimated_duration": 3598.907529189298,
    "input_throughput": 359.8058548316453,
    "output_throughput": 324.3423151422134,
    "total_throughput": 684.1481699738588,
    "itl": 21.11025200207771,
    "ttft": 4678.608872889518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.286943357680073,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8436613148078322. Arrivals time: 0.02614317601546645 Scheduler time: 0.45182377798482776 Scheduler overhead time: 0.13247552560642362 Adapter cache time: 0.031488086096942425 Engine time: 0.13410458201542497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8445448959246278,
    "estimated_duration": 3598.9040215314235,
    "input_throughput": 359.8062055150291,
    "output_throughput": 324.3426312611955,
    "total_throughput": 684.1488367762246,
    "itl": 21.11623396064548,
    "ttft": 4678.530921434141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.217834257646327,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8446139628067613. Arrivals time: 0.026331682689487934 Scheduler time: 0.45057512540370226 Scheduler overhead time: 0.13286930788308382 Adapter cache time: 0.031524579506367445 Engine time: 0.13578634103760123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.839917054399848,
    "estimated_duration": 3598.9057354267047,
    "input_throughput": 359.80603416567925,
    "output_throughput": 324.3424768005494,
    "total_throughput": 684.1485109662286,
    "itl": 21.105697325998666,
    "ttft": 4678.436326664679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.53757788521254,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8401834852993488. Arrivals time: 0.025735832285135984 Scheduler time: 0.45058436738327146 Scheduler overhead time: 0.13237393833696842 Adapter cache time: 0.03147098235785961 Engine time: 0.133208688814193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8553584381006658,
    "estimated_duration": 3598.914418300939,
    "input_throughput": 359.80516608431356,
    "output_throughput": 324.34169427987575,
    "total_throughput": 684.1468603641893,
    "itl": 21.11571435670463,
    "ttft": 4678.636663957026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.104126927684863,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.855808577965945. Arrivals time: 0.026369090657681227 Scheduler time: 0.45769725693389773 Scheduler overhead time: 0.13560989033430815 Adapter cache time: 0.03158291708678007 Engine time: 0.13657881179824471 
