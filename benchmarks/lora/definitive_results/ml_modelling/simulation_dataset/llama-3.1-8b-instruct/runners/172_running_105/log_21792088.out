INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.84848028095439,
    "estimated_duration": 3600.036358996508,
    "input_throughput": 5194.3161499659,
    "output_throughput": 4511.292770533863,
    "total_throughput": 9705.608920499764,
    "itl": 97.78491586338171,
    "ttft": 2060558.520208212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.2542452649399936,
    "arrivals": 553841,
    "finished_requests": 75587,
    "scheduler_time": 173.26579334373625
}
#Debug simulation 
Total elapsed time: 14.848666321951896. Arrivals time: 0.30701637640595436 Scheduler time: 14.383659680839628 Scheduler overhead time: 0.056134273298084736 Adapter cache time: 0.018085617572069168 Engine time: 0.05774034280329943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 32.127834727056324,
    "estimated_duration": 3600.071525396192,
    "input_throughput": 5592.81443659211,
    "output_throughput": 4866.468867746161,
    "total_throughput": 10459.28330433827,
    "itl": 118.81740191439275,
    "ttft": 1982342.296440849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2202431985596562,
    "arrivals": 484157,
    "finished_requests": 81836,
    "scheduler_time": 158.9708231143436
}
#Debug simulation 
Total elapsed time: 32.12795190187171. Arrivals time: 0.37218932528048754 Scheduler time: 31.601021063048393 Scheduler overhead time: 0.05666628759354353 Adapter cache time: 0.01589879021048546 Engine time: 0.058496321085840464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 34.29539526673034,
    "estimated_duration": 3600.092479957784,
    "input_throughput": 5446.342034032949,
    "output_throughput": 4741.569027749024,
    "total_throughput": 10187.911061781973,
    "itl": 110.97441228249248,
    "ttft": 1996876.9188679876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.936991217983891,
    "arrivals": 484157,
    "finished_requests": 79670,
    "scheduler_time": 163.4536151249764
}
#Debug simulation 
Total elapsed time: 34.29555625002831. Arrivals time: 0.6308880993165076 Scheduler time: 33.50353302946314 Scheduler overhead time: 0.059812762308865786 Adapter cache time: 0.015300243627279997 Engine time: 0.06107339123263955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.473572998773307,
    "estimated_duration": 3600.082963220665,
    "input_throughput": 5141.5470668600365,
    "output_throughput": 4480.707573908003,
    "total_throughput": 9622.25464076804,
    "itl": 98.8805668560246,
    "ttft": 2034631.1924325784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.531402869853215,
    "arrivals": 484157,
    "finished_requests": 75199,
    "scheduler_time": 171.10191313140297
}
#Debug simulation 
Total elapsed time: 16.473668549209833. Arrivals time: 0.6262660184875131 Scheduler time: 15.684739332646132 Scheduler overhead time: 0.05692314822226763 Adapter cache time: 0.021286901086568832 Engine time: 0.05837100790813565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 25.60513445781544,
    "estimated_duration": 3600.000506034107,
    "input_throughput": 5448.54812301356,
    "output_throughput": 4739.452111576551,
    "total_throughput": 10188.000234590112,
    "itl": 111.05301997988722,
    "ttft": 1998271.167305697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.24531743961386,
    "arrivals": 484157,
    "finished_requests": 79684,
    "scheduler_time": 163.33228972195073
}
#Debug simulation 
Total elapsed time: 25.60521064698696. Arrivals time: 0.6532047395594418 Scheduler time: 24.80075845681131 Scheduler overhead time: 0.055376884527504444 Adapter cache time: 0.015126966405659914 Engine time: 0.056596854235976934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 16.355251546017826,
    "estimated_duration": 3600.0631054125906,
    "input_throughput": 5137.472721573397,
    "output_throughput": 4477.155685345346,
    "total_throughput": 9614.628406918744,
    "itl": 98.71076443559251,
    "ttft": 2033841.7840627106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.840034581506646,
    "arrivals": 484157,
    "finished_requests": 75174,
    "scheduler_time": 171.22781666472764
}
#Debug simulation 
Total elapsed time: 16.355353000108153. Arrivals time: 0.5855906065553427 Scheduler time: 15.606713726650923 Scheduler overhead time: 0.057148105930536985 Adapter cache time: 0.022228877991437912 Engine time: 0.05774341709911823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 32.58354029990733,
    "estimated_duration": 3600.0142801382044,
    "input_throughput": 5464.158603072216,
    "output_throughput": 4756.56752098845,
    "total_throughput": 10220.726124060666,
    "itl": 110.89667540663619,
    "ttft": 1995942.4921133157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9238357907812915,
    "arrivals": 484157,
    "finished_requests": 79931,
    "scheduler_time": 163.6308461029072
}
#Debug simulation 
Total elapsed time: 32.583683129865676. Arrivals time: 0.6325927744619548 Scheduler time: 31.790266337338835 Scheduler overhead time: 0.05920648341998458 Adapter cache time: 0.01625504856929183 Engine time: 0.060520452447235584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.249088369775563,
    "estimated_duration": 3600.010992674659,
    "input_throughput": 5122.6193579755545,
    "output_throughput": 4465.4452535592,
    "total_throughput": 9588.064611534754,
    "itl": 98.35273670390241,
    "ttft": 2033902.6961211811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.781004330907038,
    "arrivals": 484157,
    "finished_requests": 74920,
    "scheduler_time": 171.4880939840293
}
#Debug simulation 
Total elapsed time: 16.249182276893407. Arrivals time: 0.5777825843542814 Scheduler time: 15.508363987784833 Scheduler overhead time: 0.05721435556188226 Adapter cache time: 0.021871766541153193 Engine time: 0.0578248081728816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 30.124980210326612,
    "estimated_duration": 3600.072212277753,
    "input_throughput": 5604.037866572511,
    "output_throughput": 4859.750851756023,
    "total_throughput": 10463.788718328535,
    "itl": 118.54841476445768,
    "ttft": 1981056.9104507258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.26500382560778,
    "arrivals": 472692,
    "finished_requests": 81316,
    "scheduler_time": 159.111682960519
}
#Debug simulation 
Total elapsed time: 30.12512505520135. Arrivals time: 0.33389038126915693 Scheduler time: 29.642821826506406 Scheduler overhead time: 0.05369242327287793 Adapter cache time: 0.01725521171465516 Engine time: 0.05449989764019847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 23.335888302884996,
    "estimated_duration": 3600.1033221832527,
    "input_throughput": 5450.004692671227,
    "output_throughput": 4729.08205025494,
    "total_throughput": 10179.086742926167,
    "itl": 111.00842863260799,
    "ttft": 2002522.9062070912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.324672426590704,
    "arrivals": 472692,
    "finished_requests": 79089,
    "scheduler_time": 163.13399249586615
}
#Debug simulation 
Total elapsed time: 23.335990319028497. Arrivals time: 0.3611368890851736 Scheduler time: 22.824490720871836 Scheduler overhead time: 0.05371609004214406 Adapter cache time: 0.01837608916684985 Engine time: 0.0543918632902205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.697452101390809,
    "estimated_duration": 3600.035707714034,
    "input_throughput": 5151.696123530009,
    "output_throughput": 4468.626232103439,
    "total_throughput": 9620.322355633447,
    "itl": 98.74013947912032,
    "ttft": 2040038.8132129528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1033,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.778677684781158,
    "arrivals": 472692,
    "finished_requests": 74746,
    "scheduler_time": 171.0149652283194
}
#Debug simulation 
Total elapsed time: 13.69757186435163. Arrivals time: 0.2911590104922652 Scheduler time: 13.24560298351571 Scheduler overhead time: 0.05564766330644488 Adapter cache time: 0.022812805138528347 Engine time: 0.05660273553803563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 21.70679691201076,
    "estimated_duration": 3600.0582833977783,
    "input_throughput": 5446.285714434248,
    "output_throughput": 4733.756694604329,
    "total_throughput": 10180.042409038577,
    "itl": 111.17732080671912,
    "ttft": 2002644.675567352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.071713923276396,
    "arrivals": 472692,
    "finished_requests": 79094,
    "scheduler_time": 163.0229403528741
}
#Debug simulation 
Total elapsed time: 21.706947231199592. Arrivals time: 0.35637085884809494 Scheduler time: 21.200436669867486 Scheduler overhead time: 0.05324934981763363 Adapter cache time: 0.018602536991238594 Engine time: 0.05435801204293966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 12.200646825134754,
    "estimated_duration": 3600.0808202867647,
    "input_throughput": 5146.186967692646,
    "output_throughput": 4467.413595097819,
    "total_throughput": 9613.600562790465,
    "itl": 98.80546463821311,
    "ttft": 2039475.1029932695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.749957833955932,
    "arrivals": 472692,
    "finished_requests": 74708,
    "scheduler_time": 170.92198443884712
}
#Debug simulation 
Total elapsed time: 12.200838931836188. Arrivals time: 0.3222672329284251 Scheduler time: 11.715669710654765 Scheduler overhead time: 0.055193069856613874 Adapter cache time: 0.025816618464887142 Engine time: 0.05628928914666176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.380499127786607,
    "estimated_duration": 3600.0716234800548,
    "input_throughput": 5445.071112516049,
    "output_throughput": 4727.608997830899,
    "total_throughput": 10172.680110346948,
    "itl": 111.02248452451232,
    "ttft": 2002272.717120703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7455288465134515,
    "arrivals": 472692,
    "finished_requests": 79032,
    "scheduler_time": 163.08942263499958
}
#Debug simulation 
Total elapsed time: 16.38062656763941. Arrivals time: 0.34574581775814295 Scheduler time: 15.884939744137228 Scheduler overhead time: 0.05255688028410077 Adapter cache time: 0.020234544295817614 Engine time: 0.05344989011064172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.732662854716182,
    "estimated_duration": 3600.0781780730485,
    "input_throughput": 5148.550971168356,
    "output_throughput": 4468.832398692859,
    "total_throughput": 9617.383369861216,
    "itl": 98.72952825604024,
    "ttft": 2038941.4985660454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.518764365315452,
    "arrivals": 472692,
    "finished_requests": 74705,
    "scheduler_time": 171.0304456708397
}
#Debug simulation 
Total elapsed time: 12.732761555816978. Arrivals time: 0.3399431752040982 Scheduler time: 12.233631008304656 Scheduler overhead time: 0.05566843319684267 Adapter cache time: 0.02177243959158659 Engine time: 0.05602966295555234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 28.16226830892265,
    "estimated_duration": 3600.058873224394,
    "input_throughput": 5627.523802646773,
    "output_throughput": 4859.844968126853,
    "total_throughput": 10487.368770773626,
    "itl": 118.6523984508382,
    "ttft": 1975638.4334642314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.861646874658821,
    "arrivals": 466835,
    "finished_requests": 81782,
    "scheduler_time": 158.99121405812556
}
#Debug simulation 
Total elapsed time: 28.16236662818119. Arrivals time: 0.6252451688051224 Scheduler time: 27.388750991318375 Scheduler overhead time: 0.0540561038069427 Adapter cache time: 0.01666317507624626 Engine time: 0.054390447679907084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 23.710166767705232,
    "estimated_duration": 3600.109371589696,
    "input_throughput": 5470.413247835219,
    "output_throughput": 4725.280330160703,
    "total_throughput": 10195.693577995922,
    "itl": 110.86163079961366,
    "ttft": 1994604.7889821494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.828275471571838,
    "arrivals": 466835,
    "finished_requests": 79425,
    "scheduler_time": 163.22155328764353
}
#Debug simulation 
Total elapsed time: 23.710340979974717. Arrivals time: 0.344772404525429 Scheduler time: 23.212191879283637 Scheduler overhead time: 0.055681741796433926 Adapter cache time: 0.015688809100538492 Engine time: 0.0574094639159739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.116836403962225,
    "estimated_duration": 3600.03008191705,
    "input_throughput": 5165.391559755435,
    "output_throughput": 4467.495724767829,
    "total_throughput": 9632.887284523265,
    "itl": 98.71567323138036,
    "ttft": 2029677.713312703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.265055476524891,
    "arrivals": 466835,
    "finished_requests": 75043,
    "scheduler_time": 171.0557479890986
}
#Debug simulation 
Total elapsed time: 15.117018098011613. Arrivals time: 0.2827480430714786 Scheduler time: 14.67391216661781 Scheduler overhead time: 0.05692435149103403 Adapter cache time: 0.01972544752061367 Engine time: 0.057636754121631384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 37.00489388825372,
    "estimated_duration": 3600.002359279726,
    "input_throughput": 5478.184187619753,
    "output_throughput": 4728.4619011765835,
    "total_throughput": 10206.646088796337,
    "itl": 110.79890180218344,
    "ttft": 1980987.4091775708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2694649024028286,
    "arrivals": 466835,
    "finished_requests": 79458,
    "scheduler_time": 163.21415468704083
}
#Debug simulation 
Total elapsed time: 37.005011873319745. Arrivals time: 0.3441823157481849 Scheduler time: 36.49746904661879 Scheduler overhead time: 0.06033680588006973 Adapter cache time: 0.01615572441369295 Engine time: 0.061725784093141556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.316497307270765,
    "estimated_duration": 3600.022324078818,
    "input_throughput": 5171.79542900867,
    "output_throughput": 4466.417858704358,
    "total_throughput": 9638.213287713028,
    "itl": 98.66868168955244,
    "ttft": 2031065.3372546334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.751719457241728,
    "arrivals": 466835,
    "finished_requests": 75027,
    "scheduler_time": 171.0736373099634
}
#Debug simulation 
Total elapsed time: 14.316628318279982. Arrivals time: 0.2799746934324503 Scheduler time: 13.87665609549731 Scheduler overhead time: 0.05614535789936781 Adapter cache time: 0.02086138864979148 Engine time: 0.0570359299890697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.048721828032285,
    "estimated_duration": 3600.0139453518764,
    "input_throughput": 5478.005724245165,
    "output_throughput": 4731.308061178958,
    "total_throughput": 10209.313785424123,
    "itl": 111.21228760645543,
    "ttft": 1995981.878470603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.247583013148953,
    "arrivals": 466835,
    "finished_requests": 79565,
    "scheduler_time": 162.9437095741081
}
#Debug simulation 
Total elapsed time: 17.048847216181457. Arrivals time: 0.29830368887633085 Scheduler time: 16.600865875836462 Scheduler overhead time: 0.05282560829073191 Adapter cache time: 0.018977326340973377 Engine time: 0.053997659124433994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.908260380383581,
    "estimated_duration": 3600.0796083765886,
    "input_throughput": 5170.075116309208,
    "output_throughput": 4465.953742409069,
    "total_throughput": 9636.028858718277,
    "itl": 98.75964006415677,
    "ttft": 2031538.5300829464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.598174947500247,
    "arrivals": 466835,
    "finished_requests": 75035,
    "scheduler_time": 170.9876008080295
}
#Debug simulation 
Total elapsed time: 13.908328576013446. Arrivals time: 0.5584924085997045 Scheduler time: 13.190006126184016 Scheduler overhead time: 0.055603956803679466 Adapter cache time: 0.0219541285187006 Engine time: 0.056575078051537275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 32.372842779848725,
    "estimated_duration": 3600.066282043411,
    "input_throughput": 5583.653584452979,
    "output_throughput": 4857.132794253688,
    "total_throughput": 10440.786378706667,
    "itl": 118.43733891330642,
    "ttft": 1978360.7844140304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 404,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6714132489077937,
    "arrivals": 463927,
    "finished_requests": 81182,
    "scheduler_time": 159.2626050763787
}
#Debug simulation 
Total elapsed time: 32.37303401902318. Arrivals time: 0.3769623842090368 Scheduler time: 31.845040777232498 Scheduler overhead time: 0.056059767957776785 Adapter cache time: 0.014615108724683523 Engine time: 0.056643479969352484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.866752819158137,
    "estimated_duration": 3600.052957106213,
    "input_throughput": 5428.010430076425,
    "output_throughput": 4730.059030489314,
    "total_throughput": 10158.069460565739,
    "itl": 111.02336097398407,
    "ttft": 1994192.4289573906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0174890790693505,
    "arrivals": 463927,
    "finished_requests": 78961,
    "scheduler_time": 163.1305986604436
}
#Debug simulation 
Total elapsed time: 22.86691471422091. Arrivals time: 0.3176297121681273 Scheduler time: 22.399237382225692 Scheduler overhead time: 0.05532206082716584 Adapter cache time: 0.01425992650911212 Engine time: 0.05607537645846605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.647165396716446,
    "estimated_duration": 3600.030246129989,
    "input_throughput": 5149.870343431157,
    "output_throughput": 4478.935147095925,
    "total_throughput": 9628.805490527082,
    "itl": 98.50710412086842,
    "ttft": 2030356.1789966256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.774754793727796,
    "arrivals": 463927,
    "finished_requests": 74810,
    "scheduler_time": 171.35178011295193
}
#Debug simulation 
Total elapsed time: 15.64729364681989. Arrivals time: 0.3268310292623937 Scheduler time: 15.161147938109934 Scheduler overhead time: 0.056506695691496134 Adapter cache time: 0.019333692267537117 Engine time: 0.057394375558942556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 22.123422437813133,
    "estimated_duration": 3600.0930436061517,
    "input_throughput": 5429.427729573528,
    "output_throughput": 4731.9721445131845,
    "total_throughput": 10161.399874086712,
    "itl": 110.94641275507773,
    "ttft": 1992668.2922632408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8719902523094754,
    "arrivals": 463927,
    "finished_requests": 79020,
    "scheduler_time": 163.1735993731567
}
#Debug simulation 
Total elapsed time: 22.123538269661367. Arrivals time: 0.31873638462275267 Scheduler time: 21.655682717449963 Scheduler overhead time: 0.054719504434615374 Adapter cache time: 0.014184881933033466 Engine time: 0.05614085495471954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.370176606811583,
    "estimated_duration": 3600.084830883705,
    "input_throughput": 5137.455606972463,
    "output_throughput": 4473.938186630552,
    "total_throughput": 9611.393793603014,
    "itl": 98.61075497138178,
    "ttft": 2030171.9521579961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.74932897445749,
    "arrivals": 463927,
    "finished_requests": 74673,
    "scheduler_time": 171.2043244461841
}
#Debug simulation 
Total elapsed time: 14.370334129780531. Arrivals time: 0.33069920260459185 Scheduler time: 13.878964614588767 Scheduler overhead time: 0.05731897335499525 Adapter cache time: 0.019179344177246094 Engine time: 0.05813908111304045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 22.2186574251391,
    "estimated_duration": 3600.063015578533,
    "input_throughput": 5433.735719444457,
    "output_throughput": 4732.183277425847,
    "total_throughput": 10165.918996870303,
    "itl": 111.22286069854559,
    "ttft": 1994458.6318923053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7578538463264586,
    "arrivals": 463927,
    "finished_requests": 79027,
    "scheduler_time": 163.08284306365675
}
#Debug simulation 
Total elapsed time: 22.21877353079617. Arrivals time: 0.32048791320994496 Scheduler time: 21.750008762814105 Scheduler overhead time: 0.054439709056168795 Adapter cache time: 0.014485036488622427 Engine time: 0.05536708747968078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.92585472483188,
    "estimated_duration": 3600.037770625523,
    "input_throughput": 5139.183024956242,
    "output_throughput": 4473.2397341492015,
    "total_throughput": 9612.422759105444,
    "itl": 98.35426972423446,
    "ttft": 2030158.3076389064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.833905155193089,
    "arrivals": 463927,
    "finished_requests": 74713,
    "scheduler_time": 171.43987803388268
}
#Debug simulation 
Total elapsed time: 13.925982200074941. Arrivals time: 0.3228250336833298 Scheduler time: 13.443942034617066 Scheduler overhead time: 0.05622608074918389 Adapter cache time: 0.019653094466775656 Engine time: 0.05734077887609601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 41.003614688292146,
    "estimated_duration": 3600.044591708045,
    "input_throughput": 5623.88339484266,
    "output_throughput": 4895.495194863204,
    "total_throughput": 10519.378589705864,
    "itl": 118.10901395110379,
    "ttft": 1972046.865755712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.49949061407709,
    "arrivals": 462544,
    "finished_requests": 82029,
    "scheduler_time": 159.7131786938999
}
#Debug simulation 
Total elapsed time: 41.00378063507378. Arrivals time: 0.37058493169024587 Scheduler time: 40.47143914131448 Scheduler overhead time: 0.060082508251070976 Adapter cache time: 0.015585018321871758 Engine time: 0.06182061182335019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 24.410649980884045,
    "estimated_duration": 3600.018148963413,
    "input_throughput": 5445.166715519029,
    "output_throughput": 4734.623353192775,
    "total_throughput": 10179.790068711804,
    "itl": 110.53627389522255,
    "ttft": 1995718.7722195878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8337341150827737,
    "arrivals": 462544,
    "finished_requests": 79345,
    "scheduler_time": 163.41391536419448
}
#Debug simulation 
Total elapsed time: 24.410797440912575. Arrivals time: 0.3300450826063752 Scheduler time: 23.927320220973343 Scheduler overhead time: 0.0569550939835608 Adapter cache time: 0.014237223658710718 Engine time: 0.05763696553185582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.356793018057942,
    "estimated_duration": 3600.009860731934,
    "input_throughput": 5150.553392159358,
    "output_throughput": 4484.095217649748,
    "total_throughput": 9634.648609809105,
    "itl": 98.25603775403602,
    "ttft": 2033637.325916973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0681089362362695,
    "arrivals": 462544,
    "finished_requests": 75040,
    "scheduler_time": 171.59230600884194
}
#Debug simulation 
Total elapsed time: 15.356920539867133. Arrivals time: 0.2884181849658489 Scheduler time: 14.908440753817558 Scheduler overhead time: 0.057090748101472855 Adapter cache time: 0.01801788667216897 Engine time: 0.05881368601694703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 24.50014649098739,
    "estimated_duration": 3600.018177383338,
    "input_throughput": 5457.797164313545,
    "output_throughput": 4739.818011808625,
    "total_throughput": 10197.61517612217,
    "itl": 110.80436809323263,
    "ttft": 1997207.0868747456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9541501874895726,
    "arrivals": 462544,
    "finished_requests": 79482,
    "scheduler_time": 163.24976653973488
}
#Debug simulation 
Total elapsed time: 24.500367532018572. Arrivals time: 0.3300527734681964 Scheduler time: 24.015849506482482 Scheduler overhead time: 0.056683715898543596 Adapter cache time: 0.01492057228460908 Engine time: 0.05826086923480034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.920690936036408,
    "estimated_duration": 3600.0809590536,
    "input_throughput": 5146.699535576788,
    "output_throughput": 4486.929095129691,
    "total_throughput": 9633.628630706478,
    "itl": 98.40507022143007,
    "ttft": 2032335.6904417223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.728108519371619,
    "arrivals": 462544,
    "finished_requests": 75024,
    "scheduler_time": 171.49382850799756
}
#Debug simulation 
Total elapsed time: 11.920791619922966. Arrivals time: 0.27331700548529625 Scheduler time: 11.490626156330109 Scheduler overhead time: 0.054799852427095175 Adapter cache time: 0.020573961548507214 Engine time: 0.055782243609428406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.167879399843514,
    "estimated_duration": 3600.0306144738706,
    "input_throughput": 5453.996396880505,
    "output_throughput": 4737.968041555887,
    "total_throughput": 10191.964438436391,
    "itl": 110.66736803985161,
    "ttft": 1996255.41993533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7450860044453176,
    "arrivals": 462544,
    "finished_requests": 79413,
    "scheduler_time": 163.33308885936117
}
#Debug simulation 
Total elapsed time: 24.168059127870947. Arrivals time: 0.3268899726681411 Scheduler time: 23.68748460477218 Scheduler overhead time: 0.056457667611539364 Adapter cache time: 0.014896620996296406 Engine time: 0.057610873598605394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.336541884113103,
    "estimated_duration": 3600.0177614603826,
    "input_throughput": 5154.530957778501,
    "output_throughput": 4484.495930223111,
    "total_throughput": 9639.026888001612,
    "itl": 98.27709320063377,
    "ttft": 2034038.9174604174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.827158569656343,
    "arrivals": 462544,
    "finished_requests": 75064,
    "scheduler_time": 171.57372774219292
}
#Debug simulation 
Total elapsed time: 16.336640988942236. Arrivals time: 0.2933471198193729 Scheduler time: 15.881391804665327 Scheduler overhead time: 0.058237035758793354 Adapter cache time: 0.01811759965494275 Engine time: 0.05946873174980283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.378316688816994,
    "estimated_duration": 3600.0207967397255,
    "input_throughput": 5575.192237271701,
    "output_throughput": 4866.8038295409615,
    "total_throughput": 10441.996066812662,
    "itl": 118.56074252938915,
    "ttft": 1970662.547895807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.478127150805712,
    "arrivals": 461815,
    "finished_requests": 81331,
    "scheduler_time": 159.185475156844
}
#Debug simulation 
Total elapsed time: 27.378499787766486. Arrivals time: 0.3380785374902189 Scheduler time: 26.892238229047507 Scheduler overhead time: 0.05407905159518123 Adapter cache time: 0.015437420923262835 Engine time: 0.055148697923868895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.2179449708201,
    "estimated_duration": 3600.054610657925,
    "input_throughput": 5433.789515883198,
    "output_throughput": 4741.07946848082,
    "total_throughput": 10174.868984364017,
    "itl": 110.5178061906876,
    "ttft": 1993957.7179991906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.046726482207892,
    "arrivals": 461815,
    "finished_requests": 79255,
    "scheduler_time": 163.62151136983945
}
#Debug simulation 
Total elapsed time: 17.218132426030934. Arrivals time: 0.3179522892460227 Scheduler time: 16.753351747989655 Scheduler overhead time: 0.05288530932739377 Adapter cache time: 0.015769401099532843 Engine time: 0.05421713413670659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.740687700919807,
    "estimated_duration": 3600.0824996566084,
    "input_throughput": 5133.3656941924955,
    "output_throughput": 4485.050551352679,
    "total_throughput": 9618.416245545173,
    "itl": 98.19504395927822,
    "ttft": 2026579.7412804372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.251852983967424,
    "arrivals": 461815,
    "finished_requests": 74862,
    "scheduler_time": 171.75753726892756
}
#Debug simulation 
Total elapsed time: 11.740811361931264. Arrivals time: 0.2768100737594068 Scheduler time: 11.308269605506212 Scheduler overhead time: 0.05475865490734577 Adapter cache time: 0.019554811529815197 Engine time: 0.055714637972414494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 23.45955978007987,
    "estimated_duration": 3600.0340893359644,
    "input_throughput": 5421.866714490005,
    "output_throughput": 4732.429076287581,
    "total_throughput": 10154.295790777585,
    "itl": 110.6822693470796,
    "ttft": 1991767.1187142222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1287447885889526,
    "arrivals": 461815,
    "finished_requests": 79088,
    "scheduler_time": 163.290338423435
}
#Debug simulation 
Total elapsed time: 23.459677661769092. Arrivals time: 0.32157839369028807 Scheduler time: 22.98528829123825 Scheduler overhead time: 0.05623027216643095 Adapter cache time: 0.015226011164486408 Engine time: 0.056908172089606524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.689226478803903,
    "estimated_duration": 3600.057526129002,
    "input_throughput": 5137.110967192168,
    "output_throughput": 4481.25394744648,
    "total_throughput": 9618.364914638649,
    "itl": 98.12842074447792,
    "ttft": 2026943.9652783114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.053361997343626,
    "arrivals": 461815,
    "finished_requests": 74828,
    "scheduler_time": 171.78481422515273
}
#Debug simulation 
Total elapsed time: 11.689349921885878. Arrivals time: 0.27578558027744293 Scheduler time: 11.256555353756994 Scheduler overhead time: 0.05494553176686168 Adapter cache time: 0.020155566278845072 Engine time: 0.05614633671939373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.67547832801938,
    "estimated_duration": 3600.092330578746,
    "input_throughput": 5438.308299402032,
    "output_throughput": 4740.495085373674,
    "total_throughput": 10178.803384775707,
    "itl": 110.79702447872955,
    "ttft": 1990613.3191365888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.06017371820284,
    "arrivals": 461815,
    "finished_requests": 79269,
    "scheduler_time": 163.33872562701868
}
#Debug simulation 
Total elapsed time: 17.67555146710947. Arrivals time: 0.5800019879825413 Scheduler time: 16.94928322918713 Scheduler overhead time: 0.05239425180479884 Adapter cache time: 0.01660675974562764 Engine time: 0.05361909279599786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.525132841896266,
    "estimated_duration": 3600.0147481461076,
    "input_throughput": 5130.9467577909845,
    "output_throughput": 4481.867472434356,
    "total_throughput": 9612.81423022534,
    "itl": 98.35854284535988,
    "ttft": 2028456.2557713718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.238165650889301,
    "arrivals": 461815,
    "finished_requests": 74786,
    "scheduler_time": 171.5136854918514
}
#Debug simulation 
Total elapsed time: 12.525551076978445. Arrivals time: 0.2784652356058359 Scheduler time: 12.089646914508194 Scheduler overhead time: 0.05521404603496194 Adapter cache time: 0.0199793865904212 Engine time: 0.056198247242718935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 17280, 17280, 540, 1080, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 1080, 540, 540, 540, 540, 540, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 540, 1080, 1080, 17280, 540, 540, 540, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 1080, 540, 17280, 1080, 540, 1080, 1080, 540, 1080, 17280, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1209600 . Total input tokens: 269976880 . Total output tokens: 237526373
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 30.468529749661684,
    "estimated_duration": 3600.0960229706416,
    "input_throughput": 5599.986186858551,
    "output_throughput": 4865.4613344303125,
    "total_throughput": 10465.447521288865,
    "itl": 118.31121049038364,
    "ttft": 1928461.4969642714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8596131741534909,
    "arrivals": 403594,
    "finished_requests": 81208,
    "scheduler_time": 158.5589043391241
}
#Debug simulation 
Total elapsed time: 30.468677318654954. Arrivals time: 0.34199447417631745 Scheduler time: 29.97407853929326 Scheduler overhead time: 0.05787323508411646 Adapter cache time: 0.0115917744114995 Engine time: 0.058943124022334814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 17280, 17280, 540, 1080, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 1080, 540, 540, 540, 540, 540, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 540, 1080, 1080, 17280, 540, 540, 540, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 1080, 540, 17280, 1080, 540, 1080, 1080, 540, 1080, 17280, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1209600 . Total input tokens: 269976880 . Total output tokens: 237526373
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.444478345103562,
    "estimated_duration": 3600.015078814761,
    "input_throughput": 5448.6682890389375,
    "output_throughput": 4729.932688394766,
    "total_throughput": 10178.600977433704,
    "itl": 110.68407067672713,
    "ttft": 1964086.7259351206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.777572807208637,
    "arrivals": 403594,
    "finished_requests": 78966,
    "scheduler_time": 162.6571416297732
}
#Debug simulation 
Total elapsed time: 25.444642389193177. Arrivals time: 0.33220557402819395 Scheduler time: 24.953885788097978 Scheduler overhead time: 0.0600514248944819 Adapter cache time: 0.012991157826036215 Engine time: 0.06029435433447361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 17280, 17280, 540, 1080, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 1080, 540, 540, 540, 540, 540, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 540, 1080, 1080, 17280, 540, 540, 540, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 1080, 540, 17280, 1080, 540, 1080, 1080, 540, 1080, 17280, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1209600 . Total input tokens: 269976880 . Total output tokens: 237526373
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.538517851848155,
    "estimated_duration": 3600.0326379765456,
    "input_throughput": 5134.696781635243,
    "output_throughput": 4467.854493963838,
    "total_throughput": 9602.55127559908,
    "itl": 98.3447702664547,
    "ttft": 2004371.8176736094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.225611026855214,
    "arrivals": 403594,
    "finished_requests": 74449,
    "scheduler_time": 170.69527935812388
}
#Debug simulation 
Total elapsed time: 14.538612868171185. Arrivals time: 0.28042423306033015 Scheduler time: 14.09507679566741 Scheduler overhead time: 0.05804920895025134 Adapter cache time: 0.020081146154552698 Engine time: 0.058807275258004665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 17280, 17280, 540, 1080, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 1080, 540, 540, 540, 540, 540, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 540, 1080, 1080, 17280, 540, 540, 540, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 1080, 540, 17280, 1080, 540, 1080, 1080, 540, 1080, 17280, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1209600 . Total input tokens: 269976880 . Total output tokens: 237526373
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 26.062104830984026,
    "estimated_duration": 3600.009649623668,
    "input_throughput": 5446.090402021433,
    "output_throughput": 4728.709547147899,
    "total_throughput": 10174.799949169332,
    "itl": 110.62818003063298,
    "ttft": 1960724.7622087966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5121866589179247,
    "arrivals": 403594,
    "finished_requests": 78941,
    "scheduler_time": 162.68946733619396
}
#Debug simulation 
Total elapsed time: 26.062277395278215. Arrivals time: 0.34516030829399824 Scheduler time: 25.556960015092045 Scheduler overhead time: 0.06047777459025383 Adapter cache time: 0.012961552012711763 Engine time: 0.061460989993065596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 17280, 17280, 540, 1080, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 1080, 540, 540, 540, 540, 540, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 540, 1080, 1080, 17280, 540, 540, 540, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 1080, 540, 17280, 1080, 540, 1080, 1080, 540, 1080, 17280, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1209600 . Total input tokens: 269976880 . Total output tokens: 237526373
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.461973947938532,
    "estimated_duration": 3600.039444876019,
    "input_throughput": 5137.685929059862,
    "output_throughput": 4466.74189164441,
    "total_throughput": 9604.427820704272,
    "itl": 98.16718404198205,
    "ttft": 2004744.0057474417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.035851243166285,
    "arrivals": 403594,
    "finished_requests": 74460,
    "scheduler_time": 170.84553479456977
}
#Debug simulation 
Total elapsed time: 14.462134951725602. Arrivals time: 0.27928605675697327 Scheduler time: 14.02245827531442 Scheduler overhead time: 0.057653230149298906 Adapter cache time: 0.018266580067574978 Engine time: 0.05833696434274316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 17280, 17280, 540, 1080, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 1080, 540, 540, 540, 540, 540, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 540, 1080, 1080, 17280, 540, 540, 540, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 1080, 540, 17280, 1080, 540, 1080, 1080, 540, 1080, 17280, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1209600 . Total input tokens: 269976880 . Total output tokens: 237526373
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.65015404112637,
    "estimated_duration": 3600.097578574917,
    "input_throughput": 5449.506179153622,
    "output_throughput": 4729.393753471476,
    "total_throughput": 10178.899932625098,
    "itl": 110.62911605153413,
    "ttft": 1961889.8447928533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4236143697472246,
    "arrivals": 403594,
    "finished_requests": 78976,
    "scheduler_time": 162.68649929410708
}
#Debug simulation 
Total elapsed time: 25.65027218684554. Arrivals time: 0.327319226693362 Scheduler time: 25.165822974406183 Scheduler overhead time: 0.05926741333678365 Adapter cache time: 0.012957911472767591 Engine time: 0.060125818476080894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 17280, 17280, 540, 1080, 17280, 540, 1080, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 1080, 540, 540, 540, 540, 540, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 540, 1080, 1080, 17280, 540, 540, 540, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 1080, 17280, 17280, 1080, 17280, 1080, 540, 17280, 1080, 540, 1080, 1080, 540, 1080, 17280, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 1080, 540, 17280, 17280, 1080, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1209600 . Total input tokens: 269976880 . Total output tokens: 237526373
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.666129215154797,
    "estimated_duration": 3600.0350766549295,
    "input_throughput": 5139.3574245925165,
    "output_throughput": 4474.0939065977545,
    "total_throughput": 9613.45133119027,
    "itl": 98.31416079662038,
    "ttft": 2003416.317647991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.821571971681004,
    "arrivals": 403594,
    "finished_requests": 74551,
    "scheduler_time": 170.81763315864214
}
#Debug simulation 
Total elapsed time: 13.66624181298539. Arrivals time: 0.2935491530224681 Scheduler time: 13.214989189989865 Scheduler overhead time: 0.056463804095983505 Adapter cache time: 0.017817005515098572 Engine time: 0.05738592194393277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 17280, 17280, 270, 1080, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 1080, 270, 270, 270, 270, 270, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 270, 1080, 1080, 17280, 270, 270, 270, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 1080, 270, 17280, 1080, 270, 1080, 1080, 270, 1080, 17280, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1192320 . Total input tokens: 266129892 . Total output tokens: 234150557
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.00497421901673,
    "estimated_duration": 3600.0944396923232,
    "input_throughput": 5627.709033580662,
    "output_throughput": 4873.8854754875765,
    "total_throughput": 10501.594509068238,
    "itl": 118.73537949300132,
    "ttft": 1920233.674731998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6083416309393936,
    "arrivals": 397773,
    "finished_requests": 81762,
    "scheduler_time": 158.27966814433387
}
#Debug simulation 
Total elapsed time: 27.005090143997222. Arrivals time: 0.3621113053523004 Scheduler time: 26.492394033819437 Scheduler overhead time: 0.05749528482556343 Adapter cache time: 0.010550431907176971 Engine time: 0.05876755574718118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 17280, 17280, 270, 1080, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 1080, 270, 270, 270, 270, 270, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 270, 1080, 1080, 17280, 270, 270, 270, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 1080, 270, 17280, 1080, 270, 1080, 1080, 270, 1080, 17280, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1192320 . Total input tokens: 266129892 . Total output tokens: 234150557
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 24.528578070923686,
    "estimated_duration": 3600.087459610688,
    "input_throughput": 5469.1215757656055,
    "output_throughput": 4736.482152531919,
    "total_throughput": 10205.603728297525,
    "itl": 110.96601052714718,
    "ttft": 1946617.4701754807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1480387898674247,
    "arrivals": 397773,
    "finished_requests": 79426,
    "scheduler_time": 162.44060940586758
}
#Debug simulation 
Total elapsed time: 24.528702936135232. Arrivals time: 0.3361660009250045 Scheduler time: 24.03851552726701 Scheduler overhead time: 0.0582001693546772 Adapter cache time: 0.011796883307397366 Engine time: 0.05930892564356327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 17280, 17280, 270, 1080, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 1080, 270, 270, 270, 270, 270, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 270, 1080, 1080, 17280, 270, 270, 270, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 1080, 270, 17280, 1080, 270, 1080, 1080, 270, 1080, 17280, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1192320 . Total input tokens: 266129892 . Total output tokens: 234150557
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.074092703871429,
    "estimated_duration": 3600.0774992712127,
    "input_throughput": 5152.223251792461,
    "output_throughput": 4471.96095174593,
    "total_throughput": 9624.18420353839,
    "itl": 98.60661440127177,
    "ttft": 1999141.8915810247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.38790538352451,
    "arrivals": 397773,
    "finished_requests": 74889,
    "scheduler_time": 170.33333469181716
}
#Debug simulation 
Total elapsed time: 11.074246923904866. Arrivals time: 0.27782142627984285 Scheduler time: 10.640809930860996 Scheduler overhead time: 0.05449326662346721 Adapter cache time: 0.01961649674922228 Engine time: 0.055878045968711376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 17280, 17280, 270, 1080, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 1080, 270, 270, 270, 270, 270, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 270, 1080, 1080, 17280, 270, 270, 270, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 1080, 270, 17280, 1080, 270, 1080, 1080, 270, 1080, 17280, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1192320 . Total input tokens: 266129892 . Total output tokens: 234150557
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 24.320393685717136,
    "estimated_duration": 3600.0301096710264,
    "input_throughput": 5472.604228246397,
    "output_throughput": 4739.827301488675,
    "total_throughput": 10212.431529735073,
    "itl": 111.13720991875546,
    "ttft": 1947984.9157115475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1452433925541112,
    "arrivals": 397773,
    "finished_requests": 79494,
    "scheduler_time": 162.33400490873188
}
#Debug simulation 
Total elapsed time: 24.320522910915315. Arrivals time: 0.31347079016268253 Scheduler time: 23.85287882760167 Scheduler overhead time: 0.05842616828158498 Adapter cache time: 0.011842345353215933 Engine time: 0.05942369578406215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 17280, 17280, 270, 1080, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 1080, 270, 270, 270, 270, 270, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 270, 1080, 1080, 17280, 270, 270, 270, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 1080, 270, 17280, 1080, 270, 1080, 1080, 270, 1080, 17280, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1192320 . Total input tokens: 266129892 . Total output tokens: 234150557
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.615082795731723,
    "estimated_duration": 3600.04940638175,
    "input_throughput": 5154.712312309913,
    "output_throughput": 4473.222776179963,
    "total_throughput": 9627.935088489876,
    "itl": 98.55013892162586,
    "ttft": 1999115.424777553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.420868711401733,
    "arrivals": 397773,
    "finished_requests": 74921,
    "scheduler_time": 170.4064500569336
}
#Debug simulation 
Total elapsed time: 11.61517477594316. Arrivals time: 0.25580452708527446 Scheduler time: 11.202594072557986 Scheduler overhead time: 0.05474609462544322 Adapter cache time: 0.019823765382170677 Engine time: 0.05650104768574238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 17280, 17280, 270, 1080, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 1080, 270, 270, 270, 270, 270, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 270, 1080, 1080, 17280, 270, 270, 270, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 1080, 270, 17280, 1080, 270, 1080, 1080, 270, 1080, 17280, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1192320 . Total input tokens: 266129892 . Total output tokens: 234150557
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.923360061831772,
    "estimated_duration": 3600.0327816283193,
    "input_throughput": 5471.126013216818,
    "output_throughput": 4734.911050529394,
    "total_throughput": 10206.037063746213,
    "itl": 110.86802716870959,
    "ttft": 1945145.6587111787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8299097222741681,
    "arrivals": 397773,
    "finished_requests": 79400,
    "scheduler_time": 162.49376212293632
}
#Debug simulation 
Total elapsed time: 24.92347253393382. Arrivals time: 0.3428697884082794 Scheduler time: 24.426157547160983 Scheduler overhead time: 0.05834179883822799 Adapter cache time: 0.010781913064420223 Engine time: 0.060183162335306406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 17280, 17280, 270, 1080, 17280, 270, 1080, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 1080, 270, 270, 270, 270, 270, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 270, 1080, 1080, 17280, 270, 270, 270, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 1080, 17280, 17280, 1080, 17280, 1080, 270, 17280, 1080, 270, 1080, 1080, 270, 1080, 17280, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 1080, 270, 17280, 17280, 1080, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1192320 . Total input tokens: 266129892 . Total output tokens: 234150557
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.711421750020236,
    "estimated_duration": 3600.1024338721845,
    "input_throughput": 5161.202310572833,
    "output_throughput": 4477.153996605489,
    "total_throughput": 9638.356307178323,
    "itl": 98.46662414710885,
    "ttft": 2000022.3929660306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.132144821677381,
    "arrivals": 397773,
    "finished_requests": 74999,
    "scheduler_time": 170.53689302559349
}
#Debug simulation 
Total elapsed time: 11.71153586404398. Arrivals time: 0.2765781609341502 Scheduler time: 11.278061268851161 Scheduler overhead time: 0.05519924405962229 Adapter cache time: 0.019432362634688616 Engine time: 0.05646864743903279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 17280, 17280, 135, 1080, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 1080, 135, 135, 135, 135, 135, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 135, 1080, 1080, 17280, 135, 135, 135, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 1080, 135, 17280, 1080, 135, 1080, 1080, 135, 1080, 17280, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 1183680 . Total input tokens: 264171664 . Total output tokens: 232443928
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.133567780721933,
    "estimated_duration": 3600.0791256833736,
    "input_throughput": 5612.8185783039835,
    "output_throughput": 4871.033215602244,
    "total_throughput": 10483.851793906228,
    "itl": 118.6458693093385,
    "ttft": 1925150.5015096932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7405898115783922,
    "arrivals": 394957,
    "finished_requests": 81539,
    "scheduler_time": 158.34852391190202
}
#Debug simulation 
Total elapsed time: 24.13377182278782. Arrivals time: 0.3328728638589382 Scheduler time: 23.65383105352521 Scheduler overhead time: 0.055696453899145126 Adapter cache time: 0.01051561813801527 Engine time: 0.05701795546337962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 17280, 17280, 135, 1080, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 1080, 135, 135, 135, 135, 135, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 135, 1080, 1080, 17280, 135, 135, 135, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 1080, 135, 17280, 1080, 135, 1080, 1080, 135, 1080, 17280, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 1183680 . Total input tokens: 264171664 . Total output tokens: 232443928
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 21.77122816303745,
    "estimated_duration": 3600.0540766796125,
    "input_throughput": 5457.241636247908,
    "output_throughput": 4739.655193106847,
    "total_throughput": 10196.896829354755,
    "itl": 110.94994676707802,
    "ttft": 1949299.0882806801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0264609611919158,
    "arrivals": 394957,
    "finished_requests": 79290,
    "scheduler_time": 162.4784657309345
}
#Debug simulation 
Total elapsed time: 21.771393505856395. Arrivals time: 0.3277763118967414 Scheduler time: 21.29339130828157 Scheduler overhead time: 0.0563242775388062 Adapter cache time: 0.011125865392386913 Engine time: 0.05817112512886524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 17280, 17280, 135, 1080, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 1080, 135, 135, 135, 135, 135, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 135, 1080, 1080, 17280, 135, 135, 135, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 1080, 135, 17280, 1080, 135, 1080, 1080, 135, 1080, 17280, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 1183680 . Total input tokens: 264171664 . Total output tokens: 232443928
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.229665794875473,
    "estimated_duration": 3600.0440931223093,
    "input_throughput": 5133.862119997118,
    "output_throughput": 4467.568058604213,
    "total_throughput": 9601.430178601331,
    "itl": 98.4852960963627,
    "ttft": 1995966.3233116858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.566953651006363,
    "arrivals": 394957,
    "finished_requests": 74698,
    "scheduler_time": 170.44751968939576
}
#Debug simulation 
Total elapsed time: 11.229767505079508. Arrivals time: 0.2674740431830287 Scheduler time: 10.807973061688244 Scheduler overhead time: 0.05468993401154876 Adapter cache time: 0.018034604378044605 Engine time: 0.056044463999569416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 17280, 17280, 135, 1080, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 1080, 135, 135, 135, 135, 135, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 135, 1080, 1080, 17280, 135, 135, 135, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 1080, 135, 17280, 1080, 135, 1080, 1080, 135, 1080, 17280, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 1183680 . Total input tokens: 264171664 . Total output tokens: 232443928
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 21.632033650763333,
    "estimated_duration": 3600.0004943895733,
    "input_throughput": 5454.093695431374,
    "output_throughput": 4738.665182570373,
    "total_throughput": 10192.758878001747,
    "itl": 110.95293160330476,
    "ttft": 1948234.4125930355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9251303078234191,
    "arrivals": 394957,
    "finished_requests": 79258,
    "scheduler_time": 162.47924086610956
}
#Debug simulation 
Total elapsed time: 21.632133962586522. Arrivals time: 0.31623660819604993 Scheduler time: 21.167169242165983 Scheduler overhead time: 0.05594972660765052 Adapter cache time: 0.010855790227651596 Engine time: 0.057611008174717426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 17280, 17280, 135, 1080, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 1080, 135, 135, 135, 135, 135, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 135, 1080, 1080, 17280, 135, 135, 135, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 1080, 135, 17280, 1080, 135, 1080, 1080, 135, 1080, 17280, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 1183680 . Total input tokens: 264171664 . Total output tokens: 232443928
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 12.650932615157217,
    "estimated_duration": 3600.0247353059563,
    "input_throughput": 5135.330271120711,
    "output_throughput": 4473.789260959402,
    "total_throughput": 9609.119532080113,
    "itl": 98.54061583744854,
    "ttft": 1993534.7103312209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7029590343125482,
    "arrivals": 394957,
    "finished_requests": 74768,
    "scheduler_time": 170.46706499999672
}
#Debug simulation 
Total elapsed time: 12.651032877154648. Arrivals time: 0.27163394447416067 Scheduler time: 12.22624080767855 Scheduler overhead time: 0.05529812350869179 Adapter cache time: 0.015280570834875107 Engine time: 0.05677746934816241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 17280, 17280, 135, 1080, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 1080, 135, 135, 135, 135, 135, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 135, 1080, 1080, 17280, 135, 135, 135, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 1080, 135, 17280, 1080, 135, 1080, 1080, 135, 1080, 17280, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 1183680 . Total input tokens: 264171664 . Total output tokens: 232443928
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 21.779284827876836,
    "estimated_duration": 3600.035950379494,
    "input_throughput": 5453.8908140431995,
    "output_throughput": 4738.520180111468,
    "total_throughput": 10192.410994154667,
    "itl": 110.95333186824165,
    "ttft": 1948180.6615554076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8682132479175911,
    "arrivals": 394957,
    "finished_requests": 79257,
    "scheduler_time": 162.48075039397824
}
#Debug simulation 
Total elapsed time: 21.7794305998832. Arrivals time: 0.3294578189961612 Scheduler time: 21.29976550862193 Scheduler overhead time: 0.05722736893221736 Adapter cache time: 0.01080092927441001 Engine time: 0.05763297760859132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 17280, 17280, 135, 1080, 17280, 135, 1080, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 1080, 135, 135, 135, 135, 135, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 135, 1080, 1080, 17280, 135, 135, 135, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 1080, 17280, 17280, 1080, 17280, 1080, 135, 17280, 1080, 135, 1080, 1080, 135, 1080, 17280, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 1080, 135, 17280, 17280, 1080, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 1183680 . Total input tokens: 264171664 . Total output tokens: 232443928
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.887392762117088,
    "estimated_duration": 3600.1019491556963,
    "input_throughput": 5136.219268550583,
    "output_throughput": 4475.814915124542,
    "total_throughput": 9612.034183675125,
    "itl": 98.62180763278513,
    "ttft": 1993034.9796566502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4836082056537556,
    "arrivals": 394957,
    "finished_requests": 74781,
    "scheduler_time": 170.42357438152843
}
#Debug simulation 
Total elapsed time: 12.887520196847618. Arrivals time: 0.2713893987238407 Scheduler time: 12.46348011912778 Scheduler overhead time: 0.055365531239658594 Adapter cache time: 0.014880355913192034 Engine time: 0.056707234121859074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 17280, 17280, 66, 1080, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 1080, 66, 66, 66, 66, 66, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 66, 1080, 1080, 17280, 66, 66, 66, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 1080, 66, 17280, 1080, 66, 1080, 1080, 66, 1080, 17280, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 1179264 . Total input tokens: 263182309 . Total output tokens: 231595162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 22.968043541070074,
    "estimated_duration": 3600.097966578052,
    "input_throughput": 5610.919254844688,
    "output_throughput": 4867.830032041451,
    "total_throughput": 10478.749286886139,
    "itl": 118.49075659586211,
    "ttft": 1921985.1268710657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 393528,
    "finished_requests": 81663,
    "scheduler_time": 158.27113962753725
}
#Debug simulation 
Total elapsed time: 22.96818732889369. Arrivals time: 0.33436503214761615 Scheduler time: 22.48886552453041 Scheduler overhead time: 0.05429026111960411 Adapter cache time: 0.010633143596351147 Engine time: 0.056825256906449795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 17280, 17280, 66, 1080, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 1080, 66, 66, 66, 66, 66, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 66, 1080, 1080, 17280, 66, 66, 66, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 1080, 66, 17280, 1080, 66, 1080, 1080, 66, 1080, 17280, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 1179264 . Total input tokens: 263182309 . Total output tokens: 231595162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.386143091600388,
    "estimated_duration": 3600.0011467962536,
    "input_throughput": 5451.917985489134,
    "output_throughput": 4727.935993894643,
    "total_throughput": 10179.853979383775,
    "itl": 110.50736978143443,
    "ttft": 1951993.663940367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2828467943100303,
    "arrivals": 393528,
    "finished_requests": 79258,
    "scheduler_time": 162.52757950776345
}
#Debug simulation 
Total elapsed time: 15.386240608990192. Arrivals time: 0.2975612757727504 Scheduler time: 14.944317473564297 Scheduler overhead time: 0.052744817454367876 Adapter cache time: 0.013768781907856464 Engine time: 0.054080686531960964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 17280, 17280, 66, 1080, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 1080, 66, 66, 66, 66, 66, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 66, 1080, 1080, 17280, 66, 66, 66, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 1080, 66, 17280, 1080, 66, 1080, 1080, 66, 1080, 17280, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 1179264 . Total input tokens: 263182309 . Total output tokens: 231595162
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.629095243290067,
    "estimated_duration": 3600.0415558668446,
    "input_throughput": 5149.7494438049525,
    "output_throughput": 4465.237345330957,
    "total_throughput": 9614.98678913591,
    "itl": 98.14550547689662,
    "ttft": 1990242.4675401307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.622550247423375,
    "arrivals": 393528,
    "finished_requests": 74837,
    "scheduler_time": 170.5521700202569
}
#Debug simulation 
Total elapsed time: 9.629191831219941. Arrivals time: 0.2605303288437426 Scheduler time: 9.216917953453958 Scheduler overhead time: 0.05355649907141924 Adapter cache time: 0.017938490957021713 Engine time: 0.054817377123981714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 17280, 17280, 66, 1080, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 1080, 66, 66, 66, 66, 66, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 66, 1080, 1080, 17280, 66, 66, 66, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 1080, 66, 17280, 1080, 66, 1080, 1080, 66, 1080, 17280, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 1179264 . Total input tokens: 263182309 . Total output tokens: 231595162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 15.066139081958681,
    "estimated_duration": 3600.055461689346,
    "input_throughput": 5451.531846898402,
    "output_throughput": 4727.1899505720785,
    "total_throughput": 10178.72179747048,
    "itl": 110.52405349495902,
    "ttft": 1951814.539818437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0654532854258973,
    "arrivals": 393528,
    "finished_requests": 79250,
    "scheduler_time": 162.5075619517379
}
#Debug simulation 
Total elapsed time: 15.06632364820689. Arrivals time: 0.2908151033334434 Scheduler time: 14.631664607673883 Scheduler overhead time: 0.052494388073682785 Adapter cache time: 0.014025031588971615 Engine time: 0.05338016292080283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 17280, 17280, 66, 1080, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 1080, 66, 66, 66, 66, 66, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 66, 1080, 1080, 17280, 66, 66, 66, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 1080, 66, 17280, 1080, 66, 1080, 1080, 66, 1080, 17280, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 1179264 . Total input tokens: 263182309 . Total output tokens: 231595162
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.85452816914767,
    "estimated_duration": 3600.033756478313,
    "input_throughput": 5148.223115032796,
    "output_throughput": 4465.130075814842,
    "total_throughput": 9613.353190847638,
    "itl": 98.12241877001195,
    "ttft": 1991082.1194732455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.641491890358766,
    "arrivals": 393528,
    "finished_requests": 74778,
    "scheduler_time": 170.56526185174656
}
#Debug simulation 
Total elapsed time: 9.854634586255997. Arrivals time: 0.2607561103068292 Scheduler time: 9.441558770369738 Scheduler overhead time: 0.0535638052970171 Adapter cache time: 0.018628211691975594 Engine time: 0.05454658716917038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 17280, 17280, 66, 1080, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 1080, 66, 66, 66, 66, 66, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 66, 1080, 1080, 17280, 66, 66, 66, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 1080, 66, 17280, 1080, 66, 1080, 1080, 66, 1080, 17280, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 1179264 . Total input tokens: 263182309 . Total output tokens: 231595162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 15.075815632008016,
    "estimated_duration": 3600.0816325952183,
    "input_throughput": 5458.787884716174,
    "output_throughput": 4733.466831893926,
    "total_throughput": 10192.2547166101,
    "itl": 110.72307947330982,
    "ttft": 1950864.063247463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.147273023701259,
    "arrivals": 393528,
    "finished_requests": 79373,
    "scheduler_time": 162.45638500533795
}
#Debug simulation 
Total elapsed time: 15.07596862083301. Arrivals time: 0.2826341432519257 Scheduler time: 14.650415203999728 Scheduler overhead time: 0.051709529012441635 Adapter cache time: 0.01457170071080327 Engine time: 0.0527962283231318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 17280, 17280, 66, 1080, 17280, 66, 1080, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 1080, 66, 66, 66, 66, 66, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 66, 1080, 1080, 17280, 66, 66, 66, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 1080, 17280, 17280, 1080, 17280, 1080, 66, 17280, 1080, 66, 1080, 1080, 66, 1080, 17280, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 1080, 66, 17280, 17280, 1080, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 1179264 . Total input tokens: 263182309 . Total output tokens: 231595162
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.741193911992013,
    "estimated_duration": 3600.0955984153,
    "input_throughput": 5146.096400371984,
    "output_throughput": 4463.7975744515725,
    "total_throughput": 9609.893974823557,
    "itl": 98.2096733343577,
    "ttft": 1991244.3111565139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.171470794212101,
    "arrivals": 393528,
    "finished_requests": 74814,
    "scheduler_time": 170.43879305048898
}
#Debug simulation 
Total elapsed time: 9.741297364234924. Arrivals time: 0.25476232590153813 Scheduler time: 9.334948631003499 Scheduler overhead time: 0.053875772282481194 Adapter cache time: 0.01737677538767457 Engine time: 0.05477340891957283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 17280, 17280, 33, 1080, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 1080, 33, 33, 33, 33, 33, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 33, 1080, 1080, 17280, 33, 33, 33, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 1080, 33, 17280, 1080, 33, 1080, 1080, 33, 1080, 17280, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 1177152 . Total input tokens: 262713572 . Total output tokens: 231181793
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 20.908547390718013,
    "estimated_duration": 3600.057150394138,
    "input_throughput": 5595.044789162523,
    "output_throughput": 4868.801873903869,
    "total_throughput": 10463.846663066392,
    "itl": 118.53334438553085,
    "ttft": 1919018.1709833455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7802642657700918,
    "arrivals": 392778,
    "finished_requests": 81597,
    "scheduler_time": 158.2012620981027
}
#Debug simulation 
Total elapsed time: 20.90865467907861. Arrivals time: 0.3224919633939862 Scheduler time: 20.44427511887625 Scheduler overhead time: 0.05362552870064974 Adapter cache time: 0.010099198203533888 Engine time: 0.05514991981908679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 17280, 17280, 33, 1080, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 1080, 33, 33, 33, 33, 33, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 33, 1080, 1080, 17280, 33, 33, 33, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 1080, 33, 17280, 1080, 33, 1080, 1080, 33, 1080, 17280, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 1177152 . Total input tokens: 262713572 . Total output tokens: 231181793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.027465261984617,
    "estimated_duration": 3600.1063959023213,
    "input_throughput": 5440.829199463318,
    "output_throughput": 4742.86649401105,
    "total_throughput": 10183.695693474368,
    "itl": 110.80316247254841,
    "ttft": 1950838.5007993511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.786270226552155,
    "arrivals": 392778,
    "finished_requests": 79504,
    "scheduler_time": 162.4476780717857
}
#Debug simulation 
Total elapsed time: 15.027606423944235. Arrivals time: 0.29791608778759837 Scheduler time: 14.585188630968332 Scheduler overhead time: 0.05276155984029174 Adapter cache time: 0.013378503266721964 Engine time: 0.054629857651889324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 17280, 17280, 33, 1080, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 1080, 33, 33, 33, 33, 33, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 33, 1080, 1080, 17280, 33, 33, 33, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 1080, 33, 17280, 1080, 33, 1080, 1080, 33, 1080, 17280, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 1177152 . Total input tokens: 262713572 . Total output tokens: 231181793
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.513108153827488,
    "estimated_duration": 3600.0054360488352,
    "input_throughput": 5135.573911880394,
    "output_throughput": 4478.008238146815,
    "total_throughput": 9613.582150027209,
    "itl": 98.45969856520664,
    "ttft": 1990122.1345878097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.577340294839846,
    "arrivals": 392778,
    "finished_requests": 75032,
    "scheduler_time": 170.2873013890071
}
#Debug simulation 
Total elapsed time: 9.51320210378617. Arrivals time: 0.25400502094998956 Scheduler time: 9.107463859021664 Scheduler overhead time: 0.053925647400319576 Adapter cache time: 0.016639383975416422 Engine time: 0.05550608318299055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 17280, 17280, 33, 1080, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 1080, 33, 33, 33, 33, 33, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 33, 1080, 1080, 17280, 33, 33, 33, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 1080, 33, 17280, 1080, 33, 1080, 1080, 33, 1080, 17280, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 1177152 . Total input tokens: 262713572 . Total output tokens: 231181793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 18.11786467814818,
    "estimated_duration": 3600.08767423599,
    "input_throughput": 5448.435086837894,
    "output_throughput": 4737.434624732979,
    "total_throughput": 10185.869711570873,
    "itl": 110.86585815850977,
    "ttft": 1952108.9435706907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.432878450700079,
    "arrivals": 392778,
    "finished_requests": 79541,
    "scheduler_time": 162.2868865236577
}
#Debug simulation 
Total elapsed time: 18.117973076179624. Arrivals time: 0.31767976796254516 Scheduler time: 17.648779718205333 Scheduler overhead time: 0.05615151394158602 Adapter cache time: 0.013255535159260035 Engine time: 0.0578635148704052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 17280, 17280, 33, 1080, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 1080, 33, 33, 33, 33, 33, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 33, 1080, 1080, 17280, 33, 33, 33, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 1080, 33, 17280, 1080, 33, 1080, 1080, 33, 1080, 17280, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 1177152 . Total input tokens: 262713572 . Total output tokens: 231181793
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.511237145867199,
    "estimated_duration": 3600.0704842040996,
    "input_throughput": 5134.280865083222,
    "output_throughput": 4473.428526097428,
    "total_throughput": 9607.709391180651,
    "itl": 98.52118167911516,
    "ttft": 1990414.3125534048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.735072446316512,
    "arrivals": 392778,
    "finished_requests": 74996,
    "scheduler_time": 170.1486095454178
}
#Debug simulation 
Total elapsed time: 9.511361056938767. Arrivals time: 0.2575241378508508 Scheduler time: 9.103072240017354 Scheduler overhead time: 0.05384577764198184 Adapter cache time: 0.01646128436550498 Engine time: 0.054972239304333925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 17280, 17280, 33, 1080, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 1080, 33, 33, 33, 33, 33, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 33, 1080, 1080, 17280, 33, 33, 33, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 1080, 33, 17280, 1080, 33, 1080, 1080, 33, 1080, 17280, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 1177152 . Total input tokens: 262713572 . Total output tokens: 231181793
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 13.586704349145293,
    "estimated_duration": 3600.111631605136,
    "input_throughput": 5438.449693647568,
    "output_throughput": 4738.61778346964,
    "total_throughput": 10177.067477117209,
    "itl": 110.82030749803965,
    "ttft": 1949539.3044617956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.419506036476222,
    "arrivals": 392778,
    "finished_requests": 79409,
    "scheduler_time": 162.38371288089945
}
#Debug simulation 
Total elapsed time: 13.586772660259157. Arrivals time: 0.28870097268372774 Scheduler time: 13.155148272402585 Scheduler overhead time: 0.05130786681547761 Adapter cache time: 0.012644078582525253 Engine time: 0.05549749871715903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 17280, 17280, 33, 1080, 17280, 33, 1080, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 1080, 33, 33, 33, 33, 33, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 33, 1080, 1080, 17280, 33, 33, 33, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 1080, 17280, 17280, 1080, 17280, 1080, 33, 17280, 1080, 33, 1080, 1080, 33, 1080, 17280, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 1080, 33, 17280, 17280, 1080, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 1177152 . Total input tokens: 262713572 . Total output tokens: 231181793
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.378592445049435,
    "estimated_duration": 3600.0291127420123,
    "input_throughput": 5131.059339109225,
    "output_throughput": 4474.665758391718,
    "total_throughput": 9605.725097500943,
    "itl": 98.53937433147105,
    "ttft": 1989747.571818269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.437494807243379,
    "arrivals": 392778,
    "finished_requests": 74974,
    "scheduler_time": 170.14499129171824
}
#Debug simulation 
Total elapsed time: 9.378764488268644. Arrivals time: 0.25425401236861944 Scheduler time: 8.97501462744549 Scheduler overhead time: 0.05361274862661958 Adapter cache time: 0.015713747590780258 Engine time: 0.05461576767265797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 540, 540, 17280, 540, 270, 17280, 270, 540, 540, 270, 17280, 17280, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 270, 540, 540, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 17280, 17280, 270, 540, 17280, 270, 540, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 540, 270, 270, 270, 270, 270, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 270, 540, 540, 17280, 270, 270, 270, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 270, 17280, 540, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 540, 270, 17280, 540, 270, 540, 540, 270, 540, 17280, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 1157760 . Total input tokens: 258405761 . Total output tokens: 227405826
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 20.722624620888382,
    "estimated_duration": 3600.079960825654,
    "input_throughput": 5597.954273042877,
    "output_throughput": 4870.9987530327635,
    "total_throughput": 10468.95302607564,
    "itl": 118.72305090370797,
    "ttft": 1917976.0334191963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 386275,
    "finished_requests": 81246,
    "scheduler_time": 158.23988122427443
}
#Debug simulation 
Total elapsed time: 20.722695630975068. Arrivals time: 0.6222677566111088 Scheduler time: 19.958997029345483 Scheduler overhead time: 0.05351883778348565 Adapter cache time: 0.010382339358329773 Engine time: 0.054525486659258604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 540, 540, 17280, 540, 270, 17280, 270, 540, 540, 270, 17280, 17280, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 270, 540, 540, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 17280, 17280, 270, 540, 17280, 270, 540, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 540, 270, 270, 270, 270, 270, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 270, 540, 540, 17280, 270, 270, 270, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 270, 17280, 540, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 540, 270, 17280, 540, 270, 540, 540, 270, 540, 17280, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 1157760 . Total input tokens: 258405761 . Total output tokens: 227405826
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.39713409403339,
    "estimated_duration": 3600.0902094224507,
    "input_throughput": 5425.263497253686,
    "output_throughput": 4728.369293482473,
    "total_throughput": 10153.63279073616,
    "itl": 110.84460158739113,
    "ttft": 1949577.3198829582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.462437095376668,
    "arrivals": 386275,
    "finished_requests": 78850,
    "scheduler_time": 162.41261746590732
}
#Debug simulation 
Total elapsed time: 13.397251531016082. Arrivals time: 0.3254476715810597 Scheduler time: 12.928034665063024 Scheduler overhead time: 0.05221625557169318 Adapter cache time: 0.014462718274444342 Engine time: 0.05322227440774441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 540, 540, 17280, 540, 270, 17280, 270, 540, 540, 270, 17280, 17280, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 270, 540, 540, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 17280, 17280, 270, 540, 17280, 270, 540, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 540, 270, 270, 270, 270, 270, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 270, 540, 540, 17280, 270, 270, 270, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 270, 17280, 540, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 540, 270, 17280, 540, 270, 540, 540, 270, 540, 17280, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 1157760 . Total input tokens: 258405761 . Total output tokens: 227405826
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.665227929130197,
    "estimated_duration": 3600.077457250469,
    "input_throughput": 5119.481516399421,
    "output_throughput": 4467.545265618717,
    "total_throughput": 9587.026782018138,
    "itl": 98.50211795910232,
    "ttft": 1989860.8961382026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1439143759198735,
    "arrivals": 386275,
    "finished_requests": 74473,
    "scheduler_time": 170.33686538671677
}
#Debug simulation 
Total elapsed time: 9.665339136030525. Arrivals time: 0.328147885389626 Scheduler time: 9.182669190689921 Scheduler overhead time: 0.05407533282414079 Adapter cache time: 0.019468072801828384 Engine time: 0.05532728973776102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 540, 540, 17280, 540, 270, 17280, 270, 540, 540, 270, 17280, 17280, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 270, 540, 540, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 17280, 17280, 270, 540, 17280, 270, 540, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 540, 270, 270, 270, 270, 270, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 270, 540, 540, 17280, 270, 270, 270, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 270, 17280, 540, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 540, 270, 17280, 540, 270, 540, 540, 270, 540, 17280, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 1157760 . Total input tokens: 258405761 . Total output tokens: 227405826
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 13.950987691059709,
    "estimated_duration": 3600.108043995919,
    "input_throughput": 5425.399393936117,
    "output_throughput": 4729.85971307124,
    "total_throughput": 10155.259107007358,
    "itl": 110.8245814467972,
    "ttft": 1950868.9466891563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.172317867320958,
    "arrivals": 386275,
    "finished_requests": 78882,
    "scheduler_time": 162.42505250762937
}
#Debug simulation 
Total elapsed time: 13.951101033948362. Arrivals time: 0.32033939054235816 Scheduler time: 13.487570505589247 Scheduler overhead time: 0.05183560820296407 Adapter cache time: 0.01436720509082079 Engine time: 0.05345750320702791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 540, 540, 17280, 540, 270, 17280, 270, 540, 540, 270, 17280, 17280, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 270, 540, 540, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 17280, 17280, 270, 540, 17280, 270, 540, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 540, 270, 270, 270, 270, 270, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 270, 540, 540, 17280, 270, 270, 270, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 270, 17280, 540, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 540, 270, 17280, 540, 270, 540, 540, 270, 540, 17280, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 1157760 . Total input tokens: 258405761 . Total output tokens: 227405826
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.077828485053033,
    "estimated_duration": 3600.0748386467335,
    "input_throughput": 5129.012542122852,
    "output_throughput": 4471.458156145186,
    "total_throughput": 9600.470698268038,
    "itl": 98.58476574602612,
    "ttft": 1987699.2719094735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.076109781120938,
    "arrivals": 386275,
    "finished_requests": 74579,
    "scheduler_time": 170.29958391835723
}
#Debug simulation 
Total elapsed time: 11.077935526147485. Arrivals time: 0.2564483853057027 Scheduler time: 10.668833957053721 Scheduler overhead time: 0.054956392385065556 Adapter cache time: 0.015922344755381346 Engine time: 0.055957211181521416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 540, 540, 17280, 540, 270, 17280, 270, 540, 540, 270, 17280, 17280, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 270, 540, 540, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 17280, 17280, 270, 540, 17280, 270, 540, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 540, 270, 270, 270, 270, 270, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 270, 540, 540, 17280, 270, 270, 270, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 270, 17280, 540, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 540, 270, 17280, 540, 270, 540, 540, 270, 540, 17280, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 1157760 . Total input tokens: 258405761 . Total output tokens: 227405826
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.579240256920457,
    "estimated_duration": 3600.0836474789644,
    "input_throughput": 5427.2597287238905,
    "output_throughput": 4731.527838784621,
    "total_throughput": 10158.787567508512,
    "itl": 110.8585187319802,
    "ttft": 1949878.020288041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8855322651378685,
    "arrivals": 386275,
    "finished_requests": 78920,
    "scheduler_time": 162.4316537743696
}
#Debug simulation 
Total elapsed time: 16.57935358211398. Arrivals time: 0.2975661880336702 Scheduler time: 16.13734847260639 Scheduler overhead time: 0.05261257430538535 Adapter cache time: 0.014442055951803923 Engine time: 0.053384589962661266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 540, 540, 17280, 540, 270, 17280, 270, 540, 540, 270, 17280, 17280, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 270, 540, 540, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 17280, 17280, 270, 540, 17280, 270, 540, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 540, 270, 270, 270, 270, 270, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 270, 540, 540, 17280, 270, 270, 270, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 270, 17280, 540, 540, 540, 17280, 540, 270, 540, 17280, 17280, 540, 17280, 540, 270, 17280, 540, 270, 540, 540, 270, 540, 17280, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 540, 270, 17280, 17280, 540, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 1157760 . Total input tokens: 258405761 . Total output tokens: 227405826
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.624428302049637,
    "estimated_duration": 3600.0875191934624,
    "input_throughput": 5121.63826620826,
    "output_throughput": 4468.139153351394,
    "total_throughput": 9589.777419559654,
    "itl": 98.61553770127114,
    "ttft": 1990506.584466074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7660879278555806,
    "arrivals": 386275,
    "finished_requests": 74488,
    "scheduler_time": 170.2126377105751
}
#Debug simulation 
Total elapsed time: 9.62454468710348. Arrivals time: 0.2971430770121515 Scheduler time: 9.17390757938847 Scheduler overhead time: 0.05416036723181605 Adapter cache time: 0.01856231177225709 Engine time: 0.05515191983431578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 540, 540, 17280, 540, 135, 17280, 135, 540, 540, 135, 17280, 17280, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 135, 540, 540, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 17280, 17280, 135, 540, 17280, 135, 540, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 540, 135, 135, 135, 135, 135, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 135, 540, 540, 17280, 135, 135, 135, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 135, 17280, 540, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 540, 135, 17280, 540, 135, 540, 540, 135, 540, 17280, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 1149120 . Total input tokens: 256471701 . Total output tokens: 225717122
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.34682990098372,
    "estimated_duration": 3600.0164775827266,
    "input_throughput": 5608.033220324633,
    "output_throughput": 4864.957177018237,
    "total_throughput": 10472.99039734287,
    "itl": 118.62510009354541,
    "ttft": 1919997.7124800307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6943029483547427,
    "arrivals": 383398,
    "finished_requests": 81157,
    "scheduler_time": 158.27743669763825
}
#Debug simulation 
Total elapsed time: 16.346986226271838. Arrivals time: 0.3113225419074297 Scheduler time: 15.899488845840096 Scheduler overhead time: 0.05112095316872001 Adapter cache time: 0.009487852919846773 Engine time: 0.05264792125672102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 540, 540, 17280, 540, 135, 17280, 135, 540, 540, 135, 17280, 17280, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 135, 540, 540, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 17280, 17280, 135, 540, 17280, 135, 540, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 540, 135, 135, 135, 135, 135, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 135, 540, 540, 17280, 135, 135, 135, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 135, 17280, 540, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 540, 135, 17280, 540, 135, 540, 540, 135, 540, 17280, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 1149120 . Total input tokens: 256471701 . Total output tokens: 225717122
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.88304565520957,
    "estimated_duration": 3600.0371270403384,
    "input_throughput": 5359.310840180625,
    "output_throughput": 4664.064399192475,
    "total_throughput": 10023.375239373101,
    "itl": 107.70881720976186,
    "ttft": 1937896.7440681192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4715032178815486,
    "arrivals": 383398,
    "finished_requests": 77697,
    "scheduler_time": 164.61471383613275
}
#Debug simulation 
Total elapsed time: 18.883189330343157. Arrivals time: 0.5600560535676777 Scheduler time: 18.175453207455575 Scheduler overhead time: 0.054978420957922935 Adapter cache time: 0.012892739847302437 Engine time: 0.0554183698259294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 540, 540, 17280, 540, 135, 17280, 135, 540, 540, 135, 17280, 17280, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 135, 540, 540, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 17280, 17280, 135, 540, 17280, 135, 540, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 540, 135, 135, 135, 135, 135, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 135, 540, 540, 17280, 135, 135, 135, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 135, 17280, 540, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 540, 135, 17280, 540, 135, 540, 540, 135, 540, 17280, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 1149120 . Total input tokens: 256471701 . Total output tokens: 225717122
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.949416578747332,
    "estimated_duration": 3600.004923002969,
    "input_throughput": 5145.133519581224,
    "output_throughput": 4471.191385642092,
    "total_throughput": 9616.324905223317,
    "itl": 98.60150904777386,
    "ttft": 1989559.692581248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.416792064229984,
    "arrivals": 383398,
    "finished_requests": 74608,
    "scheduler_time": 170.239565860329
}
#Debug simulation 
Total elapsed time: 8.949501053895801. Arrivals time: 0.5184307992458344 Scheduler time: 8.278946244623512 Scheduler overhead time: 0.0531534506008029 Adapter cache time: 0.019057661294937134 Engine time: 0.054575868882238865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 540, 540, 17280, 540, 135, 17280, 135, 540, 540, 135, 17280, 17280, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 135, 540, 540, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 17280, 17280, 135, 540, 17280, 135, 540, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 540, 135, 135, 135, 135, 135, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 135, 540, 540, 17280, 135, 135, 135, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 135, 17280, 540, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 540, 135, 17280, 540, 135, 540, 540, 135, 540, 17280, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 1149120 . Total input tokens: 256471701 . Total output tokens: 225717122
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 11.43044484918937,
    "estimated_duration": 3600.094099585784,
    "input_throughput": 5446.252363863468,
    "output_throughput": 4732.662127348378,
    "total_throughput": 10178.914491211846,
    "itl": 110.85143842124202,
    "ttft": 1948031.4874577122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7418092446727638,
    "arrivals": 383398,
    "finished_requests": 78848,
    "scheduler_time": 162.46834149492543
}
#Debug simulation 
Total elapsed time: 11.430536327883601. Arrivals time: 0.5482277637347579 Scheduler time: 10.744815733283758 Scheduler overhead time: 0.05033148406073451 Adapter cache time: 0.012864037416875362 Engine time: 0.0509804030880332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 540, 540, 17280, 540, 135, 17280, 135, 540, 540, 135, 17280, 17280, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 135, 540, 540, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 17280, 17280, 135, 540, 17280, 135, 540, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 540, 135, 135, 135, 135, 135, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 135, 540, 540, 17280, 135, 135, 135, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 135, 17280, 540, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 540, 135, 17280, 540, 135, 540, 540, 135, 540, 17280, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 1149120 . Total input tokens: 256471701 . Total output tokens: 225717122
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.313720864243805,
    "estimated_duration": 3600.030935319289,
    "input_throughput": 5148.1260391881215,
    "output_throughput": 4471.872961439478,
    "total_throughput": 9619.9990006276,
    "itl": 98.59290623016696,
    "ttft": 1989312.2050470463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.491828329684243,
    "arrivals": 383398,
    "finished_requests": 74630,
    "scheduler_time": 170.26155466171704
}
#Debug simulation 
Total elapsed time: 9.313810862135142. Arrivals time: 0.5238719782792032 Scheduler time: 8.63888479443267 Scheduler overhead time: 0.05331360176205635 Adapter cache time: 0.017864081542938948 Engine time: 0.054507252760231495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 540, 540, 17280, 540, 135, 17280, 135, 540, 540, 135, 17280, 17280, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 135, 540, 540, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 17280, 17280, 135, 540, 17280, 135, 540, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 540, 135, 135, 135, 135, 135, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 135, 540, 540, 17280, 135, 135, 135, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 135, 17280, 540, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 540, 135, 17280, 540, 135, 540, 540, 135, 540, 17280, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 1149120 . Total input tokens: 256471701 . Total output tokens: 225717122
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 11.393413117155433,
    "estimated_duration": 3600.0340069631898,
    "input_throughput": 5443.121915542606,
    "output_throughput": 4727.263122260281,
    "total_throughput": 10170.385037802887,
    "itl": 110.70235623117232,
    "ttft": 1947774.7685263327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.432273878357363,
    "arrivals": 383398,
    "finished_requests": 78797,
    "scheduler_time": 162.51757629461548
}
#Debug simulation 
Total elapsed time: 11.3935069530271. Arrivals time: 0.5358251803554595 Scheduler time: 10.72026049438864 Scheduler overhead time: 0.050471458584070206 Adapter cache time: 0.012813698034733534 Engine time: 0.05079105356708169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 540, 540, 17280, 540, 135, 17280, 135, 540, 540, 135, 17280, 17280, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 135, 540, 540, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 17280, 17280, 135, 540, 17280, 135, 540, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 540, 135, 135, 135, 135, 135, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 135, 540, 540, 17280, 135, 135, 135, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 135, 17280, 540, 540, 540, 17280, 540, 135, 540, 17280, 17280, 540, 17280, 540, 135, 17280, 540, 135, 540, 540, 135, 540, 17280, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 540, 135, 17280, 17280, 540, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 1149120 . Total input tokens: 256471701 . Total output tokens: 225717122
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.266201659105718,
    "estimated_duration": 3600.007838565099,
    "input_throughput": 5141.818804310716,
    "output_throughput": 4468.382770636324,
    "total_throughput": 9610.20157494704,
    "itl": 98.48329894470845,
    "ttft": 1989498.164717343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3633291213773475,
    "arrivals": 383398,
    "finished_requests": 74565,
    "scheduler_time": 170.32165882635408
}
#Debug simulation 
Total elapsed time: 9.266295768786222. Arrivals time: 0.5167615138925612 Scheduler time: 8.597333097830415 Scheduler overhead time: 0.05357162468135357 Adapter cache time: 0.018392222002148628 Engine time: 0.05468009877949953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 540, 540, 17280, 540, 66, 17280, 66, 540, 540, 66, 17280, 17280, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 66, 540, 540, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 17280, 17280, 66, 540, 17280, 66, 540, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 540, 66, 66, 66, 66, 66, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 66, 540, 540, 17280, 66, 66, 66, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 66, 17280, 540, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 540, 66, 17280, 540, 66, 540, 540, 66, 540, 17280, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 1144704 . Total input tokens: 255476844 . Total output tokens: 224859504
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.64080697717145,
    "estimated_duration": 3600.0012379346354,
    "input_throughput": 5588.983911445344,
    "output_throughput": 4869.882214278927,
    "total_throughput": 10458.866125724271,
    "itl": 118.76495719304808,
    "ttft": 1926883.9701502374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2151570257032334,
    "arrivals": 381994,
    "finished_requests": 81266,
    "scheduler_time": 158.03681326091873
}
#Debug simulation 
Total elapsed time: 12.640946125146002. Arrivals time: 0.2636349257081747 Scheduler time: 12.24518670560792 Scheduler overhead time: 0.048758682794868946 Adapter cache time: 0.01167288888245821 Engine time: 0.049494149163365364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 540, 540, 17280, 540, 66, 17280, 66, 540, 540, 66, 17280, 17280, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 66, 540, 540, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 17280, 17280, 66, 540, 17280, 66, 540, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 540, 66, 66, 66, 66, 66, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 66, 540, 540, 17280, 66, 66, 66, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 66, 17280, 540, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 540, 66, 17280, 540, 66, 540, 540, 66, 540, 17280, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 1144704 . Total input tokens: 255476844 . Total output tokens: 224859504
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.738671825267375,
    "estimated_duration": 3600.0489651874877,
    "input_throughput": 5436.948549665251,
    "output_throughput": 4735.132817592725,
    "total_throughput": 10172.081367257975,
    "itl": 110.9462556618505,
    "ttft": 1946016.5606072212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4412456872733332,
    "arrivals": 381994,
    "finished_requests": 79034,
    "scheduler_time": 162.2239840003065
}
#Debug simulation 
Total elapsed time: 11.738843002356589. Arrivals time: 0.27013725182041526 Scheduler time: 11.332265560980886 Scheduler overhead time: 0.049908979795873165 Adapter cache time: 0.01196657121181488 Engine time: 0.051184795796871185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 540, 540, 17280, 540, 66, 17280, 66, 540, 540, 66, 17280, 17280, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 66, 540, 540, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 17280, 17280, 66, 540, 17280, 66, 540, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 540, 66, 66, 66, 66, 66, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 66, 540, 540, 17280, 66, 66, 66, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 66, 17280, 540, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 540, 66, 17280, 540, 66, 540, 540, 66, 540, 17280, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 1144704 . Total input tokens: 255476844 . Total output tokens: 224859504
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.781804135069251,
    "estimated_duration": 3600.064482916356,
    "input_throughput": 5126.392343130925,
    "output_throughput": 4472.725718222674,
    "total_throughput": 9599.1180613536,
    "itl": 98.58603892823004,
    "ttft": 1985135.445472629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.672076410329931,
    "arrivals": 381994,
    "finished_requests": 74530,
    "scheduler_time": 170.14014184107486
}
#Debug simulation 
Total elapsed time: 8.78189771110192. Arrivals time: 0.25046600867062807 Scheduler time: 8.382627239916474 Scheduler overhead time: 0.05283168097957969 Adapter cache time: 0.016450212337076664 Engine time: 0.0541559224948287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 540, 540, 17280, 540, 66, 17280, 66, 540, 540, 66, 17280, 17280, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 66, 540, 540, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 17280, 17280, 66, 540, 17280, 66, 540, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 540, 66, 66, 66, 66, 66, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 66, 540, 540, 17280, 66, 66, 66, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 66, 17280, 540, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 540, 66, 17280, 540, 66, 540, 540, 66, 540, 17280, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 1144704 . Total input tokens: 255476844 . Total output tokens: 224859504
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 11.529409727081656,
    "estimated_duration": 3600.047308309738,
    "input_throughput": 5434.698303780364,
    "output_throughput": 4734.735557684364,
    "total_throughput": 10169.433861464728,
    "itl": 110.95621827316606,
    "ttft": 1946185.012009114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.316296321991828,
    "arrivals": 381994,
    "finished_requests": 79036,
    "scheduler_time": 162.21483899648845
}
#Debug simulation 
Total elapsed time: 11.529537685215473. Arrivals time: 0.27219792967662215 Scheduler time: 11.118229675572366 Scheduler overhead time: 0.05060927150771022 Adapter cache time: 0.012216340750455856 Engine time: 0.05277117434889078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 540, 540, 17280, 540, 66, 17280, 66, 540, 540, 66, 17280, 17280, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 66, 540, 540, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 17280, 17280, 66, 540, 17280, 66, 540, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 540, 66, 66, 66, 66, 66, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 66, 540, 540, 17280, 66, 66, 66, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 66, 17280, 540, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 540, 66, 17280, 540, 66, 540, 540, 66, 540, 17280, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 1144704 . Total input tokens: 255476844 . Total output tokens: 224859504
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.533280408009887,
    "estimated_duration": 3600.0675854608994,
    "input_throughput": 5123.9951923398,
    "output_throughput": 4472.799917710014,
    "total_throughput": 9596.795110049814,
    "itl": 98.6028410873744,
    "ttft": 1985688.7829233818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.540366347660345,
    "arrivals": 381994,
    "finished_requests": 74528,
    "scheduler_time": 170.1170007133382
}
#Debug simulation 
Total elapsed time: 8.5333855538629. Arrivals time: 0.2484411639161408 Scheduler time: 8.134120723232627 Scheduler overhead time: 0.05335700744763017 Adapter cache time: 0.016780694480985403 Engine time: 0.055186324287205935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 540, 540, 17280, 540, 66, 17280, 66, 540, 540, 66, 17280, 17280, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 66, 540, 540, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 17280, 17280, 66, 540, 17280, 66, 540, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 540, 66, 66, 66, 66, 66, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 66, 540, 540, 17280, 66, 66, 66, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 66, 17280, 540, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 540, 66, 17280, 540, 66, 540, 540, 66, 540, 17280, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 1144704 . Total input tokens: 255476844 . Total output tokens: 224859504
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 11.84806109033525,
    "estimated_duration": 3600.0517861254293,
    "input_throughput": 5395.125168714252,
    "output_throughput": 4705.223148534405,
    "total_throughput": 10100.348317248656,
    "itl": 109.38301378911149,
    "ttft": 1943774.5299288945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3620507480110877,
    "arrivals": 381994,
    "finished_requests": 78482,
    "scheduler_time": 163.23920860938122
}
#Debug simulation 
Total elapsed time: 11.848135932348669. Arrivals time: 0.27314535761252046 Scheduler time: 11.435543917585164 Scheduler overhead time: 0.050997113808989525 Adapter cache time: 0.012312591541558504 Engine time: 0.052418668288737535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 540, 540, 17280, 540, 66, 17280, 66, 540, 540, 66, 17280, 17280, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 66, 540, 540, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 17280, 17280, 66, 540, 17280, 66, 540, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 540, 66, 66, 66, 66, 66, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 66, 540, 540, 17280, 66, 66, 66, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 66, 17280, 540, 540, 540, 17280, 540, 66, 540, 17280, 17280, 540, 17280, 540, 66, 17280, 540, 66, 540, 540, 66, 540, 17280, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 540, 66, 17280, 17280, 540, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 1144704 . Total input tokens: 255476844 . Total output tokens: 224859504
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.871851613279432,
    "estimated_duration": 3600.0944746085174,
    "input_throughput": 5125.755762841931,
    "output_throughput": 4473.750928925662,
    "total_throughput": 9599.506691767592,
    "itl": 98.5826217832651,
    "ttft": 1986102.5291749253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.022361976914143,
    "arrivals": 381994,
    "finished_requests": 74552,
    "scheduler_time": 170.13663783518683
}
#Debug simulation 
Total elapsed time: 8.871942430268973. Arrivals time: 0.23289330396801233 Scheduler time: 8.490789093542844 Scheduler overhead time: 0.05318252043798566 Adapter cache time: 0.0158226964995265 Engine time: 0.053991947788745165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 15.306426582857966,
    "estimated_duration": 3600.122742943878,
    "input_throughput": 5601.0451420084655,
    "output_throughput": 4866.976559158151,
    "total_throughput": 10468.021701166615,
    "itl": 118.40252715571324,
    "ttft": 1926082.6828166004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.038148218016139,
    "arrivals": 381208,
    "finished_requests": 81155,
    "scheduler_time": 158.14332236141442
}
#Debug simulation 
Total elapsed time: 15.306522753089666. Arrivals time: 0.3053263667970896 Scheduler time: 14.866697764024138 Scheduler overhead time: 0.0497582065872848 Adapter cache time: 0.010083049535751343 Engine time: 0.052040989976376295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.12525097373873,
    "estimated_duration": 3600.0477581324403,
    "input_throughput": 5433.191533588657,
    "output_throughput": 4730.251136677705,
    "total_throughput": 10163.442670266362,
    "itl": 110.72583981485029,
    "ttft": 1950570.5488021038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4723342549288674,
    "arrivals": 381208,
    "finished_requests": 78849,
    "scheduler_time": 162.2275929080887
}
#Debug simulation 
Total elapsed time: 10.12536805588752. Arrivals time: 0.27418538369238377 Scheduler time: 9.715058641973883 Scheduler overhead time: 0.04978981800377369 Adapter cache time: 0.011992528103291988 Engine time: 0.05098030949011445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.214286616072059,
    "estimated_duration": 3600.0685753351877,
    "input_throughput": 5121.366333496406,
    "output_throughput": 4462.311109866647,
    "total_throughput": 9583.677443363053,
    "itl": 98.103221698246,
    "ttft": 1993142.3701998133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.282879110001988,
    "arrivals": 381208,
    "finished_requests": 74372,
    "scheduler_time": 170.3752612009777
}
#Debug simulation 
Total elapsed time: 8.214444865006953. Arrivals time: 0.26032868260517716 Scheduler time: 7.80418793624267 Scheduler overhead time: 0.053507665172219276 Adapter cache time: 0.01602355297654867 Engine time: 0.054780175909399986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 10.3233427638188,
    "estimated_duration": 3600.0786977148096,
    "input_throughput": 5434.883135310276,
    "output_throughput": 4732.547377593377,
    "total_throughput": 10167.430512903653,
    "itl": 110.81129095077016,
    "ttft": 1950556.1483559047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5802658162591947,
    "arrivals": 381208,
    "finished_requests": 78881,
    "scheduler_time": 162.18167025413698
}
#Debug simulation 
Total elapsed time: 10.323466731701046. Arrivals time: 0.26558598643168807 Scheduler time: 9.921882260590792 Scheduler overhead time: 0.04945130134001374 Adapter cache time: 0.012464825063943863 Engine time: 0.050779659766703844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.938122650142759,
    "estimated_duration": 3600.1056219164475,
    "input_throughput": 5128.412035359026,
    "output_throughput": 4470.0241298569,
    "total_throughput": 9598.436165215926,
    "itl": 98.44651668485629,
    "ttft": 1991946.8015612476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3880139742186595,
    "arrivals": 381208,
    "finished_requests": 74470,
    "scheduler_time": 170.11144088316163
}
#Debug simulation 
Total elapsed time: 7.938252078834921. Arrivals time: 0.24372181482613087 Scheduler time: 7.545955301262438 Scheduler overhead time: 0.05315588507801294 Adapter cache time: 0.015687896870076656 Engine time: 0.05438574170693755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.997897677589208,
    "estimated_duration": 3600.0682787357405,
    "input_throughput": 5434.228043827623,
    "output_throughput": 4730.756108320507,
    "total_throughput": 10164.98415214813,
    "itl": 110.74136764518197,
    "ttft": 1950359.7869771495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1386135150911203,
    "arrivals": 381208,
    "finished_requests": 78851,
    "scheduler_time": 162.22869235331194
}
#Debug simulation 
Total elapsed time: 9.998011959716678. Arrivals time: 0.2591821411624551 Scheduler time: 9.603376674465835 Scheduler overhead time: 0.04945001192390919 Adapter cache time: 0.012262643780559301 Engine time: 0.05043327575549483 
