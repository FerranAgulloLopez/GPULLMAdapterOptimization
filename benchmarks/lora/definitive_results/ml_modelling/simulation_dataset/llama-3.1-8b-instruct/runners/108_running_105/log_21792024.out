INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.523545284057036,
    "estimated_duration": 3600.0848674928966,
    "input_throughput": 5999.102741997405,
    "output_throughput": 5245.29940127509,
    "total_throughput": 11244.402143272495,
    "itl": 104.53134943799843,
    "ttft": 1719867.7981719377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9506606644252291,
    "arrivals": 251722,
    "finished_requests": 87596,
    "scheduler_time": 89.85871920973084
}
#Debug simulation 
Total elapsed time: 6.523696446092799. Arrivals time: 0.26188081642612815 Scheduler time: 6.11148769967258 Scheduler overhead time: 0.050271623535081744 Adapter cache time: 0.0233803978189826 Engine time: 0.052492470713332295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.329566756961867,
    "estimated_duration": 3600.0279064125903,
    "input_throughput": 5811.766892898669,
    "output_throughput": 5081.401721196397,
    "total_throughput": 10893.168614095066,
    "itl": 94.42854538940821,
    "ttft": 1749451.4293994058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0923398158792432,
    "arrivals": 251722,
    "finished_requests": 84797,
    "scheduler_time": 88.86396410454871
}
#Debug simulation 
Total elapsed time: 6.329674142878503. Arrivals time: 0.2596493356395513 Scheduler time: 5.908641096204519 Scheduler overhead time: 0.054501841543242335 Adapter cache time: 0.02401675726287067 Engine time: 0.05667801247909665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.864369403105229,
    "estimated_duration": 3600.0674470021527,
    "input_throughput": 5242.68066580718,
    "output_throughput": 4602.587380355291,
    "total_throughput": 9845.268046162471,
    "itl": 74.73350774506979,
    "ttft": 1839283.0509633075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9753411409445154,
    "arrivals": 251722,
    "finished_requests": 76711,
    "scheduler_time": 85.7223835066017
}
#Debug simulation 
Total elapsed time: 5.86454939795658. Arrivals time: 0.25718167796730995 Scheduler time: 5.4143727594055235 Scheduler overhead time: 0.06629330292344093 Adapter cache time: 0.026265617227181792 Engine time: 0.06862563593313098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.328475187998265,
    "estimated_duration": 3600.087967535194,
    "input_throughput": 5805.219258102946,
    "output_throughput": 5077.217047147422,
    "total_throughput": 10882.436305250367,
    "itl": 94.1809218650018,
    "ttft": 1749813.1102159629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9415809137141304,
    "arrivals": 251722,
    "finished_requests": 84715,
    "scheduler_time": 88.84490198591936
}
#Debug simulation 
Total elapsed time: 6.32859528507106. Arrivals time: 0.28275344730354846 Scheduler time: 5.884759555337951 Scheduler overhead time: 0.05444087111391127 Adapter cache time: 0.02387487585656345 Engine time: 0.056465922854840755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.7741910349577665,
    "estimated_duration": 3600.047403299758,
    "input_throughput": 5242.260138769787,
    "output_throughput": 4602.291621164086,
    "total_throughput": 9844.551759933873,
    "itl": 74.73141958017645,
    "ttft": 1839334.6739279812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9556650091661187,
    "arrivals": 251722,
    "finished_requests": 76707,
    "scheduler_time": 85.7236370301538
}
#Debug simulation 
Total elapsed time: 5.774292109999806. Arrivals time: 0.25424866075627506 Scheduler time: 5.330002353293821 Scheduler overhead time: 0.06513968715444207 Adapter cache time: 0.025560391368344426 Engine time: 0.0679219663143158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.330061853164807,
    "estimated_duration": 3600.057308465178,
    "input_throughput": 5816.859623528561,
    "output_throughput": 5086.514583237814,
    "total_throughput": 10903.374206766375,
    "itl": 94.6927993129832,
    "ttft": 1748260.929759552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8194174680625954,
    "arrivals": 251722,
    "finished_requests": 84891,
    "scheduler_time": 88.89557549023546
}
#Debug simulation 
Total elapsed time: 6.330183630110696. Arrivals time: 0.25736744585447013 Scheduler time: 5.911437424831092 Scheduler overhead time: 0.05418247217312455 Adapter cache time: 0.024153070291504264 Engine time: 0.05703479005023837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.81963358190842,
    "estimated_duration": 3600.0139253163825,
    "input_throughput": 5242.309166440634,
    "output_throughput": 4602.395530607255,
    "total_throughput": 9844.70469704789,
    "itl": 74.73310758629174,
    "ttft": 1839291.4740836376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.938888517860328,
    "arrivals": 251722,
    "finished_requests": 76708,
    "scheduler_time": 85.72272243030558
}
#Debug simulation 
Total elapsed time: 5.819759990787134. Arrivals time: 0.2642303181346506 Scheduler time: 5.364355682395399 Scheduler overhead time: 0.06559135462157428 Adapter cache time: 0.025911914184689522 Engine time: 0.06813832768239081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.637520862976089,
    "estimated_duration": 3600.019581254756,
    "input_throughput": 6110.168432009815,
    "output_throughput": 5345.935922185222,
    "total_throughput": 11456.104354195037,
    "itl": 102.66443738068841,
    "ttft": 1694688.8149751162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7904366114828965,
    "arrivals": 250208,
    "finished_requests": 89258,
    "scheduler_time": 91.51235524860002
}
#Debug simulation 
Total elapsed time: 6.637643691152334. Arrivals time: 0.2698057000525296 Scheduler time: 6.219334345078096 Scheduler overhead time: 0.051022127037867904 Adapter cache time: 0.020121317356824875 Engine time: 0.05280236108228564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.469123756047338,
    "estimated_duration": 3600.009862930633,
    "input_throughput": 5910.286307571147,
    "output_throughput": 5176.390818226786,
    "total_throughput": 11086.677125797933,
    "itl": 93.15788743688887,
    "ttft": 1724969.4641585918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0105479742027854,
    "arrivals": 250208,
    "finished_requests": 86324,
    "scheduler_time": 90.3902473529067
}
#Debug simulation 
Total elapsed time: 6.469231783179566. Arrivals time: 0.3004347546957433 Scheduler time: 6.008937721373513 Scheduler overhead time: 0.055039493599906564 Adapter cache time: 0.021039224229753017 Engine time: 0.05737526365555823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.867120927898213,
    "estimated_duration": 3600.0008552012905,
    "input_throughput": 5317.87318115222,
    "output_throughput": 4660.085837413494,
    "total_throughput": 9977.959018565714,
    "itl": 73.97275401884089,
    "ttft": 1817596.6188469103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.867573658027703,
    "arrivals": 250208,
    "finished_requests": 77672,
    "scheduler_time": 86.70424150208045
}
#Debug simulation 
Total elapsed time: 5.867233221884817. Arrivals time: 0.2536009675823152 Scheduler time: 5.424976524664089 Scheduler overhead time: 0.0658991583622992 Adapter cache time: 0.022264655446633697 Engine time: 0.06871205731295049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.472504568984732,
    "estimated_duration": 3600.0135110005367,
    "input_throughput": 5911.030315573954,
    "output_throughput": 5176.703071545006,
    "total_throughput": 11087.73338711896,
    "itl": 93.15215672541407,
    "ttft": 1724905.682927825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.798707349211904,
    "arrivals": 250208,
    "finished_requests": 86333,
    "scheduler_time": 90.39564676623209
}
#Debug simulation 
Total elapsed time: 6.472612563055009. Arrivals time: 0.2647198380436748 Scheduler time: 6.047499270644039 Scheduler overhead time: 0.055356527445837855 Adapter cache time: 0.020936287939548492 Engine time: 0.05737088993191719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.866838657995686,
    "estimated_duration": 3600.0355409455524,
    "input_throughput": 5317.9541652446005,
    "output_throughput": 4660.342046399187,
    "total_throughput": 9978.296211643788,
    "itl": 73.97278056552362,
    "ttft": 1817688.5912023839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8402341907145625,
    "arrivals": 250208,
    "finished_requests": 77675,
    "scheduler_time": 86.70539329649809
}
#Debug simulation 
Total elapsed time: 5.8669311630073935. Arrivals time: 0.24954632273875177 Scheduler time: 5.42768322955817 Scheduler overhead time: 0.06629256252199411 Adapter cache time: 0.022492100251838565 Engine time: 0.06902382802218199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.406636422965676,
    "estimated_duration": 3600.0302107004823,
    "input_throughput": 5911.500669284411,
    "output_throughput": 5177.093776769595,
    "total_throughput": 11088.594446054005,
    "itl": 93.14663596107481,
    "ttft": 1724825.409912408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.623791506574478,
    "arrivals": 250208,
    "finished_requests": 86341,
    "scheduler_time": 90.39895306158775
}
#Debug simulation 
Total elapsed time: 6.406725947977975. Arrivals time: 0.26358386455103755 Scheduler time: 5.983884013723582 Scheduler overhead time: 0.05506403697654605 Adapter cache time: 0.020816114265471697 Engine time: 0.05695162946358323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.879912770120427,
    "estimated_duration": 3600.069437652992,
    "input_throughput": 5317.904093672472,
    "output_throughput": 4660.298166620297,
    "total_throughput": 9978.202260292768,
    "itl": 73.97405550534218,
    "ttft": 1817689.2240815582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8155872466974126,
    "arrivals": 250208,
    "finished_requests": 77675,
    "scheduler_time": 86.70617346982006
}
#Debug simulation 
Total elapsed time: 5.8800040651112795. Arrivals time: 0.24952587648294866 Scheduler time: 5.44064240064472 Scheduler overhead time: 0.06635481282137334 Adapter cache time: 0.022615098394453526 Engine time: 0.06900189816951752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.676639429992065,
    "estimated_duration": 3600.0348155803354,
    "input_throughput": 6187.927656585434,
    "output_throughput": 5379.201033331746,
    "total_throughput": 11567.12868991718,
    "itl": 102.01382899249487,
    "ttft": 1686806.2347945306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8184124837862305,
    "arrivals": 249718,
    "finished_requests": 89972,
    "scheduler_time": 92.09290055302084
}
#Debug simulation 
Total elapsed time: 6.676730648847297. Arrivals time: 0.28459498449228704 Scheduler time: 6.243354093749076 Scheduler overhead time: 0.05189093598164618 Adapter cache time: 0.018685847520828247 Engine time: 0.05352717498317361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.472326301969588,
    "estimated_duration": 3600.007417282036,
    "input_throughput": 5985.890722488965,
    "output_throughput": 5205.575663549207,
    "total_throughput": 11191.466386038172,
    "itl": 92.64114931704215,
    "ttft": 1718694.5585055233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.944395266394133,
    "arrivals": 249718,
    "finished_requests": 87028,
    "scheduler_time": 90.87893973984194
}
#Debug simulation 
Total elapsed time: 6.472420185804367. Arrivals time: 0.2716891902964562 Scheduler time: 6.041657676687464 Scheduler overhead time: 0.055361736100167036 Adapter cache time: 0.01923333201557398 Engine time: 0.057689527748152614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.90089924284257,
    "estimated_duration": 3600.0509686851065,
    "input_throughput": 5374.043358910081,
    "output_throughput": 4683.787853747715,
    "total_throughput": 10057.831212657797,
    "itl": 73.6561122905004,
    "ttft": 1814127.5996942006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8534271511435545,
    "arrivals": 249718,
    "finished_requests": 78153,
    "scheduler_time": 87.13927852834082
}
#Debug simulation 
Total elapsed time: 5.900991159956902. Arrivals time: 0.24945802753791213 Scheduler time: 5.462388946209103 Scheduler overhead time: 0.06655140896327794 Adapter cache time: 0.02095632185228169 Engine time: 0.06950071663595736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.507732005091384,
    "estimated_duration": 3600.068595816777,
    "input_throughput": 5985.934830530869,
    "output_throughput": 5205.71941928459,
    "total_throughput": 11191.654249815458,
    "itl": 92.63578098701304,
    "ttft": 1718692.972439634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8097378319827808,
    "arrivals": 249718,
    "finished_requests": 87032,
    "scheduler_time": 90.88268384063024
}
#Debug simulation 
Total elapsed time: 6.5078244949691. Arrivals time: 0.26655215374194086 Scheduler time: 6.0811597048304975 Scheduler overhead time: 0.055576748913154006 Adapter cache time: 0.019556396873667836 Engine time: 0.05814991588704288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.911616470199078,
    "estimated_duration": 3600.0036363590434,
    "input_throughput": 5374.204849294888,
    "output_throughput": 4683.901379903572,
    "total_throughput": 10058.10622919846,
    "itl": 73.65548799593121,
    "ttft": 1814090.2790925845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8347866052482313,
    "arrivals": 249718,
    "finished_requests": 78155,
    "scheduler_time": 87.13893426899614
}
#Debug simulation 
Total elapsed time: 5.911734341178089. Arrivals time: 0.24802221404388547 Scheduler time: 5.475450329482555 Scheduler overhead time: 0.06649192841723561 Adapter cache time: 0.020456013036891818 Engine time: 0.06934504210948944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.4496784748043865,
    "estimated_duration": 3600.103613612822,
    "input_throughput": 5986.139376242326,
    "output_throughput": 5205.826834853866,
    "total_throughput": 11191.96621109619,
    "itl": 92.6328940034192,
    "ttft": 1718735.8663276825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.698122970191756,
    "arrivals": 249718,
    "finished_requests": 87035,
    "scheduler_time": 90.88657593399009
}
#Debug simulation 
Total elapsed time: 6.449798269895837. Arrivals time: 0.26353689027018845 Scheduler time: 6.0270040752366185 Scheduler overhead time: 0.05544247291982174 Adapter cache time: 0.019186131190508604 Engine time: 0.05786456703208387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.872121628839523,
    "estimated_duration": 3600.0080379878214,
    "input_throughput": 5374.107723052103,
    "output_throughput": 4683.882597502424,
    "total_throughput": 10057.990320554527,
    "itl": 73.65537578894414,
    "ttft": 1814127.451657492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8186314654722844,
    "arrivals": 249718,
    "finished_requests": 78154,
    "scheduler_time": 87.13950768911302
}
#Debug simulation 
Total elapsed time: 5.872212946880609. Arrivals time: 0.24625086854211986 Scheduler time: 5.437641975702718 Scheduler overhead time: 0.06638672924600542 Adapter cache time: 0.02066275291144848 Engine time: 0.06930482992902398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.734135599108413,
    "estimated_duration": 3600.090872202349,
    "input_throughput": 6281.70199108488,
    "output_throughput": 5480.071114963543,
    "total_throughput": 11761.773106048422,
    "itl": 100.42499558193136,
    "ttft": 1665772.1976322057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.692776712179182,
    "arrivals": 248697,
    "finished_requests": 91590,
    "scheduler_time": 93.68340274027874
}
#Debug simulation 
Total elapsed time: 6.734255684074014. Arrivals time: 0.2721599305514246 Scheduler time: 6.316567670088261 Scheduler overhead time: 0.05169236264191568 Adapter cache time: 0.0150298778899014 Engine time: 0.05394549365155399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.522158200852573,
    "estimated_duration": 3600.1006049119123,
    "input_throughput": 6057.722100944901,
    "output_throughput": 5290.237715583507,
    "total_throughput": 11347.95981652841,
    "itl": 91.3984475816508,
    "ttft": 1698930.4221749576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8100495958374834,
    "arrivals": 248697,
    "finished_requests": 88327,
    "scheduler_time": 92.26364639035594
}
#Debug simulation 
Total elapsed time: 6.522281181998551. Arrivals time: 0.2652095465455204 Scheduler time: 6.100343897938728 Scheduler overhead time: 0.056113480823114514 Adapter cache time: 0.01564132864587009 Engine time: 0.05803234130144119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.95745434705168,
    "estimated_duration": 3600.02463358174,
    "input_throughput": 5419.901246783226,
    "output_throughput": 4736.084259244798,
    "total_throughput": 10155.985506028024,
    "itl": 72.85121102754496,
    "ttft": 1797750.4513268305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6970321028539948,
    "arrivals": 248697,
    "finished_requests": 79022,
    "scheduler_time": 88.0502202494388
}
#Debug simulation 
Total elapsed time: 5.957575804088265. Arrivals time: 0.2461900250054896 Scheduler time: 5.525075052632019 Scheduler overhead time: 0.06694762199185789 Adapter cache time: 0.017005006782710552 Engine time: 0.06995029258541763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.57616748707369,
    "estimated_duration": 3600.020467519288,
    "input_throughput": 6058.0408352589875,
    "output_throughput": 5290.478254731744,
    "total_throughput": 11348.519089990732,
    "itl": 91.39521693471478,
    "ttft": 1698856.6939905626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.685109708239322,
    "arrivals": 248697,
    "finished_requests": 88329,
    "scheduler_time": 92.26380496963937
}
#Debug simulation 
Total elapsed time: 6.576279134955257. Arrivals time: 0.27384198107756674 Scheduler time: 6.144927995279431 Scheduler overhead time: 0.05624440498650074 Adapter cache time: 0.015712885418906808 Engine time: 0.058508261339738965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 6.013500816188753,
    "estimated_duration": 3600.070667885447,
    "input_throughput": 5419.864719339132,
    "output_throughput": 4735.999254707553,
    "total_throughput": 10155.863974046684,
    "itl": 72.85179744977991,
    "ttft": 1797723.8349648924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6872442300571164,
    "arrivals": 248697,
    "finished_requests": 79022,
    "scheduler_time": 88.05158649103659
}
#Debug simulation 
Total elapsed time: 6.013606469146907. Arrivals time: 0.25886587682180107 Scheduler time: 5.565426854649559 Scheduler overhead time: 0.06757019204087555 Adapter cache time: 0.017215746454894543 Engine time: 0.07208025548607111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.611613781889901,
    "estimated_duration": 3600.0023240111027,
    "input_throughput": 6058.238866829336,
    "output_throughput": 5290.646029022191,
    "total_throughput": 11348.884895851528,
    "itl": 91.39417605424475,
    "ttft": 1698880.7184053157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5768284723209165,
    "arrivals": 248697,
    "finished_requests": 88332,
    "scheduler_time": 92.26618780646213
}
#Debug simulation 
Total elapsed time: 6.61172083299607. Arrivals time: 0.2743581004906446 Scheduler time: 6.177855146117508 Scheduler overhead time: 0.05620690528303385 Adapter cache time: 0.015733130043372512 Engine time: 0.06055770814418793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.979993660002947,
    "estimated_duration": 3600.042714853328,
    "input_throughput": 5419.866803106791,
    "output_throughput": 4736.132415777366,
    "total_throughput": 10155.999218884157,
    "itl": 72.8530056291386,
    "ttft": 1797641.299506569,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6657574091851748,
    "arrivals": 248697,
    "finished_requests": 79023,
    "scheduler_time": 88.05179555637422
}
#Debug simulation 
Total elapsed time: 5.980087571078911. Arrivals time: 0.25338766630738974 Scheduler time: 5.538761323783547 Scheduler overhead time: 0.06767467549070716 Adapter cache time: 0.017304130364209414 Engine time: 0.07042142772115767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.14419431402348,
    "estimated_duration": 3600.0898055103594,
    "input_throughput": 4701.289110647797,
    "output_throughput": 4124.091842729804,
    "total_throughput": 8825.380953377602,
    "itl": 133.06387208857083,
    "ttft": 1828199.6673333868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.514749132646358,
    "arrivals": 200319,
    "finished_requests": 68627,
    "scheduler_time": 70.38836100572237
}
#Debug simulation 
Total elapsed time: 6.144265227951109. Arrivals time: 0.23830511327832937 Scheduler time: 5.7826348973903805 Scheduler overhead time: 0.04176320577971637 Adapter cache time: 0.019880065228790045 Engine time: 0.04228542000055313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.560318731004372,
    "estimated_duration": 3600.092147234302,
    "input_throughput": 4522.052584822483,
    "output_throughput": 3970.626421599112,
    "total_throughput": 8492.679006421595,
    "itl": 121.59063393609773,
    "ttft": 1864128.960063691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.345485653849314,
    "arrivals": 200319,
    "finished_requests": 66042,
    "scheduler_time": 69.07961063423377
}
#Debug simulation 
Total elapsed time: 5.560414587147534. Arrivals time: 0.2260668172966689 Scheduler time: 5.198342027608305 Scheduler overhead time: 0.04476764262653887 Adapter cache time: 0.024863744154572487 Engine time: 0.04532230878248811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.76032432098873,
    "estimated_duration": 3600.007827019518,
    "input_throughput": 4001.153245248737,
    "output_throughput": 3522.1426200336023,
    "total_throughput": 7523.295865282339,
    "itl": 97.42117160405012,
    "ttft": 1970389.5865436948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.987743245619225,
    "arrivals": 200319,
    "finished_requests": 58448,
    "scheduler_time": 65.30434542078298
}
#Debug simulation 
Total elapsed time: 4.760414463933557. Arrivals time: 0.2049604165367782 Scheduler time: 4.3773712082766 Scheduler overhead time: 0.05276314611546695 Adapter cache time: 0.046408276073634624 Engine time: 0.053870498202741146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.483343619853258,
    "estimated_duration": 3600.045051281275,
    "input_throughput": 4521.096755221781,
    "output_throughput": 3969.1611622789037,
    "total_throughput": 8490.257917500683,
    "itl": 121.39128976440567,
    "ttft": 1864451.0299629287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.703579857936112,
    "arrivals": 200319,
    "finished_requests": 66025,
    "scheduler_time": 69.07060982541829
}
#Debug simulation 
Total elapsed time: 5.483432475943118. Arrivals time: 0.22609744756482542 Scheduler time: 5.122082030167803 Scheduler overhead time: 0.04450381966307759 Adapter cache time: 0.024886834202334285 Engine time: 0.04500169958919287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.758901988854632,
    "estimated_duration": 3600.0881911860497,
    "input_throughput": 4006.1524146297384,
    "output_throughput": 3527.03220745733,
    "total_throughput": 7533.184622087068,
    "itl": 97.62627893320312,
    "ttft": 1968904.0752813856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.72093977705094,
    "arrivals": 200319,
    "finished_requests": 58524,
    "scheduler_time": 65.34664041046192
}
#Debug simulation 
Total elapsed time: 4.7589954358991235. Arrivals time: 0.2232629640493542 Scheduler time: 4.358247966505587 Scheduler overhead time: 0.05262148077599704 Adapter cache time: 0.04612279054708779 Engine time: 0.05370435141958296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.472644145833328,
    "estimated_duration": 3600.110897431275,
    "input_throughput": 4523.432045279342,
    "output_throughput": 3971.2085008828317,
    "total_throughput": 8494.640546162174,
    "itl": 121.46739565432608,
    "ttft": 1864331.922316058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.226598504725807,
    "arrivals": 200319,
    "finished_requests": 66059,
    "scheduler_time": 69.0912400137889
}
#Debug simulation 
Total elapsed time: 5.472762239864096. Arrivals time: 0.22434424189850688 Scheduler time: 5.113603672012687 Scheduler overhead time: 0.044571310514584184 Adapter cache time: 0.024328659055754542 Engine time: 0.045003762235865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.7887919179629534,
    "estimated_duration": 3600.073720033359,
    "input_throughput": 4006.5562879268887,
    "output_throughput": 3527.3969333834443,
    "total_throughput": 7533.953221310333,
    "itl": 97.6196952755237,
    "ttft": 1968885.1984148887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.533611449263805,
    "arrivals": 200319,
    "finished_requests": 58528,
    "scheduler_time": 65.3494350899185
}
#Debug simulation 
Total elapsed time: 4.788889538031071. Arrivals time: 0.20497819152660668 Scheduler time: 4.405179110588506 Scheduler overhead time: 0.053004524670541286 Adapter cache time: 0.045973605243489146 Engine time: 0.0549130137078464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.461623435141519,
    "estimated_duration": 3600.143905925597,
    "input_throughput": 4715.268456924518,
    "output_throughput": 4120.062249619014,
    "total_throughput": 8835.330706543533,
    "itl": 132.7121597719477,
    "ttft": 1810452.1284742462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.579346986790332,
    "arrivals": 192932,
    "finished_requests": 68735,
    "scheduler_time": 70.24164820860106
}
#Debug simulation 
Total elapsed time: 5.461744748055935. Arrivals time: 0.2271004479844123 Scheduler time: 5.110108940163627 Scheduler overhead time: 0.041457562474533916 Adapter cache time: 0.021836674539372325 Engine time: 0.041831896873191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.216171981068328,
    "estimated_duration": 3600.13133467693,
    "input_throughput": 4534.116531463938,
    "output_throughput": 3965.796709269561,
    "total_throughput": 8499.9132407335,
    "itl": 121.3013070897841,
    "ttft": 1848261.3164024586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.63869255125518,
    "arrivals": 192932,
    "finished_requests": 66143,
    "scheduler_time": 68.92486500633333
}
#Debug simulation 
Total elapsed time: 5.21626484207809. Arrivals time: 0.22101760865189135 Scheduler time: 4.857029102277011 Scheduler overhead time: 0.04443208477459848 Adapter cache time: 0.027654794044792652 Engine time: 0.045238245045766234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.9063140789512545,
    "estimated_duration": 3600.0260579541514,
    "input_throughput": 4038.2918806598123,
    "output_throughput": 3533.1316482826383,
    "total_throughput": 7571.4235289424505,
    "itl": 97.0380742035462,
    "ttft": 1954466.1146631653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.797648125165114,
    "arrivals": 192932,
    "finished_requests": 58803,
    "scheduler_time": 65.39011058382941
}
#Debug simulation 
Total elapsed time: 4.906406156951562. Arrivals time: 0.2120141654741019 Scheduler time: 4.512422805419192 Scheduler overhead time: 0.052472398383542895 Adapter cache time: 0.05059479037299752 Engine time: 0.05389788304455578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.222968510817736,
    "estimated_duration": 3600.0196212891233,
    "input_throughput": 4535.304447633381,
    "output_throughput": 3966.5556030738026,
    "total_throughput": 8501.860050707182,
    "itl": 121.27036607080153,
    "ttft": 1848037.6377766184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.910150393387344,
    "arrivals": 192932,
    "finished_requests": 66156,
    "scheduler_time": 68.93500399602767
}
#Debug simulation 
Total elapsed time: 5.223057165974751. Arrivals time: 0.2205576973501593 Scheduler time: 4.865063769510016 Scheduler overhead time: 0.04457009886391461 Adapter cache time: 0.02713753329589963 Engine time: 0.044886221177875996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.6095543331466615,
    "estimated_duration": 3600.090655183827,
    "input_throughput": 4038.7360743440977,
    "output_throughput": 3533.507963662778,
    "total_throughput": 7572.244038006876,
    "itl": 97.0335308609083,
    "ttft": 1954395.6199692336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.620247594476623,
    "arrivals": 192932,
    "finished_requests": 58810,
    "scheduler_time": 65.39360961442866
}
#Debug simulation 
Total elapsed time: 4.609645296121016. Arrivals time: 0.20269217272289097 Scheduler time: 4.22557689063251 Scheduler overhead time: 0.052072435384616256 Adapter cache time: 0.05101428576745093 Engine time: 0.05352359660901129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.251089663011953,
    "estimated_duration": 3600.1339264061367,
    "input_throughput": 4536.329851568314,
    "output_throughput": 3967.0657514280565,
    "total_throughput": 8503.39560299637,
    "itl": 121.25215343564268,
    "ttft": 1847909.1773139662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.331016827444548,
    "arrivals": 192932,
    "finished_requests": 66168,
    "scheduler_time": 68.9477257967604
}
#Debug simulation 
Total elapsed time: 5.251186923123896. Arrivals time: 0.22071256139315665 Scheduler time: 4.892133127199486 Scheduler overhead time: 0.044725473737344146 Adapter cache time: 0.027408390305936337 Engine time: 0.045234656194224954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.660933654056862,
    "estimated_duration": 3600.055906311193,
    "input_throughput": 4038.64950389001,
    "output_throughput": 3533.4573492871787,
    "total_throughput": 7572.106853177188,
    "itl": 97.0341647154481,
    "ttft": 1954439.016966143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.481011486295543,
    "arrivals": 192932,
    "finished_requests": 58807,
    "scheduler_time": 65.39656026421606
}
#Debug simulation 
Total elapsed time: 4.6610263211186975. Arrivals time: 0.22086694836616516 Scheduler time: 4.258248787140474 Scheduler overhead time: 0.05241973418742418 Adapter cache time: 0.050626682583242655 Engine time: 0.05383561551570892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.201028537005186,
    "estimated_duration": 3600.066513621851,
    "input_throughput": 4681.874053222131,
    "output_throughput": 4126.87514071874,
    "total_throughput": 8808.74919394087,
    "itl": 132.81978484768555,
    "ttft": 1804521.2411861636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.967952883499864,
    "arrivals": 188974,
    "finished_requests": 68705,
    "scheduler_time": 70.3077392119473
}
#Debug simulation 
Total elapsed time: 5.201119853183627. Arrivals time: 0.22428783006034791 Scheduler time: 4.849361388478428 Scheduler overhead time: 0.040865836665034294 Adapter cache time: 0.025371299358084798 Engine time: 0.042099168291315436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.068258957006037,
    "estimated_duration": 3600.008370152662,
    "input_throughput": 4524.643646678316,
    "output_throughput": 3989.6887793599567,
    "total_throughput": 8514.332426038272,
    "itl": 120.51788340853918,
    "ttft": 1838764.9874417458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.505461248550514,
    "arrivals": 188974,
    "finished_requests": 66408,
    "scheduler_time": 69.30662016291284
}
#Debug simulation 
Total elapsed time: 5.068356481846422. Arrivals time: 0.2169397419784218 Scheduler time: 4.711878193309531 Scheduler overhead time: 0.04382731835357845 Adapter cache time: 0.029753701062873006 Engine time: 0.04506632871925831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.706230897922069,
    "estimated_duration": 3600.004729686761,
    "input_throughput": 4113.064040693183,
    "output_throughput": 3626.711346330933,
    "total_throughput": 7739.775387024116,
    "itl": 95.0692704104383,
    "ttft": 1930636.119440822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.021139108249839,
    "arrivals": 188974,
    "finished_requests": 60297,
    "scheduler_time": 66.97858774781548
}
#Debug simulation 
Total elapsed time: 4.706350104883313. Arrivals time: 0.2090544372331351 Scheduler time: 4.320149155333638 Scheduler overhead time: 0.052537613082677126 Adapter cache time: 0.04472094704397023 Engine time: 0.05461214855313301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.071924673160538,
    "estimated_duration": 3600.1101555017945,
    "input_throughput": 4527.092032195978,
    "output_throughput": 3992.23034273981,
    "total_throughput": 8519.32237493579,
    "itl": 120.62593768033491,
    "ttft": 1838108.284730954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.803852473101616,
    "arrivals": 188974,
    "finished_requests": 66451,
    "scheduler_time": 69.33447810579682
}
#Debug simulation 
Total elapsed time: 5.072016188176349. Arrivals time: 0.22164586768485606 Scheduler time: 4.71134982816875 Scheduler overhead time: 0.04369301698170602 Adapter cache time: 0.029694090830162168 Engine time: 0.04488677461631596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.701440694974735,
    "estimated_duration": 3600.0573206618183,
    "input_throughput": 4113.137286735715,
    "output_throughput": 3626.6480883698314,
    "total_throughput": 7739.785375105546,
    "itl": 95.06641938124734,
    "ttft": 1930687.6633035268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.920633912095727,
    "arrivals": 188974,
    "finished_requests": 60298,
    "scheduler_time": 66.98173250719944
}
#Debug simulation 
Total elapsed time: 4.701566888950765. Arrivals time: 0.20734635437838733 Scheduler time: 4.31746724084951 Scheduler overhead time: 0.05282428697682917 Adapter cache time: 0.04433121858164668 Engine time: 0.05428637540899217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.3340376871638,
    "estimated_duration": 3600.016895026131,
    "input_throughput": 4528.697913202894,
    "output_throughput": 3994.0698666903427,
    "total_throughput": 8522.767779893236,
    "itl": 120.72623812676217,
    "ttft": 1837587.4650762666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.29271330180112,
    "arrivals": 188974,
    "finished_requests": 66479,
    "scheduler_time": 69.34638416609646
}
#Debug simulation 
Total elapsed time: 5.334134159144014. Arrivals time: 0.4544996456243098 Scheduler time: 4.7398973307572305 Scheduler overhead time: 0.043760672910138965 Adapter cache time: 0.02969848271459341 Engine time: 0.04546004603616893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.7392805779818445,
    "estimated_duration": 3600.077547350353,
    "input_throughput": 4113.338339308522,
    "output_throughput": 3626.9599274632747,
    "total_throughput": 7740.298266771797,
    "itl": 95.06554776335255,
    "ttft": 1930793.4093756366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.827073665540592,
    "arrivals": 188974,
    "finished_requests": 60302,
    "scheduler_time": 66.98262176298243
}
#Debug simulation 
Total elapsed time: 4.739387255162001. Arrivals time: 0.20846879808232188 Scheduler time: 4.353855648310855 Scheduler overhead time: 0.05249608913436532 Adapter cache time: 0.04471664363518357 Engine time: 0.05463141412474215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.320692277047783,
    "estimated_duration": 3600.1261834671027,
    "input_throughput": 4857.4147429351615,
    "output_throughput": 4221.554808216038,
    "total_throughput": 9078.969551151198,
    "itl": 129.63379406016145,
    "ttft": 1770290.0241128695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.27161623463973,
    "arrivals": 187135,
    "finished_requests": 70611,
    "scheduler_time": 71.81174822083821
}
#Debug simulation 
Total elapsed time: 5.3207875459920615. Arrivals time: 0.22664672345854342 Scheduler time: 4.9716660105623305 Scheduler overhead time: 0.040634822100400925 Adapter cache time: 0.020548341795802116 Engine time: 0.041894201189279556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.187844711123034,
    "estimated_duration": 3600.0857738961004,
    "input_throughput": 4691.286836125095,
    "output_throughput": 4079.9202914835614,
    "total_throughput": 8771.207127608655,
    "itl": 117.62260584188084,
    "ttft": 1802837.261851132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.573834433695307,
    "arrivals": 187135,
    "finished_requests": 68157,
    "scheduler_time": 70.79669021791821
}
#Debug simulation 
Total elapsed time: 5.1879347511567175. Arrivals time: 0.22282200609333813 Scheduler time: 4.830374856246635 Scheduler overhead time: 0.044264383148401976 Adapter cache time: 0.023554283659905195 Engine time: 0.04586034989915788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.831646548816934,
    "estimated_duration": 3600.0717984186012,
    "input_throughput": 4247.8361144679175,
    "output_throughput": 3696.0729521686108,
    "total_throughput": 7943.909066636529,
    "itl": 93.05897595404656,
    "ttft": 1897993.823094733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.391285676648873,
    "arrivals": 187135,
    "finished_requests": 61741,
    "scheduler_time": 68.19168780633967
}
#Debug simulation 
Total elapsed time: 4.831740923924372. Arrivals time: 0.23915344756096601 Scheduler time: 4.420530189760029 Scheduler overhead time: 0.05367298563942313 Adapter cache time: 0.036925884429365396 Engine time: 0.05574969295412302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.168875641189516,
    "estimated_duration": 3600.104178393382,
    "input_throughput": 4690.857864990012,
    "output_throughput": 4079.0841798787974,
    "total_throughput": 8769.942044868809,
    "itl": 117.51354524656229,
    "ttft": 1802797.3017010929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.210120538687323,
    "arrivals": 187135,
    "finished_requests": 68146,
    "scheduler_time": 70.7966867868316
}
#Debug simulation 
Total elapsed time: 5.168965958990157. Arrivals time: 0.22232031682506204 Scheduler time: 4.811949823051691 Scheduler overhead time: 0.04420975083485246 Adapter cache time: 0.02370560052804649 Engine time: 0.04572339146398008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.790395254967734,
    "estimated_duration": 3600.0470761006864,
    "input_throughput": 4242.507022031185,
    "output_throughput": 3690.672571535117,
    "total_throughput": 7933.179593566303,
    "itl": 92.89278123433111,
    "ttft": 1899218.9481596206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.304614800182206,
    "arrivals": 187135,
    "finished_requests": 61661,
    "scheduler_time": 68.14018034583127
}
#Debug simulation 
Total elapsed time: 4.790485121076927. Arrivals time: 0.22964250878430903 Scheduler time: 4.388610111549497 Scheduler overhead time: 0.05356786143966019 Adapter cache time: 0.03752621542662382 Engine time: 0.055448916275054216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.16884404188022,
    "estimated_duration": 3600.1028151455544,
    "input_throughput": 4692.047940668897,
    "output_throughput": 4080.4287417013884,
    "total_throughput": 8772.476682370287,
    "itl": 117.60084872719588,
    "ttft": 1802628.4196414782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.002718429737706,
    "arrivals": 187135,
    "finished_requests": 68170,
    "scheduler_time": 70.80686669175108
}
#Debug simulation 
Total elapsed time: 5.1689349508378655. Arrivals time: 0.21864417637698352 Scheduler time: 4.81561006559059 Scheduler overhead time: 0.04408474871888757 Adapter cache time: 0.02359388885088265 Engine time: 0.045904818922281265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.794173104921356,
    "estimated_duration": 3600.087382937077,
    "input_throughput": 4249.109083435646,
    "output_throughput": 3697.245812167177,
    "total_throughput": 7946.3548956028235,
    "itl": 93.09270858047593,
    "ttft": 1898084.7865120878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.289906487613951,
    "arrivals": 187135,
    "finished_requests": 61758,
    "scheduler_time": 68.19709712411405
}
#Debug simulation 
Total elapsed time: 4.7942728598136455. Arrivals time: 0.20727901719510555 Scheduler time: 4.415166612016037 Scheduler overhead time: 0.05331546347588301 Adapter cache time: 0.03772250679321587 Engine time: 0.05539116612635553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.35980068705976,
    "estimated_duration": 3600.0936845473293,
    "input_throughput": 4911.154972408207,
    "output_throughput": 4285.513198232208,
    "total_throughput": 9196.668170640416,
    "itl": 127.81587521328497,
    "ttft": 1755947.6254980774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4730409779492892,
    "arrivals": 186179,
    "finished_requests": 71605,
    "scheduler_time": 72.90351917327038
}
#Debug simulation 
Total elapsed time: 5.359895400004461. Arrivals time: 0.22903001261875033 Scheduler time: 5.010195243405178 Scheduler overhead time: 0.04116226639598608 Adapter cache time: 0.01711961324326694 Engine time: 0.04274268099106848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.178511925041676,
    "estimated_duration": 3600.1141522118564,
    "input_throughput": 4744.075403694293,
    "output_throughput": 4142.5175340169,
    "total_throughput": 8886.592937711192,
    "itl": 116.07677194769907,
    "ttft": 1792207.8890192392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.659139513983394,
    "arrivals": 186179,
    "finished_requests": 69128,
    "scheduler_time": 71.80460701170499
}
#Debug simulation 
Total elapsed time: 5.178635305026546. Arrivals time: 0.22240182175301015 Scheduler time: 4.825052289990708 Scheduler overhead time: 0.044547207886353135 Adapter cache time: 0.019546020310372114 Engine time: 0.045893155271187425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.817945092916489,
    "estimated_duration": 3600.087215172467,
    "input_throughput": 4267.953269366536,
    "output_throughput": 3735.8931037329553,
    "total_throughput": 8003.846373099492,
    "itl": 91.99129585902723,
    "ttft": 1893270.8890357416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4265023046685497,
    "arrivals": 186179,
    "finished_requests": 62214,
    "scheduler_time": 68.8951825537484
}
#Debug simulation 
Total elapsed time: 4.818039997946471. Arrivals time: 0.2108416783157736 Scheduler time: 4.4405497731640935 Scheduler overhead time: 0.05381490266881883 Adapter cache time: 0.03121417947113514 Engine time: 0.055833285208791494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.223676363937557,
    "estimated_duration": 3600.1288292927975,
    "input_throughput": 4742.897493297258,
    "output_throughput": 4141.587622832081,
    "total_throughput": 8884.485116129339,
    "itl": 116.04506917039825,
    "ttft": 1792292.557214038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4606239147996476,
    "arrivals": 186179,
    "finished_requests": 69112,
    "scheduler_time": 71.79667707451411
}
#Debug simulation 
Total elapsed time: 5.223801451036707. Arrivals time: 0.22490105079486966 Scheduler time: 4.867212546756491 Scheduler overhead time: 0.0445800363086164 Adapter cache time: 0.019348238361999393 Engine time: 0.0463608808349818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.049791425932199,
    "estimated_duration": 3600.0112844177,
    "input_throughput": 4270.67077999085,
    "output_throughput": 3739.2324458164453,
    "total_throughput": 8009.903225807295,
    "itl": 92.18058225715478,
    "ttft": 1891669.759677171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.409102965318609,
    "arrivals": 186179,
    "finished_requests": 62263,
    "scheduler_time": 68.92166846393863
}
#Debug simulation 
Total elapsed time: 5.049857476959005. Arrivals time: 0.21456682798452675 Scheduler time: 4.669342612847686 Scheduler overhead time: 0.05379472277127206 Adapter cache time: 0.03040992794558406 Engine time: 0.05599501961842179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.2771588009782135,
    "estimated_duration": 3600.0853455608017,
    "input_throughput": 4746.719691262772,
    "output_throughput": 4144.415914583215,
    "total_throughput": 8891.135605845988,
    "itl": 116.18138135957203,
    "ttft": 1791668.155377494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3301311433082352,
    "arrivals": 186179,
    "finished_requests": 69162,
    "scheduler_time": 71.82171346695739
}
#Debug simulation 
Total elapsed time: 5.277268882840872. Arrivals time: 0.2262001964263618 Scheduler time: 4.918858471093699 Scheduler overhead time: 0.044732440961524844 Adapter cache time: 0.0196696266066283 Engine time: 0.046412736643105745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.821514602052048,
    "estimated_duration": 3600.0515644451502,
    "input_throughput": 4270.622718808072,
    "output_throughput": 3739.060888166644,
    "total_throughput": 8009.683606974716,
    "itl": 92.17896938695364,
    "ttft": 1891714.1389826864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.39108377095313,
    "arrivals": 186179,
    "finished_requests": 62262,
    "scheduler_time": 68.92368970368811
}
#Debug simulation 
Total elapsed time: 4.821608531055972. Arrivals time: 0.2085422961972654 Scheduler time: 4.447419743519276 Scheduler overhead time: 0.053687387611716986 Adapter cache time: 0.03055495535954833 Engine time: 0.05569966742768884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.394401488127187,
    "estimated_duration": 3600.018025544826,
    "input_throughput": 4942.49469690008,
    "output_throughput": 4317.7794915756185,
    "total_throughput": 9260.2741884757,
    "itl": 126.82301186630154,
    "ttft": 1752394.4348127015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3819934876775353,
    "arrivals": 185762,
    "finished_requests": 72028,
    "scheduler_time": 73.42104428106934
}
#Debug simulation 
Total elapsed time: 5.394488018006086. Arrivals time: 0.23117249342612922 Scheduler time: 5.045477795181796 Scheduler overhead time: 0.04142212588340044 Adapter cache time: 0.013721714727580547 Engine time: 0.04290469945408404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.264780818019062,
    "estimated_duration": 3600.04595701423,
    "input_throughput": 4774.195720060932,
    "output_throughput": 4170.902032721092,
    "total_throughput": 8945.097752782023,
    "itl": 115.53455368993777,
    "ttft": 1788113.8683006344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4980590291135027,
    "arrivals": 185762,
    "finished_requests": 69528,
    "scheduler_time": 72.27942364457141
}
#Debug simulation 
Total elapsed time: 5.264872762840241. Arrivals time: 0.22338812332600355 Scheduler time: 4.912268592976034 Scheduler overhead time: 0.0449951384216547 Adapter cache time: 0.016085904324427247 Engine time: 0.04659489123150706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.897288452833891,
    "estimated_duration": 3600.103504875991,
    "input_throughput": 4287.928660687699,
    "output_throughput": 3754.814543996182,
    "total_throughput": 8042.743204683881,
    "itl": 91.80892853740265,
    "ttft": 1890095.6269256594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4336343637155402,
    "arrivals": 185762,
    "finished_requests": 62421,
    "scheduler_time": 69.19260857515306
}
#Debug simulation 
Total elapsed time: 4.897388031007722. Arrivals time: 0.21257936279289424 Scheduler time: 4.518865016754717 Scheduler overhead time: 0.054395414190366864 Adapter cache time: 0.028772312914952636 Engine time: 0.056547978427261114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.285127608804032,
    "estimated_duration": 3600.0423538571495,
    "input_throughput": 4775.223264132226,
    "output_throughput": 4172.3186906139435,
    "total_throughput": 8947.54195474617,
    "itl": 115.57191683523315,
    "ttft": 1787791.02074243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3897777931950965,
    "arrivals": 185762,
    "finished_requests": 69551,
    "scheduler_time": 72.2939439935742
}
#Debug simulation 
Total elapsed time: 5.285225824918598. Arrivals time: 0.22384899156168103 Scheduler time: 4.931972819613293 Scheduler overhead time: 0.04501255974173546 Adapter cache time: 0.01651579816825688 Engine time: 0.04638407449238002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.818401138065383,
    "estimated_duration": 3600.028846073232,
    "input_throughput": 4282.874848855129,
    "output_throughput": 3750.539114353902,
    "total_throughput": 8033.413963209031,
    "itl": 91.63398388714687,
    "ttft": 1890611.532989556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4106458536256137,
    "arrivals": 185762,
    "finished_requests": 62346,
    "scheduler_time": 69.16648222605612
}
#Debug simulation 
Total elapsed time: 4.818490694044158. Arrivals time: 0.20696079987101257 Scheduler time: 4.447137576993555 Scheduler overhead time: 0.05364547134377062 Adapter cache time: 0.028842570260167122 Engine time: 0.05581225291825831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.260426993016154,
    "estimated_duration": 3600.0756253701948,
    "input_throughput": 4772.2811373534205,
    "output_throughput": 4169.18491773533,
    "total_throughput": 8941.46605508875,
    "itl": 115.39022905904848,
    "ttft": 1788612.5849791938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.302319871876385,
    "arrivals": 185762,
    "finished_requests": 69496,
    "scheduler_time": 72.27044470500623
}
#Debug simulation 
Total elapsed time: 5.260542219039053. Arrivals time: 0.2211613531690091 Scheduler time: 4.910257292212918 Scheduler overhead time: 0.04467497346922755 Adapter cache time: 0.016485897824168205 Engine time: 0.04640679503791034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.810843802988529,
    "estimated_duration": 3600.080387012516,
    "input_throughput": 4287.327042940928,
    "output_throughput": 3754.4725525466465,
    "total_throughput": 8041.799595487574,
    "itl": 91.81344237811828,
    "ttft": 1890168.2363005544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.398633057381961,
    "arrivals": 185762,
    "finished_requests": 62413,
    "scheduler_time": 69.19084774147653
}
#Debug simulation 
Total elapsed time: 4.810937217902392. Arrivals time: 0.20809038635343313 Scheduler time: 4.438279271824285 Scheduler overhead time: 0.05392368580214679 Adapter cache time: 0.028918757801875472 Engine time: 0.055826597614213824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.251230679918081,
    "estimated_duration": 3600.0828951962267,
    "input_throughput": 4721.438226514372,
    "output_throughput": 4116.482434272458,
    "total_throughput": 8837.920660786831,
    "itl": 133.21147025058625,
    "ttft": 1665530.1741334642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.779241650737614,
    "arrivals": 146610,
    "finished_requests": 68967,
    "scheduler_time": 69.14139499615035
}
#Debug simulation 
Total elapsed time: 5.25135318399407. Arrivals time: 0.2215279301162809 Scheduler time: 4.880294381408021 Scheduler overhead time: 0.04111752915196121 Adapter cache time: 0.047340546268969774 Engine time: 0.041632037376984954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.128142218105495,
    "estimated_duration": 3600.0809369603794,
    "input_throughput": 4586.051894138763,
    "output_throughput": 4001.049213121767,
    "total_throughput": 8587.10110726053,
    "itl": 120.54916366523105,
    "ttft": 1697247.934541487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.313090579630252,
    "arrivals": 146610,
    "finished_requests": 66994,
    "scheduler_time": 68.42718545596475
}
#Debug simulation 
Total elapsed time: 5.128238171106204. Arrivals time: 0.22983291605487466 Scheduler time: 4.728705726796761 Scheduler overhead time: 0.04403304564766586 Adapter cache time: 0.059421378187835217 Engine time: 0.04528529057279229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.87754163891077,
    "estimated_duration": 3600.050389063165,
    "input_throughput": 4276.276534008783,
    "output_throughput": 3735.6485456026317,
    "total_throughput": 8011.925079611414,
    "itl": 92.27630459162,
    "ttft": 1773318.707203125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.60889771437337,
    "arrivals": 146610,
    "finished_requests": 62429,
    "scheduler_time": 67.74587050837704
}
#Debug simulation 
Total elapsed time: 4.877630356000736. Arrivals time: 0.2221402081195265 Scheduler time: 4.442676794016734 Scheduler overhead time: 0.05448576249182224 Adapter cache time: 0.07578413840383291 Engine time: 0.056476217694580555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.123112753033638,
    "estimated_duration": 3600.0307386809527,
    "input_throughput": 4588.351377814139,
    "output_throughput": 4003.42720553567,
    "total_throughput": 8591.77858334981,
    "itl": 120.5032720692889,
    "ttft": 1696627.9813982775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.644146683538246,
    "arrivals": 146610,
    "finished_requests": 67029,
    "scheduler_time": 68.45489157330425
}
#Debug simulation 
Total elapsed time: 5.123203645925969. Arrivals time: 0.21368229272775352 Scheduler time: 4.739515412831679 Scheduler overhead time: 0.04406443424522877 Adapter cache time: 0.05982911866158247 Engine time: 0.04511633049696684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.904627948068082,
    "estimated_duration": 3600.031129900388,
    "input_throughput": 4276.44552074359,
    "output_throughput": 3735.7115854640183,
    "total_throughput": 8012.157106207609,
    "itl": 92.2724241593942,
    "ttft": 1773351.764754241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.471504709581552,
    "arrivals": 146610,
    "finished_requests": 62431,
    "scheduler_time": 67.74823723388823
}
#Debug simulation 
Total elapsed time: 4.904716880992055. Arrivals time: 0.20872626639902592 Scheduler time: 4.482512733666226 Scheduler overhead time: 0.05485694273374975 Adapter cache time: 0.07593801664188504 Engine time: 0.05653311335481703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.139464721083641,
    "estimated_duration": 3600.0507508933583,
    "input_throughput": 4580.472093597013,
    "output_throughput": 3996.2917179514425,
    "total_throughput": 8576.763811548455,
    "itl": 120.67130063572762,
    "ttft": 1698823.7013199998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.25207281116103,
    "arrivals": 146610,
    "finished_requests": 66918,
    "scheduler_time": 68.35233686717727
}
#Debug simulation 
Total elapsed time: 5.139557070098817. Arrivals time: 0.2262301871087402 Scheduler time: 4.744040076853707 Scheduler overhead time: 0.044158684089779854 Adapter cache time: 0.05884410557337105 Engine time: 0.045180853456258774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.859047850128263,
    "estimated_duration": 3600.0983983779242,
    "input_throughput": 4276.3572814944655,
    "output_throughput": 3736.114270115578,
    "total_throughput": 8012.471551610044,
    "itl": 92.27198897262353,
    "ttft": 1773191.574445152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.198383987751463,
    "arrivals": 146610,
    "finished_requests": 62433,
    "scheduler_time": 67.75368847138674
}
#Debug simulation 
Total elapsed time: 4.859139839187264. Arrivals time: 0.20702368044294417 Scheduler time: 4.440420074854046 Scheduler overhead time: 0.05423692334443331 Adapter cache time: 0.07543236040510237 Engine time: 0.05615640222094953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.365119990892708,
    "estimated_duration": 3600.0737160028966,
    "input_throughput": 4856.763882994314,
    "output_throughput": 4234.730231281668,
    "total_throughput": 9091.494114275984,
    "itl": 128.5265912138609,
    "ttft": 1614738.0267202607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.175478728325528,
    "arrivals": 142827,
    "finished_requests": 70483,
    "scheduler_time": 70.88115782222387
}
#Debug simulation 
Total elapsed time: 5.365235132863745. Arrivals time: 0.22033886518329382 Scheduler time: 4.993039842462167 Scheduler overhead time: 0.041491256561130285 Adapter cache time: 0.047575458185747266 Engine time: 0.04278608271852136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.288622267078608,
    "estimated_duration": 3600.0276268093685,
    "input_throughput": 4749.08883273004,
    "output_throughput": 4146.418179915384,
    "total_throughput": 8895.507012645423,
    "itl": 115.47867754343304,
    "ttft": 1640248.8918524864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.2537859556216,
    "arrivals": 142827,
    "finished_requests": 68956,
    "scheduler_time": 70.644285091643
}
#Debug simulation 
Total elapsed time: 5.288726748898625. Arrivals time: 0.22693087137304246 Scheduler time: 4.895887361373752 Scheduler overhead time: 0.04521483206190169 Adapter cache time: 0.052450813353061676 Engine time: 0.0465670945122838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.981826934032142,
    "estimated_duration": 3600.0805557014646,
    "input_throughput": 4425.357642280804,
    "output_throughput": 3864.2551978366387,
    "total_throughput": 8289.612840117443,
    "itl": 88.72026983032744,
    "ttft": 1723870.7112201906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.402952932854827,
    "arrivals": 142827,
    "finished_requests": 64262,
    "scheduler_time": 69.72578564341303
}
#Debug simulation 
Total elapsed time: 4.981918944045901. Arrivals time: 0.2093584518879652 Scheduler time: 4.567545297788456 Scheduler overhead time: 0.05581132392399013 Adapter cache time: 0.06405020388774574 Engine time: 0.05833210935816169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.27954506711103,
    "estimated_duration": 3600.048269816586,
    "input_throughput": 4751.76906471633,
    "output_throughput": 4148.810482688597,
    "total_throughput": 8900.579547404926,
    "itl": 115.43737917640831,
    "ttft": 1639887.5206511687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.106010541497161,
    "arrivals": 142827,
    "finished_requests": 68990,
    "scheduler_time": 70.66408288183936
}
#Debug simulation 
Total elapsed time: 5.279657850973308. Arrivals time: 0.21751484274864197 Scheduler time: 4.896258830558509 Scheduler overhead time: 0.04505935683846474 Adapter cache time: 0.05222774134017527 Engine time: 0.0468450787011534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.017022046027705,
    "estimated_duration": 3600.0663007019066,
    "input_throughput": 4425.245445311352,
    "output_throughput": 3864.2957762437945,
    "total_throughput": 8289.541221555146,
    "itl": 88.71501598161187,
    "ttft": 1723845.4732330518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.279348006075894,
    "arrivals": 142827,
    "finished_requests": 64262,
    "scheduler_time": 69.72748379936736
}
#Debug simulation 
Total elapsed time: 5.017141338903457. Arrivals time: 0.2149423968512565 Scheduler time: 4.59567195805721 Scheduler overhead time: 0.05626442772336304 Adapter cache time: 0.06488964916206896 Engine time: 0.058285170467570424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.325193304102868,
    "estimated_duration": 3600.083754309079,
    "input_throughput": 4753.390245301173,
    "output_throughput": 4149.611792258721,
    "total_throughput": 8903.002037559894,
    "itl": 115.40946265972353,
    "ttft": 1639746.357716105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.261679381235366,
    "arrivals": 142827,
    "finished_requests": 69007,
    "scheduler_time": 70.68106440560776
}
#Debug simulation 
Total elapsed time: 5.325305187143385. Arrivals time: 0.22594782570376992 Scheduler time: 4.933477045968175 Scheduler overhead time: 0.04510493716225028 Adapter cache time: 0.052283185767009854 Engine time: 0.04680530121549964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.0338836868759245,
    "estimated_duration": 3600.0356814526162,
    "input_throughput": 4425.441414950513,
    "output_throughput": 3864.329198644668,
    "total_throughput": 8289.770613595181,
    "itl": 88.71343911067058,
    "ttft": 1723917.9501026906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2056,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.103364461064054,
    "arrivals": 142827,
    "finished_requests": 64263,
    "scheduler_time": 69.73035520847813
}
#Debug simulation 
Total elapsed time: 5.033973528072238. Arrivals time: 0.21077280538156629 Scheduler time: 4.616553665837273 Scheduler overhead time: 0.05645947647280991 Adapter cache time: 0.06399568449705839 Engine time: 0.05894795572385192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.506056440062821,
    "estimated_duration": 3600.133957241783,
    "input_throughput": 4970.958640025435,
    "output_throughput": 4368.06996260997,
    "total_throughput": 9339.028602635406,
    "itl": 125.54045828902987,
    "ttft": 1572171.4831151685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.417596697672474,
    "arrivals": 140936,
    "finished_requests": 72599,
    "scheduler_time": 72.88805749833384
}
#Debug simulation 
Total elapsed time: 5.506151136010885. Arrivals time: 0.22567393397912383 Scheduler time: 5.132862789789215 Scheduler overhead time: 0.04231826006434858 Adapter cache time: 0.04134355532005429 Engine time: 0.04371072631329298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.415764580015093,
    "estimated_duration": 3600.0430279335633,
    "input_throughput": 4852.993940471985,
    "output_throughput": 4268.63731371035,
    "total_throughput": 9121.631254182335,
    "itl": 112.9712835156929,
    "ttft": 1601514.5659313623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.13989672547669,
    "arrivals": 140936,
    "finished_requests": 70910,
    "scheduler_time": 72.5010269378516
}
#Debug simulation 
Total elapsed time: 5.415859165834263. Arrivals time: 0.22292847163043916 Scheduler time: 5.030363336671144 Scheduler overhead time: 0.04620537906885147 Adapter cache time: 0.046390869887545705 Engine time: 0.04787461762316525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.119021611055359,
    "estimated_duration": 3600.00851725773,
    "input_throughput": 4492.601870931107,
    "output_throughput": 3955.252031138629,
    "total_throughput": 8447.853902069735,
    "itl": 87.23301823710935,
    "ttft": 1692682.3130648467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.678050358039307,
    "arrivals": 140936,
    "finished_requests": 65635,
    "scheduler_time": 71.1466691974962
}
#Debug simulation 
Total elapsed time: 5.119110903935507. Arrivals time: 0.21606480283662677 Scheduler time: 4.699177873786539 Scheduler overhead time: 0.05843725171871483 Adapter cache time: 0.057755238842219114 Engine time: 0.060019307071343064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.274313469184563,
    "estimated_duration": 3600.048396238322,
    "input_throughput": 4853.946968673807,
    "output_throughput": 4269.155941364341,
    "total_throughput": 9123.102910038147,
    "itl": 112.94873677468105,
    "ttft": 1601120.0856321778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.458006374458787,
    "arrivals": 140936,
    "finished_requests": 70923,
    "scheduler_time": 72.51148651582407
}
#Debug simulation 
Total elapsed time: 5.274402016075328. Arrivals time: 0.22333726240321994 Scheduler time: 4.887481530429795 Scheduler overhead time: 0.04712490667589009 Adapter cache time: 0.046161820413544774 Engine time: 0.04805783252231777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.92512618098408,
    "estimated_duration": 3600.0901918334903,
    "input_throughput": 4492.764941470135,
    "output_throughput": 3955.432847849779,
    "total_throughput": 8448.197789319915,
    "itl": 87.23361645494093,
    "ttft": 1692691.2372218263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.592302350406518,
    "arrivals": 140936,
    "finished_requests": 65638,
    "scheduler_time": 71.14816865942416
}
#Debug simulation 
Total elapsed time: 4.925236386014149. Arrivals time: 0.2142111724242568 Scheduler time: 4.510091862874106 Scheduler overhead time: 0.05663074320182204 Adapter cache time: 0.05786829232238233 Engine time: 0.05902873398736119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.2318874429911375,
    "estimated_duration": 3600.0980968215526,
    "input_throughput": 4854.455498151462,
    "output_throughput": 4269.774763518598,
    "total_throughput": 9124.23026167006,
    "itl": 112.93204528945265,
    "ttft": 1600987.997486689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.967133333831985,
    "arrivals": 140936,
    "finished_requests": 70933,
    "scheduler_time": 72.52065096837445
}
#Debug simulation 
Total elapsed time: 5.231976399896666. Arrivals time: 0.2228826181963086 Scheduler time: 4.846202747197822 Scheduler overhead time: 0.046103322645649314 Adapter cache time: 0.046976475743576884 Engine time: 0.04783939174376428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.926482676062733,
    "estimated_duration": 3600.0991962161766,
    "input_throughput": 4492.753704397864,
    "output_throughput": 3955.4229547248647,
    "total_throughput": 8448.17665912273,
    "itl": 87.2342597294608,
    "ttft": 1692674.1214402167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.482021612320088,
    "arrivals": 140936,
    "finished_requests": 65638,
    "scheduler_time": 71.15077300703085
}
#Debug simulation 
Total elapsed time: 4.926569378003478. Arrivals time: 0.21719414158724248 Scheduler time: 4.508509795879945 Scheduler overhead time: 0.057144959224388 Adapter cache time: 0.05736758466809988 Engine time: 0.05915353796444833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.428698454983532,
    "estimated_duration": 3600.122549814095,
    "input_throughput": 5045.843231347235,
    "output_throughput": 4443.102082962702,
    "total_throughput": 9488.945314309938,
    "itl": 123.26212347771461,
    "ttft": 1547754.2301673633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.782297966275419,
    "arrivals": 139992,
    "finished_requests": 73879,
    "scheduler_time": 74.0645234765634
}
#Debug simulation 
Total elapsed time: 5.428793576080352. Arrivals time: 0.22630916279740632 Scheduler time: 5.059475590707734 Scheduler overhead time: 0.04272261378355324 Adapter cache time: 0.035573356319218874 Engine time: 0.04436833504587412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.298689095070586,
    "estimated_duration": 3600.0140334136313,
    "input_throughput": 4916.726667094714,
    "output_throughput": 4332.556999843206,
    "total_throughput": 9249.28366693792,
    "itl": 111.16472931677558,
    "ttft": 1578949.823918205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.09835503365845,
    "arrivals": 139992,
    "finished_requests": 71964,
    "scheduler_time": 73.48973858436554
}
#Debug simulation 
Total elapsed time: 5.2987749699968845. Arrivals time: 0.22847396368160844 Scheduler time: 4.912775881355628 Scheduler overhead time: 0.046619941014796495 Adapter cache time: 0.04030101443640888 Engine time: 0.048225580248981714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.91065892810002,
    "estimated_duration": 3600.0201784696546,
    "input_throughput": 4533.007091903875,
    "output_throughput": 3990.5548546416558,
    "total_throughput": 8523.561946545531,
    "itl": 86.22993958308321,
    "ttft": 1676970.8015514547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.957517507467455,
    "arrivals": 139992,
    "finished_requests": 66323,
    "scheduler_time": 71.75982966300393
}
#Debug simulation 
Total elapsed time: 4.9107600569259375. Arrivals time: 0.22188988234847784 Scheduler time: 4.493654229445383 Scheduler overhead time: 0.056910136016085744 Adapter cache time: 0.0520733492448926 Engine time: 0.05892450944520533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.213976772967726,
    "estimated_duration": 3600.0055030078033,
    "input_throughput": 4917.012206012073,
    "output_throughput": 4333.015320939688,
    "total_throughput": 9250.02752695176,
    "itl": 111.15627122185505,
    "ttft": 1578888.4850222876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7984993034228607,
    "arrivals": 139992,
    "finished_requests": 71970,
    "scheduler_time": 73.49361964732687
}
#Debug simulation 
Total elapsed time: 5.214065639069304. Arrivals time: 0.21299560088664293 Scheduler time: 4.844522977946326 Scheduler overhead time: 0.04592472198419273 Adapter cache time: 0.040864601964131 Engine time: 0.047666306840255857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.991509297164157,
    "estimated_duration": 3600.031569708559,
    "input_throughput": 4533.120525196155,
    "output_throughput": 3990.696115246304,
    "total_throughput": 8523.81664044246,
    "itl": 86.22926357219532,
    "ttft": 1677009.5329709596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.921425753240509,
    "arrivals": 139992,
    "finished_requests": 66325,
    "scheduler_time": 71.7631407428404
}
#Debug simulation 
Total elapsed time: 4.991616050014272. Arrivals time: 0.2084232997149229 Scheduler time: 4.586977124912664 Scheduler overhead time: 0.057177075650542974 Adapter cache time: 0.052139747655019164 Engine time: 0.05928347539156675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.2370144601445645,
    "estimated_duration": 3600.091696782394,
    "input_throughput": 4917.033089968534,
    "output_throughput": 4332.934634398806,
    "total_throughput": 9249.967724367341,
    "itl": 111.15214239193314,
    "ttft": 1579036.5809058486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5622278848383413,
    "arrivals": 139992,
    "finished_requests": 71971,
    "scheduler_time": 73.4998879180192
}
#Debug simulation 
Total elapsed time: 5.23711271607317. Arrivals time: 0.22789042280055583 Scheduler time: 4.852075371192768 Scheduler overhead time: 0.0460125096142292 Adapter cache time: 0.04089985741302371 Engine time: 0.04804926458746195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.9162481140811,
    "estimated_duration": 3600.026948240101,
    "input_throughput": 4533.051067292069,
    "output_throughput": 3990.6015167533833,
    "total_throughput": 8523.652584045452,
    "itl": 86.23245534870861,
    "ttft": 1676985.8644891875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8901510595716893,
    "arrivals": 139992,
    "finished_requests": 66323,
    "scheduler_time": 71.76363527053695
}
#Debug simulation 
Total elapsed time: 4.916339746210724. Arrivals time: 0.20638066926039755 Scheduler time: 4.514693823875859 Scheduler overhead time: 0.05660795629955828 Adapter cache time: 0.05244872369803488 Engine time: 0.05891018477268517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.375507580116391,
    "estimated_duration": 3600.115111513789,
    "input_throughput": 5141.39171294915,
    "output_throughput": 4511.393801841714,
    "total_throughput": 9652.785514790865,
    "itl": 121.42365852313755,
    "ttft": 1525737.6702178179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8250248928181805,
    "arrivals": 139506,
    "finished_requests": 75142,
    "scheduler_time": 75.07509710881185
}
#Debug simulation 
Total elapsed time: 5.3756195260211825. Arrivals time: 0.22107600211165845 Scheduler time: 5.0151135846972466 Scheduler overhead time: 0.042632175609469414 Adapter cache time: 0.032099510775879025 Engine time: 0.044237831607460976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.3192481570877135,
    "estimated_duration": 3600.0099260909133,
    "input_throughput": 5007.384248957974,
    "output_throughput": 4394.463716709342,
    "total_throughput": 9401.847965667317,
    "itl": 109.49262409910044,
    "ttft": 1558476.582045132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9965810017706855,
    "arrivals": 139506,
    "finished_requests": 73130,
    "scheduler_time": 74.46065779678167
}
#Debug simulation 
Total elapsed time: 5.319335775915533. Arrivals time: 0.21780765894800425 Scheduler time: 4.946607504505664 Scheduler overhead time: 0.04674297198653221 Adapter cache time: 0.03699850430712104 Engine time: 0.04871092620305717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.953728653024882,
    "estimated_duration": 3600.054360773765,
    "input_throughput": 4614.286434394181,
    "output_throughput": 4040.7973164253476,
    "total_throughput": 8655.083750819529,
    "itl": 84.97657703545278,
    "ttft": 1660579.0146850029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.980935518727644,
    "arrivals": 139506,
    "finished_requests": 67251,
    "scheduler_time": 72.62754687740737
}
#Debug simulation 
Total elapsed time: 4.9538296069949865. Arrivals time: 0.21144639141857624 Scheduler time: 4.550055474275723 Scheduler overhead time: 0.05756460805423558 Adapter cache time: 0.04745195270515978 Engine time: 0.05965615063905716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.314234644873068,
    "estimated_duration": 3600.0274544675503,
    "input_throughput": 5007.986530110088,
    "output_throughput": 4394.887872414866,
    "total_throughput": 9402.874402524954,
    "itl": 109.48346422180036,
    "ttft": 1558513.2639115353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8424884737329525,
    "arrivals": 139506,
    "finished_requests": 73137,
    "scheduler_time": 74.46430363588905
}
#Debug simulation 
Total elapsed time: 5.314327593892813. Arrivals time: 0.22812687046825886 Scheduler time: 4.932121033780277 Scheduler overhead time: 0.046856352128088474 Adapter cache time: 0.03634341061115265 Engine time: 0.048458328703418374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.978988442802802,
    "estimated_duration": 3600.0859892572016,
    "input_throughput": 4614.658663591466,
    "output_throughput": 4041.0318096323226,
    "total_throughput": 8655.690473223789,
    "itl": 84.97643650576501,
    "ttft": 1660494.1428890715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9655554821621688,
    "arrivals": 139506,
    "finished_requests": 67255,
    "scheduler_time": 72.62808669358402
}
#Debug simulation 
Total elapsed time: 4.979077116819099. Arrivals time: 0.20939897396601737 Scheduler time: 4.575407137628645 Scheduler overhead time: 0.05768954288214445 Adapter cache time: 0.04783040634356439 Engine time: 0.06106951809488237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.319313795072958,
    "estimated_duration": 3600.0637187877064,
    "input_throughput": 5007.935805667097,
    "output_throughput": 4394.770269601715,
    "total_throughput": 9402.706075268812,
    "itl": 109.48201045875771,
    "ttft": 1558576.3917988671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7300425748946084,
    "arrivals": 139506,
    "finished_requests": 73136,
    "scheduler_time": 74.4665641336472
}
#Debug simulation 
Total elapsed time: 5.319428719114512. Arrivals time: 0.2180573781952262 Scheduler time: 4.946908040205017 Scheduler overhead time: 0.046746435575187206 Adapter cache time: 0.03655626275576651 Engine time: 0.048607062781229615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.966400507139042,
    "estimated_duration": 3600.0117137202537,
    "input_throughput": 4614.334152494605,
    "output_throughput": 4040.8415740867254,
    "total_throughput": 8655.17572658133,
    "itl": 84.9763824339801,
    "ttft": 1660531.7968004006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9430330754071539,
    "arrivals": 139506,
    "finished_requests": 67251,
    "scheduler_time": 72.62647660244231
}
#Debug simulation 
Total elapsed time: 4.966486065182835. Arrivals time: 0.2071671423036605 Scheduler time: 4.567514695459977 Scheduler overhead time: 0.05736867943778634 Adapter cache time: 0.047744636656716466 Engine time: 0.05910355597734451 
