INFO 05-31 19:31:04 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90517161 . Total output tokens: 79860254
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 26.01196666294709,
    "estimated_duration": 3600.0536133423398,
    "input_throughput": 5137.279048138805,
    "output_throughput": 4458.002497662762,
    "total_throughput": 9595.281545801567,
    "itl": 97.94150104407179,
    "ttft": 1509747.616618363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.265702657382931,
    "arrivals": 135085,
    "finished_requests": 74507,
    "scheduler_time": 163.95263230140856
}
#Debug simulation 
Total elapsed time: 26.012110635172576. Arrivals time: 0.3182637598365545 Scheduler time: 25.516602532938123 Scheduler overhead time: 0.06374890636652708 Adapter cache time: 0.02426613448187709 Engine time: 0.062187657691538334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90517161 . Total output tokens: 79860254
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 59.08966957870871,
    "estimated_duration": 3600.0484090435502,
    "input_throughput": 5435.208579653101,
    "output_throughput": 4721.820950323327,
    "total_throughput": 10157.02952997643,
    "itl": 110.0494542523667,
    "ttft": 1434462.2878899025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.767221645344974,
    "arrivals": 135085,
    "finished_requests": 78886,
    "scheduler_time": 154.77304535422599
}
#Debug simulation 
Total elapsed time: 59.089852342847735. Arrivals time: 0.360160022508353 Scheduler time: 58.55409123329446 Scheduler overhead time: 0.06581936310976744 Adapter cache time: 0.019354316405951977 Engine time: 0.0641579357907176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90517161 . Total output tokens: 79860254
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 24.87648074608296,
    "estimated_duration": 3600.0190541277225,
    "input_throughput": 5131.440062468236,
    "output_throughput": 4459.932783297531,
    "total_throughput": 9591.372845765767,
    "itl": 98.1137752777518,
    "ttft": 1509345.9506504904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.129758259360647,
    "arrivals": 135085,
    "finished_requests": 74465,
    "scheduler_time": 163.8094275768959
}
#Debug simulation 
Total elapsed time: 24.876626352779567. Arrivals time: 0.31246707774698734 Scheduler time: 24.383019916713238 Scheduler overhead time: 0.06442830013111234 Adapter cache time: 0.026201593223959208 Engine time: 0.06349230511114001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90517161 . Total output tokens: 79860254
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 59.37738519720733,
    "estimated_duration": 3600.0363099373285,
    "input_throughput": 5431.056888517986,
    "output_throughput": 4719.662674817796,
    "total_throughput": 10150.719563335782,
    "itl": 109.8429101521212,
    "ttft": 1434577.5094708086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.136780769489686,
    "arrivals": 135085,
    "finished_requests": 78829,
    "scheduler_time": 154.9437747796551
}
#Debug simulation 
Total elapsed time: 59.37753765238449. Arrivals time: 0.35583681240677834 Scheduler time: 58.848278503865004 Scheduler overhead time: 0.06470211315900087 Adapter cache time: 0.019106232095509768 Engine time: 0.06344713130965829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90517161 . Total output tokens: 79860254
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 33.284637367818505,
    "estimated_duration": 3600.0553586538513,
    "input_throughput": 5142.893415651002,
    "output_throughput": 4462.378880197838,
    "total_throughput": 9605.272295848841,
    "itl": 97.97179750190821,
    "ttft": 1469216.17508137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.506791691910498,
    "arrivals": 135085,
    "finished_requests": 74539,
    "scheduler_time": 163.98250344048157
}
#Debug simulation 
Total elapsed time: 33.28476120810956. Arrivals time: 0.33277891809120774 Scheduler time: 32.770004778169096 Scheduler overhead time: 0.06646447535604239 Adapter cache time: 0.022199544589966536 Engine time: 0.06598669337108731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89247428 . Total output tokens: 78733657
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 35.863122483249754,
    "estimated_duration": 3600.072231796062,
    "input_throughput": 5552.259708419183,
    "output_throughput": 4856.078121320967,
    "total_throughput": 10408.337829740149,
    "itl": 117.7022397932346,
    "ttft": 1371665.8621525408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.026957100457574,
    "arrivals": 133166,
    "finished_requests": 80949,
    "scheduler_time": 148.95868786960767
}
#Debug simulation 
Total elapsed time: 35.863297306001186. Arrivals time: 0.3521242323331535 Scheduler time: 35.35127776535228 Scheduler overhead time: 0.05961209814995527 Adapter cache time: 0.017640421632677317 Engine time: 0.05843346379697323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89247428 . Total output tokens: 78733657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 33.32040386972949,
    "estimated_duration": 3600.102038918852,
    "input_throughput": 5393.49045946241,
    "output_throughput": 4725.761885657344,
    "total_throughput": 10119.252345119754,
    "itl": 110.38631352897958,
    "ttft": 1414571.4235279239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4967644388647825,
    "arrivals": 133166,
    "finished_requests": 78681,
    "scheduler_time": 153.48234746492153
}
#Debug simulation 
Total elapsed time: 33.32055509882048. Arrivals time: 0.34207409899681807 Scheduler time: 32.81108997995034 Scheduler overhead time: 0.062107536010444164 Adapter cache time: 0.019935117568820715 Engine time: 0.060431845020502806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89247428 . Total output tokens: 78733657
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.993590902071446,
    "estimated_duration": 3600.080037980678,
    "input_throughput": 5079.108466226311,
    "output_throughput": 4460.598050760945,
    "total_throughput": 9539.706516987257,
    "itl": 98.34948942476692,
    "ttft": 1497160.5780197186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.211250422960017,
    "arrivals": 133166,
    "finished_requests": 74152,
    "scheduler_time": 162.62160364099694
}
#Debug simulation 
Total elapsed time: 16.993739062920213. Arrivals time: 0.29466863349080086 Scheduler time: 16.525135184638202 Scheduler overhead time: 0.06034366926178336 Adapter cache time: 0.027358161751180887 Engine time: 0.05979386204853654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89247428 . Total output tokens: 78733657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 33.151732491794974,
    "estimated_duration": 3600.1126478339447,
    "input_throughput": 5388.323060299628,
    "output_throughput": 4726.202389871666,
    "total_throughput": 10114.525450171293,
    "itl": 110.31967996282492,
    "ttft": 1415471.3467010793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.053119344380678,
    "arrivals": 133166,
    "finished_requests": 78618,
    "scheduler_time": 153.5433882264882
}
#Debug simulation 
Total elapsed time: 33.15185266593471. Arrivals time: 0.3362828250974417 Scheduler time: 32.650048474781215 Scheduler overhead time: 0.06090081110596657 Adapter cache time: 0.01943925116211176 Engine time: 0.06028441758826375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89247428 . Total output tokens: 78733657
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 23.13031359994784,
    "estimated_duration": 3600.0113017502167,
    "input_throughput": 5084.294871824814,
    "output_throughput": 4464.195707437554,
    "total_throughput": 9548.490579262369,
    "itl": 98.30647772431637,
    "ttft": 1494806.3786170282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.516892526480312,
    "arrivals": 133166,
    "finished_requests": 74182,
    "scheduler_time": 162.71977492757
}
#Debug simulation 
Total elapsed time: 23.130457578692585. Arrivals time: 0.3160010538995266 Scheduler time: 22.636181571986526 Scheduler overhead time: 0.06294493982568383 Adapter cache time: 0.02633828530088067 Engine time: 0.06206446420401335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89247428 . Total output tokens: 78733657
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 33.632995632942766,
    "estimated_duration": 3600.0347780553334,
    "input_throughput": 5391.069585856566,
    "output_throughput": 4725.678513914209,
    "total_throughput": 10116.748099770775,
    "itl": 110.26443078841028,
    "ttft": 1417280.414900867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.743253258843883,
    "arrivals": 133166,
    "finished_requests": 78629,
    "scheduler_time": 153.59545533928667
}
#Debug simulation 
Total elapsed time: 33.63315431587398. Arrivals time: 0.34341554110869765 Scheduler time: 33.12281625298783 Scheduler overhead time: 0.061544657684862614 Adapter cache time: 0.01941352616995573 Engine time: 0.06081491010263562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89247428 . Total output tokens: 78733657
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.72892792755738,
    "estimated_duration": 3600.034754536958,
    "input_throughput": 5085.255351195821,
    "output_throughput": 4459.485836842963,
    "total_throughput": 9544.741188038784,
    "itl": 98.35942278650123,
    "ttft": 1499364.9253722245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.10839340018095,
    "arrivals": 133166,
    "finished_requests": 74142,
    "scheduler_time": 162.61070488766015
}
#Debug simulation 
Total elapsed time: 17.72902925265953. Arrivals time: 0.3050902718678117 Scheduler time: 17.24746059300378 Scheduler overhead time: 0.06143361749127507 Adapter cache time: 0.0285172825679183 Engine time: 0.06008137110620737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88632508 . Total output tokens: 78178108
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 63.273105644620955,
    "estimated_duration": 3600.0649841198397,
    "input_throughput": 5524.88471395268,
    "output_throughput": 4857.701757368571,
    "total_throughput": 10382.58647132125,
    "itl": 117.71522930270473,
    "ttft": 1379448.0189925248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.119530826904876,
    "arrivals": 132222,
    "finished_requests": 80818,
    "scheduler_time": 148.52077573068544
}
#Debug simulation 
Total elapsed time: 63.27326193964109. Arrivals time: 0.3742228616029024 Scheduler time: 62.73286119149998 Scheduler overhead time: 0.06210829596966505 Adapter cache time: 0.01777823455631733 Engine time: 0.06178085505962372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88632508 . Total output tokens: 78178108
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 50.50729323318228,
    "estimated_duration": 3600.0051116479876,
    "input_throughput": 5357.589892746224,
    "output_throughput": 4727.464398573922,
    "total_throughput": 10085.054291320146,
    "itl": 110.2127010560353,
    "ttft": 1312170.581041935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.891283643930224,
    "arrivals": 132222,
    "finished_requests": 78529,
    "scheduler_time": 153.2053364958196
}
#Debug simulation 
Total elapsed time: 50.507459649350494. Arrivals time: 0.35408488335087895 Scheduler time: 49.98006258159876 Scheduler overhead time: 0.06516555836424232 Adapter cache time: 0.017931149806827307 Engine time: 0.06421669013798237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88632508 . Total output tokens: 78178108
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.718693175818771,
    "estimated_duration": 3600.038200701166,
    "input_throughput": 5073.795882622142,
    "output_throughput": 4460.313225807598,
    "total_throughput": 9534.10910842974,
    "itl": 98.17455188577111,
    "ttft": 1495187.2469430978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.190276787625507,
    "arrivals": 132222,
    "finished_requests": 74218,
    "scheduler_time": 162.28397515837293
}
#Debug simulation 
Total elapsed time: 14.718810813967139. Arrivals time: 0.29604061180725694 Scheduler time: 14.248929590918124 Scheduler overhead time: 0.06043724762275815 Adapter cache time: 0.027555489912629128 Engine time: 0.05946967750787735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88632508 . Total output tokens: 78178108
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 50.743888697586954,
    "estimated_duration": 3600.0004819172536,
    "input_throughput": 5358.435949354795,
    "output_throughput": 4727.71714489765,
    "total_throughput": 10086.153094252444,
    "itl": 110.18540633750172,
    "ttft": 1311314.072599345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6960921929357533,
    "arrivals": 132222,
    "finished_requests": 78544,
    "scheduler_time": 153.23044798439375
}
#Debug simulation 
Total elapsed time: 50.74406873900443. Arrivals time: 0.3505208776332438 Scheduler time: 50.220181642100215 Scheduler overhead time: 0.0651980685070157 Adapter cache time: 0.01774126384407282 Engine time: 0.06437707645818591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88632508 . Total output tokens: 78178108
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 13.444882489275187,
    "estimated_duration": 3600.062737495348,
    "input_throughput": 5075.353495842685,
    "output_throughput": 4463.473048022337,
    "total_throughput": 9538.826543865021,
    "itl": 98.28391444237232,
    "ttft": 1495698.2081449446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.521217023786031,
    "arrivals": 132222,
    "finished_requests": 74260,
    "scheduler_time": 162.168053779627
}
#Debug simulation 
Total elapsed time: 13.444978163111955. Arrivals time: 0.29455027310177684 Scheduler time: 12.978692354634404 Scheduler overhead time: 0.058714138343930244 Adapter cache time: 0.02840948523953557 Engine time: 0.05816445918753743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88632508 . Total output tokens: 78178108
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 51.04443030105904,
    "estimated_duration": 3600.1089855131286,
    "input_throughput": 5371.165172446551,
    "output_throughput": 4731.257600406299,
    "total_throughput": 10102.42277285285,
    "itl": 110.26067400467858,
    "ttft": 1306688.762181737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.389862019442938,
    "arrivals": 132222,
    "finished_requests": 78628,
    "scheduler_time": 153.15337685177738
}
#Debug simulation 
Total elapsed time: 51.04460820136592. Arrivals time: 0.35894086956977844 Scheduler time: 50.5129332896322 Scheduler overhead time: 0.06544847693294287 Adapter cache time: 0.01744468091055751 Engine time: 0.06409446196630597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88632508 . Total output tokens: 78178108
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.216328596230596,
    "estimated_duration": 3600.033515681349,
    "input_throughput": 5073.313045682383,
    "output_throughput": 4461.98790373201,
    "total_throughput": 9535.300949414392,
    "itl": 98.22993367662754,
    "ttft": 1496955.911867628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.209548651631804,
    "arrivals": 132222,
    "finished_requests": 74212,
    "scheduler_time": 162.21430774233093
}
#Debug simulation 
Total elapsed time: 13.21647625695914. Arrivals time: 0.29180422658100724 Scheduler time: 12.753482426516712 Scheduler overhead time: 0.058737808372825384 Adapter cache time: 0.027720749843865633 Engine time: 0.05845250096172094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86716151 . Total output tokens: 76454574
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 71.59046758292243,
    "estimated_duration": 3600.0665841334758,
    "input_throughput": 5545.920202696938,
    "output_throughput": 4862.213681587566,
    "total_throughput": 10408.133884284503,
    "itl": 117.69880760555111,
    "ttft": 1334032.3288233583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0864687817451255,
    "arrivals": 129353,
    "finished_requests": 80901,
    "scheduler_time": 146.6596864581048
}
#Debug simulation 
Total elapsed time: 71.59062505234033. Arrivals time: 0.38251869147643447 Scheduler time: 71.03647184604779 Scheduler overhead time: 0.06493358220905066 Adapter cache time: 0.01751735620200634 Engine time: 0.0643702712841332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86716151 . Total output tokens: 76454574
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 23.725058584008366,
    "estimated_duration": 3600.052550512049,
    "input_throughput": 5387.682742920306,
    "output_throughput": 4716.546150856852,
    "total_throughput": 10104.22889377716,
    "itl": 109.73844856417948,
    "ttft": 1402851.99936373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1047,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.650167022203106,
    "arrivals": 129353,
    "finished_requests": 78422,
    "scheduler_time": 151.6244691079487
}
#Debug simulation 
Total elapsed time: 23.7251807898283. Arrivals time: 0.3195918188430369 Scheduler time: 23.24181463709101 Scheduler overhead time: 0.05867489892989397 Adapter cache time: 0.02162724221125245 Engine time: 0.05852203816175461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86716151 . Total output tokens: 76454574
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.837377298623323,
    "estimated_duration": 3600.053767433141,
    "input_throughput": 5079.63691137833,
    "output_throughput": 4452.236004082868,
    "total_throughput": 9531.872915461197,
    "itl": 97.6319930564499,
    "ttft": 1482276.2331140062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.920845934641402,
    "arrivals": 129353,
    "finished_requests": 73982,
    "scheduler_time": 160.82020681680513
}
#Debug simulation 
Total elapsed time: 13.837472850922495. Arrivals time: 0.2938956650905311 Scheduler time: 13.369967199396342 Scheduler overhead time: 0.06032057665288448 Adapter cache time: 0.028043599799275398 Engine time: 0.05864886473864317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86716151 . Total output tokens: 76454574
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 47.64212521072477,
    "estimated_duration": 3600.112270683421,
    "input_throughput": 5381.9388239028085,
    "output_throughput": 4728.245599065336,
    "total_throughput": 10110.184422968145,
    "itl": 109.99439947986218,
    "ttft": 1299470.8799839893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9023230679333154,
    "arrivals": 129353,
    "finished_requests": 78525,
    "scheduler_time": 151.52195644550974
}
#Debug simulation 
Total elapsed time: 47.64230592781678. Arrivals time: 0.3562733815051615 Scheduler time: 47.11239193286747 Scheduler overhead time: 0.06520246854051948 Adapter cache time: 0.017785120755434036 Engine time: 0.06453946325927973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86716151 . Total output tokens: 76454574
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.402862245216966,
    "estimated_duration": 3600.02680276858,
    "input_throughput": 5086.695739575349,
    "output_throughput": 4459.555130993293,
    "total_throughput": 9546.250870568641,
    "itl": 97.9160766609003,
    "ttft": 1479811.1244387424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.90196557422623,
    "arrivals": 129353,
    "finished_requests": 74112,
    "scheduler_time": 160.59995226860306
}
#Debug simulation 
Total elapsed time: 15.402960816863924. Arrivals time: 0.2971244817599654 Scheduler time: 14.93260569497943 Scheduler overhead time: 0.06051544193178415 Adapter cache time: 0.026650311890989542 Engine time: 0.059559863060712814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86716151 . Total output tokens: 76454574
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 47.0552943800576,
    "estimated_duration": 3600.0021372814927,
    "input_throughput": 5370.645144838758,
    "output_throughput": 4725.720249945992,
    "total_throughput": 10096.365394784749,
    "itl": 109.91914507214086,
    "ttft": 1300030.1637455383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6196831733034758,
    "arrivals": 129353,
    "finished_requests": 78406,
    "scheduler_time": 151.6107440989063
}
#Debug simulation 
Total elapsed time: 47.05547047499567. Arrivals time: 0.35279085068032146 Scheduler time: 46.52948469668627 Scheduler overhead time: 0.06507731787860394 Adapter cache time: 0.017718794755637646 Engine time: 0.06460049375891685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86716151 . Total output tokens: 76454574
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.821400742977858,
    "estimated_duration": 3600.091457408346,
    "input_throughput": 5089.185710073435,
    "output_throughput": 4459.803643865834,
    "total_throughput": 9548.989353939269,
    "itl": 97.9608818771726,
    "ttft": 1480830.3338253996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.24739174339908,
    "arrivals": 129353,
    "finished_requests": 74120,
    "scheduler_time": 160.59595248359412
}
#Debug simulation 
Total elapsed time: 14.821496636141092. Arrivals time: 0.29310151329264045 Scheduler time: 14.35433420771733 Scheduler overhead time: 0.06062438199296594 Adapter cache time: 0.027617663145065308 Engine time: 0.0592492688447237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 86110738 . Total output tokens: 75899232
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 35.71829356206581,
    "estimated_duration": 3600.125840459846,
    "input_throughput": 5586.600827661909,
    "output_throughput": 4859.885674931074,
    "total_throughput": 10446.486502592983,
    "itl": 117.33831440630017,
    "ttft": 1327341.6673619696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.72126004881234,
    "arrivals": 128453,
    "finished_requests": 81061,
    "scheduler_time": 146.10633358707545
}
#Debug simulation 
Total elapsed time: 35.71842190111056. Arrivals time: 0.35111626284196973 Scheduler time: 35.20338935172185 Scheduler overhead time: 0.06050827959552407 Adapter cache time: 0.01886469731107354 Engine time: 0.06007125973701477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 86110738 . Total output tokens: 75899232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.82908607693389,
    "estimated_duration": 3600.028959082011,
    "input_throughput": 5445.64619419035,
    "output_throughput": 4720.415639193438,
    "total_throughput": 10166.061833383788,
    "itl": 109.83304197872332,
    "ttft": 1386065.5516342407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.828369102296431,
    "arrivals": 128453,
    "finished_requests": 78833,
    "scheduler_time": 150.9109835309027
}
#Debug simulation 
Total elapsed time: 24.829254128038883. Arrivals time: 0.33095430582761765 Scheduler time: 24.333762062247843 Scheduler overhead time: 0.05853663384914398 Adapter cache time: 0.02233700081706047 Engine time: 0.05869399895891547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 86110738 . Total output tokens: 75899232
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 18.383011274039745,
    "estimated_duration": 3600.035083724462,
    "input_throughput": 5126.867536220002,
    "output_throughput": 4456.721844888553,
    "total_throughput": 9583.589381108555,
    "itl": 97.7272251594224,
    "ttft": 1471031.1103620755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.606175906536995,
    "arrivals": 128453,
    "finished_requests": 74256,
    "scheduler_time": 160.4301221680134
}
#Debug simulation 
Total elapsed time: 18.383132422808558. Arrivals time: 0.30408184230327606 Scheduler time: 17.903778782580048 Scheduler overhead time: 0.061209749430418015 Adapter cache time: 0.026509325485676527 Engine time: 0.06071567628532648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 86110738 . Total output tokens: 75899232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 36.63131101988256,
    "estimated_duration": 3600.1152480749483,
    "input_throughput": 5448.362246316526,
    "output_throughput": 4725.071234621171,
    "total_throughput": 10173.433480937696,
    "itl": 109.82191659822102,
    "ttft": 1345938.3493017438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.05867222827393,
    "arrivals": 128453,
    "finished_requests": 78872,
    "scheduler_time": 151.0000211522412
}
#Debug simulation 
Total elapsed time: 36.6314320419915. Arrivals time: 0.34758696565404534 Scheduler time: 36.11177148716524 Scheduler overhead time: 0.06381860608235002 Adapter cache time: 0.01948346896097064 Engine time: 0.06314940890297294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 86110738 . Total output tokens: 75899232
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.257936053909361,
    "estimated_duration": 3600.0782386521273,
    "input_throughput": 5125.38722128116,
    "output_throughput": 4453.014056161762,
    "total_throughput": 9578.401277442921,
    "itl": 97.72328956652875,
    "ttft": 1471780.4693621264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.441754572619544,
    "arrivals": 128453,
    "finished_requests": 74214,
    "scheduler_time": 160.44810144779547
}
#Debug simulation 
Total elapsed time: 15.258031216915697. Arrivals time: 0.30414879554882646 Scheduler time: 14.781208577100188 Scheduler overhead time: 0.059854325372725725 Adapter cache time: 0.027416926808655262 Engine time: 0.05897421343252063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 86110738 . Total output tokens: 75899232
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 36.12236094940454,
    "estimated_duration": 3600.0427628896437,
    "input_throughput": 5444.038388107554,
    "output_throughput": 4727.191625451721,
    "total_throughput": 10171.230013559274,
    "itl": 109.83934439578985,
    "ttft": 1347287.170099085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.590039156270191,
    "arrivals": 128453,
    "finished_requests": 78873,
    "scheduler_time": 150.99403240953205
}
#Debug simulation 
Total elapsed time: 36.12248512310907. Arrivals time: 0.35148968547582626 Scheduler time: 35.599617045372725 Scheduler overhead time: 0.06376289250329137 Adapter cache time: 0.019115673378109932 Engine time: 0.06282300502061844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 86110738 . Total output tokens: 75899232
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 20.259878146927804,
    "estimated_duration": 3600.0668607417765,
    "input_throughput": 5130.723043347631,
    "output_throughput": 4459.243847680162,
    "total_throughput": 9589.966891027792,
    "itl": 97.65920876242615,
    "ttft": 1469934.89846103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.099784615319145,
    "arrivals": 128453,
    "finished_requests": 74287,
    "scheduler_time": 160.53431333583174
}
#Debug simulation 
Total elapsed time: 20.25998884718865. Arrivals time: 0.31311047030612826 Scheduler time: 19.768669240176678 Scheduler overhead time: 0.06291549792513251 Adapter cache time: 0.025927373208105564 Engine time: 0.0622934028506279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84805049 . Total output tokens: 74740231
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 73.88736503804103,
    "estimated_duration": 3600.098361463614,
    "input_throughput": 5619.240078700406,
    "output_throughput": 4868.561144777807,
    "total_throughput": 10487.801223478213,
    "itl": 117.76710855476156,
    "ttft": 1284841.820588779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.589011868173337,
    "arrivals": 126425,
    "finished_requests": 81560,
    "scheduler_time": 144.65512935648928
}
#Debug simulation 
Total elapsed time: 73.88753462722525. Arrivals time: 0.39087834022939205 Scheduler time: 73.32157139666378 Scheduler overhead time: 0.06584813632071018 Adapter cache time: 0.018745943903923035 Engine time: 0.06514326855540276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84805049 . Total output tokens: 74740231
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 43.501713648904115,
    "estimated_duration": 3600.072817404337,
    "input_throughput": 5449.864487503898,
    "output_throughput": 4733.482033368015,
    "total_throughput": 10183.346520871914,
    "itl": 110.12148850944054,
    "ttft": 1374356.530884694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.432084105070675,
    "arrivals": 126425,
    "finished_requests": 79180,
    "scheduler_time": 149.52925110415575
}
#Debug simulation 
Total elapsed time: 43.50185102969408. Arrivals time: 0.3538453308865428 Scheduler time: 42.972787712700665 Scheduler overhead time: 0.06344940373674035 Adapter cache time: 0.023628418799489737 Engine time: 0.062496546655893326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84805049 . Total output tokens: 74740231
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.023219543043524,
    "estimated_duration": 3600.0243710277614,
    "input_throughput": 5158.5528557680955,
    "output_throughput": 4478.406626841047,
    "total_throughput": 9636.959482609143,
    "itl": 97.85800859980593,
    "ttft": 1450490.6033033493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.874232106259905,
    "arrivals": 126425,
    "finished_requests": 74912,
    "scheduler_time": 159.29428366979855
}
#Debug simulation 
Total elapsed time: 15.023336582817137. Arrivals time: 0.30604015244171023 Scheduler time: 14.543760764878243 Scheduler overhead time: 0.06035286979749799 Adapter cache time: 0.02585875801742077 Engine time: 0.059100385289639235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84805049 . Total output tokens: 74740231
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 44.221001039259136,
    "estimated_duration": 3600.0184031980652,
    "input_throughput": 5449.940751016921,
    "output_throughput": 4731.358313298845,
    "total_throughput": 10181.299064315766,
    "itl": 110.05613584785671,
    "ttft": 1374787.9186351222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.726367532801803,
    "arrivals": 126425,
    "finished_requests": 79176,
    "scheduler_time": 149.5418273847167
}
#Debug simulation 
Total elapsed time: 44.22117211529985. Arrivals time: 0.355831237975508 Scheduler time: 43.690384356770664 Scheduler overhead time: 0.06316229840740561 Adapter cache time: 0.023175648413598537 Engine time: 0.06290951743721962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84805049 . Total output tokens: 74740231
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 14.348974826280028,
    "estimated_duration": 3600.0238730183833,
    "input_throughput": 5130.23347940051,
    "output_throughput": 4457.082665550997,
    "total_throughput": 9587.316144951506,
    "itl": 97.58005841285329,
    "ttft": 1454871.1885471486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.122065215073446,
    "arrivals": 126425,
    "finished_requests": 74508,
    "scheduler_time": 159.33621177752005
}
#Debug simulation 
Total elapsed time: 14.349070048891008. Arrivals time: 0.2910076631233096 Scheduler time: 13.886002990882844 Scheduler overhead time: 0.060499788261950016 Adapter cache time: 0.025297502987086773 Engine time: 0.059690133202821016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84805049 . Total output tokens: 74740231
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 43.80593262799084,
    "estimated_duration": 3600.0734904454876,
    "input_throughput": 5451.4545472713235,
    "output_throughput": 4735.122226043936,
    "total_throughput": 10186.57677331526,
    "itl": 110.08556198515136,
    "ttft": 1374297.154120623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.367044765418358,
    "arrivals": 126425,
    "finished_requests": 79207,
    "scheduler_time": 149.59578413383184
}
#Debug simulation 
Total elapsed time: 43.80610882397741. Arrivals time: 0.3518357751891017 Scheduler time: 43.28004102315754 Scheduler overhead time: 0.06300023151561618 Adapter cache time: 0.023560660891234875 Engine time: 0.06222680304199457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84805049 . Total output tokens: 74740231
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.648668235633522,
    "estimated_duration": 3600.059986392006,
    "input_throughput": 5148.764206725541,
    "output_throughput": 4472.895468649726,
    "total_throughput": 9621.659675375267,
    "itl": 98.00913329917917,
    "ttft": 1450696.6343521557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.643403964340584,
    "arrivals": 126425,
    "finished_requests": 74821,
    "scheduler_time": 158.87109939505956
}
#Debug simulation 
Total elapsed time: 13.648772711865604. Arrivals time: 0.2895446955226362 Scheduler time: 13.189193089026958 Scheduler overhead time: 0.059203567914664745 Adapter cache time: 0.025887372437864542 Engine time: 0.05868520447984338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36068376 . Total output tokens: 31888547
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.926362846978009,
    "estimated_duration": 3600.0376050517684,
    "input_throughput": 3708.385429437208,
    "output_throughput": 3182.3617575337116,
    "total_throughput": 6890.74718697092,
    "itl": 59.200778737925695,
    "ttft": 98228.9448146558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.91707962537465,
    "arrivals": 54189,
    "finished_requests": 53328,
    "scheduler_time": 41.089679740966666
}
#Debug simulation 
Total elapsed time: 7.926467219367623. Arrivals time: 0.15481761237606406 Scheduler time: 7.515399938914925 Scheduler overhead time: 0.07977245515212417 Adapter cache time: 0.06969704292714596 Engine time: 0.07251649536192417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36068376 . Total output tokens: 31888547
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.9473500438034534,
    "estimated_duration": 3600.034051561455,
    "input_throughput": 3706.1863329356447,
    "output_throughput": 3182.768228270022,
    "total_throughput": 6888.954561205666,
    "itl": 59.37340538699602,
    "ttft": 100119.31407921798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.76314444336448,
    "arrivals": 54189,
    "finished_requests": 53301,
    "scheduler_time": 41.12811067489651
}
#Debug simulation 
Total elapsed time: 7.947451341897249. Arrivals time: 0.161164038348943 Scheduler time: 7.525431508664042 Scheduler overhead time: 0.08230382576584816 Adapter cache time: 0.0702431253157556 Engine time: 0.07316167652606964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36068376 . Total output tokens: 31888547
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.8823702512308955,
    "estimated_duration": 3600.0555188460644,
    "input_throughput": 3706.1361776655717,
    "output_throughput": 3182.457864892137,
    "total_throughput": 6888.594042557708,
    "itl": 59.39454822612081,
    "ttft": 100475.67063317956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.91499621181698,
    "arrivals": 54189,
    "finished_requests": 53296,
    "scheduler_time": 41.1302806983589
}
#Debug simulation 
Total elapsed time: 7.882480521220714. Arrivals time: 0.15695548662915826 Scheduler time: 7.471311011351645 Scheduler overhead time: 0.07866971520707011 Adapter cache time: 0.06939940340816975 Engine time: 0.07230099570006132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36068376 . Total output tokens: 31888547
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.917577226180583,
    "estimated_duration": 3600.014672557762,
    "input_throughput": 3707.1235019489686,
    "output_throughput": 3182.184808113776,
    "total_throughput": 6889.308310062745,
    "itl": 59.24049301830745,
    "ttft": 99346.03636888102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.251559894155996,
    "arrivals": 54189,
    "finished_requests": 53311,
    "scheduler_time": 41.09943778447678
}
#Debug simulation 
Total elapsed time: 7.917682622093707. Arrivals time: 0.15661302534863353 Scheduler time: 7.505150593351573 Scheduler overhead time: 0.07949677994474769 Adapter cache time: 0.07000114768743515 Engine time: 0.07259010430425406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36068376 . Total output tokens: 31888547
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.914636764675379,
    "estimated_duration": 3600.052139739558,
    "input_throughput": 3706.161044924544,
    "output_throughput": 3182.872234964062,
    "total_throughput": 6889.033279888606,
    "itl": 59.39461678805346,
    "ttft": 100309.17867566137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.551919022197374,
    "arrivals": 54189,
    "finished_requests": 53299,
    "scheduler_time": 41.12737101428324
}
#Debug simulation 
Total elapsed time: 7.914734605699778. Arrivals time: 0.1565880519337952 Scheduler time: 7.502907443325967 Scheduler overhead time: 0.07920940453186631 Adapter cache time: 0.06961720017716289 Engine time: 0.07248797221109271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36068376 . Total output tokens: 31888547
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.907793721649796,
    "estimated_duration": 3600.05387017654,
    "input_throughput": 3705.1823336593256,
    "output_throughput": 3180.7704587038493,
    "total_throughput": 6885.952792363175,
    "itl": 59.15900861861895,
    "ttft": 100298.08664705454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.705269820614646,
    "arrivals": 54189,
    "finished_requests": 53296,
    "scheduler_time": 41.06957923374713
}
#Debug simulation 
Total elapsed time: 7.907896678894758. Arrivals time: 0.15583794889971614 Scheduler time: 7.496740844100714 Scheduler overhead time: 0.07903805049136281 Adapter cache time: 0.06982833100482821 Engine time: 0.0724602472037077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36068376 . Total output tokens: 31888547
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.906573844142258,
    "estimated_duration": 3600.0043236600136,
    "input_throughput": 3706.111937786669,
    "output_throughput": 3182.313400210778,
    "total_throughput": 6888.425337997447,
    "itl": 59.347820861950666,
    "ttft": 99855.72311483443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.053823163639386,
    "arrivals": 54189,
    "finished_requests": 53305,
    "scheduler_time": 41.124910772351754
}
#Debug simulation 
Total elapsed time: 7.906678987201303. Arrivals time: 0.15715329023078084 Scheduler time: 7.492902992293239 Scheduler overhead time: 0.07947720913216472 Adapter cache time: 0.06979416171088815 Engine time: 0.07348880311474204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33502728 . Total output tokens: 29594734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.693568110931665,
    "estimated_duration": 3599.9368261991985,
    "input_throughput": 3424.7628764688193,
    "output_throughput": 3014.695958278318,
    "total_throughput": 6439.458834747137,
    "itl": 56.57908575179426,
    "ttft": 73994.91237494884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.55390459294821,
    "arrivals": 50289,
    "finished_requests": 49700,
    "scheduler_time": 36.72820605826992
}
#Debug simulation 
Total elapsed time: 6.693673378787935. Arrivals time: 0.13985492382198572 Scheduler time: 6.291056097019464 Scheduler overhead time: 0.08111209003254771 Adapter cache time: 0.07371936086565256 Engine time: 0.07326468266546726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33502728 . Total output tokens: 29594734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.733226023148745,
    "estimated_duration": 3599.8963917314168,
    "input_throughput": 3424.4299442381684,
    "output_throughput": 3014.2103603101605,
    "total_throughput": 6438.640304548329,
    "itl": 56.715457204968615,
    "ttft": 75425.88252107674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.61835329735507,
    "arrivals": 50289,
    "finished_requests": 49683,
    "scheduler_time": 36.77496318664757
}
#Debug simulation 
Total elapsed time: 6.73331597680226. Arrivals time: 0.14289211900904775 Scheduler time: 6.326733393594623 Scheduler overhead time: 0.08083966979756951 Adapter cache time: 0.07400422124192119 Engine time: 0.0741912187077105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33502728 . Total output tokens: 29594734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.753701016772538,
    "estimated_duration": 3599.903759556524,
    "input_throughput": 3424.2590422802236,
    "output_throughput": 3014.5455892234404,
    "total_throughput": 6438.804631503664,
    "itl": 56.73516706887537,
    "ttft": 74539.1717750068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.75371241167518,
    "arrivals": 50289,
    "finished_requests": 49696,
    "scheduler_time": 36.78800730818292
}
#Debug simulation 
Total elapsed time: 6.7537913848645985. Arrivals time: 0.14172496367245913 Scheduler time: 6.348382263910025 Scheduler overhead time: 0.0812093848362565 Adapter cache time: 0.0739504941739142 Engine time: 0.07392401527613401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33502728 . Total output tokens: 29594734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.74148977920413,
    "estimated_duration": 3599.90657731427,
    "input_throughput": 3423.840795667401,
    "output_throughput": 3014.2376661606113,
    "total_throughput": 6438.078461828012,
    "itl": 56.641629197298265,
    "ttft": 74930.68898484373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.83968261502818,
    "arrivals": 50289,
    "finished_requests": 49690,
    "scheduler_time": 36.77200931831598
}
#Debug simulation 
Total elapsed time: 6.7415834669955075. Arrivals time: 0.14149545598775148 Scheduler time: 6.335971829015762 Scheduler overhead time: 0.08142491616308689 Adapter cache time: 0.07404706813395023 Engine time: 0.073879549279809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33502728 . Total output tokens: 29594734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.689472004305571,
    "estimated_duration": 3599.9505289191166,
    "input_throughput": 3424.5631713449,
    "output_throughput": 3013.825860339696,
    "total_throughput": 6438.389031684596,
    "itl": 56.72270891169344,
    "ttft": 74118.00274713128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.38290996220299,
    "arrivals": 50289,
    "finished_requests": 49701,
    "scheduler_time": 36.77674804803456
}
#Debug simulation 
Total elapsed time: 6.689564077183604. Arrivals time: 0.14278824115172029 Scheduler time: 6.282329560723156 Scheduler overhead time: 0.08105153497308493 Adapter cache time: 0.07509545795619488 Engine time: 0.07354408130049706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33502728 . Total output tokens: 29594734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.741660131141543,
    "estimated_duration": 3599.9110469825255,
    "input_throughput": 3425.165466334328,
    "output_throughput": 3015.2178368680366,
    "total_throughput": 6440.383303202365,
    "itl": 56.545801228004976,
    "ttft": 73398.69910051463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.05044439347405,
    "arrivals": 50289,
    "finished_requests": 49709,
    "scheduler_time": 36.74085879545406
}
#Debug simulation 
Total elapsed time: 6.741750240325928. Arrivals time: 0.14003812102600932 Scheduler time: 6.337977246847004 Scheduler overhead time: 0.08137896284461021 Adapter cache time: 0.0738772670738399 Engine time: 0.07364009413868189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33502728 . Total output tokens: 29594734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.7593946708366275,
    "estimated_duration": 3599.919432835381,
    "input_throughput": 3423.4324489571327,
    "output_throughput": 3013.626888714901,
    "total_throughput": 6437.0593376720335,
    "itl": 56.73234458724541,
    "ttft": 75399.26540060122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.95712891606493,
    "arrivals": 50289,
    "finished_requests": 49684,
    "scheduler_time": 36.78096538325622
}
#Debug simulation 
Total elapsed time: 6.759486418683082. Arrivals time: 0.14279020763933659 Scheduler time: 6.35240225866437 Scheduler overhead time: 0.0814911425113678 Adapter cache time: 0.07460612943395972 Engine time: 0.07345883548259735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32196992 . Total output tokens: 28441169
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.913561501074582,
    "estimated_duration": 3600.0286530208605,
    "input_throughput": 3285.1105199054846,
    "output_throughput": 2877.372098499233,
    "total_throughput": 6162.482618404717,
    "itl": 54.522609102996626,
    "ttft": 62358.52218122125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.66173683796561,
    "arrivals": 48457,
    "finished_requests": 47941,
    "scheduler_time": 33.33450552284835
}
#Debug simulation 
Total elapsed time: 5.9136545630171895. Arrivals time: 0.13691168325021863 Scheduler time: 5.5034842560999095 Scheduler overhead time: 0.08368983445689082 Adapter cache time: 0.07841584086418152 Engine time: 0.07528100907802582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32196992 . Total output tokens: 28441169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.922033978160471,
    "estimated_duration": 3600.04096131741,
    "input_throughput": 3284.882901908,
    "output_throughput": 2877.544758882158,
    "total_throughput": 6162.427660790158,
    "itl": 54.641740513691914,
    "ttft": 62874.819915599044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.139350571365384,
    "arrivals": 48457,
    "finished_requests": 47936,
    "scheduler_time": 33.36383267171586
}
#Debug simulation 
Total elapsed time: 5.922124749049544. Arrivals time: 0.1368325217626989 Scheduler time: 5.511041695717722 Scheduler overhead time: 0.0837460970506072 Adapter cache time: 0.07897480437532067 Engine time: 0.07587067130953074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32196992 . Total output tokens: 28441169
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.985101546626538,
    "estimated_duration": 3600.0322900683154,
    "input_throughput": 3285.0658125001373,
    "output_throughput": 2876.529754627142,
    "total_throughput": 6161.5955671272795,
    "itl": 54.64127771090821,
    "ttft": 63522.08564501653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.731075386738404,
    "arrivals": 48457,
    "finished_requests": 47932,
    "scheduler_time": 33.3982536940849
}
#Debug simulation 
Total elapsed time: 5.98519522882998. Arrivals time: 0.1385033125989139 Scheduler time: 5.57295629568398 Scheduler overhead time: 0.0839987387880683 Adapter cache time: 0.07820348255336285 Engine time: 0.07575626345351338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32196992 . Total output tokens: 28441169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.948521912563592,
    "estimated_duration": 3600.027216998027,
    "input_throughput": 3284.972386920285,
    "output_throughput": 2878.173240212389,
    "total_throughput": 6163.145627132673,
    "itl": 54.58032675452784,
    "ttft": 62403.86263432553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.177982426804085,
    "arrivals": 48457,
    "finished_requests": 47941,
    "scheduler_time": 33.34223278511261
}
#Debug simulation 
Total elapsed time: 5.948617560788989. Arrivals time: 0.13696011435240507 Scheduler time: 5.535134464502335 Scheduler overhead time: 0.08508095238357782 Adapter cache time: 0.07931980863213539 Engine time: 0.07585369516164064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32196992 . Total output tokens: 28441169
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.950782432220876,
    "estimated_duration": 3600.0010878161993,
    "input_throughput": 3283.62956333738,
    "output_throughput": 2877.5194082743815,
    "total_throughput": 6161.148971611762,
    "itl": 54.66408888441718,
    "ttft": 62959.51222528926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.99925675410115,
    "arrivals": 48457,
    "finished_requests": 47932,
    "scheduler_time": 33.36613050497545
}
#Debug simulation 
Total elapsed time: 5.95087461033836. Arrivals time: 0.1419994505122304 Scheduler time: 5.535552009008825 Scheduler overhead time: 0.082837650552392 Adapter cache time: 0.07931454200297594 Engine time: 0.07547758985310793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32196992 . Total output tokens: 28441169
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.940006523858756,
    "estimated_duration": 3600.0385514588525,
    "input_throughput": 3284.62399248703,
    "output_throughput": 2877.640572988294,
    "total_throughput": 6162.264565475324,
    "itl": 54.48817006390509,
    "ttft": 62958.62018409419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.04450331460203,
    "arrivals": 48457,
    "finished_requests": 47934,
    "scheduler_time": 33.33162909267852
}
#Debug simulation 
Total elapsed time: 5.940103190019727. Arrivals time: 0.13905299501493573 Scheduler time: 5.527125031221658 Scheduler overhead time: 0.08384060487151146 Adapter cache time: 0.0788023960776627 Engine time: 0.07575485855340958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32196992 . Total output tokens: 28441169
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.866200155578554,
    "estimated_duration": 3600.0363261910006,
    "input_throughput": 3285.1471286438723,
    "output_throughput": 2877.4406870944467,
    "total_throughput": 6162.587815738319,
    "itl": 54.65750606586326,
    "ttft": 62165.01290848666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.779763609616026,
    "arrivals": 48457,
    "finished_requests": 47944,
    "scheduler_time": 33.35765069686367
}
#Debug simulation 
Total elapsed time: 5.866310523822904. Arrivals time: 0.13679106160998344 Scheduler time: 5.456676891073585 Scheduler overhead time: 0.0833048727363348 Adapter cache time: 0.07883738679811358 Engine time: 0.07505192700773478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31569138 . Total output tokens: 27889264
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.65405629016459,
    "estimated_duration": 3599.946874010531,
    "input_throughput": 3240.138926551803,
    "output_throughput": 2845.496713841237,
    "total_throughput": 6085.63564039304,
    "itl": 54.03839526301558,
    "ttft": 55079.46167275089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.82857329993967,
    "arrivals": 47448,
    "finished_requests": 47000,
    "scheduler_time": 32.300733628473786
}
#Debug simulation 
Total elapsed time: 5.654168915934861. Arrivals time: 0.1342537528835237 Scheduler time: 5.247880692128092 Scheduler overhead time: 0.08311076695099473 Adapter cache time: 0.07710808655247092 Engine time: 0.07588655967265368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31569138 . Total output tokens: 27889264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.596348690800369,
    "estimated_duration": 3599.9908446804043,
    "input_throughput": 3240.1418512594955,
    "output_throughput": 2844.4572338652924,
    "total_throughput": 6084.599085124788,
    "itl": 54.1467237708724,
    "ttft": 55166.966003656984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.96522839149307,
    "arrivals": 47448,
    "finished_requests": 47002,
    "scheduler_time": 32.35592735513448
}
#Debug simulation 
Total elapsed time: 5.596440031658858. Arrivals time: 0.13348502991721034 Scheduler time: 5.192212509922683 Scheduler overhead time: 0.08269363222643733 Adapter cache time: 0.0768292173743248 Engine time: 0.07545433100312948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31569138 . Total output tokens: 27889264
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.588571293279529,
    "estimated_duration": 3599.9494607175952,
    "input_throughput": 3239.6177022094266,
    "output_throughput": 2844.2271514442305,
    "total_throughput": 6083.844853653657,
    "itl": 54.17734374801649,
    "ttft": 55745.218149185166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.2364422993623,
    "arrivals": 47448,
    "finished_requests": 46995,
    "scheduler_time": 32.3676755228483
}
#Debug simulation 
Total elapsed time: 5.588665883988142. Arrivals time: 0.13369173184037209 Scheduler time: 5.1831838162615895 Scheduler overhead time: 0.08314806595444679 Adapter cache time: 0.07716615963727236 Engine time: 0.07569421175867319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31569138 . Total output tokens: 27889264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.704750603064895,
    "estimated_duration": 3599.9731267364773,
    "input_throughput": 3239.1861243061994,
    "output_throughput": 2844.147619869024,
    "total_throughput": 6083.333744175223,
    "itl": 54.066768303590784,
    "ttft": 55733.68915502951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.11907311003331,
    "arrivals": 47448,
    "finished_requests": 46995,
    "scheduler_time": 32.33817617292722
}
#Debug simulation 
Total elapsed time: 5.704870970919728. Arrivals time: 0.13454975374042988 Scheduler time: 5.297348093241453 Scheduler overhead time: 0.08347281627357006 Adapter cache time: 0.07723826682195067 Engine time: 0.07626756280660629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31569138 . Total output tokens: 27889264
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.591154922731221,
    "estimated_duration": 3599.949965737333,
    "input_throughput": 3239.996419675528,
    "output_throughput": 2844.4812004220926,
    "total_throughput": 6084.477620097621,
    "itl": 54.17848371605679,
    "ttft": 55050.54567255588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.974920050667684,
    "arrivals": 47448,
    "finished_requests": 47003,
    "scheduler_time": 32.35383019096506
}
#Debug simulation 
Total elapsed time: 5.591245756950229. Arrivals time: 0.13444344699382782 Scheduler time: 5.1836608978919685 Scheduler overhead time: 0.08350533153861761 Adapter cache time: 0.07760466821491718 Engine time: 0.07621666975319386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31569138 . Total output tokens: 27889264
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.565402285195887,
    "estimated_duration": 3599.976425533703,
    "input_throughput": 3240.02093937901,
    "output_throughput": 2844.8311292709936,
    "total_throughput": 6084.852068650004,
    "itl": 54.001347141701785,
    "ttft": 54721.982043474156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.31035240643632,
    "arrivals": 47448,
    "finished_requests": 47005,
    "scheduler_time": 32.30077243916621
}
#Debug simulation 
Total elapsed time: 5.565523906145245. Arrivals time: 0.13394919922575355 Scheduler time: 5.15850844187662 Scheduler overhead time: 0.08343866933137178 Adapter cache time: 0.07738570170477033 Engine time: 0.07619959907606244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31569138 . Total output tokens: 27889264
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.610897082369775,
    "estimated_duration": 3599.9797684793493,
    "input_throughput": 3240.1579314783617,
    "output_throughput": 2844.5554304672037,
    "total_throughput": 6084.713361945565,
    "itl": 54.16529312531771,
    "ttft": 54937.136816040125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.35049504523931,
    "arrivals": 47448,
    "finished_requests": 47005,
    "scheduler_time": 32.358979738424736
}
#Debug simulation 
Total elapsed time: 5.610990982037038. Arrivals time: 0.13480881368741393 Scheduler time: 5.205386297311634 Scheduler overhead time: 0.08287667436525226 Adapter cache time: 0.07704479107633233 Engine time: 0.07531157787889242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28375723 . Total output tokens: 25069662
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.7859515910968184,
    "estimated_duration": 3599.82788439643,
    "input_throughput": 2933.7163717677863,
    "output_throughput": 2542.4848892559116,
    "total_throughput": 5476.201261023698,
    "itl": 50.27481556656485,
    "ttft": 44672.23858745754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.5147337599049,
    "arrivals": 42675,
    "finished_requests": 42351,
    "scheduler_time": 26.439201133294926
}
#Debug simulation 
Total elapsed time: 4.7860411000438035. Arrivals time: 0.11662898305803537 Scheduler time: 4.374728221911937 Scheduler overhead time: 0.0827082647010684 Adapter cache time: 0.0966893071308732 Engine time: 0.07828920241445303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28375723 . Total output tokens: 25069662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.788951680995524,
    "estimated_duration": 3599.8406969501766,
    "input_throughput": 2933.925106449281,
    "output_throughput": 2543.047532007693,
    "total_throughput": 5476.972638456974,
    "itl": 50.41615608133538,
    "ttft": 44341.91202236318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.58015930951352,
    "arrivals": 42675,
    "finished_requests": 42356,
    "scheduler_time": 26.483836212006768
}
#Debug simulation 
Total elapsed time: 4.789070555008948. Arrivals time: 0.11648553377017379 Scheduler time: 4.3780934708192945 Scheduler overhead time: 0.0824835691601038 Adapter cache time: 0.09646040061488748 Engine time: 0.0784605098888278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28375723 . Total output tokens: 25069662
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.797288144938648,
    "estimated_duration": 3599.8528928467495,
    "input_throughput": 2933.9382231388386,
    "output_throughput": 2542.633899898548,
    "total_throughput": 5476.5721230373865,
    "itl": 50.44226140420844,
    "ttft": 44741.68483291196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.99587062839427,
    "arrivals": 42675,
    "finished_requests": 42352,
    "scheduler_time": 26.497680855254725
}
#Debug simulation 
Total elapsed time: 4.797377540264279. Arrivals time: 0.11556476633995771 Scheduler time: 4.388515304774046 Scheduler overhead time: 0.08251381246373057 Adapter cache time: 0.09582695830613375 Engine time: 0.07779421843588352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28375723 . Total output tokens: 25069662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.780700888019055,
    "estimated_duration": 3599.8723121338994,
    "input_throughput": 2933.9379522990002,
    "output_throughput": 2542.417121060257,
    "total_throughput": 5476.355073359257,
    "itl": 50.32330267265725,
    "ttft": 44357.177164791516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.72751538935325,
    "arrivals": 42675,
    "finished_requests": 42355,
    "scheduler_time": 26.452128537337597
}
#Debug simulation 
Total elapsed time: 4.780790075194091. Arrivals time: 0.11600319994613528 Scheduler time: 4.368859950918704 Scheduler overhead time: 0.08259450318291783 Adapter cache time: 0.09761718334630132 Engine time: 0.07868609577417374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28375723 . Total output tokens: 25069662
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.782232588622719,
    "estimated_duration": 3599.8445900337992,
    "input_throughput": 2933.575251897429,
    "output_throughput": 2542.356974336514,
    "total_throughput": 5475.932226233944,
    "itl": 50.43964159246748,
    "ttft": 45060.27749087545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.55633619406706,
    "arrivals": 42675,
    "finished_requests": 42348,
    "scheduler_time": 26.490036868342898
}
#Debug simulation 
Total elapsed time: 4.782317440025508. Arrivals time: 0.11611535353586078 Scheduler time: 4.37084817700088 Scheduler overhead time: 0.08226514467969537 Adapter cache time: 0.09754296625033021 Engine time: 0.07862856471911073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28375723 . Total output tokens: 25069662
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.784333524759859,
    "estimated_duration": 3599.8317975431405,
    "input_throughput": 2933.7712409807214,
    "output_throughput": 2542.3187845182433,
    "total_throughput": 5476.090025498965,
    "itl": 50.227262251953555,
    "ttft": 44402.35479190972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.71886196930594,
    "arrivals": 42675,
    "finished_requests": 42353,
    "scheduler_time": 26.418516273893246
}
#Debug simulation 
Total elapsed time: 4.784418812021613. Arrivals time: 0.11549772508442402 Scheduler time: 4.373032716102898 Scheduler overhead time: 0.08234781352803111 Adapter cache time: 0.09726315131410956 Engine time: 0.07924690190702677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28375723 . Total output tokens: 25069662
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.798389067873359,
    "estimated_duration": 3599.8691590061458,
    "input_throughput": 2933.642177960605,
    "output_throughput": 2542.327955754565,
    "total_throughput": 5475.97013371517,
    "itl": 50.416839366804155,
    "ttft": 45021.35847965274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.9107575818659,
    "arrivals": 42675,
    "finished_requests": 42349,
    "scheduler_time": 26.491831931521556
}
#Debug simulation 
Total elapsed time: 4.798496522009373. Arrivals time: 0.11579147912561893 Scheduler time: 4.3880501366220415 Scheduler overhead time: 0.08306514378637075 Adapter cache time: 0.09611655492335558 Engine time: 0.07804580125957727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27061878 . Total output tokens: 23909009
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.145444687921554,
    "estimated_duration": 3599.915353879857,
    "input_throughput": 2772.340463295537,
    "output_throughput": 2402.7676069320923,
    "total_throughput": 5175.1080702276295,
    "itl": 48.70934606243998,
    "ttft": 33404.780354704526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.90384712094572,
    "arrivals": 40673,
    "finished_requests": 40425,
    "scheduler_time": 23.25586999757564
}
#Debug simulation 
Total elapsed time: 4.145534716080874. Arrivals time: 0.11001001112163067 Scheduler time: 3.73354945005849 Scheduler overhead time: 0.08266513189300895 Adapter cache time: 0.10285095777362585 Engine time: 0.0788007415831089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27061878 . Total output tokens: 23909009
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.089970081113279,
    "estimated_duration": 3599.904360679385,
    "input_throughput": 2771.5727975942773,
    "output_throughput": 2402.1577057586082,
    "total_throughput": 5173.7305033528855,
    "itl": 48.820066920788186,
    "ttft": 34622.61643159366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.10622756850795,
    "arrivals": 40673,
    "finished_requests": 40416,
    "scheduler_time": 23.32870790763004
}
#Debug simulation 
Total elapsed time: 4.090053531341255. Arrivals time: 0.10757032688707113 Scheduler time: 3.685540818143636 Scheduler overhead time: 0.08223376702517271 Adapter cache time: 0.09977690130472183 Engine time: 0.07765663601458073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27061878 . Total output tokens: 23909009
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.166236446239054,
    "estimated_duration": 3599.8959451414016,
    "input_throughput": 2772.0245673956642,
    "output_throughput": 2402.6091675436655,
    "total_throughput": 5174.63373493933,
    "itl": 48.869597652787284,
    "ttft": 34017.97521225819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.95213425978773,
    "arrivals": 40673,
    "finished_requests": 40423,
    "scheduler_time": 23.344231483686467
}
#Debug simulation 
Total elapsed time: 4.166338729206473. Arrivals time: 0.108574487734586 Scheduler time: 3.7557656951248646 Scheduler overhead time: 0.08363954164087772 Adapter cache time: 0.10159445833414793 Engine time: 0.07876084418967366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27061878 . Total output tokens: 23909009
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.123067034874111,
    "estimated_duration": 3599.9094715382207,
    "input_throughput": 2772.2777694561373,
    "output_throughput": 2403.069596165025,
    "total_throughput": 5175.347365621162,
    "itl": 48.757107341521085,
    "ttft": 32979.10394108335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.16725851379532,
    "arrivals": 40673,
    "finished_requests": 40430,
    "scheduler_time": 23.272635962300004
}
#Debug simulation 
Total elapsed time: 4.1231506005860865. Arrivals time: 0.10927931685000658 Scheduler time: 3.7116995425894856 Scheduler overhead time: 0.08275588974356651 Adapter cache time: 0.10300800716504455 Engine time: 0.07874144427478313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27061878 . Total output tokens: 23909009
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.173010724131018,
    "estimated_duration": 3599.871824357007,
    "input_throughput": 2772.0495303419334,
    "output_throughput": 2402.8005501404164,
    "total_throughput": 5174.85008048235,
    "itl": 48.85416573806351,
    "ttft": 34100.593871524965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.30375561428444,
    "arrivals": 40673,
    "finished_requests": 40422,
    "scheduler_time": 23.339704018732572
}
#Debug simulation 
Total elapsed time: 4.173098587896675. Arrivals time: 0.11448871903121471 Scheduler time: 3.758018194232136 Scheduler overhead time: 0.08307330682873726 Adapter cache time: 0.10112886223942041 Engine time: 0.07900209538638592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27061878 . Total output tokens: 23909009
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.177754120901227,
    "estimated_duration": 3599.9086373046107,
    "input_throughput": 2771.8467342746803,
    "output_throughput": 2402.2745773001243,
    "total_throughput": 5174.121311574805,
    "itl": 48.63739664930948,
    "ttft": 34249.3828187581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.48537532424306,
    "arrivals": 40673,
    "finished_requests": 40421,
    "scheduler_time": 23.293800110876223
}
#Debug simulation 
Total elapsed time: 4.177848183084279. Arrivals time: 0.11186000052839518 Scheduler time: 3.763631626497954 Scheduler overhead time: 0.08331255568191409 Adapter cache time: 0.10271128918975592 Engine time: 0.07887181267142296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27061878 . Total output tokens: 23909009
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.1494483929127455,
    "estimated_duration": 3599.907300905759,
    "input_throughput": 2771.935543309489,
    "output_throughput": 2402.501586033594,
    "total_throughput": 5174.437129343083,
    "itl": 48.83728401476043,
    "ttft": 34089.171721070496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.7819475639022,
    "arrivals": 40673,
    "finished_requests": 40422,
    "scheduler_time": 23.336936626298158
}
#Debug simulation 
Total elapsed time: 4.149537176825106. Arrivals time: 0.1132103418931365 Scheduler time: 3.73486066237092 Scheduler overhead time: 0.08383701229467988 Adapter cache time: 0.10126451589167118 Engine time: 0.07870198972523212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26446272 . Total output tokens: 23344421
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.8909173142164946,
    "estimated_duration": 3599.9328542006806,
    "input_throughput": 2730.1142543621786,
    "output_throughput": 2364.6407710262984,
    "total_throughput": 5094.7550253884765,
    "itl": 48.3601516833951,
    "ttft": 29283.393133421316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.97658362029719,
    "arrivals": 39791,
    "finished_requests": 39567,
    "scheduler_time": 22.278764898371797
}
#Debug simulation 
Total elapsed time: 3.8910070722922683. Arrivals time: 0.10674457810819149 Scheduler time: 3.48137995461002 Scheduler overhead time: 0.08228755835443735 Adapter cache time: 0.10333962086588144 Engine time: 0.07958622928708792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26446272 . Total output tokens: 23344421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.861580351833254,
    "estimated_duration": 3599.952619052047,
    "input_throughput": 2730.2789897796424,
    "output_throughput": 2364.588899017654,
    "total_throughput": 5094.8678887972965,
    "itl": 48.49226498126799,
    "ttft": 29338.691452355473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.55044826583413,
    "arrivals": 39791,
    "finished_requests": 39567,
    "scheduler_time": 22.31880206290446
}
#Debug simulation 
Total elapsed time: 3.8616642029955983. Arrivals time: 0.10465920018032193 Scheduler time: 3.458109898958355 Scheduler overhead time: 0.08122440334409475 Adapter cache time: 0.10170401586219668 Engine time: 0.0786037603393197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26446272 . Total output tokens: 23344421
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.9086443297564983,
    "estimated_duration": 3599.9431936392234,
    "input_throughput": 2729.7333517271118,
    "output_throughput": 2364.5020329876506,
    "total_throughput": 5094.235384714762,
    "itl": 48.52945549173612,
    "ttft": 29544.498062859067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.37708268893694,
    "arrivals": 39791,
    "finished_requests": 39565,
    "scheduler_time": 22.33023978748024
}
#Debug simulation 
Total elapsed time: 3.9087576759047806. Arrivals time: 0.10698331193998456 Scheduler time: 3.4993899455294013 Scheduler overhead time: 0.08316124835982919 Adapter cache time: 0.10290352394804358 Engine time: 0.07867000484839082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26446272 . Total output tokens: 23344421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.8717908007092774,
    "estimated_duration": 3599.902051884782,
    "input_throughput": 2729.8070498487336,
    "output_throughput": 2364.4929437853584,
    "total_throughput": 5094.299993634092,
    "itl": 48.40566290898547,
    "ttft": 29744.496524307986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.2613742091758,
    "arrivals": 39791,
    "finished_requests": 39562,
    "scheduler_time": 22.290644599619974
}
#Debug simulation 
Total elapsed time: 3.87187572196126. Arrivals time: 0.10703308507800102 Scheduler time: 3.4627687106840312 Scheduler overhead time: 0.08286544308066368 Adapter cache time: 0.10239548841491342 Engine time: 0.07914890395477414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26446272 . Total output tokens: 23344421
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.870378972031176,
    "estimated_duration": 3599.9248367237674,
    "input_throughput": 2729.4505984581374,
    "output_throughput": 2364.25158469304,
    "total_throughput": 5093.702183151177,
    "itl": 48.48875876342383,
    "ttft": 30402.84336653764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.47703382335801,
    "arrivals": 39791,
    "finished_requests": 39558,
    "scheduler_time": 22.34269652620144
}
#Debug simulation 
Total elapsed time: 3.870471783913672. Arrivals time: 0.10679685464128852 Scheduler time: 3.4631932443007827 Scheduler overhead time: 0.08321684552356601 Adapter cache time: 0.10077083017677069 Engine time: 0.07900376943871379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26446272 . Total output tokens: 23344421
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.8828098797239363,
    "estimated_duration": 3599.917803775387,
    "input_throughput": 2729.110645164329,
    "output_throughput": 2364.243147739114,
    "total_throughput": 5093.353792903444,
    "itl": 48.31078277611945,
    "ttft": 30327.32075399801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.90898969399048,
    "arrivals": 39791,
    "finished_requests": 39555,
    "scheduler_time": 22.257011429919988
}
#Debug simulation 
Total elapsed time: 3.882896021939814. Arrivals time: 0.10742249293252826 Scheduler time: 3.4718452505767345 Scheduler overhead time: 0.08340078825131059 Adapter cache time: 0.10296543966978788 Engine time: 0.07957876520231366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26446272 . Total output tokens: 23344421
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8442391003482044,
    "estimated_duration": 3599.9335817275805,
    "input_throughput": 2729.017293503899,
    "output_throughput": 2364.3305652087693,
    "total_throughput": 5093.347858712668,
    "itl": 48.501015125709614,
    "ttft": 30179.319134317848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.93790345586582,
    "arrivals": 39791,
    "finished_requests": 39558,
    "scheduler_time": 22.323475009268925
}
#Debug simulation 
Total elapsed time: 3.844325417187065. Arrivals time: 0.10639470163732767 Scheduler time: 3.437672993633896 Scheduler overhead time: 0.0820147767663002 Adapter cache time: 0.10239151492714882 Engine time: 0.07849346101284027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24537569 . Total output tokens: 21616538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.3642849093303084,
    "estimated_duration": 3600.0433850411196,
    "input_throughput": 2541.3252068059455,
    "output_throughput": 2208.730326151105,
    "total_throughput": 4750.055532957051,
    "itl": 46.78008178529522,
    "ttft": 23700.93613119607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.14290877475014,
    "arrivals": 36981,
    "finished_requests": 36790,
    "scheduler_time": 19.081404137081645
}
#Debug simulation 
Total elapsed time: 3.3643657602369785. Arrivals time: 0.10037863301113248 Scheduler time: 2.948132347781211 Scheduler overhead time: 0.08338848268613219 Adapter cache time: 0.11379314493387938 Engine time: 0.08034777641296387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24537569 . Total output tokens: 21616538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.4369877981953323,
    "estimated_duration": 3600.024301392281,
    "input_throughput": 2541.2922897386575,
    "output_throughput": 2208.6800905551936,
    "total_throughput": 4749.972380293851,
    "itl": 46.91630844120865,
    "ttft": 23959.2053729604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.28065968326466,
    "arrivals": 36981,
    "finished_requests": 36788,
    "scheduler_time": 19.127157673961648
}
#Debug simulation 
Total elapsed time: 3.437079519033432. Arrivals time: 0.10141488816589117 Scheduler time: 3.0188762550242245 Scheduler overhead time: 0.08416841272264719 Adapter cache time: 0.11272106319665909 Engine time: 0.08111903723329306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24537569 . Total output tokens: 21616538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.4415275882929564,
    "estimated_duration": 3600.022060304697,
    "input_throughput": 2541.2844273586697,
    "output_throughput": 2208.7370207189797,
    "total_throughput": 4750.021448077649,
    "itl": 46.958084835597575,
    "ttft": 23974.671681135544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 80.41654261180385,
    "arrivals": 36981,
    "finished_requests": 36788,
    "scheduler_time": 19.14147686092595
}
#Debug simulation 
Total elapsed time: 3.441635755356401. Arrivals time: 0.0994473253376782 Scheduler time: 3.026822855696082 Scheduler overhead time: 0.08389513893052936 Adapter cache time: 0.11202117474749684 Engine time: 0.08090080693364143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24537569 . Total output tokens: 21616538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.374964265152812,
    "estimated_duration": 3600.0481956640674,
    "input_throughput": 2540.843206215107,
    "output_throughput": 2208.372379451851,
    "total_throughput": 4749.215585666958,
    "itl": 46.81888423474334,
    "ttft": 24199.50803285794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.35044452395223,
    "arrivals": 36981,
    "finished_requests": 36785,
    "scheduler_time": 19.09349807919404
}
#Debug simulation 
Total elapsed time: 3.375082751736045. Arrivals time: 0.09858374670147896 Scheduler time: 2.9625315368175507 Scheduler overhead time: 0.08333900943398476 Adapter cache time: 0.11166058061644435 Engine time: 0.0803670734167099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24537569 . Total output tokens: 21616538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.3673379360698164,
    "estimated_duration": 3600.038026723074,
    "input_throughput": 2541.3273226804613,
    "output_throughput": 2208.709725001927,
    "total_throughput": 4750.037047682388,
    "itl": 46.94362040338221,
    "ttft": 23963.493111993797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.72728834482537,
    "arrivals": 36981,
    "finished_requests": 36788,
    "scheduler_time": 19.136262032236612
}
#Debug simulation 
Total elapsed time: 3.3674189089797437. Arrivals time: 0.09843960218131542 Scheduler time: 2.9543287535198033 Scheduler overhead time: 0.08455103822052479 Adapter cache time: 0.11165129626169801 Engine time: 0.08022357802838087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24537569 . Total output tokens: 21616538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.4600946470163763,
    "estimated_duration": 3600.0023066001036,
    "input_throughput": 2541.4372605334866,
    "output_throughput": 2208.8941402679297,
    "total_throughput": 4750.331400801417,
    "itl": 46.74002655946976,
    "ttft": 23377.08720523286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.97826576286717,
    "arrivals": 36981,
    "finished_requests": 36792,
    "scheduler_time": 19.06579357560395
}
#Debug simulation 
Total elapsed time: 3.4601896391250193. Arrivals time: 0.10078074084594846 Scheduler time: 3.0408591674640775 Scheduler overhead time: 0.0853766044601798 Adapter cache time: 0.11311412369832397 Engine time: 0.08102643769234419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24537569 . Total output tokens: 21616538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.3473449731245637,
    "estimated_duration": 3600.040485670758,
    "input_throughput": 2541.325864643821,
    "output_throughput": 2208.77682671906,
    "total_throughput": 4750.102691362881,
    "itl": 46.9259443890906,
    "ttft": 23867.029614654908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.87746570672964,
    "arrivals": 36981,
    "finished_requests": 36789,
    "scheduler_time": 19.1318129598961
}
#Debug simulation 
Total elapsed time: 3.347423352766782. Arrivals time: 0.09816502593457699 Scheduler time: 2.9380269832909107 Scheduler overhead time: 0.0827031983062625 Adapter cache time: 0.11076528672128916 Engine time: 0.079649165738374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23901750 . Total output tokens: 21061604
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.1536088353022933,
    "estimated_duration": 3600.027476928789,
    "input_throughput": 2480.5391228897674,
    "output_throughput": 2133.864546654391,
    "total_throughput": 4614.403669544158,
    "itl": 46.01223231372973,
    "ttft": 15026.075903125702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 74.91198192295869,
    "arrivals": 35945,
    "finished_requests": 35826,
    "scheduler_time": 17.5165909932191
}
#Debug simulation 
Total elapsed time: 3.153691517189145. Arrivals time: 0.0962624279782176 Scheduler time: 2.73707516817376 Scheduler overhead time: 0.08438478549942374 Adapter cache time: 0.1163188386708498 Engine time: 0.08059258619323373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23901750 . Total output tokens: 21061604
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.1305572357960045,
    "estimated_duration": 3599.996170745021,
    "input_throughput": 2480.482360666508,
    "output_throughput": 2133.71199181313,
    "total_throughput": 4614.194352479638,
    "itl": 46.18159131442868,
    "ttft": 15145.028362769244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 84.05501145069374,
    "arrivals": 35945,
    "finished_requests": 35824,
    "scheduler_time": 17.558961444146473
}
#Debug simulation 
Total elapsed time: 3.130638469941914. Arrivals time: 0.09628495899960399 Scheduler time: 2.715009380597621 Scheduler overhead time: 0.08348570531234145 Adapter cache time: 0.11665259255096316 Engine time: 0.08065031701698899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23901750 . Total output tokens: 21061604
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.118432390037924,
    "estimated_duration": 3600.0348376414813,
    "input_throughput": 2480.455718548046,
    "output_throughput": 2133.6890742513883,
    "total_throughput": 4614.144792799435,
    "itl": 46.22463320760916,
    "ttft": 15161.324649731998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 86.20016749351271,
    "arrivals": 35945,
    "finished_requests": 35824,
    "scheduler_time": 17.573003484599326
}
#Debug simulation 
Total elapsed time: 3.11853431398049. Arrivals time: 0.09552800189703703 Scheduler time: 2.704406715929508 Scheduler overhead time: 0.08358309417963028 Adapter cache time: 0.11700612399727106 Engine time: 0.07943183090537786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23901750 . Total output tokens: 21061604
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.1447032671421766,
    "estimated_duration": 3600.0067053516045,
    "input_throughput": 2480.4751020950816,
    "output_throughput": 2133.705747986872,
    "total_throughput": 4614.180850081953,
    "itl": 46.05034386992436,
    "ttft": 15243.578951461375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 77.12339866592794,
    "arrivals": 35945,
    "finished_requests": 35824,
    "scheduler_time": 17.530799608823173
}
#Debug simulation 
Total elapsed time: 3.1447855047881603. Arrivals time: 0.09478378901258111 Scheduler time: 2.7297863480634987 Scheduler overhead time: 0.0846188273280859 Adapter cache time: 0.11632356839254498 Engine time: 0.08022678038105369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23901750 . Total output tokens: 21061604
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.1569998590275645,
    "estimated_duration": 3599.9944824661643,
    "input_throughput": 2480.483523931048,
    "output_throughput": 2133.7129924537867,
    "total_throughput": 4614.1965163848345,
    "itl": 46.208513252207645,
    "ttft": 15159.256862371009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.4352169261496,
    "arrivals": 35945,
    "finished_requests": 35824,
    "scheduler_time": 17.568269467488125
}
#Debug simulation 
Total elapsed time: 3.1570838489569724. Arrivals time: 0.09561219392344356 Scheduler time: 2.741156690288335 Scheduler overhead time: 0.08430976374074817 Adapter cache time: 0.11713181668892503 Engine time: 0.08010710682719946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23901750 . Total output tokens: 21061604
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.072140436153859,
    "estimated_duration": 3600.014935538366,
    "input_throughput": 2480.491097925011,
    "output_throughput": 2133.829480585535,
    "total_throughput": 4614.3205785105465,
    "itl": 45.9955599616127,
    "ttft": 14956.16862857735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 74.0662507524969,
    "arrivals": 35945,
    "finished_requests": 35825,
    "scheduler_time": 17.49305185081283
}
#Debug simulation 
Total elapsed time: 3.0722290547564626. Arrivals time: 0.09815173922106624 Scheduler time: 2.6530806282535195 Scheduler overhead time: 0.08352414146065712 Adapter cache time: 0.1186808617785573 Engine time: 0.07958984654396772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23901750 . Total output tokens: 21061604
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.104075293056667,
    "estimated_duration": 3600.0351315968983,
    "input_throughput": 2480.4771824654194,
    "output_throughput": 2133.8175098842744,
    "total_throughput": 4614.294692349694,
    "itl": 46.19351599805349,
    "ttft": 15050.764466392273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 84.72086080491938,
    "arrivals": 35945,
    "finished_requests": 35825,
    "scheduler_time": 17.563540520458126
}
#Debug simulation 
Total elapsed time: 3.1041503809392452. Arrivals time: 0.09415288269519806 Scheduler time: 2.688962099608034 Scheduler overhead time: 0.08346581039950252 Adapter cache time: 0.11654013069346547 Engine time: 0.08245269535109401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22597536 . Total output tokens: 19905812
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.7055561603046954,
    "estimated_duration": 3600.031325438886,
    "input_throughput": 2315.760960492099,
    "output_throughput": 2026.6076432294794,
    "total_throughput": 4342.368603721578,
    "itl": 44.71581858687552,
    "ttft": 11496.935328731695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.09102443114782,
    "arrivals": 34024,
    "finished_requests": 33924,
    "scheduler_time": 15.24913421398763
}
#Debug simulation 
Total elapsed time: 2.7056436422280967. Arrivals time: 0.08737467601895332 Scheduler time: 2.3005731785669923 Scheduler overhead time: 0.08227772917598486 Adapter cache time: 0.11982327839359641 Engine time: 0.07719356613233685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22597536 . Total output tokens: 19905812
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.7765122740529478,
    "estimated_duration": 3600.0404377680707,
    "input_throughput": 2315.7278769814434,
    "output_throughput": 2026.5786249121081,
    "total_throughput": 4342.306501893551,
    "itl": 44.882365262248854,
    "ttft": 11508.040835813175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 87.52608015808302,
    "arrivals": 34024,
    "finished_requests": 33924,
    "scheduler_time": 15.30727201719213
}
#Debug simulation 
Total elapsed time: 2.7765919668599963. Arrivals time: 0.0921964324079454 Scheduler time: 2.3599348342977464 Scheduler overhead time: 0.08474265318363905 Adapter cache time: 0.1194981699809432 Engine time: 0.07956474786624312 
