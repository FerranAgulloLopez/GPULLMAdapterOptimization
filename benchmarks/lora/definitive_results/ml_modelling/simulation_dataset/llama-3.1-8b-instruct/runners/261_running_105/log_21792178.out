INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:06 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238444611 . Total output tokens: 209454904
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.048134631942958,
    "estimated_duration": 3600.1405548783337,
    "input_throughput": 3728.2033285652083,
    "output_throughput": 3244.728871535621,
    "total_throughput": 6972.9322001008295,
    "itl": 132.884302145617,
    "ttft": 2175729.644176213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.734193419319848,
    "arrivals": 356416,
    "finished_requests": 54246,
    "scheduler_time": 114.37476444206582
}
#Debug simulation 
Total elapsed time: 5.048252026550472. Arrivals time: 0.19683689810335636 Scheduler time: 4.678914892021567 Scheduler overhead time: 0.041089669801294804 Adapter cache time: 0.06960238562896848 Engine time: 0.0426716823130846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238444611 . Total output tokens: 209454904
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.0666510090231895,
    "estimated_duration": 3600.095118875505,
    "input_throughput": 3731.152249164923,
    "output_throughput": 3246.9492094006614,
    "total_throughput": 6978.101458565584,
    "itl": 132.8266420026004,
    "ttft": 2175987.9683109196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.222118493212072,
    "arrivals": 356416,
    "finished_requests": 54283,
    "scheduler_time": 114.41752142513387
}
#Debug simulation 
Total elapsed time: 5.066764281131327. Arrivals time: 0.19023335864767432 Scheduler time: 4.704309002961963 Scheduler overhead time: 0.04156938847154379 Adapter cache time: 0.06956166727468371 Engine time: 0.041837722063064575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238444611 . Total output tokens: 209454904
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.05266630416736,
    "estimated_duration": 3600.103063959567,
    "input_throughput": 3732.279260144789,
    "output_throughput": 3248.2711723086763,
    "total_throughput": 6980.550432453465,
    "itl": 132.78845882589297,
    "ttft": 2175543.9967572396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.494661806902744,
    "arrivals": 356416,
    "finished_requests": 54299,
    "scheduler_time": 114.46970907203442
}
#Debug simulation 
Total elapsed time: 5.052780607249588. Arrivals time: 0.18946010572835803 Scheduler time: 4.690286634955555 Scheduler overhead time: 0.041922740172594786 Adapter cache time: 0.06964839203283191 Engine time: 0.0422282163053751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235229445 . Total output tokens: 206646451
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.678443039301783,
    "estimated_duration": 3600.0480988523796,
    "input_throughput": 3969.463631487434,
    "output_throughput": 3451.194167089229,
    "total_throughput": 7420.6577985766635,
    "itl": 150.48743825196382,
    "ttft": 2138498.2597882333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.137330510309354,
    "arrivals": 351637,
    "finished_requests": 57791,
    "scheduler_time": 109.57813620117423
}
#Debug simulation 
Total elapsed time: 5.6785360760986805. Arrivals time: 0.20235399017110467 Scheduler time: 5.33678386034444 Scheduler overhead time: 0.03757042530924082 Adapter cache time: 0.04644555039703846 Engine time: 0.03808494284749031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235229445 . Total output tokens: 206646451
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8916985066607594,
    "estimated_duration": 3600.090080737371,
    "input_throughput": 3745.918212479247,
    "output_throughput": 3254.107463222286,
    "total_throughput": 7000.025675701532,
    "itl": 133.54486500861606,
    "ttft": 2178109.4686290827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.087264563291708,
    "arrivals": 351637,
    "finished_requests": 54452,
    "scheduler_time": 114.21294300648088
}
#Debug simulation 
Total elapsed time: 4.891777649056166. Arrivals time: 0.19222422363236547 Scheduler time: 4.5328425243496895 Scheduler overhead time: 0.041263680439442396 Adapter cache time: 0.06485469080507755 Engine time: 0.04152502724900842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235229445 . Total output tokens: 206646451
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.906620466616005,
    "estimated_duration": 3600.0343624148786,
    "input_throughput": 3745.391194253861,
    "output_throughput": 3254.459213589527,
    "total_throughput": 6999.850407843388,
    "itl": 133.40979911205093,
    "ttft": 2178351.8934341655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.765630808282282,
    "arrivals": 351637,
    "finished_requests": 54453,
    "scheduler_time": 114.2798079737714
}
#Debug simulation 
Total elapsed time: 4.906727253925055. Arrivals time: 0.19185633398592472 Scheduler time: 4.547072219196707 Scheduler overhead time: 0.0413234937004745 Adapter cache time: 0.06491581350564957 Engine time: 0.042406377382576466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235229445 . Total output tokens: 206646451
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.932682637590915,
    "estimated_duration": 3600.087789906198,
    "input_throughput": 3747.074456856921,
    "output_throughput": 3256.5233639220414,
    "total_throughput": 7003.597820778963,
    "itl": 133.47020823138604,
    "ttft": 2177513.8777929666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.649708655077614,
    "arrivals": 351637,
    "finished_requests": 54488,
    "scheduler_time": 114.28070075084646
}
#Debug simulation 
Total elapsed time: 4.932771101593971. Arrivals time: 0.20131614012643695 Scheduler time: 4.563928234390914 Scheduler overhead time: 0.04132615961134434 Adapter cache time: 0.06526878662407398 Engine time: 0.041768782306462526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233600759 . Total output tokens: 205193568
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.414107113145292,
    "estimated_duration": 3600.0648570499143,
    "input_throughput": 3954.7712514454292,
    "output_throughput": 3446.8126249726492,
    "total_throughput": 7401.583876418078,
    "itl": 149.91213834086864,
    "ttft": 2132464.6928188372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.337229017443386,
    "arrivals": 349246,
    "finished_requests": 57688,
    "scheduler_time": 109.72292278156397
}
#Debug simulation 
Total elapsed time: 5.414192429278046. Arrivals time: 0.19610733725130558 Scheduler time: 5.081223645247519 Scheduler overhead time: 0.03755254531279206 Adapter cache time: 0.04404899291694164 Engine time: 0.03797048842534423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233600759 . Total output tokens: 205193568
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.777023373171687,
    "estimated_duration": 3600.1161809314863,
    "input_throughput": 3725.612265249074,
    "output_throughput": 3251.273684443007,
    "total_throughput": 6976.885949692081,
    "itl": 133.37130188505068,
    "ttft": 2170396.174524954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.61872626812142,
    "arrivals": 349246,
    "finished_requests": 54352,
    "scheduler_time": 114.26979133931184
}
#Debug simulation 
Total elapsed time: 4.7771039148792624. Arrivals time: 0.19257176015526056 Scheduler time: 4.419834319502115 Scheduler overhead time: 0.041067443788051605 Adapter cache time: 0.06284303590655327 Engine time: 0.04172126017510891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233600759 . Total output tokens: 205193568
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.771219271235168,
    "estimated_duration": 3600.0254542520497,
    "input_throughput": 3731.172229389342,
    "output_throughput": 3256.4189195255676,
    "total_throughput": 6987.591148914909,
    "itl": 133.53164172961067,
    "ttft": 2169921.4431895106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.10309125143619,
    "arrivals": 349246,
    "finished_requests": 54430,
    "scheduler_time": 114.24204681868115
}
#Debug simulation 
Total elapsed time: 4.771302573848516. Arrivals time: 0.18803937500342727 Scheduler time: 4.41866116411984 Scheduler overhead time: 0.04124291753396392 Adapter cache time: 0.06259218184277415 Engine time: 0.041681884322315454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233600759 . Total output tokens: 205193568
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.777103764936328,
    "estimated_duration": 3600.030394497643,
    "input_throughput": 3721.240804098653,
    "output_throughput": 3247.0661964039296,
    "total_throughput": 6968.307000502582,
    "itl": 132.58680129534426,
    "ttft": 2172313.667541553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.462299360131336,
    "arrivals": 349246,
    "finished_requests": 54275,
    "scheduler_time": 114.58257876744516
}
#Debug simulation 
Total elapsed time: 4.777224814053625. Arrivals time: 0.19133589090779424 Scheduler time: 4.420753381680697 Scheduler overhead time: 0.04163584532216191 Adapter cache time: 0.06222178973257542 Engine time: 0.04201102256774902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232827073 . Total output tokens: 204500855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.350816355086863,
    "estimated_duration": 3600.0840789500803,
    "input_throughput": 3958.111446151474,
    "output_throughput": 3451.5143889705523,
    "total_throughput": 7409.625835122027,
    "itl": 150.34756283791125,
    "ttft": 2129703.073265444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.914034839398576,
    "arrivals": 348063,
    "finished_requests": 57985,
    "scheduler_time": 109.64081574547815
}
#Debug simulation 
Total elapsed time: 5.3508970672264695. Arrivals time: 0.19717140309512615 Scheduler time: 5.014493245165795 Scheduler overhead time: 0.0375681072473526 Adapter cache time: 0.044184448197484016 Engine time: 0.040135386399924755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232827073 . Total output tokens: 204500855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.714805519208312,
    "estimated_duration": 3600.0633889393403,
    "input_throughput": 3735.5256136092985,
    "output_throughput": 3254.637414440656,
    "total_throughput": 6990.163028049955,
    "itl": 133.49156695822782,
    "ttft": 2170657.117222371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.390567188355487,
    "arrivals": 348063,
    "finished_requests": 54669,
    "scheduler_time": 114.22925845547068
}
#Debug simulation 
Total elapsed time: 4.714886031113565. Arrivals time: 0.19120157323777676 Scheduler time: 4.3583119488321245 Scheduler overhead time: 0.04131357651203871 Adapter cache time: 0.06303062289953232 Engine time: 0.041856692638248205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232827073 . Total output tokens: 204500855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.869479976128787,
    "estimated_duration": 3600.1330731210137,
    "input_throughput": 3738.571526838553,
    "output_throughput": 3257.7837434860185,
    "total_throughput": 6996.355270324571,
    "itl": 133.5756242866074,
    "ttft": 2169750.657139092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.027041384075304,
    "arrivals": 348063,
    "finished_requests": 54711,
    "scheduler_time": 114.23834018431475
}
#Debug simulation 
Total elapsed time: 4.869594797026366. Arrivals time: 0.19079166650772095 Scheduler time: 4.5133541519753635 Scheduler overhead time: 0.04128727177157998 Adapter cache time: 0.0628909058868885 Engine time: 0.042142539750784636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232827073 . Total output tokens: 204500855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.730273850262165,
    "estimated_duration": 3600.107902136451,
    "input_throughput": 3739.5079164184845,
    "output_throughput": 3259.097871215776,
    "total_throughput": 6998.60578763426,
    "itl": 133.47818003720073,
    "ttft": 2169571.926211396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.353772704141623,
    "arrivals": 348063,
    "finished_requests": 54735,
    "scheduler_time": 114.29432323434214
}
#Debug simulation 
Total elapsed time: 4.730397829320282. Arrivals time: 0.19394420087337494 Scheduler time: 4.3723738067783415 Scheduler overhead time: 0.04123926814645529 Adapter cache time: 0.06179904472082853 Engine time: 0.04183573927730322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225491827 . Total output tokens: 198093480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.2976574609056115,
    "estimated_duration": 3600.1272486151265,
    "input_throughput": 3934.6870323678263,
    "output_throughput": 3448.3847771701894,
    "total_throughput": 7383.071809538016,
    "itl": 150.5407527416426,
    "ttft": 2131257.7060095365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.843332040552493,
    "arrivals": 337149,
    "finished_requests": 57491,
    "scheduler_time": 109.44889546687072
}
#Debug simulation 
Total elapsed time: 5.297738098073751. Arrivals time: 0.19521272089332342 Scheduler time: 4.959208397660404 Scheduler overhead time: 0.03758236672729254 Adapter cache time: 0.0505978181026876 Engine time: 0.03785445401445031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225491827 . Total output tokens: 198093480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.655695409979671,
    "estimated_duration": 3600.002708380397,
    "input_throughput": 3706.3163783014934,
    "output_throughput": 3250.2900547161476,
    "total_throughput": 6956.6064330176405,
    "itl": 133.57477800642056,
    "ttft": 2172996.4523721784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.046637451904182,
    "arrivals": 337149,
    "finished_requests": 54140,
    "scheduler_time": 114.07079644575917
}
#Debug simulation 
Total elapsed time: 4.655789233278483. Arrivals time: 0.20621661096811295 Scheduler time: 4.279389813076705 Scheduler overhead time: 0.041294822469353676 Adapter cache time: 0.06808875454589725 Engine time: 0.04173205327242613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225491827 . Total output tokens: 198093480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.916176648810506,
    "estimated_duration": 3600.0664332730203,
    "input_throughput": 3708.7082273260503,
    "output_throughput": 3252.4372027642576,
    "total_throughput": 6961.145430090308,
    "itl": 133.5789090215048,
    "ttft": 2172888.3505444904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.567889306839216,
    "arrivals": 337149,
    "finished_requests": 54181,
    "scheduler_time": 114.09729756119464
}
#Debug simulation 
Total elapsed time: 4.916233850643039. Arrivals time: 0.19742784462869167 Scheduler time: 4.546918694395572 Scheduler overhead time: 0.04279826860874891 Adapter cache time: 0.06802816689014435 Engine time: 0.042036773171275854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225491827 . Total output tokens: 198093480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.642317429184914,
    "estimated_duration": 3600.137299640584,
    "input_throughput": 3710.0712801518594,
    "output_throughput": 3253.4300847829704,
    "total_throughput": 6963.50136493483,
    "itl": 133.53464188402435,
    "ttft": 2172368.7056590547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.264840653042175,
    "arrivals": 337149,
    "finished_requests": 54199,
    "scheduler_time": 114.13769679330876
}
#Debug simulation 
Total elapsed time: 4.642398758325726. Arrivals time: 0.18905186373740435 Scheduler time: 4.282003768719733 Scheduler overhead time: 0.041232443414628506 Adapter cache time: 0.06913801049813628 Engine time: 0.04176456946879625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222307840 . Total output tokens: 195309109
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.276203440967947,
    "estimated_duration": 3600.0401922554374,
    "input_throughput": 3969.3554062926632,
    "output_throughput": 3446.383189468476,
    "total_throughput": 7415.73859576114,
    "itl": 149.92169222411567,
    "ttft": 2126330.6684650504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.506099179923035,
    "arrivals": 332464,
    "finished_requests": 57665,
    "scheduler_time": 109.4958568767156
}
#Debug simulation 
Total elapsed time: 5.276305510196835. Arrivals time: 0.4456654079258442 Scheduler time: 4.687210779637098 Scheduler overhead time: 0.037906752433627844 Adapter cache time: 0.049961986020207405 Engine time: 0.03814049530774355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222307840 . Total output tokens: 195309109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.498535951133817,
    "estimated_duration": 3600.016498254916,
    "input_throughput": 3734.809828376497,
    "output_throughput": 3249.8678841253345,
    "total_throughput": 6984.677712501832,
    "itl": 133.25729388332215,
    "ttft": 2166996.16970989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.566993388947445,
    "arrivals": 332464,
    "finished_requests": 54351,
    "scheduler_time": 114.07121319617927
}
#Debug simulation 
Total elapsed time: 4.4986144453287125. Arrivals time: 0.18451663479208946 Scheduler time: 4.145143512170762 Scheduler overhead time: 0.04124060831964016 Adapter cache time: 0.06658639665693045 Engine time: 0.04198229033499956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222307840 . Total output tokens: 195309109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.49553254712373,
    "estimated_duration": 3600.144988295671,
    "input_throughput": 3736.7750587091477,
    "output_throughput": 3251.363497318866,
    "total_throughput": 6988.138556028014,
    "itl": 133.19341809279572,
    "ttft": 2167112.447792304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.97389185087815,
    "arrivals": 332464,
    "finished_requests": 54378,
    "scheduler_time": 114.12062292777837
}
#Debug simulation 
Total elapsed time: 4.495650461874902. Arrivals time: 0.2071382738649845 Scheduler time: 4.119676390662789 Scheduler overhead time: 0.04145009769126773 Adapter cache time: 0.06635350221768022 Engine time: 0.041809411719441414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222307840 . Total output tokens: 195309109
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.6859590001404285,
    "estimated_duration": 3600.022553948028,
    "input_throughput": 3736.801588991992,
    "output_throughput": 3251.4932405529,
    "total_throughput": 6988.294829544891,
    "itl": 133.05855034262805,
    "ttft": 2166966.982072773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.32002035383761,
    "arrivals": 332464,
    "finished_requests": 54381,
    "scheduler_time": 114.19281547646783
}
#Debug simulation 
Total elapsed time: 4.68605140876025. Arrivals time: 0.19467746512964368 Scheduler time: 4.323102913796902 Scheduler overhead time: 0.04146880377084017 Adapter cache time: 0.06550980266183615 Engine time: 0.04204367147758603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220693759 . Total output tokens: 193873324
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.82567359181121,
    "estimated_duration": 3600.0477713965397,
    "input_throughput": 3939.04078514463,
    "output_throughput": 3450.8778185409224,
    "total_throughput": 7389.918603685552,
    "itl": 150.48706691482414,
    "ttft": 2122119.3474326883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.049842956718475,
    "arrivals": 329992,
    "finished_requests": 57563,
    "scheduler_time": 109.36577479353053
}
#Debug simulation 
Total elapsed time: 4.8257805379107594. Arrivals time: 0.19740057922899723 Scheduler time: 4.4875874584540725 Scheduler overhead time: 0.03755138302221894 Adapter cache time: 0.0478049642406404 Engine time: 0.03801019862294197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220693759 . Total output tokens: 193873324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.403501246590167,
    "estimated_duration": 3600.1410263686003,
    "input_throughput": 3710.1254929096344,
    "output_throughput": 3254.838050558152,
    "total_throughput": 6964.963543467787,
    "itl": 133.55467777557857,
    "ttft": 2162832.8293731613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.67682350321149,
    "arrivals": 329992,
    "finished_requests": 54287,
    "scheduler_time": 113.99147336424161
}
#Debug simulation 
Total elapsed time: 4.403597477823496. Arrivals time: 0.19607815565541387 Scheduler time: 4.041184997651726 Scheduler overhead time: 0.04111653100699186 Adapter cache time: 0.06432666163891554 Engine time: 0.04177720518782735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220693759 . Total output tokens: 193873324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.529685602989048,
    "estimated_duration": 3600.0874252132876,
    "input_throughput": 3707.2991357173164,
    "output_throughput": 3252.6198997254232,
    "total_throughput": 6959.919035442739,
    "itl": 133.24877916010064,
    "ttft": 2162870.1784719336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.13340511169344,
    "arrivals": 329992,
    "finished_requests": 54251,
    "scheduler_time": 114.11935651061954
}
#Debug simulation 
Total elapsed time: 4.529766419902444. Arrivals time: 0.18913472536951303 Scheduler time: 4.173177295830101 Scheduler overhead time: 0.04117971891537309 Adapter cache time: 0.06463915249332786 Engine time: 0.04244480049237609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220693759 . Total output tokens: 193873324
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.354273681994528,
    "estimated_duration": 3600.0788538281513,
    "input_throughput": 3713.70782220044,
    "output_throughput": 3257.6503116117087,
    "total_throughput": 6971.3581338121485,
    "itl": 133.54424911891914,
    "ttft": 2162156.0566156623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.873145887997612,
    "arrivals": 329992,
    "finished_requests": 54332,
    "scheduler_time": 114.04107307363128
}
#Debug simulation 
Total elapsed time: 4.354353073053062. Arrivals time: 0.18636309169232845 Scheduler time: 4.000385396182537 Scheduler overhead time: 0.04096380854025483 Adapter cache time: 0.06577321095392108 Engine time: 0.0417947587557137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219903228 . Total output tokens: 193173845
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.689073990099132,
    "estimated_duration": 3600.0969234444583,
    "input_throughput": 3941.9580366247724,
    "output_throughput": 3448.371881088753,
    "total_throughput": 7390.329917713526,
    "itl": 150.26940373353847,
    "ttft": 2114741.607178491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.712610096089017,
    "arrivals": 328805,
    "finished_requests": 57781,
    "scheduler_time": 109.41897678174291
}
#Debug simulation 
Total elapsed time: 4.689153432846069. Arrivals time: 0.1921536042355001 Scheduler time: 4.356949468608946 Scheduler overhead time: 0.037632342893630266 Adapter cache time: 0.04727676045149565 Engine time: 0.03784719994291663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219903228 . Total output tokens: 193173845
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.278373369015753,
    "estimated_duration": 3600.1255025620167,
    "input_throughput": 3717.6551179883327,
    "output_throughput": 3251.728583258838,
    "total_throughput": 6969.383701247171,
    "itl": 133.24247906226515,
    "ttft": 2155535.189701029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2975,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.78248895455561,
    "arrivals": 328805,
    "finished_requests": 54480,
    "scheduler_time": 114.07869369903106
}
#Debug simulation 
Total elapsed time: 4.278517892118543. Arrivals time: 0.1851383913308382 Scheduler time: 3.9283038792200387 Scheduler overhead time: 0.04089858243241906 Adapter cache time: 0.06326730363070965 Engine time: 0.04182810103520751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219903228 . Total output tokens: 193173845
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.31018743198365,
    "estimated_duration": 3600.125579305513,
    "input_throughput": 3718.7086130986004,
    "output_throughput": 3252.9340274455426,
    "total_throughput": 6971.642640544143,
    "itl": 133.18271817129158,
    "ttft": 2154975.162624088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.422844482390715,
    "arrivals": 328805,
    "finished_requests": 54497,
    "scheduler_time": 114.12592015212188
}
#Debug simulation 
Total elapsed time: 4.3102685967460275. Arrivals time: 0.18557301862165332 Scheduler time: 3.958963204640895 Scheduler overhead time: 0.04135858081281185 Adapter cache time: 0.06320507964119315 Engine time: 0.04198218835517764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219903228 . Total output tokens: 193173845
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.303144074976444,
    "estimated_duration": 3600.1195090451733,
    "input_throughput": 3717.0560494946303,
    "output_throughput": 3251.0559637238807,
    "total_throughput": 6968.112013218511,
    "itl": 132.90634183970545,
    "ttft": 2155223.942493135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.113459296069617,
    "arrivals": 328805,
    "finished_requests": 54470,
    "scheduler_time": 114.24179838072253
}
#Debug simulation 
Total elapsed time: 4.303232970647514. Arrivals time: 0.19349406845867634 Scheduler time: 3.943722765892744 Scheduler overhead time: 0.04117718851193786 Adapter cache time: 0.0639264383353293 Engine time: 0.04178728349506855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215804199 . Total output tokens: 189677857
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.47106315754354,
    "estimated_duration": 3600.144178073855,
    "input_throughput": 3989.1191268022,
    "output_throughput": 3455.283839953148,
    "total_throughput": 7444.402966755348,
    "itl": 150.95683207207964,
    "ttft": 2109858.814000035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.39216199020425,
    "arrivals": 322791,
    "finished_requests": 58223,
    "scheduler_time": 109.1612307374616
}
#Debug simulation 
Total elapsed time: 4.471142438706011. Arrivals time: 0.19181693345308304 Scheduler time: 4.135984756052494 Scheduler overhead time: 0.0372202661819756 Adapter cache time: 0.050920776557177305 Engine time: 0.03788228612393141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215804199 . Total output tokens: 189677857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.25008680485189,
    "estimated_duration": 3600.1234233614696,
    "input_throughput": 3800.401094922759,
    "output_throughput": 3294.803428968171,
    "total_throughput": 7095.2045238909295,
    "itl": 132.76132409164768,
    "ttft": 2143329.6344510536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.03600471500259,
    "arrivals": 322791,
    "finished_requests": 55462,
    "scheduler_time": 114.90292684974987
}
#Debug simulation 
Total elapsed time: 4.2501954678446054. Arrivals time: 0.1895657703280449 Scheduler time: 3.897037081886083 Scheduler overhead time: 0.04068009648472071 Adapter cache time: 0.061867550015449524 Engine time: 0.04194737132638693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215804199 . Total output tokens: 189677857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.437987629324198,
    "estimated_duration": 3600.0879108899885,
    "input_throughput": 3797.467544791232,
    "output_throughput": 3292.6979266652233,
    "total_throughput": 7090.165471456455,
    "itl": 132.33335831630518,
    "ttft": 2144013.9805148244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.708308280590447,
    "arrivals": 322791,
    "finished_requests": 55422,
    "scheduler_time": 115.08704612310237
}
#Debug simulation 
Total elapsed time: 4.438081254251301. Arrivals time: 0.19982253666967154 Scheduler time: 4.07273471262306 Scheduler overhead time: 0.040996220894157887 Adapter cache time: 0.06305537465959787 Engine time: 0.04220630135387182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215804199 . Total output tokens: 189677857
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.257580713368952,
    "estimated_duration": 3600.028460261249,
    "input_throughput": 3802.7946587418155,
    "output_throughput": 3296.6050493775165,
    "total_throughput": 7099.399708119332,
    "itl": 132.66523887404648,
    "ttft": 2143019.6908939877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.485559456223914,
    "arrivals": 322791,
    "finished_requests": 55492,
    "scheduler_time": 114.97927695579537
}
#Debug simulation 
Total elapsed time: 4.257660506293178. Arrivals time: 0.18754748534411192 Scheduler time: 3.906417022459209 Scheduler overhead time: 0.04062266554683447 Adapter cache time: 0.06208612024784088 Engine time: 0.04187020333483815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214182989 . Total output tokens: 188215230
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.461030473001301,
    "estimated_duration": 3600.0510456517804,
    "input_throughput": 4012.3367187936183,
    "output_throughput": 3460.982314417211,
    "total_throughput": 7473.31903321083,
    "itl": 149.4483224768365,
    "ttft": 2107293.076386446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.342315190299809,
    "arrivals": 320386,
    "finished_requests": 58327,
    "scheduler_time": 109.61727461098228
}
#Debug simulation 
Total elapsed time: 4.461108566261828. Arrivals time: 0.19450972275808454 Scheduler time: 4.125994817819446 Scheduler overhead time: 0.03776648873463273 Adapter cache time: 0.04721303703263402 Engine time: 0.038180787581950426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214182989 . Total output tokens: 188215230
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.265795456245542,
    "estimated_duration": 3600.088621724019,
    "input_throughput": 3827.026622861893,
    "output_throughput": 3313.3237132056397,
    "total_throughput": 7140.350336067533,
    "itl": 130.69921549080115,
    "ttft": 2139573.235697715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.639068903126454,
    "arrivals": 320386,
    "finished_requests": 55721,
    "scheduler_time": 115.99072975405251
}
#Debug simulation 
Total elapsed time: 4.265875831246376. Arrivals time: 0.18832228472456336 Scheduler time: 3.91641405550763 Scheduler overhead time: 0.04082028614357114 Adapter cache time: 0.05891869077458978 Engine time: 0.04218490654602647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214182989 . Total output tokens: 188215230
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.454052804969251,
    "estimated_duration": 3600.029540794359,
    "input_throughput": 3830.4171795649413,
    "output_throughput": 3316.457508114098,
    "total_throughput": 7146.874687679039,
    "itl": 130.86055932365807,
    "ttft": 2139177.813990619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.572631864818128,
    "arrivals": 320386,
    "finished_requests": 55770,
    "scheduler_time": 115.93839624404549
}
#Debug simulation 
Total elapsed time: 4.4541951841674745. Arrivals time: 0.19218322401866317 Scheduler time: 4.099994569085538 Scheduler overhead time: 0.04144212603569031 Adapter cache time: 0.05883011221885681 Engine time: 0.04234714666381478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214182989 . Total output tokens: 188215230
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.281637008767575,
    "estimated_duration": 3600.0966000310473,
    "input_throughput": 3831.756625608611,
    "output_throughput": 3317.3570953337767,
    "total_throughput": 7149.113720942388,
    "itl": 130.82279333362814,
    "ttft": 2139050.420075704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.529804060739364,
    "arrivals": 320386,
    "finished_requests": 55789,
    "scheduler_time": 115.97368511112157
}
#Debug simulation 
Total elapsed time: 4.281721352599561. Arrivals time: 0.19142668088898063 Scheduler time: 3.929757120087743 Scheduler overhead time: 0.041001911740750074 Adapter cache time: 0.05813604034483433 Engine time: 0.042163715697824955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213417606 . Total output tokens: 187526555
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.41063242405653,
    "estimated_duration": 3600.1281991045944,
    "input_throughput": 4002.4702463606254,
    "output_throughput": 3487.9244031151743,
    "total_throughput": 7490.394649475799,
    "itl": 148.80316720728445,
    "ttft": 2106981.1157373125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.980158929718078,
    "arrivals": 319202,
    "finished_requests": 58290,
    "scheduler_time": 110.53188708038168
}
#Debug simulation 
Total elapsed time: 4.410708878189325. Arrivals time: 0.1936870370991528 Scheduler time: 4.0793119124136865 Scheduler overhead time: 0.03692898107692599 Adapter cache time: 0.04578257771208882 Engine time: 0.03783475561067462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213417606 . Total output tokens: 187526555
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.2870858372189105,
    "estimated_duration": 3600.0746983411314,
    "input_throughput": 3837.943419998103,
    "output_throughput": 3349.308558946308,
    "total_throughput": 7187.251978944411,
    "itl": 129.99977297298855,
    "ttft": 2136727.1986548696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.909696781113542,
    "arrivals": 319202,
    "finished_requests": 55908,
    "scheduler_time": 117.15562956974964
}
#Debug simulation 
Total elapsed time: 4.287196338176727. Arrivals time: 0.18941855244338512 Scheduler time: 3.9403148465789855 Scheduler overhead time: 0.04081725422292948 Adapter cache time: 0.05538688087835908 Engine time: 0.042043013498187065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213417606 . Total output tokens: 187526555
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.325946687255055,
    "estimated_duration": 3600.023707911529,
    "input_throughput": 3837.9269474354096,
    "output_throughput": 3349.5309971154047,
    "total_throughput": 7187.457944550814,
    "itl": 129.82828934327603,
    "ttft": 2136388.784677458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.042606379036062,
    "arrivals": 319202,
    "finished_requests": 55908,
    "scheduler_time": 117.24689983033828
}
#Debug simulation 
Total elapsed time: 4.326034743338823. Arrivals time: 0.19312462536618114 Scheduler time: 3.9741508178412914 Scheduler overhead time: 0.041037303395569324 Adapter cache time: 0.05598108051344752 Engine time: 0.042345205787569284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213417606 . Total output tokens: 187526555
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.295080271083862,
    "estimated_duration": 3600.101054723157,
    "input_throughput": 3840.4816392197663,
    "output_throughput": 3351.1295423699535,
    "total_throughput": 7191.611181589719,
    "itl": 129.92835754432144,
    "ttft": 2136471.435213722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.16136939178738,
    "arrivals": 319202,
    "finished_requests": 55939,
    "scheduler_time": 117.2147835987478
}
#Debug simulation 
Total elapsed time: 4.2951597310602665. Arrivals time: 0.18978289794176817 Scheduler time: 3.9474773760885 Scheduler overhead time: 0.04113482031971216 Adapter cache time: 0.05509121110662818 Engine time: 0.042361500672996044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210958209 . Total output tokens: 185390247
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.497423341032118,
    "estimated_duration": 3600.1256121350493,
    "input_throughput": 4114.698928856239,
    "output_throughput": 3577.759608326918,
    "total_throughput": 7692.458537183157,
    "itl": 144.5711667283445,
    "ttft": 2082819.3620083649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.959814238292386,
    "arrivals": 315552,
    "finished_requests": 59994,
    "scheduler_time": 113.39744692261115
}
#Debug simulation 
Total elapsed time: 4.49749972904101. Arrivals time: 0.1953611713834107 Scheduler time: 4.171020902693272 Scheduler overhead time: 0.03762522106990218 Adapter cache time: 0.037248002365231514 Engine time: 0.038649619091302156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210958209 . Total output tokens: 185390247
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.374745327979326,
    "estimated_duration": 3600.033459320506,
    "input_throughput": 3940.7042074208066,
    "output_throughput": 3427.8648072146566,
    "total_throughput": 7368.569014635464,
    "itl": 127.08972790123916,
    "ttft": 2115690.605110712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.512676206538403,
    "arrivals": 315552,
    "finished_requests": 57459,
    "scheduler_time": 119.6047829186062
}
#Debug simulation 
Total elapsed time: 4.374824620783329. Arrivals time: 0.1893946323543787 Scheduler time: 4.034289136528969 Scheduler overhead time: 0.042578399647027254 Adapter cache time: 0.04509173892438412 Engine time: 0.04365918971598148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210958209 . Total output tokens: 185390247
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.373177923262119,
    "estimated_duration": 3600.047396131486,
    "input_throughput": 3940.096459630592,
    "output_throughput": 3427.0837693019603,
    "total_throughput": 7367.180228932552,
    "itl": 126.91464794257604,
    "ttft": 2115710.7649624664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.889091136399674,
    "arrivals": 315552,
    "finished_requests": 57447,
    "scheduler_time": 119.69074764505062
}
#Debug simulation 
Total elapsed time: 4.373281456064433. Arrivals time: 0.18903363402932882 Scheduler time: 4.034974857233465 Scheduler overhead time: 0.041753999423235655 Adapter cache time: 0.04455225029960275 Engine time: 0.043212778866291046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210958209 . Total output tokens: 185390247
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.365240904968232,
    "estimated_duration": 3600.0249862870537,
    "input_throughput": 3939.2373814122266,
    "output_throughput": 3426.3137192060767,
    "total_throughput": 7365.551100618303,
    "itl": 126.76618083962235,
    "ttft": 2116010.846838738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.318248985563406,
    "arrivals": 315552,
    "finished_requests": 57432,
    "scheduler_time": 119.76178877743152
}
#Debug simulation 
Total elapsed time: 4.3653867351822555. Arrivals time: 0.19119973992928863 Scheduler time: 4.023625735193491 Scheduler overhead time: 0.04178784415125847 Adapter cache time: 0.045004361774772406 Engine time: 0.04390983795747161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210169192 . Total output tokens: 184721097
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7675274959765375,
    "estimated_duration": 3600.0760539152907,
    "input_throughput": 4158.559368132801,
    "output_throughput": 3615.268901290341,
    "total_throughput": 7773.828269423142,
    "itl": 142.84259824887224,
    "ttft": 2077162.5259343376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.333161616432649,
    "arrivals": 314288,
    "finished_requests": 60248,
    "scheduler_time": 114.64788401895957
}
#Debug simulation 
Total elapsed time: 4.767617188859731. Arrivals time: 0.21358888689428568 Scheduler time: 4.425335659645498 Scheduler overhead time: 0.03789814841002226 Adapter cache time: 0.033611678052693605 Engine time: 0.039360014256089926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210169192 . Total output tokens: 184721097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.364010771270841,
    "estimated_duration": 3600.1400623618442,
    "input_throughput": 3969.8633254351225,
    "output_throughput": 3452.1237464985243,
    "total_throughput": 7421.987071933647,
    "itl": 125.23183524387255,
    "ttft": 2110197.152481965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8422513120295605,
    "arrivals": 314288,
    "finished_requests": 57462,
    "scheduler_time": 120.98292290826237
}
#Debug simulation 
Total elapsed time: 4.364088423084468. Arrivals time: 0.19116727728396654 Scheduler time: 4.024008618667722 Scheduler overhead time: 0.042120537254959345 Adapter cache time: 0.041423508897423744 Engine time: 0.04544383706524968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210169192 . Total output tokens: 184721097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.393416348844767,
    "estimated_duration": 3600.019621693637,
    "input_throughput": 3970.4303037313816,
    "output_throughput": 3452.5167377150824,
    "total_throughput": 7422.947041446464,
    "itl": 125.21169652825719,
    "ttft": 2110165.570356023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.340546356737603,
    "arrivals": 314288,
    "finished_requests": 57468,
    "scheduler_time": 120.99434364305317
}
#Debug simulation 
Total elapsed time: 4.3934969548136. Arrivals time: 0.19434887869283557 Scheduler time: 4.051924861036241 Scheduler overhead time: 0.042222772259265184 Adapter cache time: 0.04124602023512125 Engine time: 0.04376670951023698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210169192 . Total output tokens: 184721097
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.406000110786408,
    "estimated_duration": 3600.0900179333416,
    "input_throughput": 3971.443749678131,
    "output_throughput": 3453.1953195816404,
    "total_throughput": 7424.6390692597715,
    "itl": 125.22156188109102,
    "ttft": 2110142.2615506114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.856331090172718,
    "arrivals": 314288,
    "finished_requests": 57482,
    "scheduler_time": 120.99810126554658
}
#Debug simulation 
Total elapsed time: 4.406081830151379. Arrivals time: 0.19769460475072265 Scheduler time: 4.060769158881158 Scheduler overhead time: 0.0422414387576282 Adapter cache time: 0.04166825721040368 Engine time: 0.04371569724753499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208546390 . Total output tokens: 183281918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.511213979683816,
    "estimated_duration": 3600.0647319509594,
    "input_throughput": 4132.244308823347,
    "output_throughput": 3614.898333493987,
    "total_throughput": 7747.142642317334,
    "itl": 134.6111351018417,
    "ttft": 2063567.7556899628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.813833775259642,
    "arrivals": 311871,
    "finished_requests": 60388,
    "scheduler_time": 118.65009510683946
}
#Debug simulation 
Total elapsed time: 4.511291600763798. Arrivals time: 0.19757449813187122 Scheduler time: 4.18951213080436 Scheduler overhead time: 0.039728160947561264 Adapter cache time: 0.024593908805400133 Engine time: 0.04112711874768138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208546390 . Total output tokens: 183281918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.428211158141494,
    "estimated_duration": 3600.0416416096,
    "input_throughput": 4015.4085533123994,
    "output_throughput": 3512.822422338915,
    "total_throughput": 7528.230975651315,
    "itl": 124.31087791026826,
    "ttft": 2092427.4210039608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.151456568781293,
    "arrivals": 311871,
    "finished_requests": 58707,
    "scheduler_time": 122.36204651588595
}
#Debug simulation 
Total elapsed time: 4.4283262100070715. Arrivals time: 0.19598694518208504 Scheduler time: 4.09273782139644 Scheduler overhead time: 0.04238562472164631 Adapter cache time: 0.03305577673017979 Engine time: 0.04402964608743787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208546390 . Total output tokens: 183281918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.445627246983349,
    "estimated_duration": 3600.0427281170228,
    "input_throughput": 4016.9553786279184,
    "output_throughput": 3513.9738484761633,
    "total_throughput": 7530.929227104081,
    "itl": 124.33985126637054,
    "ttft": 2092075.0683212178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.83633040783926,
    "arrivals": 311871,
    "finished_requests": 58728,
    "scheduler_time": 122.35747350495453
}
#Debug simulation 
Total elapsed time: 4.445704753044993. Arrivals time: 0.19246289459988475 Scheduler time: 4.113533617462963 Scheduler overhead time: 0.042570908553898335 Adapter cache time: 0.03300432255491614 Engine time: 0.04402281250804663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208546390 . Total output tokens: 183281918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.441239922307432,
    "estimated_duration": 3600.022637856069,
    "input_throughput": 4015.898357964162,
    "output_throughput": 3513.2984629041857,
    "total_throughput": 7529.196820868348,
    "itl": 124.27682760577258,
    "ttft": 2092154.5584885413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.519816025923916,
    "arrivals": 311871,
    "finished_requests": 58715,
    "scheduler_time": 122.38457844276476
}
#Debug simulation 
Total elapsed time: 4.441346510313451. Arrivals time: 0.19150178506970406 Scheduler time: 4.110287549905479 Scheduler overhead time: 0.0426096199080348 Adapter cache time: 0.03271578624844551 Engine time: 0.04408740671351552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141459455 . Total output tokens: 124670563
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.153866565320641,
    "estimated_duration": 3600.0136043578077,
    "input_throughput": 3938.302061647111,
    "output_throughput": 3440.2206105577434,
    "total_throughput": 7378.522672204854,
    "itl": 149.79487660081207,
    "ttft": 1997975.3706778842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.149536556526723,
    "arrivals": 211085,
    "finished_requests": 57471,
    "scheduler_time": 106.89429620883955
}
#Debug simulation 
Total elapsed time: 7.1540063531138. Arrivals time: 0.21125687006860971 Scheduler time: 6.786591166630387 Scheduler overhead time: 0.03837932785972953 Adapter cache time: 0.061391542199999094 Engine time: 0.03876794734969735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141459455 . Total output tokens: 124670563
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.035577873699367,
    "estimated_duration": 3600.1014405855612,
    "input_throughput": 3713.3006446134013,
    "output_throughput": 3246.4276890206233,
    "total_throughput": 6959.728333634025,
    "itl": 133.1106818745861,
    "ttft": 2047003.5432866977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.35668200407104,
    "arrivals": 211085,
    "finished_requests": 54176,
    "scheduler_time": 111.24806314407331
}
#Debug simulation 
Total elapsed time: 6.035653382074088. Arrivals time: 0.19674132904037833 Scheduler time: 5.658431225921959 Scheduler overhead time: 0.04146970622241497 Adapter cache time: 0.07716746348887682 Engine time: 0.04259663028642535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141459455 . Total output tokens: 124670563
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.100187233649194,
    "estimated_duration": 3600.0614271023874,
    "input_throughput": 3723.8431264186106,
    "output_throughput": 3251.931456464852,
    "total_throughput": 6975.774582883463,
    "itl": 133.22980941980472,
    "ttft": 2046799.0424670079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.027890230380663,
    "arrivals": 211085,
    "finished_requests": 54299,
    "scheduler_time": 111.26652940689438
}
#Debug simulation 
Total elapsed time: 6.100263497792184. Arrivals time: 0.19799130642786622 Scheduler time: 5.725075884722173 Scheduler overhead time: 0.0415697586722672 Adapter cache time: 0.0726775680668652 Engine time: 0.04376691346988082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141459455 . Total output tokens: 124670563
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.087134703062475,
    "estimated_duration": 3600.0501744745584,
    "input_throughput": 3721.5534091703207,
    "output_throughput": 3250.8685803825338,
    "total_throughput": 6972.421989552854,
    "itl": 132.9187928081571,
    "ttft": 2046719.1197988868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.662919339027308,
    "arrivals": 211085,
    "finished_requests": 54255,
    "scheduler_time": 111.38677376348659
}
#Debug simulation 
Total elapsed time: 6.087224225047976. Arrivals time: 0.2022257694043219 Scheduler time: 5.706760799977928 Scheduler overhead time: 0.04187139682471752 Adapter cache time: 0.07344691734761 Engine time: 0.04369088727980852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.902383318170905,
    "estimated_duration": 3600.0534425624933,
    "input_throughput": 3972.3960291602675,
    "output_throughput": 3448.7507472007414,
    "total_throughput": 7421.146776361009,
    "itl": 150.18491278913214,
    "ttft": 1979114.730970494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.681581751434184,
    "arrivals": 201527,
    "finished_requests": 57944,
    "scheduler_time": 106.44942544305341
}
#Debug simulation 
Total elapsed time: 6.902460764162242. Arrivals time: 0.2036376018077135 Scheduler time: 6.547005069442093 Scheduler overhead time: 0.038112400099635124 Adapter cache time: 0.05757731106132269 Engine time: 0.03866204246878624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.778846052940935,
    "estimated_duration": 3600.1270465435177,
    "input_throughput": 3740.6321571149633,
    "output_throughput": 3252.1630066475136,
    "total_throughput": 6992.7951637624765,
    "itl": 133.22038904590872,
    "ttft": 2029780.691882915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.2210524402645,
    "arrivals": 201527,
    "finished_requests": 54623,
    "scheduler_time": 110.85514843185666
}
#Debug simulation 
Total elapsed time: 5.778921816963702. Arrivals time: 0.1962656988762319 Scheduler time: 5.406626422423869 Scheduler overhead time: 0.04171282425522804 Adapter cache time: 0.07296930300071836 Engine time: 0.04212523018941283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.778601984027773,
    "estimated_duration": 3600.1309772871705,
    "input_throughput": 3744.1451672286735,
    "output_throughput": 3253.8674492413015,
    "total_throughput": 6998.012616469975,
    "itl": 133.1410749566508,
    "ttft": 2029624.4536446587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.433892774419576,
    "arrivals": 201527,
    "finished_requests": 54678,
    "scheduler_time": 110.91136203553106
}
#Debug simulation 
Total elapsed time: 5.7787004718557. Arrivals time: 0.19543385365977883 Scheduler time: 5.406278252135962 Scheduler overhead time: 0.04189976118505001 Adapter cache time: 0.07212182972580194 Engine time: 0.04375816881656647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135078586 . Total output tokens: 119019165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.835377682000399,
    "estimated_duration": 3600.102517441374,
    "input_throughput": 3747.795773768467,
    "output_throughput": 3257.7955608707166,
    "total_throughput": 7005.5913346391835,
    "itl": 133.25007546597286,
    "ttft": 2029248.4564233255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.073323024825033,
    "arrivals": 201527,
    "finished_requests": 54705,
    "scheduler_time": 110.92227914212727
}
#Debug simulation 
Total elapsed time: 5.835467310156673. Arrivals time: 0.19734949804842472 Scheduler time: 5.465011870488524 Scheduler overhead time: 0.041641741059720516 Adapter cache time: 0.0699773682281375 Engine time: 0.042265201453119516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.590676191728562,
    "estimated_duration": 3600.060300096886,
    "input_throughput": 3947.702764761336,
    "output_throughput": 3450.8471982165584,
    "total_throughput": 7398.549962977894,
    "itl": 150.00196448748878,
    "ttft": 1973048.9448153651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.745672141248768,
    "arrivals": 196873,
    "finished_requests": 57756,
    "scheduler_time": 106.39020536544074
}
#Debug simulation 
Total elapsed time: 6.5907830856740475. Arrivals time: 0.20384951075538993 Scheduler time: 6.242672816850245 Scheduler overhead time: 0.03836819576099515 Adapter cache time: 0.04982361476868391 Engine time: 0.038559562526643276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.667064297012985,
    "estimated_duration": 3600.01054394802,
    "input_throughput": 3720.5466029861145,
    "output_throughput": 3254.7268562025583,
    "total_throughput": 6975.273459188673,
    "itl": 133.21261379423217,
    "ttft": 2023569.926399553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.036835142392075,
    "arrivals": 196873,
    "finished_requests": 54400,
    "scheduler_time": 110.75044468799241
}
#Debug simulation 
Total elapsed time: 5.66716161230579. Arrivals time: 0.19909680355340242 Scheduler time: 5.29773584427312 Scheduler overhead time: 0.04155929759144783 Adapter cache time: 0.06750615406781435 Engine time: 0.04207088518887758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.5059997397474945,
    "estimated_duration": 3600.0320829053044,
    "input_throughput": 3717.098540188758,
    "output_throughput": 3254.7371051604623,
    "total_throughput": 6971.835645349221,
    "itl": 133.07818039387718,
    "ttft": 2023033.3265529638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.559768026788337,
    "arrivals": 196873,
    "finished_requests": 54384,
    "scheduler_time": 110.82206014628461
}
#Debug simulation 
Total elapsed time: 5.5060725579969585. Arrivals time: 0.18978583347052336 Scheduler time: 5.144990147091448 Scheduler overhead time: 0.04150504898279905 Adapter cache time: 0.06832120614126325 Engine time: 0.04227328859269619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 131900283 . Total output tokens: 116168233
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.449343862012029,
    "estimated_duration": 3600.078753557176,
    "input_throughput": 3717.7139491116513,
    "output_throughput": 3253.221610340529,
    "total_throughput": 6970.93555945218,
    "itl": 132.88696328418897,
    "ttft": 2022891.7051333075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.524305823935894,
    "arrivals": 196873,
    "finished_requests": 54370,
    "scheduler_time": 110.90039583488351
}
#Debug simulation 
Total elapsed time: 5.4494165810756385. Arrivals time: 0.19122386956587434 Scheduler time: 5.086268337443471 Scheduler overhead time: 0.041537127923220396 Adapter cache time: 0.06910712365061045 Engine time: 0.04205529345199466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.219623235985637,
    "estimated_duration": 3600.079994040107,
    "input_throughput": 3979.944896702308,
    "output_throughput": 3449.2086344072673,
    "total_throughput": 7429.153531109575,
    "itl": 149.76418421378017,
    "ttft": 1965239.712034767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.747198377424295,
    "arrivals": 194481,
    "finished_requests": 57976,
    "scheduler_time": 106.3136881224304
}
#Debug simulation 
Total elapsed time: 6.219695540610701. Arrivals time: 0.20190033875405788 Scheduler time: 5.876523489598185 Scheduler overhead time: 0.038230618461966515 Adapter cache time: 0.04697662452235818 Engine time: 0.03859483217820525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.328198177739978,
    "estimated_duration": 3600.0773379734733,
    "input_throughput": 3753.916577694248,
    "output_throughput": 3253.768711144925,
    "total_throughput": 7007.685288839173,
    "itl": 132.7616855491135,
    "ttft": 2017931.9377357766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.91618320080402,
    "arrivals": 194481,
    "finished_requests": 54662,
    "scheduler_time": 110.72593294747514
}
#Debug simulation 
Total elapsed time: 5.328309752047062. Arrivals time: 0.1938042393885553 Scheduler time: 4.968253650702536 Scheduler overhead time: 0.04169147089123726 Adapter cache time: 0.06309546483680606 Engine time: 0.04218822717666626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.317592607811093,
    "estimated_duration": 3600.0349349797084,
    "input_throughput": 3757.993531825617,
    "output_throughput": 3256.2922893041523,
    "total_throughput": 7014.28582112977,
    "itl": 132.91274496260334,
    "ttft": 2016621.282740438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.72643043825918,
    "arrivals": 194481,
    "finished_requests": 54702,
    "scheduler_time": 110.69474131219633
}
#Debug simulation 
Total elapsed time: 5.317701325751841. Arrivals time: 0.19469971349462867 Scheduler time: 4.95709439413622 Scheduler overhead time: 0.04143214179202914 Adapter cache time: 0.06258204625919461 Engine time: 0.042500298004597425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130279564 . Total output tokens: 114714553
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.306897628121078,
    "estimated_duration": 3600.0602126097174,
    "input_throughput": 3759.399621316064,
    "output_throughput": 3257.6155140190126,
    "total_throughput": 7017.015135335077,
    "itl": 132.84742909503282,
    "ttft": 2016800.1479098992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.513370727655907,
    "arrivals": 194481,
    "finished_requests": 54734,
    "scheduler_time": 110.73043411826525
}
#Debug simulation 
Total elapsed time: 5.306984153110534. Arrivals time: 0.19172752276062965 Scheduler time: 4.949079144746065 Scheduler overhead time: 0.04158892994746566 Adapter cache time: 0.063219353556633 Engine time: 0.0420267847366631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.1337505131959915,
    "estimated_duration": 3600.0095121423924,
    "input_throughput": 3965.9164654549622,
    "output_throughput": 3445.6545067899156,
    "total_throughput": 7411.570972244878,
    "itl": 149.3005059370944,
    "ttft": 1965061.605806476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1967,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.006608565845879,
    "arrivals": 193337,
    "finished_requests": 57817,
    "scheduler_time": 106.38246645238395
}
#Debug simulation 
Total elapsed time: 6.133825674187392. Arrivals time: 0.20121394889429212 Scheduler time: 5.793261242099106 Scheduler overhead time: 0.03812865912914276 Adapter cache time: 0.04517119890078902 Engine time: 0.03843080531805754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.248627820983529,
    "estimated_duration": 3600.1421681611896,
    "input_throughput": 3743.0013512168243,
    "output_throughput": 3254.3959245876717,
    "total_throughput": 6997.397275804496,
    "itl": 132.8591229474364,
    "ttft": 2015869.384376118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.046827151984424,
    "arrivals": 193337,
    "finished_requests": 54558,
    "scheduler_time": 110.65870933651651
}
#Debug simulation 
Total elapsed time: 5.248701020609587. Arrivals time: 0.19116106117144227 Scheduler time: 4.894640550017357 Scheduler overhead time: 0.041466948576271534 Adapter cache time: 0.06025599269196391 Engine time: 0.04197571938857436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.264431392773986,
    "estimated_duration": 3600.1374840684316,
    "input_throughput": 3746.6660814177976,
    "output_throughput": 3258.191125174551,
    "total_throughput": 7004.857206592349,
    "itl": 133.02708435943103,
    "ttft": 2015082.7413975315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.725807447000815,
    "arrivals": 193337,
    "finished_requests": 54616,
    "scheduler_time": 110.61890594312888
}
#Debug simulation 
Total elapsed time: 5.264505898114294. Arrivals time: 0.19119963515549898 Scheduler time: 4.910593646578491 Scheduler overhead time: 0.041497934609651566 Adapter cache time: 0.05981163680553436 Engine time: 0.04217747924849391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129505193 . Total output tokens: 114022353
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.285380380228162,
    "estimated_duration": 3600.0463066387683,
    "input_throughput": 3744.9362734968813,
    "output_throughput": 3256.6333878483633,
    "total_throughput": 7001.569661345245,
    "itl": 132.82491932217923,
    "ttft": 2014738.8633182305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.581318270332485,
    "arrivals": 193337,
    "finished_requests": 54595,
    "scheduler_time": 110.71379011928622
}
#Debug simulation 
Total elapsed time: 5.285468410234898. Arrivals time: 0.19374351622536778 Scheduler time: 4.928524230141193 Scheduler overhead time: 0.04160789493471384 Adapter cache time: 0.05976086016744375 Engine time: 0.042423696257174015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.380192511249334,
    "estimated_duration": 3600.084659777252,
    "input_throughput": 3913.4279694610595,
    "output_throughput": 3441.084355156941,
    "total_throughput": 7354.512324618,
    "itl": 149.45553516876797,
    "ttft": 1951948.5016993636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.420137862507683,
    "arrivals": 182454,
    "finished_requests": 57328,
    "scheduler_time": 105.79921254201763
}
#Debug simulation 
Total elapsed time: 6.380279595963657. Arrivals time: 0.20380253717303276 Scheduler time: 6.032078203279525 Scheduler overhead time: 0.03826644690707326 Adapter cache time: 0.05005916953086853 Engine time: 0.03856309084221721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.593999120872468,
    "estimated_duration": 3600.004148536636,
    "input_throughput": 3686.739640395982,
    "output_throughput": 3246.1876480754486,
    "total_throughput": 6932.92728847143,
    "itl": 132.76325184008948,
    "ttft": 2005467.9280013456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.612889443765685,
    "arrivals": 182454,
    "finished_requests": 53999,
    "scheduler_time": 110.08971252433203
}
#Debug simulation 
Total elapsed time: 5.594056711066514. Arrivals time: 0.19268593937158585 Scheduler time: 5.228717855643481 Scheduler overhead time: 0.04145579319447279 Adapter cache time: 0.06973079312592745 Engine time: 0.04222486773505807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.4165864191018045,
    "estimated_duration": 3600.0935852425823,
    "input_throughput": 3699.273834044684,
    "output_throughput": 3254.500951871926,
    "total_throughput": 6953.77478591661,
    "itl": 133.21993979510438,
    "ttft": 2003299.2580532378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.667529453063093,
    "arrivals": 182454,
    "finished_requests": 54163,
    "scheduler_time": 109.97934946507638
}
#Debug simulation 
Total elapsed time: 5.416740203276277. Arrivals time: 0.19011373165994883 Scheduler time: 5.053080753888935 Scheduler overhead time: 0.04155632387846708 Adapter cache time: 0.07041904702782631 Engine time: 0.04222280299291015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122267032 . Total output tokens: 107583279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.429393427912146,
    "estimated_duration": 3600.0056109578686,
    "input_throughput": 3699.1647900395037,
    "output_throughput": 3254.8896491531423,
    "total_throughput": 6954.054439192646,
    "itl": 133.06012152608798,
    "ttft": 2002839.5057192654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.87542147566732,
    "arrivals": 182454,
    "finished_requests": 54165,
    "scheduler_time": 110.05955888064688
}
#Debug simulation 
Total elapsed time: 5.429489448666573. Arrivals time: 0.1947517702355981 Scheduler time: 5.0639118743129075 Scheduler overhead time: 0.04158687312155962 Adapter cache time: 0.06815858092159033 Engine time: 0.041800765320658684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.976112125907093,
    "estimated_duration": 3600.049608617969,
    "input_throughput": 4008.3469865126826,
    "output_throughput": 3443.547547323685,
    "total_throughput": 7451.894533836368,
    "itl": 149.1468258009856,
    "ttft": 1936302.3948012944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.67802181475374,
    "arrivals": 177727,
    "finished_requests": 57909,
    "scheduler_time": 105.58632435994801
}
#Debug simulation 
Total elapsed time: 5.976183923892677. Arrivals time: 0.19799811532720923 Scheduler time: 5.633485133294016 Scheduler overhead time: 0.038210229482501745 Adapter cache time: 0.05067806504666805 Engine time: 0.03830160526558757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.323537519667298,
    "estimated_duration": 3600.0039441347917,
    "input_throughput": 3778.7197489499918,
    "output_throughput": 3248.3647744476325,
    "total_throughput": 7027.084523397624,
    "itl": 132.50039834300247,
    "ttft": 1990948.857824127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.875112101239417,
    "arrivals": 177727,
    "finished_requests": 54563,
    "scheduler_time": 109.85135942465097
}
#Debug simulation 
Total elapsed time: 5.323596010915935. Arrivals time: 0.19201402692124248 Scheduler time: 4.9612993323244154 Scheduler overhead time: 0.04156131250783801 Adapter cache time: 0.0672196107916534 Engine time: 0.04222032427787781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.134402410592884,
    "estimated_duration": 3600.1164066398173,
    "input_throughput": 3773.799640184595,
    "output_throughput": 3244.721470243474,
    "total_throughput": 7018.521110428069,
    "itl": 132.07496044315448,
    "ttft": 1991675.3476228137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.3080939531751,
    "arrivals": 177727,
    "finished_requests": 54499,
    "scheduler_time": 110.0180199308971
}
#Debug simulation 
Total elapsed time: 5.134474635589868. Arrivals time: 0.18848962476477027 Scheduler time: 4.772611991502345 Scheduler overhead time: 0.041929641738533974 Adapter cache time: 0.0683533507399261 Engine time: 0.04380177520215511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119065931 . Total output tokens: 104796168
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.103236197028309,
    "estimated_duration": 3600.0927497528714,
    "input_throughput": 3777.5807306446613,
    "output_throughput": 3247.9854861524527,
    "total_throughput": 7025.566216797114,
    "itl": 132.14418092060657,
    "ttft": 1991260.8794816155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.028635578241033,
    "arrivals": 177727,
    "finished_requests": 54561,
    "scheduler_time": 110.02279019405862
}
#Debug simulation 
Total elapsed time: 5.10332215577364. Arrivals time: 0.18893473409116268 Scheduler time: 4.742220784537494 Scheduler overhead time: 0.04189229663461447 Adapter cache time: 0.06857361923903227 Engine time: 0.042349384631961584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.818424591328949,
    "estimated_duration": 3600.0323668778433,
    "input_throughput": 3983.3300200121757,
    "output_throughput": 3443.7495934937733,
    "total_throughput": 7427.079613505949,
    "itl": 148.96574258913571,
    "ttft": 1926455.2014600253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.560524688354164,
    "arrivals": 175481,
    "finished_requests": 57931,
    "scheduler_time": 105.34414716100383
}
#Debug simulation 
Total elapsed time: 5.818533860146999. Arrivals time: 0.20057415589690208 Scheduler time: 5.476229338441044 Scheduler overhead time: 0.037993391044437885 Adapter cache time: 0.047779695596545935 Engine time: 0.038460280280560255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.84135594824329,
    "estimated_duration": 3600.101918026991,
    "input_throughput": 3749.3624645486498,
    "output_throughput": 3246.6991952288304,
    "total_throughput": 6996.061659777481,
    "itl": 132.2327848862797,
    "ttft": 1980594.7620595053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.822832125480623,
    "arrivals": 175481,
    "finished_requests": 54557,
    "scheduler_time": 109.66921644223214
}
#Debug simulation 
Total elapsed time: 4.841432080138475. Arrivals time: 0.18842129688709974 Scheduler time: 4.484365353360772 Scheduler overhead time: 0.04193261591717601 Adapter cache time: 0.06508280336856842 Engine time: 0.042333717457950115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.867032913956791,
    "estimated_duration": 3600.0745910081628,
    "input_throughput": 3758.475736529349,
    "output_throughput": 3253.7217504484315,
    "total_throughput": 7012.1974869777805,
    "itl": 132.5312835763112,
    "ttft": 1979270.7884738126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.268591296980723,
    "arrivals": 175481,
    "finished_requests": 54681,
    "scheduler_time": 109.59930298416155
}
#Debug simulation 
Total elapsed time: 4.867108744569123. Arrivals time: 0.1868094326928258 Scheduler time: 4.510312465485185 Scheduler overhead time: 0.04239261336624622 Adapter cache time: 0.06563871772959828 Engine time: 0.042622384149581194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117407741 . Total output tokens: 103372195
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.863030907697976,
    "estimated_duration": 3600.1422481785435,
    "input_throughput": 3753.208642474143,
    "output_throughput": 3249.672983315906,
    "total_throughput": 7002.881625790049,
    "itl": 132.10025675852856,
    "ttft": 1980033.4647704817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.796538836710756,
    "arrivals": 175481,
    "finished_requests": 54605,
    "scheduler_time": 109.75600068070545
}
#Debug simulation 
Total elapsed time: 4.863168225623667. Arrivals time: 0.1876481263898313 Scheduler time: 4.507225155364722 Scheduler overhead time: 0.0416916492395103 Adapter cache time: 0.0651112743653357 Engine time: 0.04214741662144661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.328082386869937,
    "estimated_duration": 3600.042904111848,
    "input_throughput": 3944.893263293945,
    "output_throughput": 3443.753680224146,
    "total_throughput": 7388.646943518092,
    "itl": 149.15359466164034,
    "ttft": 1935583.3547579006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.998469920638401,
    "arrivals": 174302,
    "finished_requests": 57519,
    "scheduler_time": 105.41946467366456
}
#Debug simulation 
Total elapsed time: 5.328174341004342. Arrivals time: 0.19611046696081758 Scheduler time: 4.990847241599113 Scheduler overhead time: 0.03796367719769478 Adapter cache time: 0.047326117753982544 Engine time: 0.03839724184945226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.732626802753657,
    "estimated_duration": 3600.125895678293,
    "input_throughput": 3717.5144391661433,
    "output_throughput": 3245.8584334585767,
    "total_throughput": 6963.37287262472,
    "itl": 132.34859252140538,
    "ttft": 1989205.8805040475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.107247363160713,
    "arrivals": 174302,
    "finished_requests": 54134,
    "scheduler_time": 109.76493973850633
}
#Debug simulation 
Total elapsed time: 4.732726133894175. Arrivals time: 0.19211376830935478 Scheduler time: 4.372657033149153 Scheduler overhead time: 0.04185886774212122 Adapter cache time: 0.0645345188677311 Engine time: 0.042199586518108845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.722961084917188,
    "estimated_duration": 3600.1414688795226,
    "input_throughput": 3718.449431979249,
    "output_throughput": 3247.279614164302,
    "total_throughput": 6965.729046143551,
    "itl": 132.33964603565622,
    "ttft": 1988538.1681910981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.73455171831006,
    "arrivals": 174302,
    "finished_requests": 54152,
    "scheduler_time": 109.78947028538853
}
#Debug simulation 
Total elapsed time: 4.723037153016776. Arrivals time: 0.188635082449764 Scheduler time: 4.363370950333774 Scheduler overhead time: 0.04191099060699344 Adapter cache time: 0.0658711101859808 Engine time: 0.043865925166755915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116625668 . Total output tokens: 102684252
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.705114325042814,
    "estimated_duration": 3600.0968088490063,
    "input_throughput": 3719.0127685151224,
    "output_throughput": 3247.469893382622,
    "total_throughput": 6966.482661897744,
    "itl": 132.19201112974307,
    "ttft": 1988338.5807078271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.30497692428676,
    "arrivals": 174302,
    "finished_requests": 54155,
    "scheduler_time": 109.85966980488544
}
#Debug simulation 
Total elapsed time: 4.705188607797027. Arrivals time: 0.18727995362132788 Scheduler time: 4.349171359557658 Scheduler overhead time: 0.041801953222602606 Adapter cache time: 0.06568909483030438 Engine time: 0.04196843318641186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.58904180303216,
    "estimated_duration": 3600.095791561857,
    "input_throughput": 3968.8630045594437,
    "output_throughput": 3449.1185009866003,
    "total_throughput": 7417.981505546044,
    "itl": 149.76579817708497,
    "ttft": 1910208.4198356278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.869781676680294,
    "arrivals": 168141,
    "finished_requests": 57823,
    "scheduler_time": 104.66581337875058
}
#Debug simulation 
Total elapsed time: 5.589097514282912. Arrivals time: 0.1987312315031886 Scheduler time: 5.245823507197201 Scheduler overhead time: 0.037839711643755436 Adapter cache time: 0.050960848107934 Engine time: 0.03829418867826462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.69734335038811,
    "estimated_duration": 3600.1251026931013,
    "input_throughput": 3737.007913957173,
    "output_throughput": 3253.634989305686,
    "total_throughput": 6990.642903262859,
    "itl": 133.00559195069997,
    "ttft": 1966867.4990305998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.420257447696546,
    "arrivals": 168141,
    "finished_requests": 54427,
    "scheduler_time": 108.90219835972076
}
#Debug simulation 
Total elapsed time: 4.697430493310094. Arrivals time: 0.18738740822300315 Scheduler time: 4.337818230967969 Scheduler overhead time: 0.04195667477324605 Adapter cache time: 0.06891396082937717 Engine time: 0.04212927212938666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.665999511256814,
    "estimated_duration": 3600.0968138601106,
    "input_throughput": 3737.0406118536043,
    "output_throughput": 3254.812746948342,
    "total_throughput": 6991.853358801946,
    "itl": 132.95858857520614,
    "ttft": 1966003.1999251856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.970642987704476,
    "arrivals": 168141,
    "finished_requests": 54428,
    "scheduler_time": 108.93927155527625
}
#Debug simulation 
Total elapsed time: 4.666082452982664. Arrivals time: 0.192956177983433 Scheduler time: 4.300039062276483 Scheduler overhead time: 0.0415787105448544 Adapter cache time: 0.0703795999288559 Engine time: 0.041911226231604815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112566408 . Total output tokens: 99121663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.650507653132081,
    "estimated_duration": 3600.0299333114654,
    "input_throughput": 3738.803079234145,
    "output_throughput": 3256.286257935895,
    "total_throughput": 6995.0893371700395,
    "itl": 132.91205685235545,
    "ttft": 1965704.4186402175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.309528099626174,
    "arrivals": 168141,
    "finished_requests": 54455,
    "scheduler_time": 108.98378003902846
}
#Debug simulation 
Total elapsed time: 4.650611402001232. Arrivals time: 0.18340024026110768 Scheduler time: 4.295944990124553 Scheduler overhead time: 0.04151137871667743 Adapter cache time: 0.06862510740756989 Engine time: 0.04194188863039017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.951731332112104,
    "estimated_duration": 3600.018501888232,
    "input_throughput": 3990.7008790273244,
    "output_throughput": 3451.9069814452337,
    "total_throughput": 7442.607860472558,
    "itl": 149.81695885299797,
    "ttft": 1900650.1952221047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.69124663281764,
    "arrivals": 165887,
    "finished_requests": 58144,
    "scheduler_time": 104.4777543790535
}
#Debug simulation 
Total elapsed time: 4.951870356220752. Arrivals time: 0.2027187356725335 Scheduler time: 4.606162549927831 Scheduler overhead time: 0.037817188538610935 Adapter cache time: 0.04955564718693495 Engine time: 0.03814528090879321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4640817190520465,
    "estimated_duration": 3600.0871384485094,
    "input_throughput": 3760.133429946313,
    "output_throughput": 3255.373981044993,
    "total_throughput": 7015.507410991306,
    "itl": 132.92721068131345,
    "ttft": 1957697.480234131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.33355527840959,
    "arrivals": 165887,
    "finished_requests": 54810,
    "scheduler_time": 108.7409308917467
}
#Debug simulation 
Total elapsed time: 4.4641568921506405. Arrivals time: 0.18633507937192917 Scheduler time: 4.107939347624779 Scheduler overhead time: 0.042863361071795225 Adapter cache time: 0.06592910783365369 Engine time: 0.041896908078342676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.455015758983791,
    "estimated_duration": 3600.065899916716,
    "input_throughput": 3763.007227260312,
    "output_throughput": 3257.0681554110615,
    "total_throughput": 7020.0753826713735,
    "itl": 132.9091532241855,
    "ttft": 1957575.4308568365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.869520380125053,
    "arrivals": 165887,
    "finished_requests": 54847,
    "scheduler_time": 108.76697415370366
}
#Debug simulation 
Total elapsed time: 4.455090492963791. Arrivals time: 0.18629619432613254 Scheduler time: 4.099244754295796 Scheduler overhead time: 0.0413396917283535 Adapter cache time: 0.06673575844615698 Engine time: 0.04224041663110256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 110949305 . Total output tokens: 97676207
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.468521807808429,
    "estimated_duration": 3600.13429995417,
    "input_throughput": 3765.204814768316,
    "output_throughput": 3258.571215009768,
    "total_throughput": 7023.776029778084,
    "itl": 132.90111713552807,
    "ttft": 1957198.7664123403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.441314851708466,
    "arrivals": 165887,
    "finished_requests": 54875,
    "scheduler_time": 108.79294981969535
}
#Debug simulation 
Total elapsed time: 4.468604695983231. Arrivals time: 0.1992687745951116 Scheduler time: 4.100089444313198 Scheduler overhead time: 0.041223250329494476 Adapter cache time: 0.06631474662572145 Engine time: 0.04254374606534839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7732178079895675,
    "estimated_duration": 3600.0132418297826,
    "input_throughput": 3918.2008655141904,
    "output_throughput": 3452.8286883972887,
    "total_throughput": 7371.029553911479,
    "itl": 149.95488180997245,
    "ttft": 1898311.2733666531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.672935641897316,
    "arrivals": 164660,
    "finished_requests": 57467,
    "scheduler_time": 104.39875350106387
}
#Debug simulation 
Total elapsed time: 4.773315394297242. Arrivals time: 0.19705233117565513 Scheduler time: 4.435364856850356 Scheduler overhead time: 0.0377611112780869 Adapter cache time: 0.04751796741038561 Engine time: 0.03826226247474551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.332094148732722,
    "estimated_duration": 3600.007547860574,
    "input_throughput": 3701.79251649617,
    "output_throughput": 3256.1676174724494,
    "total_throughput": 6957.960133968619,
    "itl": 133.1087895149363,
    "ttft": 1954345.8517357637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2992,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.87990984275885,
    "arrivals": 164660,
    "finished_requests": 54252,
    "scheduler_time": 108.64987372948683
}
#Debug simulation 
Total elapsed time: 4.332171197980642. Arrivals time: 0.18298573745414615 Scheduler time: 3.984444951172918 Scheduler overhead time: 0.04119737213477492 Adapter cache time: 0.06283199787139893 Engine time: 0.04165793163701892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.373544822912663,
    "estimated_duration": 3600.127137600216,
    "input_throughput": 3703.349768054925,
    "output_throughput": 3257.697728924588,
    "total_throughput": 6961.047496979512,
    "itl": 133.0511661518166,
    "ttft": 1953963.4027616202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.43365744168928,
    "arrivals": 164660,
    "finished_requests": 54276,
    "scheduler_time": 108.69590067372654
}
#Debug simulation 
Total elapsed time: 4.373631801921874. Arrivals time: 0.19362970860674977 Scheduler time: 4.014405661262572 Scheduler overhead time: 0.041231181006878614 Adapter cache time: 0.06338075501844287 Engine time: 0.041814498603343964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110174748 . Total output tokens: 96969079
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.356359771918505,
    "estimated_duration": 3600.0590575809247,
    "input_throughput": 3704.223399313009,
    "output_throughput": 3258.8840383867164,
    "total_throughput": 6963.107437699725,
    "itl": 132.9994473431151,
    "ttft": 1953477.3077752297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.068771849485618,
    "arrivals": 164660,
    "finished_requests": 54287,
    "scheduler_time": 108.73218395886187
}
#Debug simulation 
Total elapsed time: 4.356433625798672. Arrivals time: 0.18306779023259878 Scheduler time: 4.008320327848196 Scheduler overhead time: 0.04124597925692797 Adapter cache time: 0.06255203112959862 Engine time: 0.04200919670984149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.481648549437523,
    "estimated_duration": 3600.1599548030576,
    "input_throughput": 3996.317436064322,
    "output_throughput": 3455.008154125318,
    "total_throughput": 7451.32559018964,
    "itl": 149.69517231781285,
    "ttft": 1881063.6731387612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.393688226379883,
    "arrivals": 161177,
    "finished_requests": 58123,
    "scheduler_time": 104.21004378757826
}
#Debug simulation 
Total elapsed time: 4.481721829157323. Arrivals time: 0.18880190327763557 Scheduler time: 4.15112571651116 Scheduler overhead time: 0.03751816786825657 Adapter cache time: 0.04863701947033405 Engine time: 0.03823659336194396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.248602150008082,
    "estimated_duration": 3600.044657940519,
    "input_throughput": 3809.789684066361,
    "output_throughput": 3291.953885588663,
    "total_throughput": 7101.743569655024,
    "itl": 131.716334559611,
    "ttft": 1930036.6209417288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.345946158761684,
    "arrivals": 161177,
    "finished_requests": 55405,
    "scheduler_time": 109.36618867667599
}
#Debug simulation 
Total elapsed time: 4.248721822164953. Arrivals time: 0.18488329788669944 Scheduler time: 3.900154025759548 Scheduler overhead time: 0.04082299908623099 Adapter cache time: 0.061545395758002996 Engine time: 0.04211036628112197 
