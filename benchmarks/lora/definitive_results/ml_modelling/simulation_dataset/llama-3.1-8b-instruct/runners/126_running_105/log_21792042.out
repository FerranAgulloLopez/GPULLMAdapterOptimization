INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 62.42859667586163,
    "estimated_duration": 3600.029580387107,
    "input_throughput": 6731.221079965208,
    "output_throughput": 5911.925867484525,
    "total_throughput": 12643.146947449733,
    "itl": 98.28248760158914,
    "ttft": 1941214.885370057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4045663249911713,
    "arrivals": 650482,
    "finished_requests": 98580,
    "scheduler_time": 223.41114238453744
}
#Debug simulation 
Total elapsed time: 62.42879937309772. Arrivals time: 0.45179654844105244 Scheduler time: 61.78979049390182 Scheduler overhead time: 0.0710267717950046 Adapter cache time: 0.015611947048455477 Engine time: 0.07111380249261856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 55.15188153786585,
    "estimated_duration": 3600.0466822012872,
    "input_throughput": 6520.117118494516,
    "output_throughput": 5736.60950067794,
    "total_throughput": 12256.726619172456,
    "itl": 91.67985232232436,
    "ttft": 1956647.934157468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7307976039778596,
    "arrivals": 650482,
    "finished_requests": 95595,
    "scheduler_time": 230.74807369837862
}
#Debug simulation 
Total elapsed time: 55.15206885011867. Arrivals time: 0.41053537698462605 Scheduler time: 54.54556450806558 Scheduler overhead time: 0.07488696975633502 Adapter cache time: 0.015959526412189007 Engine time: 0.07433016272261739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 62.06735840300098,
    "estimated_duration": 3600.079587234937,
    "input_throughput": 6731.043970783923,
    "output_throughput": 5912.461512093494,
    "total_throughput": 12643.505482877417,
    "itl": 98.29555457531934,
    "ttft": 1941010.0253975422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2152205663779663,
    "arrivals": 650482,
    "finished_requests": 98585,
    "scheduler_time": 223.40375656395918
}
#Debug simulation 
Total elapsed time: 62.06751634879038. Arrivals time: 0.4245389150455594 Scheduler time: 61.45364521443844 Scheduler overhead time: 0.07181655056774616 Adapter cache time: 0.015220976434648037 Engine time: 0.0725318375043571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 55.88481232011691,
    "estimated_duration": 3600.053991930146,
    "input_throughput": 6532.826188917987,
    "output_throughput": 5744.449123917826,
    "total_throughput": 12277.275312835813,
    "itl": 91.98902929390367,
    "ttft": 1958639.434335714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8691682508588014,
    "arrivals": 650482,
    "finished_requests": 95727,
    "scheduler_time": 230.3590860568711
}
#Debug simulation 
Total elapsed time: 55.884967097081244. Arrivals time: 0.40392915764823556 Scheduler time: 55.28687622118741 Scheduler overhead time: 0.07384521001949906 Adapter cache time: 0.015974737238138914 Engine time: 0.0733539848588407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 63.64080725517124,
    "estimated_duration": 3600.0276991504534,
    "input_throughput": 6934.09303653159,
    "output_throughput": 5970.570450075225,
    "total_throughput": 12904.663486606814,
    "itl": 100.81829135577587,
    "ttft": 1931971.808475635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3143431611824856,
    "arrivals": 645743,
    "finished_requests": 100536,
    "scheduler_time": 220.8655251180397
}
#Debug simulation 
Total elapsed time: 63.64097006479278. Arrivals time: 0.4865120556205511 Scheduler time: 62.96675955085084 Scheduler overhead time: 0.07178315473720431 Adapter cache time: 0.015557486098259687 Engine time: 0.0711319618858397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 61.49777622614056,
    "estimated_duration": 3600.036163998529,
    "input_throughput": 6855.206691198696,
    "output_throughput": 5903.605417228438,
    "total_throughput": 12758.812108427133,
    "itl": 98.04183529823742,
    "ttft": 1935771.6980509763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.493431422649885,
    "arrivals": 645743,
    "finished_requests": 99446,
    "scheduler_time": 223.560643041916
}
#Debug simulation 
Total elapsed time: 61.49793546600267. Arrivals time: 0.44068019930273294 Scheduler time: 60.8650394291617 Scheduler overhead time: 0.07336732745170593 Adapter cache time: 0.015609914902597666 Engine time: 0.07310623629018664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 55.883298859000206,
    "estimated_duration": 3600.0636714112,
    "input_throughput": 6663.569922527611,
    "output_throughput": 5734.971346189221,
    "total_throughput": 12398.541268716832,
    "itl": 91.65543457878483,
    "ttft": 1953277.6319608218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.918206863263641,
    "arrivals": 645743,
    "finished_requests": 96577,
    "scheduler_time": 230.66043627327485
}
#Debug simulation 
Total elapsed time: 55.883471394423395. Arrivals time: 0.4736025985330343 Scheduler time: 55.21439941274002 Scheduler overhead time: 0.07440624898299575 Adapter cache time: 0.015835261903703213 Engine time: 0.07437219610437751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 60.045366674195975,
    "estimated_duration": 3600.092676229693,
    "input_throughput": 6856.682374591478,
    "output_throughput": 5903.5113568959705,
    "total_throughput": 12760.193731487449,
    "itl": 98.02149851197866,
    "ttft": 1937393.7488163228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.476734860236754,
    "arrivals": 645743,
    "finished_requests": 99362,
    "scheduler_time": 223.64402230647542
}
#Debug simulation 
Total elapsed time: 60.04554070997983. Arrivals time: 0.42603834345936775 Scheduler time: 59.43248316971585 Scheduler overhead time: 0.07117443764582276 Adapter cache time: 0.015088674146682024 Engine time: 0.07121513690799475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 55.423805403057486,
    "estimated_duration": 3600.0015614862505,
    "input_throughput": 6659.736833586806,
    "output_throughput": 5736.796400575361,
    "total_throughput": 12396.533234162167,
    "itl": 91.74274575306235,
    "ttft": 1953078.3953394664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8952668703766733,
    "arrivals": 645743,
    "finished_requests": 96567,
    "scheduler_time": 230.5519720847706
}
#Debug simulation 
Total elapsed time: 55.42397722695023. Arrivals time: 0.47890219185501337 Scheduler time: 54.746912497095764 Scheduler overhead time: 0.07499256264418364 Adapter cache time: 0.01798297045752406 Engine time: 0.07429659366607666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 60.339691950939596,
    "estimated_duration": 3600.0415946908092,
    "input_throughput": 6859.577410555146,
    "output_throughput": 5904.675943563833,
    "total_throughput": 12764.253354118979,
    "itl": 98.10720744158958,
    "ttft": 1937726.169916025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4769613249413567,
    "arrivals": 645743,
    "finished_requests": 99459,
    "scheduler_time": 223.52695653135538
}
#Debug simulation 
Total elapsed time: 60.339863129891455. Arrivals time: 0.49065274419263005 Scheduler time: 59.659699014388025 Scheduler overhead time: 0.07184070954099298 Adapter cache time: 0.015866847708821297 Engine time: 0.07196526369079947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 54.31121509335935,
    "estimated_duration": 3600.01686448958,
    "input_throughput": 6666.218771561942,
    "output_throughput": 5741.342270886972,
    "total_throughput": 12407.561042448913,
    "itl": 91.87425296097271,
    "ttft": 1954193.0975756105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9980749284476254,
    "arrivals": 645743,
    "finished_requests": 96661,
    "scheduler_time": 230.37724543717908
}
#Debug simulation 
Total elapsed time: 54.31139121437445. Arrivals time: 0.4804811663925648 Scheduler time: 53.633502264041454 Scheduler overhead time: 0.07480733888223767 Adapter cache time: 0.016413347329944372 Engine time: 0.07481978368014097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 63.94010096415877,
    "estimated_duration": 3600.091180037824,
    "input_throughput": 6862.82784641594,
    "output_throughput": 5960.98429922948,
    "total_throughput": 12823.812145645421,
    "itl": 100.1724672233266,
    "ttft": 1928974.6407767783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.115970890223981,
    "arrivals": 643390,
    "finished_requests": 99856,
    "scheduler_time": 221.32213799161013
}
#Debug simulation 
Total elapsed time: 63.94026665715501. Arrivals time: 0.42936829570680857 Scheduler time: 63.31923600938171 Scheduler overhead time: 0.07387230265885592 Adapter cache time: 0.015304489061236382 Engine time: 0.07259027706459165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 57.15645399922505,
    "estimated_duration": 3600.000606110159,
    "input_throughput": 6789.23774582612,
    "output_throughput": 5906.434838902734,
    "total_throughput": 12695.672584728853,
    "itl": 98.03339148201844,
    "ttft": 1936350.797852348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6108445884054556,
    "arrivals": 643390,
    "finished_requests": 98834,
    "scheduler_time": 223.49337172330206
}
#Debug simulation 
Total elapsed time: 57.15662530902773. Arrivals time: 0.4138050968758762 Scheduler time: 56.55529015837237 Scheduler overhead time: 0.07190850330516696 Adapter cache time: 0.015194725710898638 Engine time: 0.07121257157996297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 54.33533523790538,
    "estimated_duration": 3600.09784417761,
    "input_throughput": 6592.233330097556,
    "output_throughput": 5737.626001861781,
    "total_throughput": 12329.859331959338,
    "itl": 91.63812632934673,
    "ttft": 1951846.615849587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6653668930893915,
    "arrivals": 643390,
    "finished_requests": 95984,
    "scheduler_time": 230.5772111522667
}
#Debug simulation 
Total elapsed time: 54.33549570199102. Arrivals time: 0.41299572214484215 Scheduler time: 53.726493149995804 Scheduler overhead time: 0.0740745086222887 Adapter cache time: 0.016065786127001047 Engine time: 0.07468342036008835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 59.51252573588863,
    "estimated_duration": 3600.040316288656,
    "input_throughput": 6785.409565963691,
    "output_throughput": 5897.63423035444,
    "total_throughput": 12683.04379631813,
    "itl": 97.6987692187889,
    "ttft": 1935423.7225313156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4867262601712685,
    "arrivals": 643390,
    "finished_requests": 98755,
    "scheduler_time": 223.85515733855016
}
#Debug simulation 
Total elapsed time: 59.51269511971623. Arrivals time: 0.4231986724771559 Scheduler time: 58.89655006490648 Scheduler overhead time: 0.07382393209263682 Adapter cache time: 0.015842168126255274 Engine time: 0.07334979949519038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 51.57130228122696,
    "estimated_duration": 3600.092795240765,
    "input_throughput": 6600.3540329328835,
    "output_throughput": 5743.931386251132,
    "total_throughput": 12344.285419184014,
    "itl": 91.82202334868546,
    "ttft": 1953659.8624906114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.857682764767688,
    "arrivals": 643390,
    "finished_requests": 96152,
    "scheduler_time": 230.32986325548478
}
#Debug simulation 
Total elapsed time: 51.571550958324224. Arrivals time: 0.40424226643517613 Scheduler time: 50.97426593117416 Scheduler overhead time: 0.07332957768812776 Adapter cache time: 0.01591174164786935 Engine time: 0.07312600268051028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 57.809301977045834,
    "estimated_duration": 3600.1007176989788,
    "input_throughput": 6797.822316382841,
    "output_throughput": 5907.703608246203,
    "total_throughput": 12705.525924629044,
    "itl": 98.01561425488902,
    "ttft": 1936395.9056365297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2343723291996778,
    "arrivals": 643390,
    "finished_requests": 98970,
    "scheduler_time": 223.51446297351293
}
#Debug simulation 
Total elapsed time: 57.80947233969346. Arrivals time: 0.42547244438901544 Scheduler time: 57.19558688998222 Scheduler overhead time: 0.07166708586737514 Adapter cache time: 0.015303432941436768 Engine time: 0.07142662908881903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 52.9769785637036,
    "estimated_duration": 3600.0234358565476,
    "input_throughput": 6595.992893682432,
    "output_throughput": 5740.72596143608,
    "total_throughput": 12336.718855118512,
    "itl": 91.71413540634373,
    "ttft": 1952049.3505779854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.633519723843798,
    "arrivals": 643390,
    "finished_requests": 96065,
    "scheduler_time": 230.45905469968747
}
#Debug simulation 
Total elapsed time: 52.97714605694637. Arrivals time: 0.4118748130276799 Scheduler time: 52.37002110155299 Scheduler overhead time: 0.07418500818312168 Adapter cache time: 0.01589094614610076 Engine time: 0.07454828824847937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 58.1851964071393,
    "estimated_duration": 3600.0025743324304,
    "input_throughput": 6865.886756923627,
    "output_throughput": 5967.433232734195,
    "total_throughput": 12833.319989657823,
    "itl": 100.675435258883,
    "ttft": 1930999.0433369728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1820949805434826,
    "arrivals": 642182,
    "finished_requests": 99670,
    "scheduler_time": 220.95339593705302
}
#Debug simulation 
Total elapsed time: 58.185362454969436. Arrivals time: 0.4283351036719978 Scheduler time: 57.56796899205074 Scheduler overhead time: 0.07237160112708807 Adapter cache time: 0.015468462835997343 Engine time: 0.07191136525943875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 59.14992406172678,
    "estimated_duration": 3600.03155215929,
    "input_throughput": 6782.358889425544,
    "output_throughput": 5899.242185047468,
    "total_throughput": 12681.601074473012,
    "itl": 97.74057343607831,
    "ttft": 1937939.1540679433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.413490745490419,
    "arrivals": 642182,
    "finished_requests": 98561,
    "scheduler_time": 223.90148323911757
}
#Debug simulation 
Total elapsed time: 59.15010195085779. Arrivals time: 0.4311772892251611 Scheduler time: 58.52724421862513 Scheduler overhead time: 0.07335708057507873 Adapter cache time: 0.015772325918078423 Engine time: 0.07272969512268901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 53.99724640510976,
    "estimated_duration": 3600.0786368155086,
    "input_throughput": 6594.889555246318,
    "output_throughput": 5735.829431288673,
    "total_throughput": 12330.71898653499,
    "itl": 91.62776146453565,
    "ttft": 1953085.77626839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6832278462313273,
    "arrivals": 642182,
    "finished_requests": 95661,
    "scheduler_time": 230.6722490648991
}
#Debug simulation 
Total elapsed time: 53.997406548820436. Arrivals time: 0.7235248885117471 Scheduler time: 53.07525047799572 Scheduler overhead time: 0.07550428993999958 Adapter cache time: 0.01613708958029747 Engine time: 0.07574715465307236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 59.73577736504376,
    "estimated_duration": 3600.0434928814766,
    "input_throughput": 6785.623853796106,
    "output_throughput": 5898.094298578815,
    "total_throughput": 12683.71815237492,
    "itl": 97.74453141202922,
    "ttft": 1935422.0364890941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2516260755388036,
    "arrivals": 642182,
    "finished_requests": 98430,
    "scheduler_time": 223.91455625631883
}
#Debug simulation 
Total elapsed time: 59.73594305617735. Arrivals time: 0.49728678073734045 Scheduler time: 59.04466147394851 Scheduler overhead time: 0.07427565287798643 Adapter cache time: 0.01593651669099927 Engine time: 0.07384128030389547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 53.54698504228145,
    "estimated_duration": 3600.082758555685,
    "input_throughput": 6596.916680195437,
    "output_throughput": 5740.095821655641,
    "total_throughput": 12337.012501851077,
    "itl": 91.78507029140266,
    "ttft": 1953519.8418519853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8777186276391338,
    "arrivals": 642182,
    "finished_requests": 95768,
    "scheduler_time": 230.46422754838022
}
#Debug simulation 
Total elapsed time: 53.547159580979496. Arrivals time: 0.40575312823057175 Scheduler time: 52.94374733790755 Scheduler overhead time: 0.07507306942716241 Adapter cache time: 0.016283546574413776 Engine time: 0.07540709944441915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 58.251316986978054,
    "estimated_duration": 3600.077976909598,
    "input_throughput": 6792.448151634592,
    "output_throughput": 5902.5152055848375,
    "total_throughput": 12694.963357219429,
    "itl": 97.86925068906692,
    "ttft": 1936782.2823913754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.042854700982563,
    "arrivals": 642182,
    "finished_requests": 98546,
    "scheduler_time": 223.79219493021313
}
#Debug simulation 
Total elapsed time: 58.25148501712829. Arrivals time: 0.42580275423824787 Scheduler time: 57.633043554611504 Scheduler overhead time: 0.07375793484970927 Adapter cache time: 0.015452063642442226 Engine time: 0.07364581385627389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 56.361715350300074,
    "estimated_duration": 3600.02134555914,
    "input_throughput": 6591.193696468096,
    "output_throughput": 5729.902970004801,
    "total_throughput": 12321.096666472899,
    "itl": 91.43926775212292,
    "ttft": 1950478.990371943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2798368538729945,
    "arrivals": 642182,
    "finished_requests": 95598,
    "scheduler_time": 230.89679337576746
}
#Debug simulation 
Total elapsed time: 56.36188170313835. Arrivals time: 0.4015622758306563 Scheduler time: 55.76050970191136 Scheduler overhead time: 0.07668824400752783 Adapter cache time: 0.015468040946871042 Engine time: 0.07627097750082612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 60.31762690609321,
    "estimated_duration": 3600.100329548464,
    "input_throughput": 6871.107673574907,
    "output_throughput": 5963.141311312447,
    "total_throughput": 12834.248984887354,
    "itl": 100.59482874508669,
    "ttft": 1927521.5800038476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149032935383732,
    "arrivals": 641592,
    "finished_requests": 99940,
    "scheduler_time": 221.29684953322638
}
#Debug simulation 
Total elapsed time: 60.31778697995469. Arrivals time: 0.43114213878288865 Scheduler time: 59.696903250180185 Scheduler overhead time: 0.07246986543759704 Adapter cache time: 0.015344591345638037 Engine time: 0.0722625614143908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 56.768158741761,
    "estimated_duration": 3600.0569615967197,
    "input_throughput": 6789.414795581237,
    "output_throughput": 5897.913623728521,
    "total_throughput": 12687.328419309759,
    "itl": 97.84847836353835,
    "ttft": 1935428.684655781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3779636617936224,
    "arrivals": 641592,
    "finished_requests": 98778,
    "scheduler_time": 224.04907916574533
}
#Debug simulation 
Total elapsed time: 56.76831861399114. Arrivals time: 0.4180674166418612 Scheduler time: 56.15904224431142 Scheduler overhead time: 0.07283555576577783 Adapter cache time: 0.01561263157054782 Engine time: 0.07275991281494498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 53.90614729374647,
    "estimated_duration": 3600.02605065077,
    "input_throughput": 6598.3453080029785,
    "output_throughput": 5733.694064871749,
    "total_throughput": 12332.039372874728,
    "itl": 91.668149741702,
    "ttft": 1950899.3700565323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5965678041149074,
    "arrivals": 641592,
    "finished_requests": 96016,
    "scheduler_time": 230.8972144012062
}
#Debug simulation 
Total elapsed time: 53.90628773998469. Arrivals time: 0.41146324994042516 Scheduler time: 53.29842091770843 Scheduler overhead time: 0.07515571545809507 Adapter cache time: 0.015453592874109745 Engine time: 0.07483787462115288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 60.030823226086795,
    "estimated_duration": 3600.105204219684,
    "input_throughput": 6802.97230516864,
    "output_throughput": 5899.487874717112,
    "total_throughput": 12702.460179885753,
    "itl": 97.93812537852213,
    "ttft": 1933647.7753805092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2444111175509147,
    "arrivals": 641592,
    "finished_requests": 98999,
    "scheduler_time": 223.93146245194976
}
#Debug simulation 
Total elapsed time: 60.030996209941804. Arrivals time: 0.7471475740894675 Scheduler time: 59.091019097715616 Scheduler overhead time: 0.07371854642406106 Adapter cache time: 0.015357908327132463 Engine time: 0.0732932579703629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 53.7853526561521,
    "estimated_duration": 3600.072165430335,
    "input_throughput": 6596.218883618244,
    "output_throughput": 5733.671451981186,
    "total_throughput": 12329.89033559943,
    "itl": 91.6765099291886,
    "ttft": 1950509.645087163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.563585800565793,
    "arrivals": 641592,
    "finished_requests": 95986,
    "scheduler_time": 230.9058449561601
}
#Debug simulation 
Total elapsed time: 53.785516710951924. Arrivals time: 0.41484508104622364 Scheduler time: 53.1711232974194 Scheduler overhead time: 0.07632333878427744 Adapter cache time: 0.015811889432370663 Engine time: 0.07608408946543932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 57.67228793120012,
    "estimated_duration": 3600.0917274639805,
    "input_throughput": 6802.906385180442,
    "output_throughput": 5904.717604230179,
    "total_throughput": 12707.62398941062,
    "itl": 98.13481027094237,
    "ttft": 1934466.5989281351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1513813569722613,
    "arrivals": 641592,
    "finished_requests": 99000,
    "scheduler_time": 223.75451378760374
}
#Debug simulation 
Total elapsed time: 57.67244991194457. Arrivals time: 0.4243584703654051 Scheduler time: 57.05783287389204 Scheduler overhead time: 0.07220059912651777 Adapter cache time: 0.015495278406888247 Engine time: 0.07278424920514226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 52.712734173983335,
    "estimated_duration": 3600.0549690537355,
    "input_throughput": 6593.283214850186,
    "output_throughput": 5728.656139220237,
    "total_throughput": 12321.939354070422,
    "itl": 91.50837486312759,
    "ttft": 1952259.896626596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3206833240762452,
    "arrivals": 641592,
    "finished_requests": 95861,
    "scheduler_time": 231.10920328429407
}
#Debug simulation 
Total elapsed time: 52.71291114483029. Arrivals time: 0.4078641226515174 Scheduler time: 52.107105331961066 Scheduler overhead time: 0.07420784328132868 Adapter cache time: 0.015463763382285833 Engine time: 0.07714267494156957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 57.89023540215567,
    "estimated_duration": 3600.045011962792,
    "input_throughput": 6842.008341048647,
    "output_throughput": 5979.801899272057,
    "total_throughput": 12821.810240320705,
    "itl": 101.07557367274583,
    "ttft": 1933668.8478168978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.552389886332691,
    "arrivals": 636231,
    "finished_requests": 99861,
    "scheduler_time": 220.46013195349582
}
#Debug simulation 
Total elapsed time: 57.89040794596076. Arrivals time: 0.47956413915380836 Scheduler time: 57.223805715795606 Scheduler overhead time: 0.07095410814508796 Adapter cache time: 0.01554619800299406 Engine time: 0.07101045968011022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 55.97813156619668,
    "estimated_duration": 3600.0714657579006,
    "input_throughput": 6769.354228602654,
    "output_throughput": 5918.430843015061,
    "total_throughput": 12687.785071617716,
    "itl": 98.56774024368592,
    "ttft": 1939397.0849088118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.14850112375338,
    "arrivals": 636231,
    "finished_requests": 98793,
    "scheduler_time": 222.9659653987641
}
#Debug simulation 
Total elapsed time: 55.97830700594932. Arrivals time: 0.4829518427141011 Scheduler time: 55.30590310646221 Scheduler overhead time: 0.07174570253118873 Adapter cache time: 0.01635675085708499 Engine time: 0.07165704341605306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 52.76958713168278,
    "estimated_duration": 3600.0195768189865,
    "input_throughput": 6581.616986909891,
    "output_throughput": 5751.335390874478,
    "total_throughput": 12332.95237778437,
    "itl": 92.23837160914512,
    "ttft": 1956277.487800992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.453546373513554,
    "arrivals": 636231,
    "finished_requests": 95998,
    "scheduler_time": 229.87627502094853
}
#Debug simulation 
Total elapsed time: 52.76975285867229. Arrivals time: 0.3994956477545202 Scheduler time: 52.175186762586236 Scheduler overhead time: 0.07380796829238534 Adapter cache time: 0.01643848791718483 Engine time: 0.0742664048448205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 57.838779903016984,
    "estimated_duration": 3600.100210215003,
    "input_throughput": 6772.278152375081,
    "output_throughput": 5915.060902909768,
    "total_throughput": 12687.339055284849,
    "itl": 98.39383019366122,
    "ttft": 1940352.4459443393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7565224914532123,
    "arrivals": 636231,
    "finished_requests": 98755,
    "scheduler_time": 223.12420659908886
}
#Debug simulation 
Total elapsed time: 57.83894974691793. Arrivals time: 0.4148889724165201 Scheduler time: 57.2336886478588 Scheduler overhead time: 0.07226861361414194 Adapter cache time: 0.01596268219873309 Engine time: 0.07228936580941081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 52.62617004010826,
    "estimated_duration": 3600.054204315806,
    "input_throughput": 6585.664730152548,
    "output_throughput": 5752.618662011481,
    "total_throughput": 12338.283392164029,
    "itl": 92.22995804258666,
    "ttft": 1956644.62259467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.33669909259307,
    "arrivals": 636231,
    "finished_requests": 96047,
    "scheduler_time": 229.8751051365598
}
#Debug simulation 
Total elapsed time: 52.62633718876168. Arrivals time: 0.4656982412561774 Scheduler time: 51.96568255638704 Scheduler overhead time: 0.07403896795585752 Adapter cache time: 0.016416282393038273 Engine time: 0.07383177755400538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 59.83155047195032,
    "estimated_duration": 3600.070845358506,
    "input_throughput": 6765.3968619538555,
    "output_throughput": 5910.4895192364065,
    "total_throughput": 12675.886381190261,
    "itl": 98.1536969195589,
    "ttft": 1940418.1322163378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.381202510832799,
    "arrivals": 636231,
    "finished_requests": 98617,
    "scheduler_time": 223.37320039583506
}
#Debug simulation 
Total elapsed time: 59.831726209726185. Arrivals time: 0.41534059308469296 Scheduler time: 59.227353343740106 Scheduler overhead time: 0.07212139759212732 Adapter cache time: 0.015624528285115957 Engine time: 0.0713751963339746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 52.87137947930023,
    "estimated_duration": 3600.033586434318,
    "input_throughput": 6584.809122150256,
    "output_throughput": 5750.514405757116,
    "total_throughput": 12335.323527907372,
    "itl": 92.2435783895891,
    "ttft": 1955838.7281849016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2839405710809184,
    "arrivals": 636231,
    "finished_requests": 96027,
    "scheduler_time": 229.8659983651413
}
#Debug simulation 
Total elapsed time: 52.87154523702338. Arrivals time: 0.47065187245607376 Scheduler time: 52.2052997360006 Scheduler overhead time: 0.07365985307842493 Adapter cache time: 0.016382094006985426 Engine time: 0.07422819221392274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 57.06065888609737,
    "estimated_duration": 3600.026774631771,
    "input_throughput": 6848.026290727141,
    "output_throughput": 5966.719234247117,
    "total_throughput": 12814.745524974258,
    "itl": 100.65633362030376,
    "ttft": 1925256.053565091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4069168876297877,
    "arrivals": 633808,
    "finished_requests": 99746,
    "scheduler_time": 220.86722853244387
}
#Debug simulation 
Total elapsed time: 57.060834483243525. Arrivals time: 0.42367292335256934 Scheduler time: 56.448979690205306 Scheduler overhead time: 0.07168868975713849 Adapter cache time: 0.015218328684568405 Engine time: 0.07159017957746983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 54.20852034725249,
    "estimated_duration": 3600.0773356054283,
    "input_throughput": 6793.358508751899,
    "output_throughput": 5909.394998155584,
    "total_throughput": 12702.753506907482,
    "itl": 98.21398167779275,
    "ttft": 1933424.3338505265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0594000837067177,
    "arrivals": 633808,
    "finished_requests": 98846,
    "scheduler_time": 223.26716162352326
}
#Debug simulation 
Total elapsed time: 54.20868661813438. Arrivals time: 0.7249921215698123 Scheduler time: 53.29435098962858 Scheduler overhead time: 0.07165963714942336 Adapter cache time: 0.016032105311751366 Engine time: 0.07217468833550811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 52.839452140033245,
    "estimated_duration": 3600.0268543747206,
    "input_throughput": 6593.04970771461,
    "output_throughput": 5742.546329863613,
    "total_throughput": 12335.596037578223,
    "itl": 91.86600405654205,
    "ttft": 1948281.8289470985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2873664454557243,
    "arrivals": 633808,
    "finished_requests": 95970,
    "scheduler_time": 230.26975831844803
}
#Debug simulation 
Total elapsed time: 52.83962334971875. Arrivals time: 0.4052339163608849 Scheduler time: 52.23598510585725 Scheduler overhead time: 0.07526354258880019 Adapter cache time: 0.016661494970321655 Engine time: 0.0752321844920516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 57.326288886833936,
    "estimated_duration": 3600.0888229262496,
    "input_throughput": 6783.6987366742815,
    "output_throughput": 5908.388388792747,
    "total_throughput": 12692.087125467027,
    "itl": 98.07751410803996,
    "ttft": 1931194.7606181044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7318178447382486,
    "arrivals": 633808,
    "finished_requests": 98858,
    "scheduler_time": 223.43773539523377
}
#Debug simulation 
Total elapsed time: 57.32645541289821. Arrivals time: 0.7222755602560937 Scheduler time: 56.412951870821416 Scheduler overhead time: 0.07282115425914526 Adapter cache time: 0.015951115638017654 Engine time: 0.07251445576548576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 54.50177373178303,
    "estimated_duration": 3600.0891119243156,
    "input_throughput": 6589.608552028179,
    "output_throughput": 5739.122937697538,
    "total_throughput": 12328.731489725717,
    "itl": 91.77296046705257,
    "ttft": 1947608.5990328037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2369380818680167,
    "arrivals": 633808,
    "finished_requests": 95928,
    "scheduler_time": 230.37972884751218
}
#Debug simulation 
Total elapsed time: 54.50194864999503. Arrivals time: 0.40954656014218926 Scheduler time: 53.89390509435907 Scheduler overhead time: 0.0753694768063724 Adapter cache time: 0.016557794995605946 Engine time: 0.07518255803734064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 55.33346698107198,
    "estimated_duration": 3600.029255149285,
    "input_throughput": 6783.676817367224,
    "output_throughput": 5905.612564006339,
    "total_throughput": 12689.289381373565,
    "itl": 98.000309527986,
    "ttft": 1933348.6216899205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.559952297168773,
    "arrivals": 633808,
    "finished_requests": 98827,
    "scheduler_time": 223.51901938058003
}
#Debug simulation 
Total elapsed time: 55.333627042826265. Arrivals time: 0.72137914551422 Scheduler time: 54.423937269020826 Scheduler overhead time: 0.07169139897450805 Adapter cache time: 0.01552628818899393 Engine time: 0.0711007034406066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 53.37900664191693,
    "estimated_duration": 3600.0310809492958,
    "input_throughput": 6596.2558283630715,
    "output_throughput": 5741.878482490562,
    "total_throughput": 12338.134310853633,
    "itl": 91.89464819564931,
    "ttft": 1947681.6035170588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2936717266030855,
    "arrivals": 633808,
    "finished_requests": 95921,
    "scheduler_time": 230.23940191571768
}
#Debug simulation 
Total elapsed time: 53.3791760741733. Arrivals time: 0.4147594626992941 Scheduler time: 52.766847953666 Scheduler overhead time: 0.07510553020983934 Adapter cache time: 0.016383410431444645 Engine time: 0.07496153376996517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 61.266734613105655,
    "estimated_duration": 3600.104463888264,
    "input_throughput": 6858.139603352994,
    "output_throughput": 5971.672548851697,
    "total_throughput": 12829.81215220469,
    "itl": 100.72628872366764,
    "ttft": 1926364.4801976772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.559002295364641,
    "arrivals": 632594,
    "finished_requests": 99940,
    "scheduler_time": 220.82519708676807
}
#Debug simulation 
Total elapsed time: 61.26690458925441. Arrivals time: 0.4308190727606416 Scheduler time: 60.645881896838546 Scheduler overhead time: 0.07279378175735474 Adapter cache time: 0.015760370064526796 Engine time: 0.07233315706253052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 58.38883662968874,
    "estimated_duration": 3600.1005340710303,
    "input_throughput": 6778.550701306198,
    "output_throughput": 5910.190229032142,
    "total_throughput": 12688.74093033834,
    "itl": 98.15060729372235,
    "ttft": 1932531.4579180852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.953092685737652,
    "arrivals": 632594,
    "finished_requests": 98850,
    "scheduler_time": 223.38328697740033
}
#Debug simulation 
Total elapsed time: 58.38901719683781. Arrivals time: 0.46644638758152723 Scheduler time: 57.72965941950679 Scheduler overhead time: 0.07335818745195866 Adapter cache time: 0.01565800653770566 Engine time: 0.0736358086578548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 57.247273054905236,
    "estimated_duration": 3600.046287638945,
    "input_throughput": 6584.461450229373,
    "output_throughput": 5743.61698375856,
    "total_throughput": 12328.078433987934,
    "itl": 91.89238015479238,
    "ttft": 1949313.9612104686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2611244883435084,
    "arrivals": 632594,
    "finished_requests": 96064,
    "scheduler_time": 230.27551552254204
}
#Debug simulation 
Total elapsed time: 57.24744518613443. Arrivals time: 0.7300230371765792 Scheduler time: 56.31945862015709 Scheduler overhead time: 0.0758169605396688 Adapter cache time: 0.016690537333488464 Engine time: 0.07468055281788111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 58.45424977177754,
    "estimated_duration": 3600.001434065573,
    "input_throughput": 6782.093965009037,
    "output_throughput": 5910.735978782506,
    "total_throughput": 12692.829943791543,
    "itl": 98.13109666461902,
    "ttft": 1932583.0686228557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.740147170578127,
    "arrivals": 632594,
    "finished_requests": 98865,
    "scheduler_time": 223.39180690558874
}
#Debug simulation 
Total elapsed time: 58.45443150168285. Arrivals time: 0.4233716526068747 Scheduler time: 57.83791916118935 Scheduler overhead time: 0.07392895221710205 Adapter cache time: 0.016212958842515945 Engine time: 0.07318862294778228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 61.790211244951934,
    "estimated_duration": 3600.0722643326203,
    "input_throughput": 6582.117596573516,
    "output_throughput": 5742.486395292517,
    "total_throughput": 12324.603991866034,
    "itl": 91.88947338558786,
    "ttft": 1948357.9177678863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.197700749374949,
    "arrivals": 632594,
    "finished_requests": 96041,
    "scheduler_time": 230.2796830842093
}
#Debug simulation 
Total elapsed time: 61.79038905818015. Arrivals time: 0.42039467487484217 Scheduler time: 61.16892321873456 Scheduler overhead time: 0.07701333099976182 Adapter cache time: 0.016653348226100206 Engine time: 0.07613734155893326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 59.247678995132446,
    "estimated_duration": 3600.0065576661495,
    "input_throughput": 6785.52180633704,
    "output_throughput": 5905.573964782644,
    "total_throughput": 12691.095771119684,
    "itl": 97.8407678652848,
    "ttft": 1933387.64345042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2726758548431008,
    "arrivals": 632594,
    "finished_requests": 98783,
    "scheduler_time": 223.72452187232412
}
#Debug simulation 
Total elapsed time: 59.24785505281761. Arrivals time: 0.4206834570504725 Scheduler time: 58.63287155888975 Scheduler overhead time: 0.07411235244944692 Adapter cache time: 0.015791655983775854 Engine time: 0.07418039022013545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 56.09341322584078,
    "estimated_duration": 3600.0693711027607,
    "input_throughput": 6583.320918824454,
    "output_throughput": 5743.601544451956,
    "total_throughput": 12326.92246327641,
    "itl": 91.88783055978595,
    "ttft": 1948843.5881697794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2048904990032554,
    "arrivals": 632594,
    "finished_requests": 96054,
    "scheduler_time": 230.27620134409364
}
#Debug simulation 
Total elapsed time: 56.093588741030544. Arrivals time: 0.41056667966768146 Scheduler time: 55.48430375056341 Scheduler overhead time: 0.07576204324141145 Adapter cache time: 0.016400679014623165 Engine time: 0.07526496751233935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 63.20946926716715,
    "estimated_duration": 3600.035062599193,
    "input_throughput": 6861.8053909077325,
    "output_throughput": 5971.4732290632155,
    "total_throughput": 12833.278619970948,
    "itl": 100.90052903280915,
    "ttft": 1917691.5530574194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2283818437671337,
    "arrivals": 632045,
    "finished_requests": 99971,
    "scheduler_time": 220.77127464251515
}
#Debug simulation 
Total elapsed time: 63.209640209097415. Arrivals time: 0.4149101385846734 Scheduler time: 62.60455481335521 Scheduler overhead time: 0.07260893564671278 Adapter cache time: 0.01535098534077406 Engine time: 0.07280756672844291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 64.10413124365732,
    "estimated_duration": 3600.01074815716,
    "input_throughput": 6802.465523897632,
    "output_throughput": 5912.3376259072265,
    "total_throughput": 12714.803149804859,
    "itl": 98.38533417528191,
    "ttft": 1923093.092328019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7013338494254313,
    "arrivals": 632045,
    "finished_requests": 99010,
    "scheduler_time": 223.26479278076013
}
#Debug simulation 
Total elapsed time: 64.10429298877716. Arrivals time: 0.4624215578660369 Scheduler time: 63.448484387714416 Scheduler overhead time: 0.07439525984227657 Adapter cache time: 0.01566996518522501 Engine time: 0.07344694389030337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 57.372708183247596,
    "estimated_duration": 3600.0949851733717,
    "input_throughput": 6613.909660178962,
    "output_throughput": 5745.225080222138,
    "total_throughput": 12359.1347404011,
    "itl": 91.93170446743423,
    "ttft": 1942235.957404022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.853598276274296,
    "arrivals": 632045,
    "finished_requests": 96205,
    "scheduler_time": 230.3129880209152
}
#Debug simulation 
Total elapsed time: 57.37287420127541. Arrivals time: 0.4065613728016615 Scheduler time: 56.76761321909726 Scheduler overhead time: 0.07606263225898147 Adapter cache time: 0.016098509076982737 Engine time: 0.07526681013405323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 62.37960340920836,
    "estimated_duration": 3600.0483425497187,
    "input_throughput": 6796.537066130269,
    "output_throughput": 5910.9497915599495,
    "total_throughput": 12707.486857690217,
    "itl": 98.3129942791657,
    "ttft": 1923778.140367133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.430659192679447,
    "arrivals": 632045,
    "finished_requests": 98974,
    "scheduler_time": 223.36154336896817
}
#Debug simulation 
Total elapsed time: 62.37977090291679. Arrivals time: 0.4329123734496534 Scheduler time: 61.75475434958935 Scheduler overhead time: 0.0732929790392518 Adapter cache time: 0.015170723665505648 Engine time: 0.07365541439503431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 59.93152621621266,
    "estimated_duration": 3600.0293817516676,
    "input_throughput": 6614.977400104651,
    "output_throughput": 5743.3442362460855,
    "total_throughput": 12358.321636350736,
    "itl": 91.84150358016494,
    "ttft": 1941035.7872288998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7099869966460544,
    "arrivals": 632045,
    "finished_requests": 96296,
    "scheduler_time": 230.3865126868559
}
#Debug simulation 
Total elapsed time: 59.93169032316655. Arrivals time: 0.4167091199196875 Scheduler time: 59.313729426823556 Scheduler overhead time: 0.07710138289257884 Adapter cache time: 0.016057932283729315 Engine time: 0.07638063980266452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 63.51290669012815,
    "estimated_duration": 3600.06297603777,
    "input_throughput": 6799.929379830706,
    "output_throughput": 5911.2229818328415,
    "total_throughput": 12711.152361663548,
    "itl": 98.34552500193867,
    "ttft": 1923221.8948222697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1769170407345433,
    "arrivals": 632045,
    "finished_requests": 99043,
    "scheduler_time": 223.32623155250317
}
#Debug simulation 
Total elapsed time: 63.513079069089144. Arrivals time: 0.49846738250926137 Scheduler time: 62.82197652943432 Scheduler overhead time: 0.07427779491990805 Adapter cache time: 0.01518902974203229 Engine time: 0.07346533797681332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 59.18485725577921,
    "estimated_duration": 3600.105298242707,
    "input_throughput": 6614.354588912541,
    "output_throughput": 5747.7691027816645,
    "total_throughput": 12362.123691694205,
    "itl": 92.0265297512521,
    "ttft": 1940817.0263451554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7504128876887424,
    "arrivals": 632045,
    "finished_requests": 96307,
    "scheduler_time": 230.19959595481026
}
#Debug simulation 
Total elapsed time: 59.18502410501242. Arrivals time: 0.4212484355084598 Scheduler time: 58.56445911107585 Scheduler overhead time: 0.07627135189250112 Adapter cache time: 0.015796986408531666 Engine time: 0.07579499809071422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 62.21768728271127,
    "estimated_duration": 3600.05480537732,
    "input_throughput": 6833.48041347987,
    "output_throughput": 5976.771511328379,
    "total_throughput": 12810.25192480825,
    "itl": 100.95914113741271,
    "ttft": 1916925.1688814296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7838242024509463,
    "arrivals": 629108,
    "finished_requests": 99873,
    "scheduler_time": 220.56763036769948
}
#Debug simulation 
Total elapsed time: 62.2178643187508. Arrivals time: 0.503735673148185 Scheduler time: 61.524595766328275 Scheduler overhead time: 0.07279422832652926 Adapter cache time: 0.015676258597522974 Engine time: 0.07167474506422877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 63.011666079983115,
    "estimated_duration": 3600.003956759213,
    "input_throughput": 6750.617024842748,
    "output_throughput": 5909.961559918097,
    "total_throughput": 12660.578584760846,
    "itl": 98.20413465342268,
    "ttft": 1921520.8675871084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0924340562615584,
    "arrivals": 629108,
    "finished_requests": 98643,
    "scheduler_time": 223.3377463091393
}
#Debug simulation 
Total elapsed time: 63.011840329971164. Arrivals time: 0.7310597756877542 Scheduler time: 62.08680499577895 Scheduler overhead time: 0.07396292686462402 Adapter cache time: 0.016284478828310966 Engine time: 0.0737550244666636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 59.86893208231777,
    "estimated_duration": 3600.0095993641594,
    "input_throughput": 6559.816397203774,
    "output_throughput": 5744.974958859246,
    "total_throughput": 12304.791356063019,
    "itl": 92.04125846141027,
    "ttft": 1936534.295023784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7208296840405404,
    "arrivals": 629108,
    "finished_requests": 95932,
    "scheduler_time": 230.06282130043192
}
#Debug simulation 
Total elapsed time: 59.8690941631794. Arrivals time: 0.4853420602157712 Scheduler time: 59.18462921958417 Scheduler overhead time: 0.07552288845181465 Adapter cache time: 0.01691426755860448 Engine time: 0.07548705022782087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 61.95329773472622,
    "estimated_duration": 3600.0796410961857,
    "input_throughput": 6754.605015514518,
    "output_throughput": 5911.996156151522,
    "total_throughput": 12666.60117166604,
    "itl": 98.30641506960119,
    "ttft": 1921681.3216544066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.966918029370714,
    "arrivals": 629108,
    "finished_requests": 98755,
    "scheduler_time": 223.22803109951013
}
#Debug simulation 
Total elapsed time: 61.95347822876647. Arrivals time: 0.4856050303205848 Scheduler time: 61.27406487427652 Scheduler overhead time: 0.07405373034998775 Adapter cache time: 0.016168262343853712 Engine time: 0.07338877022266388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 60.83773047523573,
    "estimated_duration": 3600.0914682395055,
    "input_throughput": 6545.920904483035,
    "output_throughput": 5745.859843421022,
    "total_throughput": 12291.780747904057,
    "itl": 92.06375039331293,
    "ttft": 1936916.7740486423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6271731820935686,
    "arrivals": 629108,
    "finished_requests": 95849,
    "scheduler_time": 230.05964572911967
}
#Debug simulation 
Total elapsed time: 60.83790714107454. Arrivals time: 0.4838355304673314 Scheduler time: 60.152950833551586 Scheduler overhead time: 0.07662040088325739 Adapter cache time: 0.017057583201676607 Engine time: 0.07591429399326444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 62.912467770278454,
    "estimated_duration": 3600.053291183602,
    "input_throughput": 6755.562218914849,
    "output_throughput": 5912.0399834421605,
    "total_throughput": 12667.60220235701,
    "itl": 98.30538425122151,
    "ttft": 1921845.8141374087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.738702083504747,
    "arrivals": 629108,
    "finished_requests": 98761,
    "scheduler_time": 223.23899883266776
}
#Debug simulation 
Total elapsed time: 62.9126459620893. Arrivals time: 0.4972033235244453 Scheduler time: 62.22291222214699 Scheduler overhead time: 0.07365663070231676 Adapter cache time: 0.015901373233646154 Engine time: 0.07330570602789521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 60.215395263861865,
    "estimated_duration": 3600.053083661888,
    "input_throughput": 6556.120826971867,
    "output_throughput": 5747.869689452452,
    "total_throughput": 12303.99051642432,
    "itl": 92.05219304307963,
    "ttft": 1937395.9790149997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6233872178756004,
    "arrivals": 629108,
    "finished_requests": 95977,
    "scheduler_time": 230.04258984689062
}
#Debug simulation 
Total elapsed time: 60.21556273009628. Arrivals time: 0.4716008617542684 Scheduler time: 59.5432769744657 Scheduler overhead time: 0.0758920181542635 Adapter cache time: 0.01683610351756215 Engine time: 0.07672250038012862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 67.35989752504975,
    "estimated_duration": 3600.0172583395047,
    "input_throughput": 6872.605663955047,
    "output_throughput": 5981.466880503845,
    "total_throughput": 12854.072544458892,
    "itl": 101.15569695420548,
    "ttft": 1917221.3895367698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0152585185692016,
    "arrivals": 627971,
    "finished_requests": 100345,
    "scheduler_time": 220.3146284051879
}
#Debug simulation 
Total elapsed time: 67.3600799748674. Arrivals time: 0.42924272269010544 Scheduler time: 66.73786062560976 Scheduler overhead time: 0.07357854535803199 Adapter cache time: 0.016268134117126465 Engine time: 0.07317269220948219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 66.99079238669947,
    "estimated_duration": 3600.052949600208,
    "input_throughput": 6795.386440834638,
    "output_throughput": 5916.622976994107,
    "total_throughput": 12712.009417828745,
    "itl": 98.48780606590053,
    "ttft": 1923337.9395402535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2897878991765945,
    "arrivals": 627971,
    "finished_requests": 99234,
    "scheduler_time": 222.98213153405197
}
#Debug simulation 
Total elapsed time: 66.99096060078591. Arrivals time: 0.46650479594245553 Scheduler time: 66.33075607568026 Scheduler overhead time: 0.07337577035650611 Adapter cache time: 0.016378186643123627 Engine time: 0.07368677761405706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 63.60242093959823,
    "estimated_duration": 3600.021960992831,
    "input_throughput": 6588.201476820722,
    "output_throughput": 5747.4741054895485,
    "total_throughput": 12335.67558231027,
    "itl": 92.09499185799746,
    "ttft": 1938808.55401536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.64006895030386,
    "arrivals": 627971,
    "finished_requests": 96326,
    "scheduler_time": 229.97957474504864
}
#Debug simulation 
Total elapsed time: 63.60259264195338. Arrivals time: 0.4138432708568871 Scheduler time: 62.9878308866173 Scheduler overhead time: 0.07622791361063719 Adapter cache time: 0.016831316985189915 Engine time: 0.07655360829085112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 66.84058156376705,
    "estimated_duration": 3600.0183687463605,
    "input_throughput": 6796.275322484002,
    "output_throughput": 5917.000364478081,
    "total_throughput": 12713.275686962083,
    "itl": 98.47229374902695,
    "ttft": 1923411.304731657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.120972646675069,
    "arrivals": 627971,
    "finished_requests": 99240,
    "scheduler_time": 223.00256496801748
}
#Debug simulation 
Total elapsed time: 66.84075921494514. Arrivals time: 0.7316412222571671 Scheduler time: 65.9142162213102 Scheduler overhead time: 0.07396433549001813 Adapter cache time: 0.016441504936665297 Engine time: 0.07425367459654808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 62.922778888139874,
    "estimated_duration": 3600.028395960914,
    "input_throughput": 6584.156121266702,
    "output_throughput": 5748.9227093931795,
    "total_throughput": 12333.07883065988,
    "itl": 92.06729836836047,
    "ttft": 1938639.0937582466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.519752187612495,
    "arrivals": 627971,
    "finished_requests": 96262,
    "scheduler_time": 230.039923859306
}
#Debug simulation 
Total elapsed time: 62.92295054579154. Arrivals time: 0.41758526349440217 Scheduler time: 62.30450439406559 Scheduler overhead time: 0.07570115849375725 Adapter cache time: 0.016890129540115595 Engine time: 0.07651001634076238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 66.09452078398317,
    "estimated_duration": 3600.086745808685,
    "input_throughput": 6796.185960931346,
    "output_throughput": 5916.895481699037,
    "total_throughput": 12713.081442630384,
    "itl": 98.46928402632611,
    "ttft": 1923521.5822191334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.942987553603003,
    "arrivals": 627971,
    "finished_requests": 99239,
    "scheduler_time": 223.01457812415998
}
#Debug simulation 
Total elapsed time: 66.0947006419301. Arrivals time: 0.43051272816956043 Scheduler time: 65.46897368039936 Scheduler overhead time: 0.07488767616450787 Adapter cache time: 0.016175213735550642 Engine time: 0.07406866364181042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 64.07690589874983,
    "estimated_duration": 3600.0144235485263,
    "input_throughput": 6575.355322234286,
    "output_throughput": 5742.232271287274,
    "total_throughput": 12317.58759352156,
    "itl": 91.88699747301564,
    "ttft": 1938227.0876260821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4495491613261673,
    "arrivals": 627971,
    "finished_requests": 96168,
    "scheduler_time": 230.26026210601162
}
#Debug simulation 
Total elapsed time: 64.0770798115991. Arrivals time: 0.40810295986011624 Scheduler time: 63.467457184102386 Scheduler overhead time: 0.07641367288306355 Adapter cache time: 0.016720694489777088 Engine time: 0.07666313461959362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 84.3247483279556,
    "estimated_duration": 3600.0256349043643,
    "input_throughput": 6850.362886556261,
    "output_throughput": 5954.500932482794,
    "total_throughput": 12804.863819039056,
    "itl": 100.35028779055975,
    "ttft": 1908480.0412110754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7507621572911956,
    "arrivals": 627360,
    "finished_requests": 99810,
    "scheduler_time": 221.44541874975755
}
#Debug simulation 
Total elapsed time: 84.32490265136585. Arrivals time: 0.5030365874990821 Scheduler time: 83.62269630422816 Scheduler overhead time: 0.07599912956357002 Adapter cache time: 0.016347529366612434 Engine time: 0.07613024022430182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 82.74196525802836,
    "estimated_duration": 3600.1036153673163,
    "input_throughput": 6788.318784959899,
    "output_throughput": 5895.18060241569,
    "total_throughput": 12683.49938737559,
    "itl": 97.9650708059792,
    "ttft": 1912866.8699990562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0741133304871657,
    "arrivals": 627360,
    "finished_requests": 98875,
    "scheduler_time": 223.8002900008757
}
#Debug simulation 
Total elapsed time: 82.74211936909705. Arrivals time: 0.49108872609212995 Scheduler time: 82.04975508805364 Scheduler overhead time: 0.07766217738389969 Adapter cache time: 0.016312480438500643 Engine time: 0.0767281842418015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 78.69919133698568,
    "estimated_duration": 3600.0682355394033,
    "input_throughput": 6607.838086278859,
    "output_throughput": 5739.637875753769,
    "total_throughput": 12347.475962032628,
    "itl": 91.67363267159772,
    "ttft": 1932080.487678173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.219035315080568,
    "arrivals": 627360,
    "finished_requests": 96234,
    "scheduler_time": 230.55221859514037
}
#Debug simulation 
Total elapsed time: 78.69936973089352. Arrivals time: 0.5006238981150091 Scheduler time: 77.98884592903778 Scheduler overhead time: 0.08038271591067314 Adapter cache time: 0.017192556988447905 Engine time: 0.08002482214942575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 83.18626538896933,
    "estimated_duration": 3600.0855786889683,
    "input_throughput": 6788.375016601626,
    "output_throughput": 5895.436243415386,
    "total_throughput": 12683.811260017013,
    "itl": 97.9600181708431,
    "ttft": 1912833.276433481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.857003152407703,
    "arrivals": 627360,
    "finished_requests": 98879,
    "scheduler_time": 223.81342920850597
}
#Debug simulation 
Total elapsed time: 83.1864221659489. Arrivals time: 0.4510310315527022 Scheduler time: 82.534431619104 Scheduler overhead time: 0.07746824901551008 Adapter cache time: 0.016368609853088856 Engine time: 0.07609379943460226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 79.03960509924218,
    "estimated_duration": 3600.0330566575785,
    "input_throughput": 6604.204913072114,
    "output_throughput": 5736.716212037932,
    "total_throughput": 12340.921125110046,
    "itl": 91.57344127721917,
    "ttft": 1932513.2890501732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8411182389315393,
    "arrivals": 627360,
    "finished_requests": 96232,
    "scheduler_time": 230.65961968168426
}
#Debug simulation 
Total elapsed time: 79.03977040108293. Arrivals time: 0.8085480364970863 Scheduler time: 78.02170044044033 Scheduler overhead time: 0.08042584266513586 Adapter cache time: 0.016521983314305544 Engine time: 0.0802676877938211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 84.54341399297118,
    "estimated_duration": 3600.0055555875024,
    "input_throughput": 6788.068968969131,
    "output_throughput": 5894.596458903772,
    "total_throughput": 12682.665427872904,
    "itl": 97.86518921125662,
    "ttft": 1913167.8556753243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.674862874099042,
    "arrivals": 627360,
    "finished_requests": 98867,
    "scheduler_time": 223.90373602137274
}
#Debug simulation 
Total elapsed time: 84.54357822891325. Arrivals time: 0.5189098822884262 Scheduler time: 83.82307008793578 Scheduler overhead time: 0.0774634862318635 Adapter cache time: 0.016539175529032946 Engine time: 0.07617107219994068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 80.44200000492856,
    "estimated_duration": 3600.076110425588,
    "input_throughput": 6606.862541355605,
    "output_throughput": 5738.892280685031,
    "total_throughput": 12345.754822040635,
    "itl": 91.64952248118489,
    "ttft": 1932057.4398706504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.159178451038919,
    "arrivals": 627360,
    "finished_requests": 96220,
    "scheduler_time": 230.5882122773269
}
#Debug simulation 
Total elapsed time: 80.44216843601316. Arrivals time: 0.5069084716960788 Scheduler time: 79.72620983654633 Scheduler overhead time: 0.08142715273424983 Adapter cache time: 0.01675430964678526 Engine time: 0.07873705588281155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 83.91555838566273,
    "estimated_duration": 3600.01446315084,
    "input_throughput": 6865.32741825944,
    "output_throughput": 5979.825975798587,
    "total_throughput": 12845.153394058027,
    "itl": 100.4820030401079,
    "ttft": 1909614.8493406666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.678025657939744,
    "arrivals": 625657,
    "finished_requests": 99917,
    "scheduler_time": 221.6408590202534
}
#Debug simulation 
Total elapsed time: 83.91571948397905. Arrivals time: 0.5094470041804016 Scheduler time: 83.20910290395841 Scheduler overhead time: 0.07570229051634669 Adapter cache time: 0.015857912600040436 Engine time: 0.07562039233744144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 82.79855576716363,
    "estimated_duration": 3600.059802263288,
    "input_throughput": 6793.853808934939,
    "output_throughput": 5936.714714173221,
    "total_throughput": 12730.568523108159,
    "itl": 97.68933106321961,
    "ttft": 1912975.9495232143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.778498084638271,
    "arrivals": 625657,
    "finished_requests": 98928,
    "scheduler_time": 224.6061042063143
}
#Debug simulation 
Total elapsed time: 82.79871208406985. Arrivals time: 0.5080209434963763 Scheduler time: 82.09029489336535 Scheduler overhead time: 0.07721017999574542 Adapter cache time: 0.016029016114771366 Engine time: 0.07617022981867194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 76.60671239672229,
    "estimated_duration": 3600.0305147195995,
    "input_throughput": 6618.412789163763,
    "output_throughput": 5773.80800385215,
    "total_throughput": 12392.220793015913,
    "itl": 91.5587274226044,
    "ttft": 1932577.8344413568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.802192181842419,
    "arrivals": 625657,
    "finished_requests": 96359,
    "scheduler_time": 231.26689943486713
}
#Debug simulation 
Total elapsed time: 76.60689036175609. Arrivals time: 0.48678972385823727 Scheduler time: 75.91414957260713 Scheduler overhead time: 0.0791010707616806 Adapter cache time: 0.016373727470636368 Engine time: 0.07869958691298962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 82.60007044533268,
    "estimated_duration": 3600.0102606516507,
    "input_throughput": 6785.940936617758,
    "output_throughput": 5929.873376565264,
    "total_throughput": 12715.814313183022,
    "itl": 97.909050918207,
    "ttft": 1909552.400886644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.584704332300458,
    "arrivals": 625657,
    "finished_requests": 98731,
    "scheduler_time": 224.2082218679218
}
#Debug simulation 
Total elapsed time: 82.60023051034659. Arrivals time: 0.4400712628848851 Scheduler time: 81.96043747011572 Scheduler overhead time: 0.07724429992958903 Adapter cache time: 0.015749656595289707 Engine time: 0.07596563268452883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 69.05197453359142,
    "estimated_duration": 3600.015275204159,
    "input_throughput": 6376.437666281345,
    "output_throughput": 5566.879990214339,
    "total_throughput": 11943.317656495683,
    "itl": 84.74215739103379,
    "ttft": 1935507.3082005281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7969578939024533,
    "arrivals": 625657,
    "finished_requests": 92794,
    "scheduler_time": 241.2903011349379
}
#Debug simulation 
Total elapsed time: 69.05214878590778. Arrivals time: 0.46998450672253966 Scheduler time: 68.36559826787561 Scheduler overhead time: 0.08293149061501026 Adapter cache time: 0.01699891733005643 Engine time: 0.08260308112949133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 82.0165387489833,
    "estimated_duration": 3600.0048763099253,
    "input_throughput": 6799.2382902241225,
    "output_throughput": 5939.294455044305,
    "total_throughput": 12738.532745268429,
    "itl": 97.83003884341919,
    "ttft": 1914100.5049950976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4514256411790747,
    "arrivals": 625657,
    "finished_requests": 99006,
    "scheduler_time": 224.43709333867014
}
#Debug simulation 
Total elapsed time: 82.01669842517003. Arrivals time: 0.44748368859291077 Scheduler time: 81.36934672575444 Scheduler overhead time: 0.07692223694175482 Adapter cache time: 0.015925857238471508 Engine time: 0.07624176284298301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 69.18657671520486,
    "estimated_duration": 3600.050188905059,
    "input_throughput": 6395.169731509309,
    "output_throughput": 5578.932222083438,
    "total_throughput": 11974.101953592746,
    "itl": 85.1086941368909,
    "ttft": 1935556.60939431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7376783537306055,
    "arrivals": 625657,
    "finished_requests": 93075,
    "scheduler_time": 240.65097259874855
}
#Debug simulation 
Total elapsed time: 69.18675705930218. Arrivals time: 0.47436983324587345 Scheduler time: 68.50085107423365 Scheduler overhead time: 0.08086171373724937 Adapter cache time: 0.01667560450732708 Engine time: 0.08086962345987558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 83.06504016276449,
    "estimated_duration": 3600.0226429504273,
    "input_throughput": 6826.755395032225,
    "output_throughput": 5980.936826095538,
    "total_throughput": 12807.692221127763,
    "itl": 100.18176705807224,
    "ttft": 1907035.685098629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4069168876297877,
    "arrivals": 625114,
    "finished_requests": 99456,
    "scheduler_time": 221.89990008942357
}
#Debug simulation 
Total elapsed time: 83.06519731599838. Arrivals time: 0.4812628421932459 Scheduler time: 82.38601023517549 Scheduler overhead time: 0.07635007752105594 Adapter cache time: 0.016105168033391237 Engine time: 0.07529944367706776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 81.48828780511394,
    "estimated_duration": 3600.0454642225673,
    "input_throughput": 6754.466087069582,
    "output_throughput": 5922.223264089841,
    "total_throughput": 12676.689351159423,
    "itl": 97.48572079083797,
    "ttft": 1910864.2752616853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.517862216243524,
    "arrivals": 625114,
    "finished_requests": 98467,
    "scheduler_time": 224.552008861062
}
#Debug simulation 
Total elapsed time: 81.48845406109467. Arrivals time: 0.44105063704773784 Scheduler time: 80.84732573106885 Scheduler overhead time: 0.0761149413883686 Adapter cache time: 0.01612501870840788 Engine time: 0.07666189037263393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 75.5272432952188,
    "estimated_duration": 3600.0191969294788,
    "input_throughput": 6592.415679405864,
    "output_throughput": 5779.907512089749,
    "total_throughput": 12372.323191495612,
    "itl": 91.5636905101656,
    "ttft": 1931557.5752843362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6021621818980343,
    "arrivals": 625114,
    "finished_requests": 96105,
    "scheduler_time": 231.34387873872024
}
#Debug simulation 
Total elapsed time: 75.52741703530774. Arrivals time: 0.43174194963648915 Scheduler time: 74.88836779631674 Scheduler overhead time: 0.07952339528128505 Adapter cache time: 0.016449373681098223 Engine time: 0.07948056515306234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 81.47318777209148,
    "estimated_duration": 3600.0357770404307,
    "input_throughput": 6757.142291513067,
    "output_throughput": 5930.712171297462,
    "total_throughput": 12687.854462810528,
    "itl": 97.62736262799122,
    "ttft": 1908101.6920432725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3687653881730495,
    "arrivals": 625114,
    "finished_requests": 98516,
    "scheduler_time": 224.49652733861464
}
#Debug simulation 
Total elapsed time: 81.47335203224793. Arrivals time: 0.44837919482961297 Scheduler time: 80.82285362295806 Scheduler overhead time: 0.07824447099119425 Adapter cache time: 0.01582204271107912 Engine time: 0.07671429822221398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 75.33308278303593,
    "estimated_duration": 3600.069818012086,
    "input_throughput": 6592.751863102983,
    "output_throughput": 5780.30400851802,
    "total_throughput": 12373.055871621003,
    "itl": 91.5643452401313,
    "ttft": 1931580.161826071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5785508237639583,
    "arrivals": 625114,
    "finished_requests": 96113,
    "scheduler_time": 231.34699340358492
}
#Debug simulation 
Total elapsed time: 75.33325801882893. Arrivals time: 0.4438962461426854 Scheduler time: 74.68290619784966 Scheduler overhead time: 0.07910688687115908 Adapter cache time: 0.01653680531308055 Engine time: 0.07872808445245028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 81.94117931043729,
    "estimated_duration": 3600.007073634668,
    "input_throughput": 6754.892282877714,
    "output_throughput": 5923.049195142743,
    "total_throughput": 12677.941478020457,
    "itl": 97.48765817261233,
    "ttft": 1910676.07056779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.183300961675114,
    "arrivals": 625114,
    "finished_requests": 98476,
    "scheduler_time": 224.55893908637734
}
#Debug simulation 
Total elapsed time: 81.94133867742494. Arrivals time: 0.7441277098841965 Scheduler time: 80.99661333952099 Scheduler overhead time: 0.07717507425695658 Adapter cache time: 0.015920625999569893 Engine time: 0.07661110488697886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 75.53708682814613,
    "estimated_duration": 3600.0220302987923,
    "input_throughput": 6591.339108563888,
    "output_throughput": 5778.5674156759005,
    "total_throughput": 12369.906524239788,
    "itl": 91.53159260610933,
    "ttft": 1931391.0426954718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5458796753548225,
    "arrivals": 625114,
    "finished_requests": 96086,
    "scheduler_time": 231.38758823022215
}
#Debug simulation 
Total elapsed time: 75.5372641007416. Arrivals time: 0.4318611999042332 Scheduler time: 74.89887928683311 Scheduler overhead time: 0.07965611852705479 Adapter cache time: 0.016127859707921743 Engine time: 0.0787311582826078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 84.6325659188442,
    "estimated_duration": 3600.089185385618,
    "input_throughput": 6912.548750465025,
    "output_throughput": 6018.420901336418,
    "total_throughput": 12930.969651801443,
    "itl": 99.48163061470676,
    "ttft": 1902888.531377258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6200402128277327,
    "arrivals": 623927,
    "finished_requests": 100290,
    "scheduler_time": 223.6525609504482
}
#Debug simulation 
Total elapsed time: 84.63271764619276. Arrivals time: 0.5149275185540318 Scheduler time: 83.91931754397228 Scheduler overhead time: 0.07686134846881032 Adapter cache time: 0.015100270044058561 Engine time: 0.07608484011143446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 83.79434440564364,
    "estimated_duration": 3600.055451893499,
    "input_throughput": 6844.922898906778,
    "output_throughput": 5964.933953643798,
    "total_throughput": 12809.856852550576,
    "itl": 96.90850384106999,
    "ttft": 1908514.7651462357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6357288478594278,
    "arrivals": 623927,
    "finished_requests": 99275,
    "scheduler_time": 226.3486917383435
}
#Debug simulation 
Total elapsed time: 83.79450229555368. Arrivals time: 0.5088544874452055 Scheduler time: 83.08433027286083 Scheduler overhead time: 0.07800917467102408 Adapter cache time: 0.015394738409668207 Engine time: 0.07690260233357549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 79.15542543819174,
    "estimated_duration": 3600.0610448413854,
    "input_throughput": 6674.197937401538,
    "output_throughput": 5805.260449665736,
    "total_throughput": 12479.458387067274,
    "itl": 90.86709778559,
    "ttft": 1926280.0833941957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.607259378544988,
    "arrivals": 623927,
    "finished_requests": 96765,
    "scheduler_time": 233.12891691612015
}
#Debug simulation 
Total elapsed time: 79.1555958809331. Arrivals time: 0.442409242503345 Scheduler time: 78.50361799122766 Scheduler overhead time: 0.08120765397325158 Adapter cache time: 0.015327987261116505 Engine time: 0.08023145329207182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 83.86719549074769,
    "estimated_duration": 3600.04291041408,
    "input_throughput": 6844.037033204702,
    "output_throughput": 5964.266408571868,
    "total_throughput": 12808.30344177657,
    "itl": 96.84414381269266,
    "ttft": 1908930.0656532114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5382795266062008,
    "arrivals": 623927,
    "finished_requests": 99261,
    "scheduler_time": 226.43368657209044
}
#Debug simulation 
Total elapsed time: 83.86735064908862. Arrivals time: 0.5051581356674433 Scheduler time: 83.16104601696134 Scheduler overhead time: 0.0776611971668899 Adapter cache time: 0.014880395960062742 Engine time: 0.07734233466908336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 78.91272063087672,
    "estimated_duration": 3600.0151859337284,
    "input_throughput": 6669.8232534739145,
    "output_throughput": 5802.008580856166,
    "total_throughput": 12471.831834330082,
    "itl": 90.713326740268,
    "ttft": 1926489.668346436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5871705089276675,
    "arrivals": 623927,
    "finished_requests": 96702,
    "scheduler_time": 233.3156663891519
}
#Debug simulation 
Total elapsed time: 78.91289456561208. Arrivals time: 0.5265013882890344 Scheduler time: 78.17907497147098 Scheduler overhead time: 0.0801457054913044 Adapter cache time: 0.015225023031234741 Engine time: 0.07938912650570273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 84.62293350789696,
    "estimated_duration": 3600.0227938336006,
    "input_throughput": 6843.0969498852255,
    "output_throughput": 5961.7000305559795,
    "total_throughput": 12804.796980441204,
    "itl": 96.66820365998163,
    "ttft": 1909353.1387676827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4108465278660836,
    "arrivals": 623927,
    "finished_requests": 99227,
    "scheduler_time": 226.61520767379824
}
#Debug simulation 
Total elapsed time: 84.6230945000425. Arrivals time: 0.8056165347807109 Scheduler time: 83.6158188553527 Scheduler overhead time: 0.07791983522474766 Adapter cache time: 0.01532147079706192 Engine time: 0.07767987763509154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_160_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 78.8159158769995,
    "estimated_duration": 3600.0516761440927,
    "input_throughput": 6674.215306191148,
    "output_throughput": 5805.275557151059,
    "total_throughput": 12479.490863342206,
    "itl": 90.8684533736795,
    "ttft": 1926246.9160629765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5720509550347945,
    "arrivals": 623927,
    "finished_requests": 96765,
    "scheduler_time": 233.1225306713658
}
#Debug simulation 
Total elapsed time: 78.81608603289351. Arrivals time: 0.49048166489228606 Scheduler time: 78.11830699956045 Scheduler overhead time: 0.08026231778785586 Adapter cache time: 0.015166150871664286 Engine time: 0.07954513700678945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 81.98525924701244,
    "estimated_duration": 3600.030027401179,
    "input_throughput": 6830.841357662824,
    "output_throughput": 5927.809723133148,
    "total_throughput": 12758.651080795971,
    "itl": 99.65965922364133,
    "ttft": 1892251.1381489201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9175986192654795,
    "arrivals": 540089,
    "finished_requests": 99358,
    "scheduler_time": 221.7759865535207
}
#Debug simulation 
Total elapsed time: 81.98542549880221. Arrivals time: 0.533722510561347 Scheduler time: 81.2477768198587 Scheduler overhead time: 0.07909439317882061 Adapter cache time: 0.015764005482196808 Engine time: 0.07822803594172001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 81.13261918816715,
    "estimated_duration": 3600.055012716665,
    "input_throughput": 6744.18444002563,
    "output_throughput": 5864.393717713888,
    "total_throughput": 12608.578157739517,
    "itl": 96.63716558014563,
    "ttft": 1894021.4130517952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.093728036852556,
    "arrivals": 540089,
    "finished_requests": 98028,
    "scheduler_time": 225.29457343482156
}
#Debug simulation 
Total elapsed time: 81.1327871568501. Arrivals time: 0.48227130714803934 Scheduler time: 80.44374902592972 Scheduler overhead time: 0.08003775216639042 Adapter cache time: 0.016169690992683172 Engine time: 0.07943500857800245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_160_slots_32_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 70.88550079800189,
    "estimated_duration": 3600.063970505585,
    "input_throughput": 6587.393778080424,
    "output_throughput": 5718.730324980502,
    "total_throughput": 12306.124103060927,
    "itl": 90.97667864434818,
    "ttft": 1916567.1579746315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3581711742933935,
    "arrivals": 540089,
    "finished_requests": 95727,
    "scheduler_time": 231.24508193942378
}
#Debug simulation 
Total elapsed time: 70.88567231502384. Arrivals time: 0.5081033110618591 Scheduler time: 70.16955086123198 Scheduler overhead time: 0.0803100485354662 Adapter cache time: 0.01621434837579727 Engine time: 0.0792187531478703 
