INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 17.722830826882273,
    "estimated_duration": 3600.0092410549873,
    "input_throughput": 5447.94962644387,
    "output_throughput": 4745.920039636652,
    "total_throughput": 10193.869666080524,
    "itl": 110.18797597839941,
    "ttft": 1772372.1881281796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.17824717629235,
    "arrivals": 236027,
    "finished_requests": 79404,
    "scheduler_time": 146.28130384757426
}
#Debug simulation 
Total elapsed time: 17.723031369037926. Arrivals time: 0.31279807072132826 Scheduler time: 17.245297210291028 Scheduler overhead time: 0.05983790382742882 Adapter cache time: 0.023412544280290604 Engine time: 0.0566352684982121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 11.237963032908738,
    "estimated_duration": 3600.0340198675567,
    "input_throughput": 5148.513291183255,
    "output_throughput": 4481.605982321677,
    "total_throughput": 9630.119273504934,
    "itl": 97.81819879578832,
    "ttft": 1825367.1877130407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.278265312593305,
    "arrivals": 236027,
    "finished_requests": 75014,
    "scheduler_time": 152.3434602168358
}
#Debug simulation 
Total elapsed time: 11.238112438935786. Arrivals time: 0.28252590261399746 Scheduler time: 10.782266719732434 Scheduler overhead time: 0.06200898811221123 Adapter cache time: 0.027697211131453514 Engine time: 0.05689627444371581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 23.6831774758175,
    "estimated_duration": 3600.095080719879,
    "input_throughput": 5447.320573566237,
    "output_throughput": 4750.289538625287,
    "total_throughput": 10197.610112191524,
    "itl": 110.17323458151836,
    "ttft": 1766113.7541445578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 920,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.8732072653248615,
    "arrivals": 236027,
    "finished_requests": 79397,
    "scheduler_time": 146.34676921902414
}
#Debug simulation 
Total elapsed time: 23.683306884020567. Arrivals time: 0.3209474291652441 Scheduler time: 23.195320073049515 Scheduler overhead time: 0.062477180268615484 Adapter cache time: 0.020576929207891226 Engine time: 0.05861844774335623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.543427643366158,
    "estimated_duration": 3600.0922085698276,
    "input_throughput": 5164.844932509831,
    "output_throughput": 4492.1482737311735,
    "total_throughput": 9656.993206241004,
    "itl": 97.75728892213832,
    "ttft": 1822276.6531163745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.664788123499495,
    "arrivals": 236027,
    "finished_requests": 75210,
    "scheduler_time": 152.5968303896063
}
#Debug simulation 
Total elapsed time: 11.543530219234526. Arrivals time: 0.2725796983577311 Scheduler time: 11.098509055562317 Scheduler overhead time: 0.061809788923710585 Adapter cache time: 0.02678838698193431 Engine time: 0.05703290272504091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 27.052644026000053,
    "estimated_duration": 3600.0273305014966,
    "input_throughput": 5624.15396918098,
    "output_throughput": 4918.111551540244,
    "total_throughput": 10542.265520721225,
    "itl": 116.87694064686578,
    "ttft": 1736418.6226468408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.197353499112751,
    "arrivals": 233648,
    "finished_requests": 81744,
    "scheduler_time": 144.3236096661371
}
#Debug simulation 
Total elapsed time: 27.05277426633984. Arrivals time: 0.3374536740593612 Scheduler time: 26.553512025624514 Scheduler overhead time: 0.061422888189554214 Adapter cache time: 0.019335045479238033 Engine time: 0.05680702393874526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 17.539178436622024,
    "estimated_duration": 3600.0798672087403,
    "input_throughput": 5455.298139045774,
    "output_throughput": 4772.377178765466,
    "total_throughput": 10227.67531781124,
    "itl": 109.31521102022198,
    "ttft": 1766577.4757016832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.799405552279213,
    "arrivals": 233648,
    "finished_requests": 79220,
    "scheduler_time": 147.27353471534744
}
#Debug simulation 
Total elapsed time: 17.539305886719376. Arrivals time: 0.31444858852773905 Scheduler time: 17.063148258253932 Scheduler overhead time: 0.06014992017298937 Adapter cache time: 0.020820703357458115 Engine time: 0.05589542631059885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 13.136617872864008,
    "estimated_duration": 3600.089499809821,
    "input_throughput": 5182.325328574629,
    "output_throughput": 4534.231996416288,
    "total_throughput": 9716.557324990916,
    "itl": 96.82242141833943,
    "ttft": 1811992.86980872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.434059350434682,
    "arrivals": 233648,
    "finished_requests": 75330,
    "scheduler_time": 154.06888089788265
}
#Debug simulation 
Total elapsed time: 13.136741118039936. Arrivals time: 0.28223783196881413 Scheduler time: 12.681208278983831 Scheduler overhead time: 0.06374626979231834 Adapter cache time: 0.024023798294365406 Engine time: 0.058470248244702816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 19.03885318012908,
    "estimated_duration": 3600.046597686911,
    "input_throughput": 5486.310375174123,
    "output_throughput": 4790.591602642328,
    "total_throughput": 10276.901977816451,
    "itl": 109.12909186316497,
    "ttft": 1759738.3471734915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.792275430196887,
    "arrivals": 233648,
    "finished_requests": 79611,
    "scheduler_time": 147.7102434937131
}
#Debug simulation 
Total elapsed time: 19.03898435877636. Arrivals time: 0.3182993661612272 Scheduler time: 18.557747276034206 Scheduler overhead time: 0.06076783686876297 Adapter cache time: 0.02006201585754752 Engine time: 0.056940785609185696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 11.016373770777136,
    "estimated_duration": 3600.0388043148205,
    "input_throughput": 5156.480807304274,
    "output_throughput": 4514.293284983938,
    "total_throughput": 9670.774092288213,
    "itl": 97.25750143229064,
    "ttft": 1813245.0261816587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.565139994281294,
    "arrivals": 233648,
    "finished_requests": 74985,
    "scheduler_time": 153.36234805736376
}
#Debug simulation 
Total elapsed time: 11.01649293070659. Arrivals time: 0.2710130256600678 Scheduler time: 10.572824112139642 Scheduler overhead time: 0.062434620689600706 Adapter cache time: 0.025513377506285906 Engine time: 0.05779678234830499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 20.075569605920464,
    "estimated_duration": 3600.112711892513,
    "input_throughput": 5472.256725441155,
    "output_throughput": 4784.761305693893,
    "total_throughput": 10257.018031135049,
    "itl": 109.01620168263844,
    "ttft": 1763768.8177574293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.579546902058619,
    "arrivals": 233648,
    "finished_requests": 79480,
    "scheduler_time": 147.7187514934051
}
#Debug simulation 
Total elapsed time: 20.075726355891675. Arrivals time: 0.3235445274040103 Scheduler time: 19.58658731309697 Scheduler overhead time: 0.06195353763177991 Adapter cache time: 0.020976070780307055 Engine time: 0.057158018462359905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.216000842861831,
    "estimated_duration": 3600.0176145577275,
    "input_throughput": 5164.114732334149,
    "output_throughput": 4520.397881997376,
    "total_throughput": 9684.512614331526,
    "itl": 97.17769022140384,
    "ttft": 1814604.4621403406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.520604532752143,
    "arrivals": 233648,
    "finished_requests": 75102,
    "scheduler_time": 153.5310124018436
}
#Debug simulation 
Total elapsed time: 11.216120752040297. Arrivals time: 0.27622679667547345 Scheduler time: 10.767604176420718 Scheduler overhead time: 0.06188033567741513 Adapter cache time: 0.025921619962900877 Engine time: 0.05769197642803192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 31.181712828110904,
    "estimated_duration": 3600.0982393094323,
    "input_throughput": 5657.318396929846,
    "output_throughput": 4961.273502199233,
    "total_throughput": 10618.59189912908,
    "itl": 116.17328658944878,
    "ttft": 1721371.1231563573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.332654152102809,
    "arrivals": 232444,
    "finished_requests": 82888,
    "scheduler_time": 145.37807918924995
}
#Debug simulation 
Total elapsed time: 31.18184846267104. Arrivals time: 0.34679033095017076 Scheduler time: 30.670062916353345 Scheduler overhead time: 0.06410181196406484 Adapter cache time: 0.016637178137898445 Engine time: 0.05927010718733072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 20.561590414959937,
    "estimated_duration": 3600.0060186302576,
    "input_throughput": 5523.099655140361,
    "output_throughput": 4850.136891338709,
    "total_throughput": 10373.236546479071,
    "itl": 108.1998478052735,
    "ttft": 1744964.641761756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.626294022193184,
    "arrivals": 232444,
    "finished_requests": 80897,
    "scheduler_time": 149.27254999370925
}
#Debug simulation 
Total elapsed time: 20.561693239957094. Arrivals time: 0.32061119517311454 Scheduler time: 20.076866153627634 Scheduler overhead time: 0.06290527991950512 Adapter cache time: 0.017434486653655767 Engine time: 0.058328961953520775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.53371618501842,
    "estimated_duration": 3600.038592947484,
    "input_throughput": 5205.906135760526,
    "output_throughput": 4573.693746577063,
    "total_throughput": 9779.59988233759,
    "itl": 96.54333235394526,
    "ttft": 1800900.615460442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.004310558107701,
    "arrivals": 232444,
    "finished_requests": 76252,
    "scheduler_time": 154.91489309131185
}
#Debug simulation 
Total elapsed time: 12.533822306897491. Arrivals time: 0.28938881680369377 Scheduler time: 12.074727829545736 Scheduler overhead time: 0.0628741318359971 Adapter cache time: 0.021110812202095985 Engine time: 0.05846236739307642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 24.186452717985958,
    "estimated_duration": 3600.102473281021,
    "input_throughput": 5510.500366929815,
    "output_throughput": 4837.734517075369,
    "total_throughput": 10348.234884005184,
    "itl": 108.18638953975966,
    "ttft": 1746236.0936306987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.782964497278439,
    "arrivals": 232444,
    "finished_requests": 80723,
    "scheduler_time": 149.1274416557421
}
#Debug simulation 
Total elapsed time: 24.186610258184373. Arrivals time: 0.3357213558629155 Scheduler time: 23.682219123933464 Scheduler overhead time: 0.06449710205197334 Adapter cache time: 0.01735696103423834 Engine time: 0.06087201228365302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 12.00823974981904,
    "estimated_duration": 3600.0187137636694,
    "input_throughput": 5182.007784758606,
    "output_throughput": 4554.530768774324,
    "total_throughput": 9736.538553532931,
    "itl": 96.18905211445457,
    "ttft": 1804861.180301802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.356429753028807,
    "arrivals": 232444,
    "finished_requests": 75943,
    "scheduler_time": 154.9835567103954
}
#Debug simulation 
Total elapsed time: 12.0083830030635. Arrivals time: 0.2804068187251687 Scheduler time: 11.557554989121854 Scheduler overhead time: 0.06294434238225222 Adapter cache time: 0.02172894962131977 Engine time: 0.05836903350427747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 22.39996402990073,
    "estimated_duration": 3600.1172005152935,
    "input_throughput": 5528.789728609683,
    "output_throughput": 4852.9472866881415,
    "total_throughput": 10381.737015297824,
    "itl": 108.2223446995388,
    "ttft": 1754091.3039000053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.175084295133109,
    "arrivals": 232444,
    "finished_requests": 81003,
    "scheduler_time": 149.31121602155565
}
#Debug simulation 
Total elapsed time: 22.40012120688334. Arrivals time: 0.3195567359216511 Scheduler time: 21.914767454378307 Scheduler overhead time: 0.06334801483899355 Adapter cache time: 0.017978655640035868 Engine time: 0.05867810221388936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.768504062201828,
    "estimated_duration": 3600.0922102507816,
    "input_throughput": 5172.444179895839,
    "output_throughput": 4547.982397056283,
    "total_throughput": 9720.42657695212,
    "itl": 96.14763953947269,
    "ttft": 1805398.582010323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.592569541074358,
    "arrivals": 232444,
    "finished_requests": 75804,
    "scheduler_time": 154.91427799244636
}
#Debug simulation 
Total elapsed time: 12.768625780008733. Arrivals time: 0.2842785641551018 Scheduler time: 12.313465858343989 Scheduler overhead time: 0.0638602189719677 Adapter cache time: 0.021038871724158525 Engine time: 0.058709883596748114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 39.524663608986884,
    "estimated_duration": 3600.0149655632667,
    "input_throughput": 5728.874240047254,
    "output_throughput": 4973.671823944347,
    "total_throughput": 10702.546063991602,
    "itl": 115.00108351671543,
    "ttft": 1695810.3837778475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1291957082878814,
    "arrivals": 231825,
    "finished_requests": 83094,
    "scheduler_time": 146.22801149053421
}
#Debug simulation 
Total elapsed time: 39.52480795001611. Arrivals time: 0.3514794996008277 Scheduler time: 39.0052077001892 Scheduler overhead time: 0.06631442392244935 Adapter cache time: 0.014592907391488552 Engine time: 0.062010086607187986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 17.698538686148822,
    "estimated_duration": 3600.0772125963363,
    "input_throughput": 5595.84498063343,
    "output_throughput": 4866.345071350659,
    "total_throughput": 10462.19005198409,
    "itl": 107.37966310613953,
    "ttft": 1746670.6511832634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4525399358244675,
    "arrivals": 231825,
    "finished_requests": 81220,
    "scheduler_time": 149.97022491383106
}
#Debug simulation 
Total elapsed time: 17.698689001146704. Arrivals time: 0.31984311109408736 Scheduler time: 17.218482917174697 Scheduler overhead time: 0.061134759336709976 Adapter cache time: 0.016730467323213816 Engine time: 0.05694022215902805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.565326256211847,
    "estimated_duration": 3600.0537180329184,
    "input_throughput": 5261.398157789045,
    "output_throughput": 4572.894820301531,
    "total_throughput": 9834.292978090576,
    "itl": 95.53079951268096,
    "ttft": 1805864.1001373257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.104804079383637,
    "arrivals": 231825,
    "finished_requests": 76271,
    "scheduler_time": 155.76152740841334
}
#Debug simulation 
Total elapsed time: 11.56546665308997. Arrivals time: 0.2860656287521124 Scheduler time: 11.109389312565327 Scheduler overhead time: 0.0638015465810895 Adapter cache time: 0.02059616381302476 Engine time: 0.058324099984019995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 19.397229835856706,
    "estimated_duration": 3600.096332207796,
    "input_throughput": 5583.634754482382,
    "output_throughput": 4859.522742068173,
    "total_throughput": 10443.157496550555,
    "itl": 107.29734135349256,
    "ttft": 1747559.0972855208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9570019144518245,
    "arrivals": 231825,
    "finished_requests": 81067,
    "scheduler_time": 149.9521806258301
}
#Debug simulation 
Total elapsed time: 19.397390895988792. Arrivals time: 0.30660039046779275 Scheduler time: 18.930204595904797 Scheduler overhead time: 0.06170276878401637 Adapter cache time: 0.016067175660282373 Engine time: 0.05723201064392924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 11.695352628827095,
    "estimated_duration": 3600.086974537327,
    "input_throughput": 5270.334893072532,
    "output_throughput": 4581.561255785984,
    "total_throughput": 9851.896148858517,
    "itl": 95.91311553743527,
    "ttft": 1805800.7410806208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.6625795747991905,
    "arrivals": 231825,
    "finished_requests": 76414,
    "scheduler_time": 155.5127278097756
}
#Debug simulation 
Total elapsed time: 11.695479919202626. Arrivals time: 0.2756840460933745 Scheduler time: 11.251651871949434 Scheduler overhead time: 0.06262953812256455 Adapter cache time: 0.02030796743929386 Engine time: 0.05803846661001444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 17.75348143465817,
    "estimated_duration": 3600.0980628751745,
    "input_throughput": 5604.163455449614,
    "output_throughput": 4876.136620006472,
    "total_throughput": 10480.300075456085,
    "itl": 107.29852947566046,
    "ttft": 1747254.317471226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8878078528074367,
    "arrivals": 231825,
    "finished_requests": 81359,
    "scheduler_time": 150.151921707212
}
#Debug simulation 
Total elapsed time: 17.753614605870098. Arrivals time: 0.31014220509678125 Scheduler time: 17.283943406306207 Scheduler overhead time: 0.06096577551215887 Adapter cache time: 0.016741096042096615 Engine time: 0.05636724038049579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.061256993096322,
    "estimated_duration": 3600.051020094264,
    "input_throughput": 5253.589433714407,
    "output_throughput": 4567.486379559546,
    "total_throughput": 9821.075813273954,
    "itl": 96.13070113477959,
    "ttft": 1806689.797303245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.17072774210947,
    "arrivals": 231825,
    "finished_requests": 76162,
    "scheduler_time": 155.10099692150678
}
#Debug simulation 
Total elapsed time: 11.061359435785562. Arrivals time: 0.27392478520050645 Scheduler time: 10.618089064024389 Scheduler overhead time: 0.06331446347758174 Adapter cache time: 0.020971721038222313 Engine time: 0.05790176475420594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 14.524099102243781,
    "estimated_duration": 3600.041505305688,
    "input_throughput": 5592.219970333515,
    "output_throughput": 4882.226767134886,
    "total_throughput": 10474.446737468403,
    "itl": 117.30719378421117,
    "ttft": 1616199.8436451012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.638351203748043,
    "arrivals": 183717,
    "finished_requests": 81138,
    "scheduler_time": 139.75526845078159
}
#Debug simulation 
Total elapsed time: 14.524201644118875. Arrivals time: 0.2991046588867903 Scheduler time: 14.080350968521088 Scheduler overhead time: 0.0557410535402596 Adapter cache time: 0.013545611407607794 Engine time: 0.05194872384890914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.65417515905574,
    "estimated_duration": 3600.120269967033,
    "input_throughput": 5440.1193658397815,
    "output_throughput": 4745.263690914537,
    "total_throughput": 10185.38305675432,
    "itl": 109.59170017054649,
    "ttft": 1648243.9168615032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3997027761396064,
    "arrivals": 183717,
    "finished_requests": 78863,
    "scheduler_time": 142.85739271729423
}
#Debug simulation 
Total elapsed time: 12.654280561953783. Arrivals time: 0.27776117343455553 Scheduler time: 12.226490563247353 Scheduler overhead time: 0.057690472807735205 Adapter cache time: 0.014833283144980669 Engine time: 0.052983670961111784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 9.921237278729677,
    "estimated_duration": 3600.026580385733,
    "input_throughput": 5142.4934195948,
    "output_throughput": 4484.666332177502,
    "total_throughput": 9627.159751772302,
    "itl": 97.36296733931124,
    "ttft": 1708788.261046847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.343171486668311,
    "arrivals": 183717,
    "finished_requests": 74543,
    "scheduler_time": 148.8014960802861
}
#Debug simulation 
Total elapsed time: 9.921341367997229. Arrivals time: 0.25584860518574715 Scheduler time: 9.500281108077615 Scheduler overhead time: 0.06187995010986924 Adapter cache time: 0.019998399075120687 Engine time: 0.056449949741363525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 12.4295984050259,
    "estimated_duration": 3600.0194340831467,
    "input_throughput": 5437.887311012738,
    "output_throughput": 4746.879374653207,
    "total_throughput": 10184.766685665945,
    "itl": 109.6042659980961,
    "ttft": 1647715.8738061998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.172317867320958,
    "arrivals": 183717,
    "finished_requests": 78860,
    "scheduler_time": 142.8553062959864
}
#Debug simulation 
Total elapsed time: 12.429708546027541. Arrivals time: 0.2789948941208422 Scheduler time: 12.000734969042242 Scheduler overhead time: 0.057408442720770836 Adapter cache time: 0.014620163477957249 Engine time: 0.05331511190161109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 9.960052060894668,
    "estimated_duration": 3600.0819053508008,
    "input_throughput": 5141.967457042118,
    "output_throughput": 4483.282165333752,
    "total_throughput": 9625.24962237587,
    "itl": 97.36309312085483,
    "ttft": 1709561.2316096649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.315670426352902,
    "arrivals": 183717,
    "finished_requests": 74499,
    "scheduler_time": 148.80010822040276
}
#Debug simulation 
Total elapsed time: 9.960154220927507. Arrivals time: 0.2592785879969597 Scheduler time: 9.535364691633731 Scheduler overhead time: 0.06195081351324916 Adapter cache time: 0.02008402906358242 Engine time: 0.056564031168818474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 12.767977478913963,
    "estimated_duration": 3600.0556017001322,
    "input_throughput": 5440.81485595664,
    "output_throughput": 4746.048364345009,
    "total_throughput": 10186.86322030165,
    "itl": 109.58208585618426,
    "ttft": 1647878.115018756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.840844818553875,
    "arrivals": 183717,
    "finished_requests": 78892,
    "scheduler_time": 142.8718541498755
}
#Debug simulation 
Total elapsed time: 12.768081138841808. Arrivals time: 0.2888238960877061 Scheduler time: 12.3291303566657 Scheduler overhead time: 0.057784460950642824 Adapter cache time: 0.014384010341018438 Engine time: 0.053334747441112995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 9.965616263914853,
    "estimated_duration": 3600.063504372289,
    "input_throughput": 5143.033165251994,
    "output_throughput": 4485.354211221201,
    "total_throughput": 9628.387376473194,
    "itl": 97.36129873839485,
    "ttft": 1709039.220384674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 877,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.440055994894375,
    "arrivals": 183717,
    "finished_requests": 74519,
    "scheduler_time": 148.80084803508953
}
#Debug simulation 
Total elapsed time: 9.965718501713127. Arrivals time: 0.25983902299776673 Scheduler time: 9.540024903137237 Scheduler overhead time: 0.0616706321015954 Adapter cache time: 0.020440421532839537 Engine time: 0.05679764412343502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 12.476997538935393,
    "estimated_duration": 3600.0615202095873,
    "input_throughput": 5557.310309195844,
    "output_throughput": 4889.249503429395,
    "total_throughput": 10446.559812625239,
    "itl": 118.17744558375199,
    "ttft": 1593576.3892340064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8697855198662983,
    "arrivals": 179046,
    "finished_requests": 80996,
    "scheduler_time": 138.8789471673321
}
#Debug simulation 
Total elapsed time: 12.477102244272828. Arrivals time: 0.2826885231770575 Scheduler time: 12.050291656050831 Scheduler overhead time: 0.056864097248762846 Adapter cache time: 0.013768373057246208 Engine time: 0.05032190354540944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.481114956084639,
    "estimated_duration": 3600.034422756769,
    "input_throughput": 5401.936680679878,
    "output_throughput": 4755.332585650847,
    "total_throughput": 10157.269266330724,
    "itl": 110.45725743584838,
    "ttft": 1623778.0500348934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9118236277252483,
    "arrivals": 179046,
    "finished_requests": 78741,
    "scheduler_time": 141.9267065539243
}
#Debug simulation 
Total elapsed time: 11.481191696133465. Arrivals time: 0.27805671701207757 Scheduler time: 11.054500037338585 Scheduler overhead time: 0.056361837312579155 Adapter cache time: 0.01579388976097107 Engine time: 0.051986382342875004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 9.470768062863499,
    "estimated_duration": 3600.0752587147463,
    "input_throughput": 5111.314813615684,
    "output_throughput": 4497.914025769828,
    "total_throughput": 9609.228839385512,
    "itl": 98.15043470859989,
    "ttft": 1685294.6705998867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.931922731213295,
    "arrivals": 179046,
    "finished_requests": 74562,
    "scheduler_time": 147.7998947088643
}
#Debug simulation 
Total elapsed time: 9.470870410092175. Arrivals time: 0.2547436263412237 Scheduler time: 9.048750801477581 Scheduler overhead time: 0.06356247002258897 Adapter cache time: 0.019807117991149426 Engine time: 0.057036991231143475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 11.351622020825744,
    "estimated_duration": 3600.1066479386313,
    "input_throughput": 5401.879972398947,
    "output_throughput": 4755.282183043769,
    "total_throughput": 10157.162155442717,
    "itl": 110.46189605209558,
    "ttft": 1623531.4007206755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4498862405167845,
    "arrivals": 179046,
    "finished_requests": 78734,
    "scheduler_time": 141.94915014745146
}
#Debug simulation 
Total elapsed time: 11.351729300804436. Arrivals time: 0.27624055929481983 Scheduler time: 10.926178445573896 Scheduler overhead time: 0.05688435351476073 Adapter cache time: 0.015338099095970392 Engine time: 0.052603543270379305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 9.26820314815268,
    "estimated_duration": 3600.097855516344,
    "input_throughput": 5101.124674114189,
    "output_throughput": 4489.497410531324,
    "total_throughput": 9590.622084645513,
    "itl": 97.9655264775437,
    "ttft": 1685605.926406871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.361195662105474,
    "arrivals": 179046,
    "finished_requests": 74370,
    "scheduler_time": 147.87547079039544
}
#Debug simulation 
Total elapsed time: 9.268275163136423. Arrivals time: 0.2552245859988034 Scheduler time: 8.847129922360182 Scheduler overhead time: 0.0613686041906476 Adapter cache time: 0.02183837816119194 Engine time: 0.05601521860808134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 11.240438661072403,
    "estimated_duration": 3600.0816883880675,
    "input_throughput": 5402.584630991693,
    "output_throughput": 4756.005413773363,
    "total_throughput": 10158.590044765057,
    "itl": 110.46471199392188,
    "ttft": 1624405.8195535566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5239243591949183,
    "arrivals": 179046,
    "finished_requests": 78769,
    "scheduler_time": 141.9324257340427
}
#Debug simulation 
Total elapsed time: 11.240541866980493. Arrivals time: 0.2780793500132859 Scheduler time: 10.813440441153944 Scheduler overhead time: 0.05671455338597298 Adapter cache time: 0.015602283645421267 Engine time: 0.05233104294165969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 8.97385922819376,
    "estimated_duration": 3600.006050773457,
    "input_throughput": 5104.764475618502,
    "output_throughput": 4494.458556958183,
    "total_throughput": 9599.223032576685,
    "itl": 98.0558908535422,
    "ttft": 1685569.301670189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.873209095839431,
    "arrivals": 179046,
    "finished_requests": 74475,
    "scheduler_time": 147.82091317749993
}
#Debug simulation 
Total elapsed time: 8.973965046927333. Arrivals time: 0.2565203085541725 Scheduler time: 8.55140513787046 Scheduler overhead time: 0.06172806676477194 Adapter cache time: 0.02106470661237836 Engine time: 0.0563351996243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 10.91863590106368,
    "estimated_duration": 3600.034965076345,
    "input_throughput": 5557.131026247058,
    "output_throughput": 4887.834471248486,
    "total_throughput": 10444.965497495545,
    "itl": 117.83847044223343,
    "ttft": 1585394.8764639043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1078322450165037,
    "arrivals": 176720,
    "finished_requests": 81289,
    "scheduler_time": 138.68641594368674
}
#Debug simulation 
Total elapsed time: 10.918747272342443. Arrivals time: 0.2736539412289858 Scheduler time: 10.504661473445594 Scheduler overhead time: 0.0538917500525713 Adapter cache time: 0.013910686131566763 Engine time: 0.049525358248502016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 9.873325971886516,
    "estimated_duration": 3600.1206265273863,
    "input_throughput": 5404.601961564853,
    "output_throughput": 4755.122335029286,
    "total_throughput": 10159.724296594139,
    "itl": 110.13619436982182,
    "ttft": 1617479.89509473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.913211848698561,
    "arrivals": 176720,
    "finished_requests": 79097,
    "scheduler_time": 141.7242659473505
}
#Debug simulation 
Total elapsed time: 9.873429218772799. Arrivals time: 0.2617846014909446 Scheduler time: 9.465413658879697 Scheduler overhead time: 0.05554009648039937 Adapter cache time: 0.015171113889664412 Engine time: 0.05127277644351125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 8.616522702854127,
    "estimated_duration": 3600.019879366811,
    "input_throughput": 5086.637744684011,
    "output_throughput": 4485.317731867652,
    "total_throughput": 9571.955476551662,
    "itl": 97.50423552805918,
    "ttft": 1678111.9761617351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7360832332540586,
    "arrivals": 176720,
    "finished_requests": 74478,
    "scheduler_time": 147.86133272741407
}
#Debug simulation 
Total elapsed time: 8.616629651747644. Arrivals time: 0.24657803494483232 Scheduler time: 8.207309307996184 Scheduler overhead time: 0.0608887760899961 Adapter cache time: 0.018885175231844187 Engine time: 0.05624731909483671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 9.82972413720563,
    "estimated_duration": 3600.0376908512885,
    "input_throughput": 5402.312328402616,
    "output_throughput": 4755.081882476639,
    "total_throughput": 10157.394210879254,
    "itl": 110.18278423374917,
    "ttft": 1616904.839398151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.796289523085574,
    "arrivals": 176720,
    "finished_requests": 79085,
    "scheduler_time": 141.7055739570626
}
#Debug simulation 
Total elapsed time: 9.829829066991806. Arrivals time: 0.2597797904163599 Scheduler time: 9.422260686289519 Scheduler overhead time: 0.056662995368242264 Adapter cache time: 0.015516305807977915 Engine time: 0.051391991786658764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 8.456577213015407,
    "estimated_duration": 3600.0047951709957,
    "input_throughput": 5095.4821017477825,
    "output_throughput": 4494.509568905021,
    "total_throughput": 9589.991670652804,
    "itl": 97.85623516071948,
    "ttft": 1676521.1577915451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.175104503263747,
    "arrivals": 176720,
    "finished_requests": 74625,
    "scheduler_time": 147.6509140024158
}
#Debug simulation 
Total elapsed time: 8.456675593741238. Arrivals time: 0.24885077076032758 Scheduler time: 8.045979843940586 Scheduler overhead time: 0.06104336492717266 Adapter cache time: 0.01785155711695552 Engine time: 0.05622755782678723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 9.965729088988155,
    "estimated_duration": 3600.1136210819072,
    "input_throughput": 5400.85287479254,
    "output_throughput": 4754.708268028454,
    "total_throughput": 10155.561142820994,
    "itl": 110.08391613656171,
    "ttft": 1616355.933323808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.300487126274951,
    "arrivals": 176720,
    "finished_requests": 79032,
    "scheduler_time": 141.76863326496974
}
#Debug simulation 
Total elapsed time: 9.96582540217787. Arrivals time: 0.2641437812708318 Scheduler time: 9.553864975459874 Scheduler overhead time: 0.056395371444523335 Adapter cache time: 0.015022249892354012 Engine time: 0.051895163021981716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 8.529569443315268,
    "estimated_duration": 3600.0347873426335,
    "input_throughput": 5096.60713960588,
    "output_throughput": 4495.2721170635095,
    "total_throughput": 9591.879256669388,
    "itl": 97.85063884477033,
    "ttft": 1677147.4378678685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.033974140211969,
    "arrivals": 176720,
    "finished_requests": 74647,
    "scheduler_time": 147.6515555533583
}
#Debug simulation 
Total elapsed time: 8.529672619886696. Arrivals time: 0.24758684216067195 Scheduler time: 8.12014254881069 Scheduler overhead time: 0.0612266412936151 Adapter cache time: 0.017731768544763327 Engine time: 0.05625854153186083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 10.844458584208041,
    "estimated_duration": 3600.122811895245,
    "input_throughput": 5600.647826062745,
    "output_throughput": 4887.262718334167,
    "total_throughput": 10487.910544396913,
    "itl": 117.83597334728985,
    "ttft": 1582002.8848421013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0020337005053013,
    "arrivals": 175562,
    "finished_requests": 81657,
    "scheduler_time": 138.5856456670383
}
#Debug simulation 
Total elapsed time: 10.844542865175754. Arrivals time: 0.2836407609283924 Scheduler time: 10.420605512335896 Scheduler overhead time: 0.053494207095354795 Adapter cache time: 0.013926691841334105 Engine time: 0.04968989314511418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 9.643870876170695,
    "estimated_duration": 3600.0404677477036,
    "input_throughput": 5441.3091117988015,
    "output_throughput": 4750.048271179162,
    "total_throughput": 10191.357382977963,
    "itl": 109.99862687847806,
    "ttft": 1613727.6320862188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8848997229896534,
    "arrivals": 175562,
    "finished_requests": 79336,
    "scheduler_time": 141.7107129975675
}
#Debug simulation 
Total elapsed time: 9.64398212917149. Arrivals time: 0.26877338346093893 Scheduler time: 9.228612437378615 Scheduler overhead time: 0.05566254677250981 Adapter cache time: 0.015274111647158861 Engine time: 0.051370905712246895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 8.280348280910403,
    "estimated_duration": 3600.0632242623524,
    "input_throughput": 5146.600447217528,
    "output_throughput": 4493.334420068275,
    "total_throughput": 9639.934867285803,
    "itl": 97.77029725815501,
    "ttft": 1676300.5557271168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.465850268537205,
    "arrivals": 175562,
    "finished_requests": 75022,
    "scheduler_time": 147.586534063647
}
#Debug simulation 
Total elapsed time: 8.280451348051429. Arrivals time: 0.26162434834986925 Scheduler time: 7.856274547986686 Scheduler overhead time: 0.06100560538470745 Adapter cache time: 0.018457456026226282 Engine time: 0.05645702825859189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 9.697014208883047,
    "estimated_duration": 3600.104290628485,
    "input_throughput": 5440.921823012094,
    "output_throughput": 4751.135416972596,
    "total_throughput": 10192.05723998469,
    "itl": 109.97482791898588,
    "ttft": 1613549.0887711397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.676657099309372,
    "arrivals": 175562,
    "finished_requests": 79329,
    "scheduler_time": 141.73261594431364
}
#Debug simulation 
Total elapsed time: 9.697117319796234. Arrivals time: 0.27805224619805813 Scheduler time: 9.271156339440495 Scheduler overhead time: 0.05628345115110278 Adapter cache time: 0.01554157817736268 Engine time: 0.0517365513369441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 8.235668465029448,
    "estimated_duration": 3600.0407273671094,
    "input_throughput": 5145.721507864197,
    "output_throughput": 4492.31834436156,
    "total_throughput": 9638.039852225756,
    "itl": 97.74208974105866,
    "ttft": 1675859.862873786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.240647152187332,
    "arrivals": 175562,
    "finished_requests": 75017,
    "scheduler_time": 147.60327545086284
}
#Debug simulation 
Total elapsed time: 8.235770314000547. Arrivals time: 0.2527980678714812 Scheduler time: 7.820687585044652 Scheduler overhead time: 0.060798728838562965 Adapter cache time: 0.01828348683193326 Engine time: 0.056472602766007185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 9.626787665765733,
    "estimated_duration": 3600.008296223296,
    "input_throughput": 5444.548841890851,
    "output_throughput": 4754.24237715101,
    "total_throughput": 10198.791219041861,
    "itl": 110.14084415018495,
    "ttft": 1613222.1847091608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.338790651918374,
    "arrivals": 175562,
    "finished_requests": 79408,
    "scheduler_time": 141.64956077923247
}
#Debug simulation 
Total elapsed time: 9.626913939137012. Arrivals time: 0.2603486003354192 Scheduler time: 9.22006853716448 Scheduler overhead time: 0.055939392652362585 Adapter cache time: 0.014889743644744158 Engine time: 0.051353226881474257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 8.273186893202364,
    "estimated_duration": 3600.0198106947305,
    "input_throughput": 5148.295835745226,
    "output_throughput": 4494.406100747984,
    "total_throughput": 9642.701936493211,
    "itl": 97.76514160787396,
    "ttft": 1676365.1961563479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.087194634266227,
    "arrivals": 175562,
    "finished_requests": 75054,
    "scheduler_time": 147.59169734552003
}
#Debug simulation 
Total elapsed time: 8.273294560145587. Arrivals time: 0.2501435889862478 Scheduler time: 7.859799757599831 Scheduler overhead time: 0.06149256695061922 Adapter cache time: 0.018299198243767023 Engine time: 0.05655238218605518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 9.646174285095185,
    "estimated_duration": 3600.023767878362,
    "input_throughput": 5596.110553423629,
    "output_throughput": 4890.114103434115,
    "total_throughput": 10486.224656857745,
    "itl": 117.84117952526853,
    "ttft": 1576124.7123187936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9226847921218995,
    "arrivals": 174997,
    "finished_requests": 81430,
    "scheduler_time": 138.361522295327
}
#Debug simulation 
Total elapsed time: 9.646282812114805. Arrivals time: 0.2652502693235874 Scheduler time: 9.243304095696658 Scheduler overhead time: 0.05283378064632416 Adapter cache time: 0.013511875178664923 Engine time: 0.04842575779184699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 8.880849360022694,
    "estimated_duration": 3600.096403771647,
    "input_throughput": 5441.136792747537,
    "output_throughput": 4757.577319889572,
    "total_throughput": 10198.714112637108,
    "itl": 110.20871488989228,
    "ttft": 1607787.5443782704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6434156174166183,
    "arrivals": 174997,
    "finished_requests": 79153,
    "scheduler_time": 141.37299407889162
}
#Debug simulation 
Total elapsed time: 8.88095643511042. Arrivals time: 0.2581501337699592 Scheduler time: 8.477673175744712 Scheduler overhead time: 0.05554452259093523 Adapter cache time: 0.01440683426335454 Engine time: 0.05111848749220371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.739246032200754,
    "estimated_duration": 3600.054721100597,
    "input_throughput": 5146.477049753234,
    "output_throughput": 4497.9771849272165,
    "total_throughput": 9644.45423468045,
    "itl": 97.8559973964422,
    "ttft": 1668984.0876072394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.914358611539968,
    "arrivals": 174997,
    "finished_requests": 74791,
    "scheduler_time": 147.3314875434217
}
#Debug simulation 
Total elapsed time: 7.739346426911652. Arrivals time: 0.2482948382385075 Scheduler time: 7.330828168429434 Scheduler overhead time: 0.06045424239709973 Adapter cache time: 0.01737019745633006 Engine time: 0.05576602229848504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 8.881503563839942,
    "estimated_duration": 3600.0348516930553,
    "input_throughput": 5443.514523417413,
    "output_throughput": 4757.989215561194,
    "total_throughput": 10201.503738978607,
    "itl": 110.18589327660109,
    "ttft": 1607956.0570752174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4737598501844293,
    "arrivals": 174997,
    "finished_requests": 79156,
    "scheduler_time": 141.37919613511158
}
#Debug simulation 
Total elapsed time: 8.881609845906496. Arrivals time: 0.2664195359684527 Scheduler time: 8.469326757825911 Scheduler overhead time: 0.05580672575160861 Adapter cache time: 0.01491141365841031 Engine time: 0.050966514740139246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 7.654076264239848,
    "estimated_duration": 3600.0007338585256,
    "input_throughput": 5148.009783913647,
    "output_throughput": 4498.35352745692,
    "total_throughput": 9646.363311370567,
    "itl": 97.84278735494965,
    "ttft": 1669223.2019165677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9348512399103805,
    "arrivals": 174997,
    "finished_requests": 74806,
    "scheduler_time": 147.33377370088553
}
#Debug simulation 
Total elapsed time: 7.6541833388619125. Arrivals time: 0.24197066575288773 Scheduler time: 7.251761582214385 Scheduler overhead time: 0.0607768720947206 Adapter cache time: 0.01747908815741539 Engine time: 0.05563742155209184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 9.019840775988996,
    "estimated_duration": 3600.057755849312,
    "input_throughput": 5445.588190396961,
    "output_throughput": 4757.838390834125,
    "total_throughput": 10203.426581231086,
    "itl": 110.16694944997423,
    "ttft": 1607915.5622115964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1025855771172655,
    "arrivals": 174997,
    "finished_requests": 79192,
    "scheduler_time": 141.39158904051297
}
#Debug simulation 
Total elapsed time: 9.019951907917857. Arrivals time: 0.25865017529577017 Scheduler time: 8.615523314569145 Scheduler overhead time: 0.055488329380750656 Adapter cache time: 0.014403111767023802 Engine time: 0.051623787730932236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.757482943125069,
    "estimated_duration": 3600.017363127248,
    "input_throughput": 5147.110452796181,
    "output_throughput": 4498.749413233745,
    "total_throughput": 9645.859866029925,
    "itl": 97.8696037129863,
    "ttft": 1668933.1320481598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.857913374230297,
    "arrivals": 174997,
    "finished_requests": 74817,
    "scheduler_time": 147.32260665803744
}
#Debug simulation 
Total elapsed time: 7.757588658947498. Arrivals time: 0.24385102838277817 Scheduler time: 7.353703781496733 Scheduler overhead time: 0.06034755427390337 Adapter cache time: 0.01725745853036642 Engine time: 0.05581916123628616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 9.41696997685358,
    "estimated_duration": 3600.0412079155426,
    "input_throughput": 5524.659538971199,
    "output_throughput": 4884.617976409714,
    "total_throughput": 10409.277515380913,
    "itl": 117.71498870475604,
    "ttft": 1570665.3129863348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4120030604862106,
    "arrivals": 169522,
    "finished_requests": 80793,
    "scheduler_time": 137.8769885252667
}
#Debug simulation 
Total elapsed time: 9.41707752412185. Arrivals time: 0.27079163724556565 Scheduler time: 9.00574305979535 Scheduler overhead time: 0.05364958802238107 Adapter cache time: 0.014321094378829002 Engine time: 0.0494944634847343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 8.881495338864625,
    "estimated_duration": 3600.107154465931,
    "input_throughput": 5377.643822624505,
    "output_throughput": 4751.223301445726,
    "total_throughput": 10128.867124070232,
    "itl": 110.17128227629544,
    "ttft": 1602645.1384239306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.057548919189727,
    "arrivals": 169522,
    "finished_requests": 78601,
    "scheduler_time": 140.85046505447747
}
#Debug simulation 
Total elapsed time: 8.881626333110034. Arrivals time: 0.25806087255477905 Scheduler time: 8.476858434267342 Scheduler overhead time: 0.05575758498162031 Adapter cache time: 0.01548951305449009 Engine time: 0.05113678192719817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.886309488676488,
    "estimated_duration": 3600.1086958642272,
    "input_throughput": 5073.931245738393,
    "output_throughput": 4495.134554851317,
    "total_throughput": 9569.065800589711,
    "itl": 97.91221817046375,
    "ttft": 1665976.9562174408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.604689294281442,
    "arrivals": 169522,
    "finished_requests": 74209,
    "scheduler_time": 146.75273588262272
}
#Debug simulation 
Total elapsed time: 7.886436240747571. Arrivals time: 0.24781104596331716 Scheduler time: 7.476869016420096 Scheduler overhead time: 0.06081996811553836 Adapter cache time: 0.018201542552560568 Engine time: 0.056067348923534155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 8.88725925469771,
    "estimated_duration": 3600.0153181430283,
    "input_throughput": 5376.8751767380545,
    "output_throughput": 4751.17089469019,
    "total_throughput": 10128.046071428245,
    "itl": 110.1705776946818,
    "ttft": 1602507.5614945777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.809057364966715,
    "arrivals": 169522,
    "finished_requests": 78586,
    "scheduler_time": 140.8539809133113
}
#Debug simulation 
Total elapsed time: 8.887391110882163. Arrivals time: 0.263656550552696 Scheduler time: 8.47692917007953 Scheduler overhead time: 0.055702761746943 Adapter cache time: 0.01539813494309783 Engine time: 0.051400845404714346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 7.955375549849123,
    "estimated_duration": 3600.0388224302405,
    "input_throughput": 5074.353333686579,
    "output_throughput": 4494.125146427781,
    "total_throughput": 9568.47848011436,
    "itl": 97.92525317809728,
    "ttft": 1665179.6097296302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.947438981551703,
    "arrivals": 169522,
    "finished_requests": 74186,
    "scheduler_time": 146.7298997014576
}
#Debug simulation 
Total elapsed time: 7.955517212860286. Arrivals time: 0.24944521579891443 Scheduler time: 7.543411063961685 Scheduler overhead time: 0.060895129572600126 Adapter cache time: 0.018889796920120716 Engine time: 0.056198153644800186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 8.887135511729866,
    "estimated_duration": 3600.034975556765,
    "input_throughput": 5377.932751057719,
    "output_throughput": 4752.179108302734,
    "total_throughput": 10130.111859360451,
    "itl": 110.15798148481937,
    "ttft": 1602466.5562364866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.555843963897771,
    "arrivals": 169522,
    "finished_requests": 78603,
    "scheduler_time": 140.87095057606956
}
#Debug simulation 
Total elapsed time: 8.887271577958018. Arrivals time: 0.26290796138346195 Scheduler time: 8.477104963734746 Scheduler overhead time: 0.05583124468103051 Adapter cache time: 0.015369823668152094 Engine time: 0.05164341535419226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.826766253914684,
    "estimated_duration": 3600.0349356831657,
    "input_throughput": 5072.312165363687,
    "output_throughput": 4493.733335654431,
    "total_throughput": 9566.04550101812,
    "itl": 97.89913464387968,
    "ttft": 1665165.55889405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4007520542480325,
    "arrivals": 169522,
    "finished_requests": 74160,
    "scheduler_time": 146.76302377186417
}
#Debug simulation 
Total elapsed time: 7.826901689171791. Arrivals time: 0.24273401917889714 Scheduler time: 7.422879573423415 Scheduler overhead time: 0.060507241170853376 Adapter cache time: 0.01825965056195855 Engine time: 0.05590325407683849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 8.527255048975348,
    "estimated_duration": 3600.066023601238,
    "input_throughput": 5629.279259641918,
    "output_throughput": 4886.635379648416,
    "total_throughput": 10515.914639290333,
    "itl": 117.49589945856047,
    "ttft": 1546621.6235453207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.775685557243469,
    "arrivals": 167239,
    "finished_requests": 81606,
    "scheduler_time": 137.410759323921
}
#Debug simulation 
Total elapsed time: 8.527374496683478. Arrivals time: 0.27032723324373364 Scheduler time: 8.117771001998335 Scheduler overhead time: 0.0528422687202692 Adapter cache time: 0.015050586313009262 Engine time: 0.04838834283873439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.99990191264078,
    "estimated_duration": 3600.0990211777034,
    "input_throughput": 5471.773382932082,
    "output_throughput": 4750.8998778608175,
    "total_throughput": 10222.673260792899,
    "itl": 109.85856557995814,
    "ttft": 1577802.6035806919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.720390762207105,
    "arrivals": 167239,
    "finished_requests": 79323,
    "scheduler_time": 140.4284623646149
}
#Debug simulation 
Total elapsed time: 8.00002256873995. Arrivals time: 0.2579147876240313 Scheduler time: 7.594492876902223 Scheduler overhead time: 0.055552192497998476 Adapter cache time: 0.01637809630483389 Engine time: 0.05135701457038522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.169964829925448,
    "estimated_duration": 3600.071518038922,
    "input_throughput": 5168.596764470952,
    "output_throughput": 4489.929969170475,
    "total_throughput": 9658.526733641425,
    "itl": 97.49910465222652,
    "ttft": 1640719.9484793313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.426108985398921,
    "arrivals": 167239,
    "finished_requests": 74929,
    "scheduler_time": 146.35929309214418
}
#Debug simulation 
Total elapsed time: 7.170082333963364. Arrivals time: 0.2470997148193419 Scheduler time: 6.760020552203059 Scheduler overhead time: 0.060614639427512884 Adapter cache time: 0.019571245182305574 Engine time: 0.055968920700252056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 8.015958442818373,
    "estimated_duration": 3600.0816900759796,
    "input_throughput": 5470.377256796182,
    "output_throughput": 4750.514147260657,
    "total_throughput": 10220.89140405684,
    "itl": 109.84426994216807,
    "ttft": 1577265.5698239338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.377792990286829,
    "arrivals": 167239,
    "finished_requests": 79302,
    "scheduler_time": 140.44101754792106
}
#Debug simulation 
Total elapsed time: 8.016074536833912. Arrivals time: 0.25692378357052803 Scheduler time: 7.611874734517187 Scheduler overhead time: 0.05561623256653547 Adapter cache time: 0.016213887371122837 Engine time: 0.05113495606929064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 7.152962372172624,
    "estimated_duration": 3600.0943462240975,
    "input_throughput": 5170.5003285603625,
    "output_throughput": 4490.807585905867,
    "total_throughput": 9661.30791446623,
    "itl": 97.49413803378351,
    "ttft": 1640950.4112982275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.272499722768578,
    "arrivals": 167239,
    "finished_requests": 74958,
    "scheduler_time": 146.36606394883242
}
#Debug simulation 
Total elapsed time: 7.153064085170627. Arrivals time: 0.24281176691874862 Scheduler time: 6.7472291914746165 Scheduler overhead time: 0.0607453384436667 Adapter cache time: 0.01969148265197873 Engine time: 0.05583746777847409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.958958092145622,
    "estimated_duration": 3600.0265230866994,
    "input_throughput": 5471.261634792585,
    "output_throughput": 4751.586381461791,
    "total_throughput": 10222.848016254375,
    "itl": 109.84784709284912,
    "ttft": 1577626.9293552793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.219771741717103,
    "arrivals": 167239,
    "finished_requests": 79320,
    "scheduler_time": 140.43704055704734
}
#Debug simulation 
Total elapsed time: 7.959059685934335. Arrivals time: 0.25743986014276743 Scheduler time: 7.554141881875694 Scheduler overhead time: 0.05559403728693724 Adapter cache time: 0.016466735862195492 Engine time: 0.051183016039431095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.410818766802549,
    "estimated_duration": 3600.077682921969,
    "input_throughput": 5170.334264812987,
    "output_throughput": 4491.047811745356,
    "total_throughput": 9661.382076558342,
    "itl": 97.4987296081129,
    "ttft": 1640619.9764690897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.189450224489,
    "arrivals": 167239,
    "finished_requests": 74954,
    "scheduler_time": 146.36535177879398
}
#Debug simulation 
Total elapsed time: 7.41089382302016. Arrivals time: 0.2485362198203802 Scheduler time: 7.001132602803409 Scheduler overhead time: 0.05973670678213239 Adapter cache time: 0.019277026876807213 Engine time: 0.055673915427178144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.8698617103509605,
    "estimated_duration": 3600.1152430494353,
    "input_throughput": 5581.802704454165,
    "output_throughput": 4887.7321452341,
    "total_throughput": 10469.534849688265,
    "itl": 117.80969750343331,
    "ttft": 1544161.3481581358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.960833010138073,
    "arrivals": 166072,
    "finished_requests": 81489,
    "scheduler_time": 137.16215911152327
}
#Debug simulation 
Total elapsed time: 7.869984334334731. Arrivals time: 0.25802772026509047 Scheduler time: 7.473142667673528 Scheduler overhead time: 0.052018357906490564 Adapter cache time: 0.015483968891203403 Engine time: 0.048384149093180895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.426407770253718,
    "estimated_duration": 3600.091124220335,
    "input_throughput": 5430.570039871984,
    "output_throughput": 4752.2805422613255,
    "total_throughput": 10182.85058213331,
    "itl": 110.01842891609364,
    "ttft": 1577050.650122679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.037934212824336,
    "arrivals": 166072,
    "finished_requests": 79256,
    "scheduler_time": 140.22868817465536
}
#Debug simulation 
Total elapsed time: 7.426526847295463. Arrivals time: 0.2469052392989397 Scheduler time: 7.031922256108373 Scheduler overhead time: 0.05547725409269333 Adapter cache time: 0.016957575920969248 Engine time: 0.0508656851015985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.688884004950523,
    "estimated_duration": 3600.0761343223726,
    "input_throughput": 5142.716795206012,
    "output_throughput": 4493.813018497491,
    "total_throughput": 9636.529813703502,
    "itl": 97.74977138465975,
    "ttft": 1640365.4224272983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.5595166613627445,
    "arrivals": 166072,
    "finished_requests": 74978,
    "scheduler_time": 146.09994779851849
}
#Debug simulation 
Total elapsed time: 6.688994581345469. Arrivals time: 0.2369367885403335 Scheduler time: 6.289779360871762 Scheduler overhead time: 0.06014616601169109 Adapter cache time: 0.0198180521838367 Engine time: 0.05567944468930364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 7.406528905034065,
    "estimated_duration": 3600.0422362664704,
    "input_throughput": 5433.169312003655,
    "output_throughput": 4755.354486550207,
    "total_throughput": 10188.523798553862,
    "itl": 110.09561448473326,
    "ttft": 1576853.8032676745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.70976635687984,
    "arrivals": 166072,
    "finished_requests": 79301,
    "scheduler_time": 140.1957264447373
}
#Debug simulation 
Total elapsed time: 7.406637430656701. Arrivals time: 0.2506676665507257 Scheduler time: 7.009622546844184 Scheduler overhead time: 0.05490811122581363 Adapter cache time: 0.01670157490298152 Engine time: 0.05064743664115667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.720907551236451,
    "estimated_duration": 3600.04453342027,
    "input_throughput": 5143.05915610698,
    "output_throughput": 4494.645788347262,
    "total_throughput": 9637.704944454243,
    "itl": 97.74690879374883,
    "ttft": 1640389.5346027613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.387012714971813,
    "arrivals": 166072,
    "finished_requests": 74981,
    "scheduler_time": 146.112551443654
}
#Debug simulation 
Total elapsed time: 6.721009633969516. Arrivals time: 0.24111609114333987 Scheduler time: 6.317241022828966 Scheduler overhead time: 0.06023129681125283 Adapter cache time: 0.019642486702650785 Engine time: 0.05601427750661969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.499193605966866,
    "estimated_duration": 3600.0854730813026,
    "input_throughput": 5435.334007015143,
    "output_throughput": 4755.056825178162,
    "total_throughput": 10190.390832193305,
    "itl": 110.0796260643361,
    "ttft": 1576779.940814447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3729858442907945,
    "arrivals": 166072,
    "finished_requests": 79313,
    "scheduler_time": 140.2108660015967
}
#Debug simulation 
Total elapsed time: 7.499310551211238. Arrivals time: 0.2547342577017844 Scheduler time: 7.096494251862168 Scheduler overhead time: 0.05550243193283677 Adapter cache time: 0.016877212096005678 Engine time: 0.05130783747881651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.7004461898468435,
    "estimated_duration": 3600.1075751035764,
    "input_throughput": 5142.258005850667,
    "output_throughput": 4494.303201352114,
    "total_throughput": 9636.561207202782,
    "itl": 97.74755415601894,
    "ttft": 1640410.7944996585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 867,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.3914002172835405,
    "arrivals": 166072,
    "finished_requests": 74983,
    "scheduler_time": 146.1109818466457
}
#Debug simulation 
Total elapsed time: 6.700584068894386. Arrivals time: 0.24273677123710513 Scheduler time: 6.294543265830725 Scheduler overhead time: 0.06051662005484104 Adapter cache time: 0.019686906598508358 Engine time: 0.056071081198751926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.568842355161905,
    "estimated_duration": 3600.016676133084,
    "input_throughput": 5584.912462571254,
    "output_throughput": 4888.693187639388,
    "total_throughput": 10473.605650210642,
    "itl": 117.61141181251176,
    "ttft": 1549440.263720113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.742623512083718,
    "arrivals": 165445,
    "finished_requests": 81318,
    "scheduler_time": 137.1457805386738
}
#Debug simulation 
Total elapsed time: 7.568972821813077. Arrivals time: 0.25384904351085424 Scheduler time: 7.176460331771523 Scheduler overhead time: 0.05222092103213072 Adapter cache time: 0.0147289102897048 Engine time: 0.048655313439667225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.117715734988451,
    "estimated_duration": 3600.098579503054,
    "input_throughput": 5424.592012893083,
    "output_throughput": 4753.667329399162,
    "total_throughput": 10178.259342292244,
    "itl": 110.00384085410052,
    "ttft": 1581250.207417911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.767580797616398,
    "arrivals": 165445,
    "finished_requests": 79041,
    "scheduler_time": 140.13049289449992
}
#Debug simulation 
Total elapsed time: 7.11781852087006. Arrivals time: 0.2476282948628068 Scheduler time: 6.724578199442476 Scheduler overhead time: 0.05465223826467991 Adapter cache time: 0.016264610923826694 Engine time: 0.05064677074551582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.531132393050939,
    "estimated_duration": 3600.039722301339,
    "input_throughput": 5114.899117898866,
    "output_throughput": 4492.91848081617,
    "total_throughput": 9607.817598715037,
    "itl": 97.6561988039905,
    "ttft": 1644807.1743691037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.903036050507825,
    "arrivals": 165445,
    "finished_requests": 74524,
    "scheduler_time": 146.0613859761803
}
#Debug simulation 
Total elapsed time: 6.531234588008374. Arrivals time: 0.23997537977993488 Scheduler time: 6.130990656092763 Scheduler overhead time: 0.059638983104377985 Adapter cache time: 0.01850017113611102 Engine time: 0.05562997376546264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 7.115430026315153,
    "estimated_duration": 3600.0313371398593,
    "input_throughput": 5426.151099984468,
    "output_throughput": 4753.987784338865,
    "total_throughput": 10180.138884323333,
    "itl": 109.99313257252267,
    "ttft": 1581087.8674023126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.371966253272252,
    "arrivals": 165445,
    "finished_requests": 79062,
    "scheduler_time": 140.1402608832852
}
#Debug simulation 
Total elapsed time: 7.115534781012684. Arrivals time: 0.25173550518229604 Scheduler time: 6.718491904437542 Scheduler overhead time: 0.05463826982304454 Adapter cache time: 0.015956480987370014 Engine time: 0.050659182481467724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.534290479961783,
    "estimated_duration": 3600.043752743588,
    "input_throughput": 5114.038401885862,
    "output_throughput": 4493.372889613365,
    "total_throughput": 9607.411291499227,
    "itl": 97.65051160827635,
    "ttft": 1644605.98901125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.902095223502285,
    "arrivals": 165445,
    "finished_requests": 74516,
    "scheduler_time": 146.0629368477129
}
#Debug simulation 
Total elapsed time: 6.534461470786482. Arrivals time: 0.23342527262866497 Scheduler time: 6.14030504738912 Scheduler overhead time: 0.060053592547774315 Adapter cache time: 0.018632037565112114 Engine time: 0.05533704673871398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.155521561391652,
    "estimated_duration": 3600.100379729541,
    "input_throughput": 5424.554023537287,
    "output_throughput": 4754.225492258586,
    "total_throughput": 10178.779515795874,
    "itl": 109.9724011916886,
    "ttft": 1581084.4264318028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.015486271618847,
    "arrivals": 165445,
    "finished_requests": 79051,
    "scheduler_time": 140.15960025124258
}
#Debug simulation 
Total elapsed time: 7.155635565053672. Arrivals time: 0.23985855048522353 Scheduler time: 6.769248287193477 Scheduler overhead time: 0.05529062543064356 Adapter cache time: 0.01602457230910659 Engine time: 0.050923746544867754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.5785222430713475,
    "estimated_duration": 3600.087669379502,
    "input_throughput": 5116.366236485206,
    "output_throughput": 4494.501936056693,
    "total_throughput": 9610.8681725419,
    "itl": 97.64225095579474,
    "ttft": 1645268.6064150108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.595974269956379,
    "arrivals": 165445,
    "finished_requests": 74557,
    "scheduler_time": 146.068740753635
}
#Debug simulation 
Total elapsed time: 6.578654426150024. Arrivals time: 0.24083897564560175 Scheduler time: 6.177196281962097 Scheduler overhead time: 0.06023693084716797 Adapter cache time: 0.018210405949503183 Engine time: 0.055590670090168715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.318402414210141,
    "estimated_duration": 3600.035398025702,
    "input_throughput": 5579.612359093974,
    "output_throughput": 4882.025884978401,
    "total_throughput": 10461.638244072376,
    "itl": 117.476790160113,
    "ttft": 1538764.0938066868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.70803523074844,
    "arrivals": 162486,
    "finished_requests": 80936,
    "scheduler_time": 136.92112578050012
}
#Debug simulation 
Total elapsed time: 7.318520714063197. Arrivals time: 0.2522884118370712 Scheduler time: 6.926030027680099 Scheduler overhead time: 0.052050257567316294 Adapter cache time: 0.016930943820625544 Engine time: 0.04832574678584933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.9939244501292706,
    "estimated_duration": 3600.08517553359,
    "input_throughput": 5425.225528755762,
    "output_throughput": 4745.026622173767,
    "total_throughput": 10170.252150929527,
    "itl": 109.81391021385654,
    "ttft": 1571485.2886126158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.854273489220075,
    "arrivals": 162486,
    "finished_requests": 78661,
    "scheduler_time": 139.9463888159576
}
#Debug simulation 
Total elapsed time: 6.994047284126282. Arrivals time: 0.24703569570556283 Scheduler time: 6.598796277306974 Scheduler overhead time: 0.05504622822627425 Adapter cache time: 0.018117797560989857 Engine time: 0.05080417636781931 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.406224363017827,
    "estimated_duration": 3600.098145519523,
    "input_throughput": 5126.329687141559,
    "output_throughput": 4484.444964394222,
    "total_throughput": 9610.77465153578,
    "itl": 97.4661287516297,
    "ttft": 1636199.6907955531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.676943315709956,
    "arrivals": 162486,
    "finished_requests": 74339,
    "scheduler_time": 145.86548396616766
}
#Debug simulation 
Total elapsed time: 6.406335190869868. Arrivals time: 0.2401786702685058 Scheduler time: 6.002137632574886 Scheduler overhead time: 0.05993889132514596 Adapter cache time: 0.021255026571452618 Engine time: 0.056184759829193354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.946283094584942,
    "estimated_duration": 3600.1097810478054,
    "input_throughput": 5427.678651041816,
    "output_throughput": 4746.9771866307065,
    "total_throughput": 10174.655837672522,
    "itl": 109.78623924407403,
    "ttft": 1571915.8891864573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.52858926673419,
    "arrivals": 162486,
    "finished_requests": 78685,
    "scheduler_time": 139.9609837337198
}
#Debug simulation 
Total elapsed time: 6.946387683972716. Arrivals time: 0.24762284802272916 Scheduler time: 6.550905422307551 Scheduler overhead time: 0.05469782184809446 Adapter cache time: 0.018169879913330078 Engine time: 0.05077417707070708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.415631941054016,
    "estimated_duration": 3600.0113451172497,
    "input_throughput": 5126.218845123932,
    "output_throughput": 4484.781422119147,
    "total_throughput": 9611.000267243078,
    "itl": 97.46173878171211,
    "ttft": 1636049.5312873013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.565005640210599,
    "arrivals": 162486,
    "finished_requests": 74338,
    "scheduler_time": 145.86380136512247
}
#Debug simulation 
Total elapsed time: 6.415746129117906. Arrivals time: 0.24391667684540153 Scheduler time: 6.006863886024803 Scheduler overhead time: 0.06038506980985403 Adapter cache time: 0.02165948785841465 Engine time: 0.05608917959034443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.967637944035232,
    "estimated_duration": 3600.0951347160913,
    "input_throughput": 5427.938504058738,
    "output_throughput": 4747.0473308333085,
    "total_throughput": 10174.985834892046,
    "itl": 109.78166037439618,
    "ttft": 1571660.3263317745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.119904594337543,
    "arrivals": 162486,
    "finished_requests": 78691,
    "scheduler_time": 139.97373802883465
}
#Debug simulation 
Total elapsed time: 6.9677423988468945. Arrivals time: 0.26009181747213006 Scheduler time: 6.5603574751876295 Scheduler overhead time: 0.05475047789514065 Adapter cache time: 0.01790930051356554 Engine time: 0.0505124730989337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.380407766904682,
    "estimated_duration": 3600.010624002789,
    "input_throughput": 5126.394593658206,
    "output_throughput": 4485.2559301745805,
    "total_throughput": 9611.650523832786,
    "itl": 97.46060884983311,
    "ttft": 1636037.1045985355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.301076460126805,
    "arrivals": 162486,
    "finished_requests": 74345,
    "scheduler_time": 145.8734717718804
}
#Debug simulation 
Total elapsed time: 6.380494392942637. Arrivals time: 0.22479701368138194 Scheduler time: 5.992035103961825 Scheduler overhead time: 0.06003761477768421 Adapter cache time: 0.02105288067832589 Engine time: 0.05599662754684687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.763450474943966,
    "estimated_duration": 3600.1212437449412,
    "input_throughput": 5610.777424536949,
    "output_throughput": 4882.391400161771,
    "total_throughput": 10493.16882469872,
    "itl": 117.21594455269002,
    "ttft": 1531492.5949494736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.899795092674994,
    "arrivals": 161281,
    "finished_requests": 81628,
    "scheduler_time": 136.58990706447858
}
#Debug simulation 
Total elapsed time: 6.763549882918596. Arrivals time: 0.24594488414004445 Scheduler time: 6.377931967377663 Scheduler overhead time: 0.05229672230780125 Adapter cache time: 0.01658876473084092 Engine time: 0.047883075661957264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.442764563951641,
    "estimated_duration": 3600.012297005906,
    "input_throughput": 5453.9216480814675,
    "output_throughput": 4749.392665747317,
    "total_throughput": 10203.314313828783,
    "itl": 109.57871511980557,
    "ttft": 1564809.208649829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.08632337878459,
    "arrivals": 161281,
    "finished_requests": 79327,
    "scheduler_time": 139.58904773185475
}
#Debug simulation 
Total elapsed time: 6.4429486356675625. Arrivals time: 0.245525186881423 Scheduler time: 6.051009772345424 Scheduler overhead time: 0.05400419281795621 Adapter cache time: 0.01793288253247738 Engine time: 0.05037750490009785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.977911313995719,
    "estimated_duration": 3600.0431283233765,
    "input_throughput": 5144.357814575725,
    "output_throughput": 4488.414283949254,
    "total_throughput": 9632.772098524978,
    "itl": 97.38814002272436,
    "ttft": 1629669.810555582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.418843120886011,
    "arrivals": 161281,
    "finished_requests": 74885,
    "scheduler_time": 145.44920895932032
}
#Debug simulation 
Total elapsed time: 5.978041258174926. Arrivals time: 0.231817742343992 Scheduler time: 5.580973470117897 Scheduler overhead time: 0.060443004593253136 Adapter cache time: 0.02226455183699727 Engine time: 0.055874151177704334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.489460237789899,
    "estimated_duration": 3600.005915223901,
    "input_throughput": 5454.691870632299,
    "output_throughput": 4750.190250433638,
    "total_throughput": 10204.882121065937,
    "itl": 109.57442953454604,
    "ttft": 1564669.405952001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.728710073912508,
    "arrivals": 161281,
    "finished_requests": 79339,
    "scheduler_time": 139.59782320453078
}
#Debug simulation 
Total elapsed time: 6.489579842891544. Arrivals time: 0.2426728499121964 Scheduler time: 6.099245430901647 Scheduler overhead time: 0.05466612474992871 Adapter cache time: 0.01816212246194482 Engine time: 0.05066423397511244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.956480603199452,
    "estimated_duration": 3600.1001120687292,
    "input_throughput": 5144.288331848044,
    "output_throughput": 4488.260186385485,
    "total_throughput": 9632.548518233529,
    "itl": 97.39388310709187,
    "ttft": 1629774.922596357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.356497857696377,
    "arrivals": 161281,
    "finished_requests": 74883,
    "scheduler_time": 145.4490724399405
}
#Debug simulation 
Total elapsed time: 5.9565949803218246. Arrivals time: 0.23164102202281356 Scheduler time: 5.560977129265666 Scheduler overhead time: 0.05955046648159623 Adapter cache time: 0.022364303935319185 Engine time: 0.05551933916285634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.485909133218229,
    "estimated_duration": 3600.1164980262392,
    "input_throughput": 5454.915142542386,
    "output_throughput": 4750.627933672869,
    "total_throughput": 10205.543076215255,
    "itl": 109.56310839514124,
    "ttft": 1564527.8836764202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.388029273841504,
    "arrivals": 161281,
    "finished_requests": 79349,
    "scheduler_time": 139.6157972140984
}
#Debug simulation 
Total elapsed time: 6.486027338076383. Arrivals time: 0.24745817435905337 Scheduler time: 6.0907595390453935 Scheduler overhead time: 0.05492468969896436 Adapter cache time: 0.01808383548632264 Engine time: 0.05062015261501074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.968239870388061,
    "estimated_duration": 3600.067055516764,
    "input_throughput": 5144.197236998872,
    "output_throughput": 4488.586670972566,
    "total_throughput": 9632.783907971438,
    "itl": 97.39266556649648,
    "ttft": 1629594.745754753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.232857882343238,
    "arrivals": 161281,
    "finished_requests": 74876,
    "scheduler_time": 145.45216390279282
}
#Debug simulation 
Total elapsed time: 5.968341083265841. Arrivals time: 0.23692796286195517 Scheduler time: 5.566370681393892 Scheduler overhead time: 0.0603140271268785 Adapter cache time: 0.02229114156216383 Engine time: 0.05586662283167243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107531037 . Total output tokens: 95055354
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.778530200012028,
    "estimated_duration": 3600.0872709944824,
    "input_throughput": 5572.236584825487,
    "output_throughput": 4888.414550889083,
    "total_throughput": 10460.65113571457,
    "itl": 118.02014583529214,
    "ttft": 1529376.6334490748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.362663724911505,
    "arrivals": 160680,
    "finished_requests": 81202,
    "scheduler_time": 136.187010415985
}
#Debug simulation 
Total elapsed time: 6.778606259264052. Arrivals time: 0.46697156643494964 Scheduler time: 6.171588090248406 Scheduler overhead time: 0.051571798510849476 Adapter cache time: 0.017494894098490477 Engine time: 0.04811378661543131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107531037 . Total output tokens: 95055354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.234104294795543,
    "estimated_duration": 3600.078216969441,
    "input_throughput": 5419.341698754432,
    "output_throughput": 4753.742826845161,
    "total_throughput": 10173.084525599594,
    "itl": 110.32388679727165,
    "ttft": 1562585.3452243328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.585402535367766,
    "arrivals": 160680,
    "finished_requests": 78960,
    "scheduler_time": 139.16337569151935
}
#Debug simulation 
Total elapsed time: 6.234203867148608. Arrivals time: 0.23840047791600227 Scheduler time: 5.847533826250583 Scheduler overhead time: 0.054437723476439714 Adapter cache time: 0.01900571398437023 Engine time: 0.05084948567673564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107531037 . Total output tokens: 95055354
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.823573486879468,
    "estimated_duration": 3600.0937285842233,
    "input_throughput": 5121.343051046251,
    "output_throughput": 4494.399096204383,
    "total_throughput": 9615.742147250634,
    "itl": 97.90416553246015,
    "ttft": 1628409.9167393746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.590922357323564,
    "arrivals": 160680,
    "finished_requests": 74594,
    "scheduler_time": 145.04030259988988
}
#Debug simulation 
Total elapsed time: 5.823658647947013. Arrivals time: 0.2240041447803378 Scheduler time: 5.435283953789622 Scheduler overhead time: 0.059666561894118786 Adapter cache time: 0.022650353144854307 Engine time: 0.05550043424591422 
