INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:06 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252230559 . Total output tokens: 222259201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.349472281057388,
    "estimated_duration": 3600.1361070022936,
    "input_throughput": 3739.8363839113103,
    "output_throughput": 3248.3577432681072,
    "total_throughput": 6988.194127179418,
    "itl": 133.36403297243885,
    "ttft": 2183181.0327983587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.253379488140562,
    "arrivals": 377711,
    "finished_requests": 54493,
    "scheduler_time": 125.08013089510585
}
#Debug simulation 
Total elapsed time: 4.34961063368246. Arrivals time: 0.2037296872586012 Scheduler time: 3.9978048391640186 Scheduler overhead time: 0.04051857814192772 Adapter cache time: 0.04764673672616482 Engine time: 0.041090555023401976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252230559 . Total output tokens: 222259201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.362318417057395,
    "estimated_duration": 3600.0204705371452,
    "input_throughput": 3739.6104022684312,
    "output_throughput": 3248.2912515925764,
    "total_throughput": 6987.901653861008,
    "itl": 133.28543549728826,
    "ttft": 2182958.3523960155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.374314370495943,
    "arrivals": 377711,
    "finished_requests": 54487,
    "scheduler_time": 125.12220492058451
}
#Debug simulation 
Total elapsed time: 4.362423533108085. Arrivals time: 0.20048864977434278 Scheduler time: 4.013722736854106 Scheduler overhead time: 0.04079318791627884 Adapter cache time: 0.047864682506769896 Engine time: 0.040760019328445196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251283552 . Total output tokens: 221449305
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.61688976502046,
    "estimated_duration": 3600.0359341066933,
    "input_throughput": 3954.735247256023,
    "output_throughput": 3440.8850985743748,
    "total_throughput": 7395.620345830397,
    "itl": 150.5018983020884,
    "ttft": 2144734.1440172843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.150047864043414,
    "arrivals": 376270,
    "finished_requests": 57703,
    "scheduler_time": 119.18646315423712
}
#Debug simulation 
Total elapsed time: 4.616980019956827. Arrivals time: 0.212297554127872 Scheduler time: 4.278633497655392 Scheduler overhead time: 0.036974065471440554 Adapter cache time: 0.03508064616471529 Engine time: 0.037000562995672226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251283552 . Total output tokens: 221449305
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.264066386967897,
    "estimated_duration": 3600.0781519347984,
    "input_throughput": 3730.47957105661,
    "output_throughput": 3245.5650980022438,
    "total_throughput": 6976.044669058853,
    "itl": 133.53072745808782,
    "ttft": 2182325.27771654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.512127280980039,
    "arrivals": 376270,
    "finished_requests": 54394,
    "scheduler_time": 125.10963331942177
}
#Debug simulation 
Total elapsed time: 4.264157528057694. Arrivals time: 0.20393392210826278 Scheduler time: 3.9121864615008235 Scheduler overhead time: 0.04029294243082404 Adapter cache time: 0.048086356837302446 Engine time: 0.04091605916619301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251283552 . Total output tokens: 221449305
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.280295649077743,
    "estimated_duration": 3600.0973728035565,
    "input_throughput": 3733.3365207100996,
    "output_throughput": 3248.6004651847416,
    "total_throughput": 6981.936985894841,
    "itl": 133.6949419757424,
    "ttft": 2182040.563743995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.562310282113256,
    "arrivals": 376270,
    "finished_requests": 54447,
    "scheduler_time": 125.05701290736391
}
#Debug simulation 
Total elapsed time: 4.28039229195565. Arrivals time: 0.2179396217688918 Scheduler time: 3.9148090560920537 Scheduler overhead time: 0.040296745486557484 Adapter cache time: 0.04773086681962013 Engine time: 0.040894863195717335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251283552 . Total output tokens: 221449305
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.235287991818041,
    "estimated_duration": 3600.003718878765,
    "input_throughput": 3728.329204109915,
    "output_throughput": 3244.2044264436245,
    "total_throughput": 6972.533630553539,
    "itl": 133.2141320811828,
    "ttft": 2182929.049026564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.597751603415942,
    "arrivals": 376270,
    "finished_requests": 54363,
    "scheduler_time": 125.2721538477767
}
#Debug simulation 
Total elapsed time: 4.235379846766591. Arrivals time: 0.20051773078739643 Scheduler time: 3.8874818584881723 Scheduler overhead time: 0.040417011361569166 Adapter cache time: 0.04750994825735688 Engine time: 0.04072938859462738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249316425 . Total output tokens: 219720730
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.509301256854087,
    "estimated_duration": 3600.0447149572005,
    "input_throughput": 3967.1785021619635,
    "output_throughput": 3444.0347222596656,
    "total_throughput": 7411.213224421629,
    "itl": 150.2203584702581,
    "ttft": 2141035.2722103554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.954728065435964,
    "arrivals": 373284,
    "finished_requests": 57703,
    "scheduler_time": 119.18227554231945
}
#Debug simulation 
Total elapsed time: 4.509391346015036. Arrivals time: 0.21119112195447087 Scheduler time: 4.177909673191607 Scheduler overhead time: 0.03679751744493842 Adapter cache time: 0.029385126195847988 Engine time: 0.03706233901903033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249316425 . Total output tokens: 219720730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.1909670061431825,
    "estimated_duration": 3600.1363816045764,
    "input_throughput": 3738.8719685115634,
    "output_throughput": 3252.022912193643,
    "total_throughput": 6990.894880705207,
    "itl": 133.3893938470992,
    "ttft": 2178588.868415567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.598188113299916,
    "arrivals": 373284,
    "finished_requests": 54474,
    "scheduler_time": 125.10616609920056
}
#Debug simulation 
Total elapsed time: 4.1910914881154895. Arrivals time: 0.20133454725146294 Scheduler time: 3.849600672721863 Scheduler overhead time: 0.04003870952874422 Adapter cache time: 0.04101135302335024 Engine time: 0.04045696696266532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249316425 . Total output tokens: 219720730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.210442315321416,
    "estimated_duration": 3600.0711637310797,
    "input_throughput": 3739.4799679592174,
    "output_throughput": 3252.572648554089,
    "total_throughput": 6992.052616513307,
    "itl": 133.3581619167892,
    "ttft": 2178494.363942534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.906287406981066,
    "arrivals": 373284,
    "finished_requests": 54482,
    "scheduler_time": 125.12816912679817
}
#Debug simulation 
Total elapsed time: 4.2105320720002055. Arrivals time: 0.20147478161379695 Scheduler time: 3.86850740108639 Scheduler overhead time: 0.04008721746504307 Adapter cache time: 0.04134903196245432 Engine time: 0.040550289675593376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249316425 . Total output tokens: 219720730
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.218271030113101,
    "estimated_duration": 3600.0901018101945,
    "input_throughput": 3740.754430903967,
    "output_throughput": 3253.4194058395033,
    "total_throughput": 6994.173836743471,
    "itl": 133.31895587330916,
    "ttft": 2178289.9059491884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.942040492138245,
    "arrivals": 373284,
    "finished_requests": 54499,
    "scheduler_time": 125.16127995751971
}
#Debug simulation 
Total elapsed time: 4.218385649845004. Arrivals time: 0.20118870632722974 Scheduler time: 3.8763913763687015 Scheduler overhead time: 0.04010204505175352 Adapter cache time: 0.041348421946167946 Engine time: 0.04075242066755891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169427239 . Total output tokens: 149312575
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.561144990846515,
    "estimated_duration": 3600.03140185735,
    "input_throughput": 3933.6212436074557,
    "output_throughput": 3434.3755983964925,
    "total_throughput": 7367.996842003948,
    "itl": 150.78404013423662,
    "ttft": 2058107.3414227944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.022374548743908,
    "arrivals": 253064,
    "finished_requests": 57486,
    "scheduler_time": 116.90760716869652
}
#Debug simulation 
Total elapsed time: 8.5612389636226. Arrivals time: 0.48227599123492837 Scheduler time: 7.919300067704171 Scheduler overhead time: 0.03853210946545005 Adapter cache time: 0.06582027953118086 Engine time: 0.038076650351285934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169427239 . Total output tokens: 149312575
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.54788128612563,
    "estimated_duration": 3600.057676276888,
    "input_throughput": 2927.2875458202716,
    "output_throughput": 2557.8337426868957,
    "total_throughput": 5485.121288507167,
    "itl": 94.53566396436284,
    "ttft": 2274119.9795422293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.047745390362063,
    "arrivals": 253064,
    "finished_requests": 42759,
    "scheduler_time": 144.66294826460518
}
#Debug simulation 
Total elapsed time: 8.547997851856053. Arrivals time: 0.20150019554421306 Scheduler time: 8.182097984943539 Scheduler overhead time: 0.054139102809131145 Adapter cache time: 0.032838703133165836 Engine time: 0.053009309340268373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169427239 . Total output tokens: 149312575
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 8.56637271028012,
    "estimated_duration": 3600.06761815861,
    "input_throughput": 3305.400970798024,
    "output_throughput": 2887.5357639302006,
    "total_throughput": 6192.936734728225,
    "itl": 109.6209766193818,
    "ttft": 2188410.2787079327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.071617927127603,
    "arrivals": 253064,
    "finished_requests": 48235,
    "scheduler_time": 134.3889756279906
}
#Debug simulation 
Total elapsed time: 8.566489279270172. Arrivals time: 0.21565487142652273 Scheduler time: 8.191872218623757 Scheduler overhead time: 0.04913763236254454 Adapter cache time: 0.03931797342374921 Engine time: 0.048393906094133854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169427239 . Total output tokens: 149312575
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.983018728904426,
    "estimated_duration": 3600.0790349289705,
    "input_throughput": 3019.305935936059,
    "output_throughput": 2639.6628817865644,
    "total_throughput": 5658.9688177226235,
    "itl": 97.73300797817859,
    "ttft": 2252486.099680453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.788383547496011,
    "arrivals": 253064,
    "finished_requests": 44105,
    "scheduler_time": 142.20491635597546
}
#Debug simulation 
Total elapsed time: 8.983136031311005. Arrivals time: 0.20713433530181646 Scheduler time: 8.614399585872889 Scheduler overhead time: 0.05307370005175471 Adapter cache time: 0.03295246511697769 Engine time: 0.05156000051647425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161762081 . Total output tokens: 142588191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.853684037923813,
    "estimated_duration": 3600.052520627203,
    "input_throughput": 3925.2210680354433,
    "output_throughput": 3427.55888401601,
    "total_throughput": 7352.779952051453,
    "itl": 150.18598304844195,
    "ttft": 2044306.41875078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3025,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.002537321648063,
    "arrivals": 241330,
    "finished_requests": 57081,
    "scheduler_time": 116.73981025197915
}
#Debug simulation 
Total elapsed time: 7.8538095890544355. Arrivals time: 0.23506149416789412 Scheduler time: 7.46017309371382 Scheduler overhead time: 0.03861076198518276 Adapter cache time: 0.06450394168496132 Engine time: 0.03806974506005645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161762081 . Total output tokens: 142588191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.346737360116094,
    "estimated_duration": 3600.003803482435,
    "input_throughput": 3691.2230445827736,
    "output_throughput": 3228.303533667837,
    "total_throughput": 6919.526578250611,
    "itl": 133.3112017837528,
    "ttft": 2091685.9780903233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3912,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.611037669590793,
    "arrivals": 241330,
    "finished_requests": 53655,
    "scheduler_time": 122.33248487140123
}
#Debug simulation 
Total elapsed time: 6.346853984054178. Arrivals time: 0.22909622825682163 Scheduler time: 5.935141708701849 Scheduler overhead time: 0.04147185059264302 Adapter cache time: 0.08099506329745054 Engine time: 0.041064432356506586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161762081 . Total output tokens: 142588191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.270928000099957,
    "estimated_duration": 3600.0714399893805,
    "input_throughput": 3693.738088719491,
    "output_throughput": 3235.7474550656034,
    "total_throughput": 6929.485543785095,
    "itl": 133.77448891783243,
    "ttft": 2090694.1519407015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.64328599412545,
    "arrivals": 241330,
    "finished_requests": 53746,
    "scheduler_time": 122.15866810691574
}
#Debug simulation 
Total elapsed time: 6.271022832021117. Arrivals time: 0.21926359506323934 Scheduler time: 5.865400404203683 Scheduler overhead time: 0.04143740888684988 Adapter cache time: 0.08451250148937106 Engine time: 0.041324063669890165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161762081 . Total output tokens: 142588191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.240634310990572,
    "estimated_duration": 3600.05630056916,
    "input_throughput": 3695.314986573064,
    "output_throughput": 3235.6510641676346,
    "total_throughput": 6930.966050740698,
    "itl": 133.5640807875863,
    "ttft": 2090043.2249842433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.70804962767986,
    "arrivals": 241330,
    "finished_requests": 53732,
    "scheduler_time": 122.30472417525391
}
#Debug simulation 
Total elapsed time: 6.240753170102835. Arrivals time: 0.21732489299029112 Scheduler time: 5.839260896202177 Scheduler overhead time: 0.04156706668436527 Adapter cache time: 0.0822415896691382 Engine time: 0.04132643947377801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157889463 . Total output tokens: 139202281
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.1689083417877555,
    "estimated_duration": 3600.0817556929155,
    "input_throughput": 3931.206000424845,
    "output_throughput": 3431.6342901002167,
    "total_throughput": 7362.840290525061,
    "itl": 150.42241894382448,
    "ttft": 2036954.8586307615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.108335866159237,
    "arrivals": 235580,
    "finished_requests": 57257,
    "scheduler_time": 116.4650573393069
}
#Debug simulation 
Total elapsed time: 7.169032846111804. Arrivals time: 0.22734070988371968 Scheduler time: 6.784264754038304 Scheduler overhead time: 0.03813376696780324 Adapter cache time: 0.06419760407879949 Engine time: 0.03773890342563391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157889463 . Total output tokens: 139202281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.186855609994382,
    "estimated_duration": 3600.12351641055,
    "input_throughput": 3705.6275817172973,
    "output_throughput": 3233.848490733934,
    "total_throughput": 6939.476072451232,
    "itl": 133.41097593944568,
    "ttft": 2085217.3370653882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.43939912317712,
    "arrivals": 235580,
    "finished_requests": 53963,
    "scheduler_time": 122.14235724472476
}
#Debug simulation 
Total elapsed time: 6.186979585327208. Arrivals time: 0.21625357121229172 Scheduler time: 5.790417981334031 Scheduler overhead time: 0.041332466062158346 Adapter cache time: 0.07842238899320364 Engine time: 0.04145644884556532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157889463 . Total output tokens: 139202281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.017691826913506,
    "estimated_duration": 3600.141475433302,
    "input_throughput": 3696.5377863097124,
    "output_throughput": 3225.150755666494,
    "total_throughput": 6921.688541976207,
    "itl": 132.60308408564202,
    "ttft": 2085811.2118274681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3710,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.407128917398666,
    "arrivals": 235580,
    "finished_requests": 53833,
    "scheduler_time": 122.52875391814948
}
#Debug simulation 
Total elapsed time: 6.017815798986703. Arrivals time: 0.21548996167257428 Scheduler time: 5.622465675231069 Scheduler overhead time: 0.04173214780166745 Adapter cache time: 0.07746915658935905 Engine time: 0.04155090032145381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157889463 . Total output tokens: 139202281
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.930739618837833,
    "estimated_duration": 3600.143096421372,
    "input_throughput": 3714.551794703105,
    "output_throughput": 3239.368460546053,
    "total_throughput": 6953.920255249158,
    "itl": 133.56008494743278,
    "ttft": 2083394.6767470038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.98028264045472,
    "arrivals": 235580,
    "finished_requests": 54076,
    "scheduler_time": 122.1307030150599
}
#Debug simulation 
Total elapsed time: 5.930831369943917. Arrivals time: 0.21945832390338182 Scheduler time: 5.529917036183178 Scheduler overhead time: 0.04120311141014099 Adapter cache time: 0.08011225936934352 Engine time: 0.04120226530358195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155958110 . Total output tokens: 137481854
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.1063636732287705,
    "estimated_duration": 3600.040629432422,
    "input_throughput": 3944.389372694038,
    "output_throughput": 3442.475870599792,
    "total_throughput": 7386.86524329383,
    "itl": 151.06954658448356,
    "ttft": 2026035.0589915665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.74109343272172,
    "arrivals": 232701,
    "finished_requests": 57755,
    "scheduler_time": 116.05501552750978
}
#Debug simulation 
Total elapsed time: 7.106471760198474. Arrivals time: 0.23712621117010713 Scheduler time: 6.718437969684601 Scheduler overhead time: 0.037857059855014086 Adapter cache time: 0.05826373165473342 Engine time: 0.03751751268282533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155958110 . Total output tokens: 137481854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.915815967135131,
    "estimated_duration": 3600.117435185182,
    "input_throughput": 3710.6531218787463,
    "output_throughput": 3243.48447244454,
    "total_throughput": 6954.137594323286,
    "itl": 133.73956198344533,
    "ttft": 2074315.6425028732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.049508134233108,
    "arrivals": 232701,
    "finished_requests": 54349,
    "scheduler_time": 121.77476129047756
}
#Debug simulation 
Total elapsed time: 5.915917739737779. Arrivals time: 0.21908374736085534 Scheduler time: 5.523462567012757 Scheduler overhead time: 0.041237976867705584 Adapter cache time: 0.07238468015566468 Engine time: 0.04086789349094033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155958110 . Total output tokens: 137481854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.921577211935073,
    "estimated_duration": 3600.060218731882,
    "input_throughput": 3720.4608218242483,
    "output_throughput": 3249.229537643792,
    "total_throughput": 6969.69035946804,
    "itl": 134.1443298062375,
    "ttft": 2072704.6331734227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.350089720511455,
    "arrivals": 232701,
    "finished_requests": 54499,
    "scheduler_time": 121.64343499872429
}
#Debug simulation 
Total elapsed time: 5.921668583061546. Arrivals time: 0.21706113778054714 Scheduler time: 5.531272091437131 Scheduler overhead time: 0.04096502624452114 Adapter cache time: 0.07236094074323773 Engine time: 0.04106920585036278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155958110 . Total output tokens: 137481854
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.122193814255297,
    "estimated_duration": 3600.072719507424,
    "input_throughput": 3723.7331144339278,
    "output_throughput": 3250.0615714231744,
    "total_throughput": 6973.794685857102,
    "itl": 134.06700228705597,
    "ttft": 2072728.7893602757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.16497350566274,
    "arrivals": 232701,
    "finished_requests": 54518,
    "scheduler_time": 121.6849951106063
}
#Debug simulation 
Total elapsed time: 6.122260270174593. Arrivals time: 0.45984322763979435 Scheduler time: 5.4870485733263195 Scheduler overhead time: 0.04131343029439449 Adapter cache time: 0.07410680968314409 Engine time: 0.041018471121788025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 155001906 . Total output tokens: 136655995
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.899417056236416,
    "estimated_duration": 3600.146542595949,
    "input_throughput": 3913.8462374478386,
    "output_throughput": 3436.4915021150896,
    "total_throughput": 7350.337739562929,
    "itl": 150.4390743065625,
    "ttft": 2028755.6528764896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.372324763108406,
    "arrivals": 231176,
    "finished_requests": 57433,
    "scheduler_time": 116.31014660434816
}
#Debug simulation 
Total elapsed time: 6.899531756993383. Arrivals time: 0.2303836364299059 Scheduler time: 6.52192473039031 Scheduler overhead time: 0.03808513469994068 Adapter cache time: 0.05423260619863868 Engine time: 0.037625652737915516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 155001906 . Total output tokens: 136655995
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.757798902690411,
    "estimated_duration": 3600.035566005605,
    "input_throughput": 3685.5599775981054,
    "output_throughput": 3237.784123597698,
    "total_throughput": 6923.344101195804,
    "itl": 133.27628251317856,
    "ttft": 2076630.2361125585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.20837944842347,
    "arrivals": 231176,
    "finished_requests": 54063,
    "scheduler_time": 122.05851850117548
}
#Debug simulation 
Total elapsed time: 5.7578937048092484. Arrivals time: 0.21315463166683912 Scheduler time: 5.374391091056168 Scheduler overhead time: 0.041394357569515705 Adapter cache time: 0.06896791560575366 Engine time: 0.041076320223510265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 155001906 . Total output tokens: 136655995
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.809457421768457,
    "estimated_duration": 3600.0360536406215,
    "input_throughput": 3697.6982456989786,
    "output_throughput": 3245.1194448971555,
    "total_throughput": 6942.817690596134,
    "itl": 133.78333954334073,
    "ttft": 2075018.667257973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.9983415998384,
    "arrivals": 231176,
    "finished_requests": 54186,
    "scheduler_time": 121.8815085405549
}
#Debug simulation 
Total elapsed time: 5.809552034828812. Arrivals time: 0.2222051783464849 Scheduler time: 5.418372093234211 Scheduler overhead time: 0.04079124005511403 Adapter cache time: 0.06835391419008374 Engine time: 0.040971879847347736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 155001906 . Total output tokens: 136655995
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.813411501701921,
    "estimated_duration": 3600.142765704267,
    "input_throughput": 3696.6228469544017,
    "output_throughput": 3245.3696312552743,
    "total_throughput": 6941.992478209676,
    "itl": 133.5598333665305,
    "ttft": 2075619.774717236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.288100749134752,
    "arrivals": 231176,
    "finished_requests": 54202,
    "scheduler_time": 122.00930763743149
}
#Debug simulation 
Total elapsed time: 5.813506946898997. Arrivals time: 0.21372252609580755 Scheduler time: 5.431096972897649 Scheduler overhead time: 0.041113074868917465 Adapter cache time: 0.06745940819382668 Engine time: 0.04119747690856457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146301359 . Total output tokens: 129047843
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.382561576087028,
    "estimated_duration": 3600.0411828184383,
    "input_throughput": 3940.828251551561,
    "output_throughput": 3427.4455133704764,
    "total_throughput": 7368.273764922038,
    "itl": 149.58555744175723,
    "ttft": 2015638.6630078699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.49338182618804,
    "arrivals": 218283,
    "finished_requests": 57441,
    "scheduler_time": 116.01867760128454
}
#Debug simulation 
Total elapsed time: 7.382682252675295. Arrivals time: 0.2297772909514606 Scheduler time: 6.984755587298423 Scheduler overhead time: 0.038531511556357145 Adapter cache time: 0.07460270309820771 Engine time: 0.03769152797758579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146301359 . Total output tokens: 129047843
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.978682111017406,
    "estimated_duration": 3600.081772545534,
    "input_throughput": 3715.118945907453,
    "output_throughput": 3236.258989684557,
    "total_throughput": 6951.3779355920105,
    "itl": 133.53053093176064,
    "ttft": 2063356.1484006818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.24473634985192,
    "arrivals": 218283,
    "finished_requests": 54180,
    "scheduler_time": 121.26366074944866
}
#Debug simulation 
Total elapsed time: 5.978774129413068. Arrivals time: 0.22407772298902273 Scheduler time: 5.5708902617916465 Scheduler overhead time: 0.041831313632428646 Adapter cache time: 0.08160423347726464 Engine time: 0.04143749549984932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146301359 . Total output tokens: 129047843
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.030065226834267,
    "estimated_duration": 3600.0377904026454,
    "input_throughput": 3708.5130149444303,
    "output_throughput": 3232.1113492251993,
    "total_throughput": 6940.62436416963,
    "itl": 132.82921480853787,
    "ttft": 2064957.7620925298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.520169374445288,
    "arrivals": 218283,
    "finished_requests": 54100,
    "scheduler_time": 121.62048990938646
}
#Debug simulation 
Total elapsed time: 6.030191095080227. Arrivals time: 0.21991445077583194 Scheduler time: 5.628323137294501 Scheduler overhead time: 0.04185468563809991 Adapter cache time: 0.07952197641134262 Engine time: 0.04144574236124754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146301359 . Total output tokens: 129047843
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.979674832895398,
    "estimated_duration": 3600.0221943152437,
    "input_throughput": 3719.0029053547573,
    "output_throughput": 3240.1164132874715,
    "total_throughput": 6959.119318642229,
    "itl": 133.42342260292145,
    "ttft": 2063112.7505374262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.727201390501573,
    "arrivals": 218283,
    "finished_requests": 54227,
    "scheduler_time": 121.3758512476087
}
#Debug simulation 
Total elapsed time: 5.979792104102671. Arrivals time: 0.21723528346046805 Scheduler time: 5.579217901453376 Scheduler overhead time: 0.041217983700335026 Adapter cache time: 0.08209418505430222 Engine time: 0.04104140680283308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142453126 . Total output tokens: 125634299
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.750152571126819,
    "estimated_duration": 3600.0736429051954,
    "input_throughput": 3928.0927010671157,
    "output_throughput": 3430.3667716180703,
    "total_throughput": 7358.459472685186,
    "itl": 150.03799631885536,
    "ttft": 2008541.0630438803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.56611832553947,
    "arrivals": 212473,
    "finished_requests": 57046,
    "scheduler_time": 115.86652073864732
}
#Debug simulation 
Total elapsed time: 6.750270425342023. Arrivals time: 0.2250713324174285 Scheduler time: 6.371507972944528 Scheduler overhead time: 0.03776051849126816 Adapter cache time: 0.06121851783245802 Engine time: 0.03745465027168393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142453126 . Total output tokens: 125634299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.67360420897603,
    "estimated_duration": 3600.0901511440857,
    "input_throughput": 3695.16941006947,
    "output_throughput": 3236.4211758134047,
    "total_throughput": 6931.590585882875,
    "itl": 133.5003726492061,
    "ttft": 2057111.9743378826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.918580852248034,
    "arrivals": 212473,
    "finished_requests": 53761,
    "scheduler_time": 121.32483572599891
}
#Debug simulation 
Total elapsed time: 5.673705573193729. Arrivals time: 0.21713620703667402 Scheduler time: 5.2810030886903405 Scheduler overhead time: 0.041245874017477036 Adapter cache time: 0.07447042688727379 Engine time: 0.04097655415534973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142453126 . Total output tokens: 125634299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.621646178886294,
    "estimated_duration": 3600.011130735546,
    "input_throughput": 3698.736897316039,
    "output_throughput": 3237.7341560103728,
    "total_throughput": 6936.471053326412,
    "itl": 133.53571358497047,
    "ttft": 2056687.5950923185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.900853758194213,
    "arrivals": 212473,
    "finished_requests": 53793,
    "scheduler_time": 121.33852353387972
}
#Debug simulation 
Total elapsed time: 5.621745315846056. Arrivals time: 0.2066288636997342 Scheduler time: 5.238603593315929 Scheduler overhead time: 0.04113361472263932 Adapter cache time: 0.07548254448920488 Engine time: 0.04109872691333294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142453126 . Total output tokens: 125634299
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.6416485770605505,
    "estimated_duration": 3600.0183771290262,
    "input_throughput": 3696.59807420562,
    "output_throughput": 3236.2584796834326,
    "total_throughput": 6932.8565538890525,
    "itl": 133.1678114076413,
    "ttft": 2056955.8914512508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.886356571947307,
    "arrivals": 212473,
    "finished_requests": 53768,
    "scheduler_time": 121.50857072829515
}
#Debug simulation 
Total elapsed time: 5.641739150043577. Arrivals time: 0.2003899966366589 Scheduler time: 5.264580209739506 Scheduler overhead time: 0.04150344571098685 Adapter cache time: 0.07527242973446846 Engine time: 0.041074201464653015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140507344 . Total output tokens: 123871760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.504064803943038,
    "estimated_duration": 3600.060136812934,
    "input_throughput": 3922.0639276597963,
    "output_throughput": 3439.2236600139217,
    "total_throughput": 7361.287587673718,
    "itl": 150.2936031854859,
    "ttft": 2002114.7678066646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.317899254677023,
    "arrivals": 209565,
    "finished_requests": 57264,
    "scheduler_time": 115.49780566803796
}
#Debug simulation 
Total elapsed time: 6.504150460008532. Arrivals time: 0.2176389368250966 Scheduler time: 6.137984878383577 Scheduler overhead time: 0.03783765062689781 Adapter cache time: 0.05597994290292263 Engine time: 0.037441685795784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140507344 . Total output tokens: 123871760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.440459768753499,
    "estimated_duration": 3600.116636900435,
    "input_throughput": 3681.9101537255524,
    "output_throughput": 3231.392250117738,
    "total_throughput": 6913.30240384329,
    "itl": 132.8245177864722,
    "ttft": 2053500.3897098291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.187650374206093,
    "arrivals": 209565,
    "finished_requests": 53793,
    "scheduler_time": 121.3155253579688
}
#Debug simulation 
Total elapsed time: 5.440547546837479. Arrivals time: 0.19975603139027953 Scheduler time: 5.069543367251754 Scheduler overhead time: 0.04105277266353369 Adapter cache time: 0.07024323288351297 Engine time: 0.04096189420670271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140507344 . Total output tokens: 123871760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.479341302998364,
    "estimated_duration": 3600.0426735476776,
    "input_throughput": 3688.110170904106,
    "output_throughput": 3236.2060832237257,
    "total_throughput": 6924.316254127832,
    "itl": 133.07253682778668,
    "ttft": 2052136.6175494718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.347228515865883,
    "arrivals": 209565,
    "finished_requests": 53862,
    "scheduler_time": 121.24215322011383
}
#Debug simulation 
Total elapsed time: 5.4794284934177995. Arrivals time: 0.20381571538746357 Scheduler time: 5.104468351230025 Scheduler overhead time: 0.041207012720406055 Adapter cache time: 0.0697497446089983 Engine time: 0.041161146480590105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140507344 . Total output tokens: 123871760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.447424740064889,
    "estimated_duration": 3600.0093672850753,
    "input_throughput": 3690.5903969965707,
    "output_throughput": 3238.181018620909,
    "total_throughput": 6928.77141561748,
    "itl": 133.03957286252268,
    "ttft": 2051905.8990120015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.09885870858732,
    "arrivals": 209565,
    "finished_requests": 53906,
    "scheduler_time": 121.27110441598036
}
#Debug simulation 
Total elapsed time: 5.447516956366599. Arrivals time: 0.19949215138331056 Scheduler time: 5.077038328163326 Scheduler overhead time: 0.04098450671881437 Adapter cache time: 0.06997954426333308 Engine time: 0.041117016691714525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139554158 . Total output tokens: 123071260
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.359350122977048,
    "estimated_duration": 3600.0745463573994,
    "input_throughput": 3925.18538659092,
    "output_throughput": 3436.90105320715,
    "total_throughput": 7362.08643979807,
    "itl": 150.2370292012545,
    "ttft": 2002839.2780560085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.434888916747111,
    "arrivals": 208142,
    "finished_requests": 57221,
    "scheduler_time": 115.65839425631385
}
#Debug simulation 
Total elapsed time: 6.3594361720606685. Arrivals time: 0.21184358792379498 Scheduler time: 6.006477658636868 Scheduler overhead time: 0.03750037308782339 Adapter cache time: 0.048885675612837076 Engine time: 0.037594729103147984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139554158 . Total output tokens: 123071260
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.338060198351741,
    "estimated_duration": 3600.03638865584,
    "input_throughput": 3686.6752352343533,
    "output_throughput": 3240.253914309855,
    "total_throughput": 6926.9291495442085,
    "itl": 133.37611269995722,
    "ttft": 2052681.7536631206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.453650645729528,
    "arrivals": 208142,
    "finished_requests": 53833,
    "scheduler_time": 121.21447838932988
}
#Debug simulation 
Total elapsed time: 5.338147577363998. Arrivals time: 0.1998544903472066 Scheduler time: 4.971037802752107 Scheduler overhead time: 0.04110234137624502 Adapter cache time: 0.0661470452323556 Engine time: 0.041189378593117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139554158 . Total output tokens: 123071260
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.341045052744448,
    "estimated_duration": 3600.050863108371,
    "input_throughput": 3688.127613990412,
    "output_throughput": 3241.5467013496777,
    "total_throughput": 6929.67431534009,
    "itl": 133.31844731801385,
    "ttft": 2052321.6573886566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.078471367420214,
    "arrivals": 208142,
    "finished_requests": 53843,
    "scheduler_time": 121.26274558484121
}
#Debug simulation 
Total elapsed time: 5.341132126748562. Arrivals time: 0.1974379513412714 Scheduler time: 4.976749574299902 Scheduler overhead time: 0.041101187001913786 Adapter cache time: 0.06582861160859466 Engine time: 0.04109041905030608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139554158 . Total output tokens: 123071260
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.328902716748416,
    "estimated_duration": 3600.1021212373275,
    "input_throughput": 3690.9316881914197,
    "output_throughput": 3244.8387869578187,
    "total_throughput": 6935.770475149238,
    "itl": 133.50650363184167,
    "ttft": 2051040.3051918675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.617789050374757,
    "arrivals": 208142,
    "finished_requests": 53903,
    "scheduler_time": 121.21672157889257
}
#Debug simulation 
Total elapsed time: 5.329018376767635. Arrivals time: 0.1974936556071043 Scheduler time: 4.963776506483555 Scheduler overhead time: 0.041173444129526615 Adapter cache time: 0.06657608738169074 Engine time: 0.0410659359768033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134781964 . Total output tokens: 118793465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.657864216249436,
    "estimated_duration": 3600.046826075726,
    "input_throughput": 3950.8097219679944,
    "output_throughput": 3440.1366421947455,
    "total_throughput": 7390.94636416274,
    "itl": 150.5816203259462,
    "ttft": 1986464.8539194039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.788906532121153,
    "arrivals": 200966,
    "finished_requests": 57529,
    "scheduler_time": 115.07460770523561
}
#Debug simulation 
Total elapsed time: 6.657955348026007. Arrivals time: 0.21706828474998474 Scheduler time: 6.29337817337364 Scheduler overhead time: 0.037776325829327106 Adapter cache time: 0.0552597614005208 Engine time: 0.0372863351367414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134781964 . Total output tokens: 118793465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.32074606930837,
    "estimated_duration": 3600.0067953492257,
    "input_throughput": 3721.67130831771,
    "output_throughput": 3241.4705480765615,
    "total_throughput": 6963.141856394272,
    "itl": 133.68547591350355,
    "ttft": 2037175.7584307007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.608450927724416,
    "arrivals": 200966,
    "finished_requests": 54149,
    "scheduler_time": 120.5993176276662
}
#Debug simulation 
Total elapsed time: 5.320872669108212. Arrivals time: 0.2029699976556003 Scheduler time: 4.945706317666918 Scheduler overhead time: 0.04127930384129286 Adapter cache time: 0.07042874721810222 Engine time: 0.04153270833194256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134781964 . Total output tokens: 118793465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.319271238986403,
    "estimated_duration": 3600.123663443035,
    "input_throughput": 3723.472095172407,
    "output_throughput": 3243.353032165851,
    "total_throughput": 6966.825127338258,
    "itl": 133.64814262994423,
    "ttft": 2037072.9766426964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.179376451527382,
    "arrivals": 200966,
    "finished_requests": 54187,
    "scheduler_time": 120.6323469358484
}
#Debug simulation 
Total elapsed time: 5.319385595154017. Arrivals time: 0.21162179671227932 Scheduler time: 4.9341546865180135 Scheduler overhead time: 0.0411499822512269 Adapter cache time: 0.07195807108655572 Engine time: 0.041494580917060375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134781964 . Total output tokens: 118793465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.306222498882562,
    "estimated_duration": 3600.0187370508716,
    "input_throughput": 3725.3994991666855,
    "output_throughput": 3244.5883905506303,
    "total_throughput": 6969.987889717316,
    "itl": 133.57753226880857,
    "ttft": 2037030.6709762386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.539349253486744,
    "arrivals": 200966,
    "finished_requests": 54205,
    "scheduler_time": 120.6877639776625
}
#Debug simulation 
Total elapsed time: 5.306318220682442. Arrivals time: 0.1960821500979364 Scheduler time: 4.937926021404564 Scheduler overhead time: 0.041050434578210115 Adapter cache time: 0.07136069564148784 Engine time: 0.04094395553693175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132843901 . Total output tokens: 117048456
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.06351576000452,
    "estimated_duration": 3600.0345443104225,
    "input_throughput": 3937.3799960897677,
    "output_throughput": 3440.57254105392,
    "total_throughput": 7377.952537143688,
    "itl": 150.22637522589542,
    "ttft": 1980606.0189967547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.22837800058113,
    "arrivals": 198105,
    "finished_requests": 57544,
    "scheduler_time": 115.16764461474926
}
#Debug simulation 
Total elapsed time: 6.063624779693782. Arrivals time: 0.20945080369710922 Scheduler time: 5.712065085303038 Scheduler overhead time: 0.03755235532298684 Adapter cache time: 0.05020366609096527 Engine time: 0.0372794889844954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132843901 . Total output tokens: 117048456
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.0467329560779035,
    "estimated_duration": 3600.047925101749,
    "input_throughput": 3700.510736846226,
    "output_throughput": 3233.4683432501797,
    "total_throughput": 6933.979080096406,
    "itl": 132.6322778486056,
    "ttft": 2034426.825010175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.941076328283504,
    "arrivals": 198105,
    "finished_requests": 54011,
    "scheduler_time": 120.94961240415175
}
#Debug simulation 
Total elapsed time: 5.046862516086549. Arrivals time: 0.19964286964386702 Scheduler time: 4.679238712415099 Scheduler overhead time: 0.04134290758520365 Adapter cache time: 0.06648624921217561 Engine time: 0.04113956540822983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132843901 . Total output tokens: 117048456
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.051443245727569,
    "estimated_duration": 3600.144219392665,
    "input_throughput": 3713.528454772669,
    "output_throughput": 3242.928140798077,
    "total_throughput": 6956.456595570746,
    "itl": 133.32595412928134,
    "ttft": 2031881.8413533615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.679957634490528,
    "arrivals": 198105,
    "finished_requests": 54211,
    "scheduler_time": 120.69657607539015
}
#Debug simulation 
Total elapsed time: 5.051558507140726. Arrivals time: 0.19699977291747928 Scheduler time: 4.6859886408783495 Scheduler overhead time: 0.04091409873217344 Adapter cache time: 0.06752657238394022 Engine time: 0.04117340175434947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132843901 . Total output tokens: 117048456
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.075868418905884,
    "estimated_duration": 3600.0237677795294,
    "input_throughput": 3710.7707786717356,
    "output_throughput": 3242.117483907343,
    "total_throughput": 6952.888262579078,
    "itl": 133.0489541826253,
    "ttft": 2032041.4510541433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.82207452047304,
    "arrivals": 198105,
    "finished_requests": 54171,
    "scheduler_time": 120.84078335952458
}
#Debug simulation 
Total elapsed time: 5.075976630207151. Arrivals time: 0.20867124432697892 Scheduler time: 4.700071229133755 Scheduler overhead time: 0.04105634707957506 Adapter cache time: 0.06612648535519838 Engine time: 0.04110943339765072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131935873 . Total output tokens: 116223218
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.751817693933845,
    "estimated_duration": 3600.156546971296,
    "input_throughput": 3958.8500705587885,
    "output_throughput": 3439.0282307073003,
    "total_throughput": 7397.878301266089,
    "itl": 150.15436329849672,
    "ttft": 1973526.835350703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.9323458303189,
    "arrivals": 196756,
    "finished_requests": 57640,
    "scheduler_time": 115.11835474989431
}
#Debug simulation 
Total elapsed time: 5.7519045867957175. Arrivals time: 0.20414933236315846 Scheduler time: 5.408711270894855 Scheduler overhead time: 0.03748323488980532 Adapter cache time: 0.046842449344694614 Engine time: 0.03750480059534311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131935873 . Total output tokens: 116223218
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.922635161783546,
    "estimated_duration": 3600.132635286202,
    "input_throughput": 3735.0993316753197,
    "output_throughput": 3245.782359646605,
    "total_throughput": 6980.881691321924,
    "itl": 133.46385228448165,
    "ttft": 2025795.8001782126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.217077477424798,
    "arrivals": 196756,
    "finished_requests": 54353,
    "scheduler_time": 120.56557265348009
}
#Debug simulation 
Total elapsed time: 4.922722007147968. Arrivals time: 0.2012384277768433 Scheduler time: 4.557516362052411 Scheduler overhead time: 0.04144771536812186 Adapter cache time: 0.06254912167787552 Engine time: 0.04101003520190716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131935873 . Total output tokens: 116223218
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.896767190191895,
    "estimated_duration": 3600.1089994237627,
    "input_throughput": 3733.9866660014077,
    "output_throughput": 3246.0700500652915,
    "total_throughput": 6980.0567160667,
    "itl": 133.32896484083,
    "ttft": 2025186.6437878096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.856639878945835,
    "arrivals": 196756,
    "finished_requests": 54345,
    "scheduler_time": 120.64748845304177
}
#Debug simulation 
Total elapsed time: 4.89685316523537. Arrivals time: 0.19695731718093157 Scheduler time: 4.537265099119395 Scheduler overhead time: 0.04109664587303996 Adapter cache time: 0.0616752440109849 Engine time: 0.040982863400131464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131935873 . Total output tokens: 116223218
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.90435716509819,
    "estimated_duration": 3600.0175161669317,
    "input_throughput": 3729.59018663214,
    "output_throughput": 3242.7181111134037,
    "total_throughput": 6972.308297745543,
    "itl": 132.93386963532808,
    "ttft": 2025205.2381850858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.270781731914195,
    "arrivals": 196756,
    "finished_requests": 54282,
    "scheduler_time": 120.84118689996552
}
#Debug simulation 
Total elapsed time: 4.9044448006898165. Arrivals time: 0.1954049952328205 Scheduler time: 4.545975718647242 Scheduler overhead time: 0.04131991183385253 Adapter cache time: 0.06188576063141227 Engine time: 0.04090818716213107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129022349 . Total output tokens: 113672470
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.434298381675035,
    "estimated_duration": 3600.1066572373034,
    "input_throughput": 3942.4568079024116,
    "output_throughput": 3438.413685637662,
    "total_throughput": 7380.870493540074,
    "itl": 150.385437242153,
    "ttft": 1966933.9478319227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.097656056117653,
    "arrivals": 192504,
    "finished_requests": 57536,
    "scheduler_time": 114.73299003408489
}
#Debug simulation 
Total elapsed time: 5.4343879437074065. Arrivals time: 0.20576386246830225 Scheduler time: 5.090018036775291 Scheduler overhead time: 0.037291474640369415 Adapter cache time: 0.0468124165199697 Engine time: 0.037369287107139826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129022349 . Total output tokens: 113672470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.673021827824414,
    "estimated_duration": 3600.0932345718975,
    "input_throughput": 3718.045930438717,
    "output_throughput": 3244.8084643533157,
    "total_throughput": 6962.8543947920325,
    "itl": 133.3794200803149,
    "ttft": 2019438.7254480028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2781,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.335775146088093,
    "arrivals": 192504,
    "finished_requests": 54289,
    "scheduler_time": 120.28302169923191
}
#Debug simulation 
Total elapsed time: 4.6731395306997. Arrivals time: 0.19295907765626907 Scheduler time: 4.319186487235129 Scheduler overhead time: 0.041172741912305355 Adapter cache time: 0.0600003101862967 Engine time: 0.04089790675789118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129022349 . Total output tokens: 113672470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.672462871763855,
    "estimated_duration": 3600.015506095844,
    "input_throughput": 3716.940379101732,
    "output_throughput": 3244.712413105093,
    "total_throughput": 6961.652792206825,
    "itl": 133.1899547222385,
    "ttft": 2019682.8521805468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.121346169878237,
    "arrivals": 192504,
    "finished_requests": 54277,
    "scheduler_time": 120.37674493864695
}
#Debug simulation 
Total elapsed time: 4.672549630049616. Arrivals time: 0.1928046396933496 Scheduler time: 4.318347344640642 Scheduler overhead time: 0.040993968956172466 Adapter cache time: 0.060724768321961164 Engine time: 0.04074531048536301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129022349 . Total output tokens: 113672470
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.6598666799254715,
    "estimated_duration": 3600.051034670454,
    "input_throughput": 3722.5838942104783,
    "output_throughput": 3248.912831334533,
    "total_throughput": 6971.496725545011,
    "itl": 133.40709024165292,
    "ttft": 2018416.7747870618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.779219819490198,
    "arrivals": 192504,
    "finished_requests": 54358,
    "scheduler_time": 120.30743968300065
}
#Debug simulation 
Total elapsed time: 4.659987945109606. Arrivals time: 0.1940631540492177 Scheduler time: 4.304941177368164 Scheduler overhead time: 0.040855081751942635 Adapter cache time: 0.0605941591784358 Engine time: 0.04063500324264169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128072035 . Total output tokens: 112848373
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.181874375324696,
    "estimated_duration": 3600.1211315736878,
    "input_throughput": 3926.9575892909456,
    "output_throughput": 3434.74331781575,
    "total_throughput": 7361.700907106695,
    "itl": 149.46761545531677,
    "ttft": 1973525.4066502103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.927259657462477,
    "arrivals": 191087,
    "finished_requests": 57128,
    "scheduler_time": 114.98665426303594
}
#Debug simulation 
Total elapsed time: 5.181958741974086. Arrivals time: 0.2029978120699525 Scheduler time: 4.841702637728304 Scheduler overhead time: 0.03772279154509306 Adapter cache time: 0.0441550356335938 Engine time: 0.03824408072978258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128072035 . Total output tokens: 112848373
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.557831699959934,
    "estimated_duration": 3600.1332809873716,
    "input_throughput": 3693.4724250967647,
    "output_throughput": 3240.31725758792,
    "total_throughput": 6933.7896826846845,
    "itl": 132.77629747143797,
    "ttft": 2026014.5306426752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.319211344448448,
    "arrivals": 191087,
    "finished_requests": 53784,
    "scheduler_time": 120.51534545966241
}
#Debug simulation 
Total elapsed time: 4.557930110953748. Arrivals time: 0.19528079684823751 Scheduler time: 4.206150603014976 Scheduler overhead time: 0.04096070025116205 Adapter cache time: 0.055394497234374285 Engine time: 0.04118644259870052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128072035 . Total output tokens: 112848373
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.538048835936934,
    "estimated_duration": 3600.06356669818,
    "input_throughput": 3694.7678155026188,
    "output_throughput": 3241.6480386493117,
    "total_throughput": 6936.41585415193,
    "itl": 132.7642209530975,
    "ttft": 2025428.1276509096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.337134543974305,
    "arrivals": 191087,
    "finished_requests": 53808,
    "scheduler_time": 120.54273104301603
}
#Debug simulation 
Total elapsed time: 4.5381356119178236. Arrivals time: 0.19690475706011057 Scheduler time: 4.183832380454987 Scheduler overhead time: 0.040761266835033894 Adapter cache time: 0.0560128353536129 Engine time: 0.04171374812722206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128072035 . Total output tokens: 112848373
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.531578035093844,
    "estimated_duration": 3600.1462870075825,
    "input_throughput": 3702.08595359001,
    "output_throughput": 3246.9975017921765,
    "total_throughput": 6949.083455382186,
    "itl": 133.0313991921209,
    "ttft": 2024674.5925005006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.151319979644494,
    "arrivals": 191087,
    "finished_requests": 53906,
    "scheduler_time": 120.44330320363383
}
#Debug simulation 
Total elapsed time: 4.531664962414652. Arrivals time: 0.19183713803067803 Scheduler time: 4.182725375518203 Scheduler overhead time: 0.04090194357559085 Adapter cache time: 0.05625583790242672 Engine time: 0.04105906467884779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126104445 . Total output tokens: 111117433
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.788320867810398,
    "estimated_duration": 3600.007309839356,
    "input_throughput": 3946.2914314565514,
    "output_throughput": 3441.398567758142,
    "total_throughput": 7387.689999214693,
    "itl": 149.7893710219332,
    "ttft": 1957386.5940561113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.950149356909382,
    "arrivals": 188115,
    "finished_requests": 57419,
    "scheduler_time": 114.74468215495715
}
#Debug simulation 
Total elapsed time: 4.788422912824899. Arrivals time: 0.20230476651340723 Scheduler time: 4.456204509362578 Scheduler overhead time: 0.03730703052133322 Adapter cache time: 0.0383113631978631 Engine time: 0.037142123095691204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126104445 . Total output tokens: 111117433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.33086491888389,
    "estimated_duration": 3600.118419881974,
    "input_throughput": 3724.5763711404793,
    "output_throughput": 3248.1023222517665,
    "total_throughput": 6972.678693392246,
    "itl": 132.92765575292424,
    "ttft": 2008842.5901825898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.457448434461513,
    "arrivals": 188115,
    "finished_requests": 54246,
    "scheduler_time": 120.28261392632456
}
#Debug simulation 
Total elapsed time: 4.330984516069293. Arrivals time: 0.20236365962773561 Scheduler time: 3.9799833241850138 Scheduler overhead time: 0.040619479957968 Adapter cache time: 0.04832897474989295 Engine time: 0.040831375401467085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126104445 . Total output tokens: 111117433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.344357125926763,
    "estimated_duration": 3600.083613664135,
    "input_throughput": 3724.651268961049,
    "output_throughput": 3248.120947973885,
    "total_throughput": 6972.7722169349345,
    "itl": 132.81206329717952,
    "ttft": 2008882.2666799414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.494287454420935,
    "arrivals": 188115,
    "finished_requests": 54250,
    "scheduler_time": 120.34165023054427
}
#Debug simulation 
Total elapsed time: 4.344470439013094. Arrivals time: 0.19537563249468803 Scheduler time: 4.000065803062171 Scheduler overhead time: 0.04084130050614476 Adapter cache time: 0.04789688577875495 Engine time: 0.04131901590153575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126104445 . Total output tokens: 111117433
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.347486027982086,
    "estimated_duration": 3600.1201917493286,
    "input_throughput": 3725.896160561846,
    "output_throughput": 3249.6520607316975,
    "total_throughput": 6975.548221293544,
    "itl": 132.86603142051078,
    "ttft": 2008132.3029685568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.648822970940513,
    "arrivals": 188115,
    "finished_requests": 54272,
    "scheduler_time": 120.33307952611138
}
#Debug simulation 
Total elapsed time: 4.347572503611445. Arrivals time: 0.19254516623914242 Scheduler time: 4.0032947664149106 Scheduler overhead time: 0.040618831757456064 Adapter cache time: 0.048944983165711164 Engine time: 0.0410449611954391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53946690 . Total output tokens: 47536914
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.273497480899096,
    "estimated_duration": 3600.0282339901137,
    "input_throughput": 4005.8302498412027,
    "output_throughput": 3430.851425937433,
    "total_throughput": 7436.6816757786355,
    "itl": 146.12851682505234,
    "ttft": 1385876.8532975945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.48015700812414,
    "arrivals": 80883,
    "finished_requests": 57745,
    "scheduler_time": 80.29293887557039
}
#Debug simulation 
Total elapsed time: 9.273587429895997. Arrivals time: 0.22098672995343804 Scheduler time: 8.890243601053953 Scheduler overhead time: 0.04089409252628684 Adapter cache time: 0.06291165761649609 Engine time: 0.04044824931770563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53946690 . Total output tokens: 47536914
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.322601470164955,
    "estimated_duration": 3600.048601741427,
    "input_throughput": 3787.6783089550613,
    "output_throughput": 3246.5250592301486,
    "total_throughput": 7034.20336818521,
    "itl": 130.85215145381335,
    "ttft": 1544696.0060846354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4086,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.86066201058134,
    "arrivals": 80883,
    "finished_requests": 54603,
    "scheduler_time": 86.41604250484957
}
#Debug simulation 
Total elapsed time: 7.322685684077442. Arrivals time: 0.21779528353363276 Scheduler time: 6.912789585068822 Scheduler overhead time: 0.04349676379933953 Adapter cache time: 0.08574303006753325 Engine time: 0.04327159421518445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53946690 . Total output tokens: 47536914
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 7.37752901436761,
    "estimated_duration": 3600.1375861311117,
    "input_throughput": 3787.1641496491015,
    "output_throughput": 3247.741432172638,
    "total_throughput": 7034.905581821739,
    "itl": 130.78744779099506,
    "ttft": 1544009.370851802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.09620472045232,
    "arrivals": 80883,
    "finished_requests": 54636,
    "scheduler_time": 86.43190848516281
}
#Debug simulation 
Total elapsed time: 7.37762359296903. Arrivals time: 0.2182755209505558 Scheduler time: 6.966441009193659 Scheduler overhead time: 0.04394276347011328 Adapter cache time: 0.08589309733361006 Engine time: 0.04318795586004853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53946690 . Total output tokens: 47536914
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.410389869939536,
    "estimated_duration": 3600.127514034505,
    "input_throughput": 3792.5087227532963,
    "output_throughput": 3249.953218153667,
    "total_throughput": 7042.461940906963,
    "itl": 130.69143237366097,
    "ttft": 1542159.450529034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.650594339214717,
    "arrivals": 80883,
    "finished_requests": 54724,
    "scheduler_time": 86.39492261326994
}
#Debug simulation 
Total elapsed time: 7.410485350061208. Arrivals time: 0.21090111322700977 Scheduler time: 7.010089046321809 Scheduler overhead time: 0.043795882258564234 Adapter cache time: 0.08252897579222918 Engine time: 0.0434805853292346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50082758 . Total output tokens: 44147738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.692491699941456,
    "estimated_duration": 3600.086814073166,
    "input_throughput": 3983.483660432791,
    "output_throughput": 3431.22253377664,
    "total_throughput": 7414.7061942094315,
    "itl": 145.590717278543,
    "ttft": 1164670.6268527817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.74973954225823,
    "arrivals": 75147,
    "finished_requests": 57385,
    "scheduler_time": 72.33059499683716
}
#Debug simulation 
Total elapsed time: 8.692582960706204. Arrivals time: 0.19778537098318338 Scheduler time: 8.329707384109497 Scheduler overhead time: 0.04079962708055973 Adapter cache time: 0.0656239315867424 Engine time: 0.0405000732280314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50082758 . Total output tokens: 44147738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.16628633486107,
    "estimated_duration": 3600.008396289528,
    "input_throughput": 3753.526801195063,
    "output_throughput": 3245.553541497997,
    "total_throughput": 6999.08034269306,
    "itl": 130.41167321176584,
    "ttft": 1354965.3063874028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.95734610211948,
    "arrivals": 75147,
    "finished_requests": 54079,
    "scheduler_time": 77.49848089160345
}
#Debug simulation 
Total elapsed time: 7.166371184866875. Arrivals time: 0.19027999369427562 Scheduler time: 6.7828086647205055 Scheduler overhead time: 0.04404180450364947 Adapter cache time: 0.08590612560510635 Engine time: 0.04355475027114153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50082758 . Total output tokens: 44147738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.849826172925532,
    "estimated_duration": 3600.08519310339,
    "input_throughput": 3759.766859387007,
    "output_throughput": 3251.4352778161697,
    "total_throughput": 7011.202137203177,
    "itl": 130.62061293826406,
    "ttft": 1349156.4732429148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.63726068900517,
    "arrivals": 75147,
    "finished_requests": 54195,
    "scheduler_time": 77.38810469203032
}
#Debug simulation 
Total elapsed time: 6.849914783146232. Arrivals time: 0.19064263068139553 Scheduler time: 6.465464417356998 Scheduler overhead time: 0.04373120376840234 Adapter cache time: 0.08716801973059773 Engine time: 0.043193113058805466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50082758 . Total output tokens: 44147738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.756932787131518,
    "estimated_duration": 3600.1428260886078,
    "input_throughput": 3754.936860293132,
    "output_throughput": 3245.4379074438502,
    "total_throughput": 7000.374767736982,
    "itl": 129.99950349988902,
    "ttft": 1354387.9474037045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.814743538068416,
    "arrivals": 75147,
    "finished_requests": 54106,
    "scheduler_time": 77.57291428999743
}
#Debug simulation 
Total elapsed time: 6.75705385627225. Arrivals time: 0.1877000154927373 Scheduler time: 6.373573604039848 Scheduler overhead time: 0.04402065649628639 Adapter cache time: 0.08851218037307262 Engine time: 0.04348489874973893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48119276 . Total output tokens: 42362198
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.726653818041086,
    "estimated_duration": 3600.0807030386677,
    "input_throughput": 3950.5328277767894,
    "output_throughput": 3440.1617690254807,
    "total_throughput": 7390.69459680227,
    "itl": 146.18871576612707,
    "ttft": 1019510.0885263127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.090532339567954,
    "arrivals": 72240,
    "finished_requests": 57216,
    "scheduler_time": 67.28875791463703
}
#Debug simulation 
Total elapsed time: 7.726766324136406. Arrivals time: 0.18239840772002935 Scheduler time: 7.374671446159482 Scheduler overhead time: 0.040326149202883244 Adapter cache time: 0.07147911144420505 Engine time: 0.03979860199615359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48119276 . Total output tokens: 42362198
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.45883725816384,
    "estimated_duration": 3599.982846561969,
    "input_throughput": 3740.575878815705,
    "output_throughput": 3253.6432808801096,
    "total_throughput": 6994.219159695815,
    "itl": 130.4832605574885,
    "ttft": 1212646.6280711908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.212986270547002,
    "arrivals": 72240,
    "finished_requests": 54181,
    "scheduler_time": 71.82456778055234
}
#Debug simulation 
Total elapsed time: 6.458931806962937. Arrivals time: 0.17810134449973702 Scheduler time: 6.089170082937926 Scheduler overhead time: 0.04355994611978531 Adapter cache time: 0.08537221373990178 Engine time: 0.04308480815961957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48119276 . Total output tokens: 42362198
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.48319276003167,
    "estimated_duration": 3600.092620935596,
    "input_throughput": 3737.5988389162935,
    "output_throughput": 3253.846007149592,
    "total_throughput": 6991.444846065886,
    "itl": 130.24326012247633,
    "ttft": 1214911.564367495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.47710548156492,
    "arrivals": 72240,
    "finished_requests": 54138,
    "scheduler_time": 71.9032885384112
}
#Debug simulation 
Total elapsed time: 6.483316262252629. Arrivals time: 0.1833359352312982 Scheduler time: 6.106353921350092 Scheduler overhead time: 0.04352650186046958 Adapter cache time: 0.08704992290586233 Engine time: 0.043324755504727364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48119276 . Total output tokens: 42362198
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.504373352974653,
    "estimated_duration": 3600.0761525910116,
    "input_throughput": 3746.560469364688,
    "output_throughput": 3260.817688967825,
    "total_throughput": 7007.378158332513,
    "itl": 130.56329476773095,
    "ttft": 1206458.4926403866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.431708281634133,
    "arrivals": 72240,
    "finished_requests": 54275,
    "scheduler_time": 71.70493766807438
}
#Debug simulation 
Total elapsed time: 6.504496440757066. Arrivals time: 0.1824578340165317 Scheduler time: 6.129649602342397 Scheduler overhead time: 0.04368823394179344 Adapter cache time: 0.08592626731842756 Engine time: 0.042990302201360464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47183440 . Total output tokens: 41541158
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.687577149365097,
    "estimated_duration": 3600.108891117121,
    "input_throughput": 3954.2731707713983,
    "output_throughput": 3447.3498928386284,
    "total_throughput": 7401.623063610026,
    "itl": 146.31049618421486,
    "ttft": 928410.52724276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.59612789834762,
    "arrivals": 70816,
    "finished_requests": 57586,
    "scheduler_time": 65.16428272496596
}
#Debug simulation 
Total elapsed time: 7.687692431267351. Arrivals time: 0.18192927772179246 Scheduler time: 7.34075874928385 Scheduler overhead time: 0.040178296621888876 Adapter cache time: 0.06705341255292296 Engine time: 0.03975897189229727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47183440 . Total output tokens: 41541158
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.276272791437805,
    "estimated_duration": 3600.1305180737786,
    "input_throughput": 3736.1031586145277,
    "output_throughput": 3264.5860868089626,
    "total_throughput": 7000.68924542349,
    "itl": 130.829836516779,
    "ttft": 1129748.0167813841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3958,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.953285766922985,
    "arrivals": 70816,
    "finished_requests": 54471,
    "scheduler_time": 69.31997180032393
}
#Debug simulation 
Total elapsed time: 6.276362008415163. Arrivals time: 0.17414232343435287 Scheduler time: 5.916069153696299 Scheduler overhead time: 0.04295531939715147 Adapter cache time: 0.08083731029182673 Engine time: 0.04279049253091216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47183440 . Total output tokens: 41541158
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.259841604158282,
    "estimated_duration": 3600.087119024933,
    "input_throughput": 3739.3825635103376,
    "output_throughput": 3268.134523140832,
    "total_throughput": 7007.517086651169,
    "itl": 130.9295086582965,
    "ttft": 1126355.3758811266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.113977739984005,
    "arrivals": 70816,
    "finished_requests": 54527,
    "scheduler_time": 69.27178362791135
}
#Debug simulation 
Total elapsed time: 6.259954309090972. Arrivals time: 0.1756180003285408 Scheduler time: 5.895455645862967 Scheduler overhead time: 0.0428542117588222 Adapter cache time: 0.0834598052315414 Engine time: 0.04293336207047105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47183440 . Total output tokens: 41541158
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.2597871869802475,
    "estimated_duration": 3600.1342245362716,
    "input_throughput": 3743.13266104288,
    "output_throughput": 3269.340326197445,
    "total_throughput": 7012.472987240325,
    "itl": 130.81410067419884,
    "ttft": 1124994.413556532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.014477832827286,
    "arrivals": 70816,
    "finished_requests": 54552,
    "scheduler_time": 69.27448955968332
}
#Debug simulation 
Total elapsed time: 6.259877506177872. Arrivals time: 0.1761932708323002 Scheduler time: 5.894720310810953 Scheduler overhead time: 0.04342016018927097 Adapter cache time: 0.08277948247268796 Engine time: 0.043177821673452854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42391707 . Total output tokens: 37296696
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.305135641712695,
    "estimated_duration": 3600.065447136643,
    "input_throughput": 3929.0146825664438,
    "output_throughput": 3431.0217915133294,
    "total_throughput": 7360.036474079773,
    "itl": 144.1162584393865,
    "ttft": 531722.5231710119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.640888525395464,
    "arrivals": 63706,
    "finished_requests": 57105,
    "scheduler_time": 55.593737607395155
}
#Debug simulation 
Total elapsed time: 8.3052489599213. Arrivals time: 0.1605186639353633 Scheduler time: 7.975580501835793 Scheduler overhead time: 0.04103390546515584 Adapter cache time: 0.06954468553885818 Engine time: 0.04030327033251524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42391707 . Total output tokens: 37296696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.522899121046066,
    "estimated_duration": 3600.053881222095,
    "input_throughput": 3730.609997270608,
    "output_throughput": 3258.7015047723557,
    "total_throughput": 6989.311502042963,
    "itl": 129.99792292853306,
    "ttft": 749728.9266567604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.76610171736586,
    "arrivals": 63706,
    "finished_requests": 54212,
    "scheduler_time": 58.19944883007931
}
#Debug simulation 
Total elapsed time: 6.522989470046014. Arrivals time: 0.1610598098486662 Scheduler time: 6.163769504055381 Scheduler overhead time: 0.043635908514261246 Adapter cache time: 0.09113036701455712 Engine time: 0.04364057211205363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42391707 . Total output tokens: 37296696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.602868619840592,
    "estimated_duration": 3600.065826086106,
    "input_throughput": 3731.6159339800597,
    "output_throughput": 3258.3151438518835,
    "total_throughput": 6989.931077831943,
    "itl": 129.74892100840813,
    "ttft": 750039.8492482082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.592440481647866,
    "arrivals": 63706,
    "finished_requests": 54217,
    "scheduler_time": 58.242205126108736
}
#Debug simulation 
Total elapsed time: 6.602956895250827. Arrivals time: 0.16144120087847114 Scheduler time: 6.242486179806292 Scheduler overhead time: 0.043434346094727516 Adapter cache time: 0.0922884289175272 Engine time: 0.04342361353337765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42391707 . Total output tokens: 37296696
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.529774187132716,
    "estimated_duration": 3600.0975047934257,
    "input_throughput": 3733.357216604392,
    "output_throughput": 3260.2816963629684,
    "total_throughput": 6993.63891296736,
    "itl": 129.55486369567265,
    "ttft": 747893.6476605347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.89590176469469,
    "arrivals": 63706,
    "finished_requests": 54240,
    "scheduler_time": 58.211275487204915
}
#Debug simulation 
Total elapsed time: 6.52986351121217. Arrivals time: 0.1601489488966763 Scheduler time: 6.17074142023921 Scheduler overhead time: 0.044310994911938906 Adapter cache time: 0.09151861444115639 Engine time: 0.04331126483157277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40373969 . Total output tokens: 35593910
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.301687768660486,
    "estimated_duration": 3600.0036355260686,
    "input_throughput": 3924.7535365156127,
    "output_throughput": 3420.3459903452745,
    "total_throughput": 7345.099526860887,
    "itl": 143.12507174520513,
    "ttft": 321665.4040744589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.429291436373116,
    "arrivals": 60894,
    "finished_requests": 57170,
    "scheduler_time": 51.47134026319933
}
#Debug simulation 
Total elapsed time: 8.301788000855595. Arrivals time: 0.15382433030754328 Scheduler time: 7.980490006972104 Scheduler overhead time: 0.0411891327239573 Adapter cache time: 0.06742972554638982 Engine time: 0.040498748887330294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40373969 . Total output tokens: 35593910
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.36809984408319,
    "estimated_duration": 3600.1000442964537,
    "input_throughput": 3733.807070527371,
    "output_throughput": 3263.466807988665,
    "total_throughput": 6997.273878516036,
    "itl": 129.7968820700537,
    "ttft": 537979.9787748548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.45735053613224,
    "arrivals": 60894,
    "finished_requests": 54472,
    "scheduler_time": 53.28170896310532
}
#Debug simulation 
Total elapsed time: 6.368188964203. Arrivals time: 0.15356237953528762 Scheduler time: 6.020950755104423 Scheduler overhead time: 0.04342144262045622 Adapter cache time: 0.08747860044240952 Engine time: 0.04304244602099061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40373969 . Total output tokens: 35593910
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.485200736671686,
    "estimated_duration": 3600.045524232665,
    "input_throughput": 3738.9854959873196,
    "output_throughput": 3264.6773272416053,
    "total_throughput": 7003.662823228925,
    "itl": 129.6340256454939,
    "ttft": 535474.4554845039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.82073232218709,
    "arrivals": 60894,
    "finished_requests": 54499,
    "scheduler_time": 53.242637054918625
}
#Debug simulation 
Total elapsed time: 6.4852873790077865. Arrivals time: 0.1524523594416678 Scheduler time: 6.138226804789156 Scheduler overhead time: 0.043667484540492296 Adapter cache time: 0.08755046594887972 Engine time: 0.04364990023896098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40373969 . Total output tokens: 35593910
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.418292087968439,
    "estimated_duration": 3600.118315154079,
    "input_throughput": 3741.3750940636883,
    "output_throughput": 3267.266786896303,
    "total_throughput": 7008.641880959992,
    "itl": 129.51035492350962,
    "ttft": 533587.7027574707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.150815760248992,
    "arrivals": 60894,
    "finished_requests": 54519,
    "scheduler_time": 53.21558231421374
}
#Debug simulation 
Total elapsed time: 6.418381715659052. Arrivals time: 0.15254072984680533 Scheduler time: 6.073410974349827 Scheduler overhead time: 0.04338962025940418 Adapter cache time: 0.08607109170407057 Engine time: 0.04326294269412756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39419020 . Total output tokens: 34744317
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.810003741178662,
    "estimated_duration": 3600.0463920978423,
    "input_throughput": 3920.938916505042,
    "output_throughput": 3423.370884067499,
    "total_throughput": 7344.3098005725415,
    "itl": 142.4619281101149,
    "ttft": 223156.86000743648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.708538851890744,
    "arrivals": 59412,
    "finished_requests": 56890,
    "scheduler_time": 49.51646252851464
}
#Debug simulation 
Total elapsed time: 7.810114782303572. Arrivals time: 0.14834972796961665 Scheduler time: 7.4970182199031115 Scheduler overhead time: 0.04096667701378465 Adapter cache time: 0.06530279153957963 Engine time: 0.040117009077221155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39419020 . Total output tokens: 34744317
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.1085042036138475,
    "estimated_duration": 3600.037057433779,
    "input_throughput": 3735.468214759444,
    "output_throughput": 3263.9414018632338,
    "total_throughput": 6999.409616622678,
    "itl": 128.95702028387743,
    "ttft": 446387.22181560344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.10149469184613,
    "arrivals": 59412,
    "finished_requests": 54215,
    "scheduler_time": 51.17567883247932
}
#Debug simulation 
Total elapsed time: 6.10859219962731. Arrivals time: 0.14721307205036283 Scheduler time: 5.775007807649672 Scheduler overhead time: 0.043487393762916327 Adapter cache time: 0.07983860233798623 Engine time: 0.04324028315022588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39419020 . Total output tokens: 34744317
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.150078147649765,
    "estimated_duration": 3600.0653728808875,
    "input_throughput": 3740.159859715275,
    "output_throughput": 3268.627033453966,
    "total_throughput": 7008.786893169241,
    "itl": 129.2259584812356,
    "ttft": 440745.64243228245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.499430822544607,
    "arrivals": 59412,
    "finished_requests": 54274,
    "scheduler_time": 51.10923720510961
}
#Debug simulation 
Total elapsed time: 6.1501922039315104. Arrivals time: 0.1479472517967224 Scheduler time: 5.814590037800372 Scheduler overhead time: 0.04345502844080329 Adapter cache time: 0.08112507266923785 Engine time: 0.0432542422786355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39419020 . Total output tokens: 34744317
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.166327666025609,
    "estimated_duration": 3600.052736946155,
    "input_throughput": 3745.8448487727514,
    "output_throughput": 3273.413991706271,
    "total_throughput": 7019.258840479022,
    "itl": 129.25756614698585,
    "ttft": 432490.5184576022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.852604221643293,
    "arrivals": 59412,
    "finished_requests": 54377,
    "scheduler_time": 51.033293906118494
}
#Debug simulation 
Total elapsed time: 6.166423175018281. Arrivals time: 0.15113254263997078 Scheduler time: 5.827514030504972 Scheduler overhead time: 0.04335490148514509 Adapter cache time: 0.0809534746222198 Engine time: 0.04368378361687064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.509629912208766,
    "estimated_duration": 3600.059767639351,
    "input_throughput": 3719.356028575074,
    "output_throughput": 3229.3602746554916,
    "total_throughput": 6948.716303230566,
    "itl": 125.67634436642969,
    "ttft": 97824.09539922044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.241598975455737,
    "arrivals": 55057,
    "finished_requests": 54059,
    "scheduler_time": 43.973097732942634
}
#Debug simulation 
Total elapsed time: 7.509724410250783. Arrivals time: 0.1412078239955008 Scheduler time: 7.179691886529326 Scheduler overhead time: 0.04460920300334692 Adapter cache time: 0.07994108414277434 Engine time: 0.044259585440158844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.818634004332125,
    "estimated_duration": 3600.0097858713525,
    "input_throughput": 3716.959340642797,
    "output_throughput": 3225.731787056587,
    "total_throughput": 6942.691127699384,
    "itl": 125.6686303184911,
    "ttft": 103604.99822630042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.094203839184747,
    "arrivals": 55057,
    "finished_requests": 54015,
    "scheduler_time": 44.13637821115229
}
#Debug simulation 
Total elapsed time: 6.818733184132725. Arrivals time: 0.14050434064120054 Scheduler time: 6.488348359707743 Scheduler overhead time: 0.044411573093384504 Adapter cache time: 0.08151257410645485 Engine time: 0.043908289168030024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.825766503345221,
    "estimated_duration": 3600.040590360362,
    "input_throughput": 3719.1450107121605,
    "output_throughput": 3226.3491781456128,
    "total_throughput": 6945.494188857773,
    "itl": 125.50494866614851,
    "ttft": 101746.36313050211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.402708210615426,
    "arrivals": 55057,
    "finished_requests": 54047,
    "scheduler_time": 44.15030608443085
}
#Debug simulation 
Total elapsed time: 6.825868313200772. Arrivals time: 0.14063487388193607 Scheduler time: 6.4941494087688625 Scheduler overhead time: 0.04441317683085799 Adapter cache time: 0.08226193394511938 Engine time: 0.04424667963758111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.8259598249569535,
    "estimated_duration": 3600.0911465013505,
    "input_throughput": 3716.4192392746636,
    "output_throughput": 3227.4927292582206,
    "total_throughput": 6943.911968532884,
    "itl": 125.39307108384196,
    "ttft": 102688.89897970049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.50831533292099,
    "arrivals": 55057,
    "finished_requests": 54024,
    "scheduler_time": 44.110524403488114
}
#Debug simulation 
Total elapsed time: 6.826046111993492. Arrivals time: 0.13795418478548527 Scheduler time: 6.498154344968498 Scheduler overhead time: 0.044249001890420914 Adapter cache time: 0.08202762622386217 Engine time: 0.04367627575993538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.260756454896182,
    "estimated_duration": 3600.0489126747257,
    "input_throughput": 3648.3007088483687,
    "output_throughput": 3141.9636994865464,
    "total_throughput": 6790.264408334915,
    "itl": 119.4976041583026,
    "ttft": 75452.91783118127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.848414370219192,
    "arrivals": 53529,
    "finished_requests": 52712,
    "scheduler_time": 41.836439776559516
}
#Debug simulation 
Total elapsed time: 6.2608406860381365. Arrivals time: 0.13414496183395386 Scheduler time: 5.931313085835427 Scheduler overhead time: 0.04607002669945359 Adapter cache time: 0.08278157655149698 Engine time: 0.045843788888305426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.1736372406594455,
    "estimated_duration": 3600.133548357862,
    "input_throughput": 3647.512189093574,
    "output_throughput": 3141.3681876214177,
    "total_throughput": 6788.880376714991,
    "itl": 119.72071076725805,
    "ttft": 76301.78260318447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.048864358634646,
    "arrivals": 53529,
    "finished_requests": 52703,
    "scheduler_time": 41.85196231890713
}
#Debug simulation 
Total elapsed time: 6.173736548982561. Arrivals time: 0.1343923988752067 Scheduler time: 5.844169582705945 Scheduler overhead time: 0.046107036992907524 Adapter cache time: 0.08332618279382586 Engine time: 0.04498079884797335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.19134828587994,
    "estimated_duration": 3600.0112540621294,
    "input_throughput": 3647.70498569485,
    "output_throughput": 3141.405457341058,
    "total_throughput": 6789.110443035908,
    "itl": 119.5517835615219,
    "ttft": 76304.31440071386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.94460469389893,
    "arrivals": 53529,
    "finished_requests": 52700,
    "scheduler_time": 41.841608463168654
}
#Debug simulation 
Total elapsed time: 6.191431517247111. Arrivals time: 0.13442243169993162 Scheduler time: 5.861037962604314 Scheduler overhead time: 0.04625687003135681 Adapter cache time: 0.08351050782948732 Engine time: 0.04542705416679382 
